[
    {
        "id": 1,
        "title": "Sector Rotation by Factor Model and Fundamental Analysis",
        "corpus": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on. Authors: achieve the best HTML results from your LaTeX submissions by selecting from this list of supported packages. This study presents an analytical approach to sector rotation, leveraging both factor models and fundamental metrics. We initiate with a systematic classification of sectors, followed by an empirical investigation into their returns. Through factor analysis, the paper underscores the significance of momentum and short-term reversion in dictating sectoral shifts. A subsequent in-depth fundamental analysis evaluates metrics such as PE, PB, EV-to-EBITDA, Dividend Yield, among others. Our primary contribution lies in developing a predictive framework based on these fundamental indicators. The constructed models, post rigorous training, exhibit noteworthy predictive capabilities. The findings furnish a nuanced understanding of sector rotation strategies, with implications for asset management and portfolio construction in the financial domain. Keywords: US Industrial Sectors, Factor Analysis, Fundamental Analysis, Trading Strategy. Sector is composed by a basket of stocks that representing companies in certain business class, which has unique features according to the business. Under certain conditions, such as economic cycles, sectors may behave accordingly due to the different characteristics of businesses. In this report, we are exploring how to capture returns by finding the hidden features behind different sectors and determining the leading sectors in some particular market conditions or social environments. Generally, this report covers a brief exploration of market and fundamental factors, explaining the meaning of each factors and how they are related to some sectors.Then we applied a neural network model to do a classification and prediction using the fundamental factors as inputs. At the end of the report, we also covers how sectors behaved under global events. There are many different ways to divide sectors. For the purpose of common acceptance and convenience for future data acquirement, we used the MSCI Global Industry Classification Standard, which includes 11 level one sectors, 24 level two industry groups, 69 level three industries, and 158 sub-industries. We use the 11 level one sectors as our main target. They are Energy, Materials, Industrials, Consumer Discretionary, Consumer Staples, Health Care, Financials, Information Technology, Communication Services, Utilities, and Real Estate. In order to track the performance of each sector, we use the S&\\&&P500 GICS Indices which are constructed exactly as the MSCI classification.Before working on any strategies further, we need to determine if there are actually possible profits. In our case, we need to check how big the differences between sectors\u2019 returns are. For each observation time period,\nDefine: Return Difference =(\u2211top 3subscripttop 3\\sum_{\\text{top 3}}\u2211 start_POSTSUBSCRIPT top 3 end_POSTSUBSCRIPT Sector Return - \u2211bottom 3subscriptbottom 3\\sum_{\\text{bottom 3}}\u2211 start_POSTSUBSCRIPT bottom 3 end_POSTSUBSCRIPT Sector Return )/3\nBased on a monthly frequency, we calculate the return difference and get the following plot. Also, by calculation, the quarterly return difference has a mean of 0.1306, median of 0.1185, standard deviation of 0.0523. We can reach to a result that half of the quarterly return difference is more than 11.85%percent\\%%. It is easy to see that there does exist potential investment opportunity by capturing the return differences between sectors. Momentum premium was first recognized by UCLA scholars Narasimhan Jegadeesh and Sheridan Titman in 1993. The momentum premium is established on the observation that assets that have performed well in the past have the trend to persist good performance in the future. Though the momentum effect is considered to be a market anomaly, it has been recognized widely among many asset classes. We will explore the momentum effect based on the sector indices introduced above. First of all, we need to construct the momentum factor. Typically, the momentum factor is constructed by the past 6 or 12 months cumulative return and excludes the most recent month\u2019s return, considering that there are also short-term reversion effects based on the mean-reversion effects. However, without a clear idea of how the sector indices carry the momentum effect, we need to explore through time intervals to find the best possible momentum factor. Then we constructed 12 different momentum factors using the past 1 to 12 month\u2019s return and excluding the most recent 0.1 portion trading days of each time period to avoid short-term reversion. For each of the factors with the period of n months where Rdsubscript\ud835\udc45\ud835\udc51R_{d}italic_R start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT is the daily return. For the 12 factors we got, we normalized them cross sections. Then we rank the factor exposures for each sector and take long positions of sectors with the highest two factor exposures, take short position of sectors with the lowest two factor exposures. Then we trade our portfolio under a monthly frequency. Here are the results from 2002 to 2022 February: Since there are several market crashes where the momentum factor led to negative returns, we also take a look at the most recent five years from 2017 to 2022 February: From this table, we can tell that by using the MOM__\\__7M factor, we can reach a maximum annual return rate of 21.19%percent\\%% and a maximum Sharpe ratio of 0.62. It is also interesting that we find the momentum factor with a short time period, for example, MOM__\\__1M and MOM__\\__2M, have a very small even negative return rate. However, it exactly conforms to the short term reversion effect that the typical momentum factor would exclude. Short term reversion factor follows the simple principle that asset\u2019s price will have the trend to stay on an average level. Since we can see from the previous results of the momentum factor that there does exist short term reversion effect, we can try different reversion factors and find out what would be the best short term reversion observation period. Similarly, we can define several reversion factors with different time periods. And we take the negative number of the past n days cumulative return as the factor exposures. For the purpose of exploring the optimal time period, we take 5-day time interval and create 12 reversion factors from 5 trade days to 55 trade days. By using the same method, we compute the rank of each sector\u2019s factor exposure, and long the top two sectors, short the last two sectors on a monthly observation frequency. Between 2002 and 2022 February, the results are: From this table, we can tell that for the time between 2002 to recent time, the short term reversion effect is optimal for taking the past 30 days cumulative return. It has an optimal annual return rate of 8.77%percent\\%% on average and leads to a sharp ratio of 0.8735. Fundamental Analysis are always a good aspect to look at for investing. We collected quarterly data for all 11 indices from Bloomberg, including their P/E ratio, EV/EBIT, Profit Margin, etc. Our fundamental analysis would start from discovering features for each of the fundamental ratio,then we are trying to predict the sector performance by constructing using some of the features we found. The P/E is one of the most widely used tools to determine a stock\u2019s relative valuation. The purpose of analyzing the ratio is to show whether certain sector is worth to be invested because P/E ratio can reflect the investment risk in this sector. The figure below shows distribution of P/E ratios in different sectors. By comparing cross-sectional data, it is obvious that P/E of Real Estate Sector and Consumer Discretionary Sector are higher than others. The reason is that earning growth in the future is expected to grow fast in the two sectors or these sectors have some special advantages that guarantee long-term profitability with low risk. On the other hand, Financials Sector\u2019s ratio is relatively low compared with other sectors, which may result from its high volatility so investors are reluctant to pay for it.\nWe also notice that the ratio in Energy Sector surged in 2015, which is related to some changes in the sector. The end of the oil age and emergence of alternative energy have reduced the earnings of the original sector. As a result, its relative price becomes higher than before. The change in EV/EBIT and EV/EBITDA is also due to this reason. The P/B ratio provides a valuable reality check for investors who are seeking growth at a reasonable price. For those sectors with more assets, their book value and market value are close, so P/B ratio is more useful when we analyze Real Estate sector and Financials sector. The figure below shows distribution of P/B ratio in different sectors. As the picture shows, Consumer Discretionary sector and IT sector have higher P/B ratio while Financials sector and Energy sector have relatively low ratios. What\u2019s more, Real Estate sector with high P/E ratio has relatively lower P/B ratio. EV/Sales can help investors better understand cost relative to unit sales and whether the company is overvalued or undervalued. If EV/Sales is relatively high, the company or sector is less attractive to investors. The figure below shows distribution of EV/Sales in different sectors. The result shows that Real Estate sector\u2019s ratio is higher than others\u2019, which means that index in this sector is overvalued. On the other hand, ratio in Energy sector is low, which can attract more investors. EV/EBIT and EV/EBITDA are independent of the capital structure of the company, whereas multiples like P/E ratio are impacted by financing decisions. Because of this reason, the two are the most commonly relied-upon multiples in relative valuation. However, one obvious distinction is that EV/EBIT considers depreciation and amortization. In some capital-intensive industries which have significant differences in D&\\&&A, EV/EBIT may make it a more accurate measure of value. But in our analysis, there is no such difference in the comparison of these two ratios under different sectors. The results can show that Real Estate sector has a higher ratio. The three ratio EV/Sales, EV/EBIT and EV/EBITDA can give a consensus conclusion that Real Estate sector is overvalued in the market. Dividend Yield is used to measure the amount of cash flow investors are getting back for each dollar. It is essentially the return on investment for a stock without any capital gains. The figure below shows distribution of Dividend yield in different sectors. The ratio in Communication Services sector is higher before 2018 while Energy sector\u2019s ratio is higher after that time. This is because communication services sector took place a reorganization of S&\\&&P500 index in 2018. It now includes at least eighteen companies from IT and Consumer Discretionary sectors. Due to this reshuffling, dividend yield of this sector is impacted. Gross margin equals net sales less the cost of goods sold (COGS). Net sales are equivalent to the total revenue from sales, and COGS is the direct cost associated with producing goods. By calculating gross margin, we could measure one company\u2019s retain revenue after subtracting the production cost. The higher the gross margin, the more capital a company retains, which it can then use to pay other costs or satisfy debt obligations. Generally, companies with good gross margins would have a relatively sustainable competitive advantage. By analyzing gross margin data across sectors, we may observe some sectors that have more stable development in the long run. For our 11 sectors\u2019 gross margin data, the line chart above shows significant differences between the sectors. Overall, each industry index is relatively flat on its own, and have gaps between each others. Utilities, Communication Services and Information Technology(IT) have been among the top spears for last 10 years, occupying the first, second and third positions respectively, all above 40%percent\\%%. On the contrary, the energy sector has been an under-performer for the past decade, ranking at the bottom, with gross margins consistently below 20%percent\\%%. Gross margins in the rest industries are concentrated in the 25%percent\\%%-35%percent\\%% range and have not fluctuate much.\nAt the same time, by observing the comparison of fluctuations between industries, it is not difficult to see that the gross margin fluctuations of the energy industry and the utilities industry maybe relatively high in the past decade, and their peaks correspond to each other. During 2016, the utilities industry grew significantly, while energy declined comparatively. The trend was even more pronounced in 2020, with utilities reaching its highest level and the energy industry fell to the bottom.\nGenerally, the gross margin feature maybe a significant indicator for Utilities, Communication Services and IT sectors. And our conjecture about the correlation between utilities and energy sectors will need further observation and verification. Operating margin equals operating income divided by revenue, it is a profitability ratio measuring revenue after covering operating and non-operating expenses of a business. And profit margin measures the profit ratio after paying for variable costs of production. It is calculated by the formula: Both operating margin and profit margin are used to gauge the degree of the company\u2019s activity makes money. Higher ratios are generally better, illustrating the company is efficient in its operations and is good at turning sales into profits. In our analysis, there is not a very big difference in the comparison of these two ratios under different sectors, which is determined by their definition. For these two ratios, Real Estate sector, IT sector and Financial sector have the top three high ratios.And Energy sector has the relatively lowest ratio. Also, both operating margin and profit margin for almost all sectors have similar trends in the last decade curves. This is attributed to the definition difference between the two features, and that\u2019s why the operating margin was slightly higher than the profit margin.\nAnother thing that is worth to mentioning is that for Energy Sector, not just operating margin and profit margin, but also the gross margin, it always has the relatively lowest ratios and similar curve fluctuation, with sharp declines in 2016 and 2020. The two time nodes may consistent with some big revolution in the energy industry, which we will analyze later. Return on equity (ROE) and return on assets (ROA) are two of the most important measures for evaluating how effectively a company\u2019s management team is doing its job of managing the capital entrusted to it. ROE equals to generally net income divided by equity, while Return on Assets (ROA) is net income divided by average assets. So the primary differentiator between ROE and ROA is financial leverage or debt. ROE measures profitability and ROA is an efficiency measure of how well a company is using its assets.\nInvestors may prefer to observe ROE, since equity represents the owner\u2019s interest in the business. Compared to other sources of fund, equity capital tends to be the most expensive source of funding and carries the largest risk premium of all financing options. Therefore, in our analysis, ROE may be a better feature that it could reflect the trend of market investment. As shown in the picture, IT sector has the highest ROA, the Consumer Staples sector and Consumer Discretionary sector also have a relatively higher ratio. In contrast, Financial sector has a lower ROA.\nThe past ten years, or even twenty years, has been an era of rapid development of information technology. And compared with traditional industry and commerce, information technology is more flexible in the time and form of investment assets, that\u2019s the reason why IT will have the highest ratio. Also for the the Consumer Staples sector and Consumer Discretionary sector,they are all industries with fast innovation and short production cycle. Generally, these three will have constantly higher ratio for the long run. Therefore, for these three industries, if the ROA indicator fluctuates significantly, it may have an impact on the investment trend. For ROE ratio, similarly, IT, Consumer Staples stay high, and Consumer Discretionary sectors is also at a slightly higher level, except that the IT sector lost its prominence in ROA ratio.\nBy comparing cross-sectional data, the Consumer Discretionary Sector and Industrials Sector have similar patterns in the last decade for both ROA and ROE ratios. They both have a low peak in 2020. It is conceivable that this is affected by the general environment of the epidemic.\nAnd as we mentioned before, the ROE and ROA curves of the energy sector still have a similar pattern, falling sharply in 2016 and 2020. In 2016, it was affected by changes in energy policy since 2015, reducing oil production while encouraging the development of clean and new energy. For 2020, we attribute this decline to the outbreak of the COVID-19 pandemic. Having these fundamental data, next step is to find out what quantitative relationships they have to futures sector returns. For fundamental factors, they are usually exposed in the company report with annual, semi-annual, or quarterly frequency. Our fundamental factors for each sector are reported quarterly, leading to a problem that the sample size for each individual sector is very small. To have a better performance of the prediction model, we need to combine all the sectors together and make a uniformed and comparable large sample. We neutralized each factor cross-sectional for the factor to have a mean of 0 and standard deviation of 1. If Xi,tsubscript\ud835\udc4b\ud835\udc56\ud835\udc61X_{i,t}italic_X start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT denotes one specific factor exposure for i\ud835\udc56iitalic_i-th sector at time t\ud835\udc61titalic_t, in this case would be at t\ud835\udc61titalic_t-th quarter, then for each individual t\ud835\udc61titalic_t we have the neutralized exposure to be: Then we used the next quarter\u2019s cross-sectional normalized return as the corresponding return. First, we want to have a general view of the relations. The scatter plots between neutralized factors and future returns are as following: From the scatter plots, the relations between all factors and their future returns cannot be well interpreted by simple linear models. However, it is very common in the financial field that the sample will have a very low signal-noise ratio. As we observed before, the relations between each factor and its future return cannot be interpreted very well by linear models. Also, we have no idea what model would exactly best fit the data. Therefore, converting prediction of future returns to a classification problem and fitting the training sample with a neural network model which has comparably good performance with non-linear relations would be a great start point. [height=10]\n\n\n\n\n\\inputlayer[count=10, bias=false, title=Input layer, text=x\\hiddenlayersubscript\ud835\udc65\\hiddenlayerx_{\\hiddenlayer}italic_x start_POSTSUBSCRIPT end_POSTSUBSCRIPT[count=5, bias=false, title=Hidden layer 1, text=h\\linklayers(1)subscriptsuperscript\u210e1\\linklayersh^{(1)}_{\\linklayers}italic_h start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT end_POSTSUBSCRIPT\\hiddenlayer[count=5, bias=false, title=Hidden layer 2, text=h\\linklayers(2)subscriptsuperscript\u210e2\\linklayersh^{(2)}_{\\linklayers}italic_h start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT end_POSTSUBSCRIPT\\outputlayer[count=2, title=Output layer, text=y^\\linklayerssubscript^\ud835\udc66\\linklayers\\hat{y}_{\\linklayers}over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT end_POSTSUBSCRIPT Neural network takes a vector as the input, and goes to each of the neuron in the first hidden layer and gains new activation vectors which act as the input for next hidden layer. After the last hidden layer, neural network model would pass out the probability for each of the prediction class and we choose the one with the highest probability as the prediction. This process is called front propagation. After comparing the prediction to the actual results, we adjust the weights of the nodes by using back propagation for each training pair in the training samples. Also, we use the rectified linear unit function as the activation function for hidden layers and sigmoid function as the activation function for final output. Since we only have a sample of size 200, choosing quasi-Newton methods as the solver has better performance for small sample training.\nThen we need to construct the training, validation, and test sets. Since the fundamental factors are already neutralized (normalized) within each sector, we divide the sample data to 60%percent\\%%, 20%percent\\%%, 20%percent\\%% by convention. Without shuffling, we will have the historical data divided where test set contains the most recent data. For the corresponding output value, we assign 1 to samples with positive future return and 0 with negative returns.\nThe complexity of neural network directly related to the number and sizes of hidden layers. For the purpose of avoiding overfitting or under-fitting, we need to find proper hyper parameters for neural network model. We start from a simple model with two layers. Let N\ud835\udc41Nitalic_N denote the number of nodes in each hidden layer, alpha is the hyper parameter for L2 regularization penalty function. With larger N\ud835\udc41Nitalic_N, the model is more complex. If alpha increases, the penalty for large weights increases, which makes the model tend to be more simple. Considering our sample size is small, intuitively we need to focus more on the overfitting problem. For a range of alpha and N\ud835\udc41Nitalic_N, we train the model using the training set data, and get the score for prediction on validation set. The score represents the probability of making a right prediction. Here are the results: To better understand how the hyperparameters influence model performance, we visualize the data by using N\ud835\udc41Nitalic_N and alpha as the bottom coordinates, and use the corresponding probability as the height. From the figure, we can tell that the model have several local optimal pairs. And the scores at the optimal points with relative large N values are also combined with small alpha values. For example, the combination of 14 nodes and alpha equals 0.01 has a local optimal score of 0.6. Since we are training with a small sample, using such a complex model with a high score is highly likely overfitting. Therefore, we start from the simple model by looking at models with 5 nodes model and check how the score varies with alpha. For model with 5 nodes, we see there are two local peaks with alpha equal to 1 and 0.25, then we pick the middle value 0.5 as the value of alpha considering the trade-off between variance and bias. Constructed and trained the model, next we would test the model by feeding a new data set to the model. On the test set, the score of the model is 0.64, which means the model predicts 64%percent\\%% of the results correctly. More detailed results are showed in the following table: On the test set, we have a 0.59 winning rates on the positive predictions and 0.72 on the negative predictions, which gives an overall winning rate of 0.64. By using the predictions from the trained model, we used the data from validation set to get trade signals. Instead of having signals of 1 or 0 as the model\u2019s output, we choose the probability of the prediction output being 1, which is given by the activation sigmoid function. Then we will have a time series of the probability for each sector, and rank the probability from highest to lowest where the highest probability will have a rank 1. For each cross-sectional ranking, we equally-weighted long sectors with rank 1 to 3 and short sectors with rank 9 to 11 to construct a dollar-neutral portfolio. On the test set, which is from September in 2020 to September in 2021, we have a Sharpe ratio of 2.21. The cumulative return plot is following: There are still issues that need to be considered carefully in the future. First is the factor neutralization. In previous model, we neutralized the factor exposure cross-sectionally, where the exposures reflect the relative level of factor exposure for one sector compared to other sectors at a given time. However, different sectors may have inner trends of higher exposures than others for some factors, especially for fundamental factor. What\u2019s more, we only have quarterly fundamental data available from 2017 and it is hard to implement time series normalization for each sector. Therefore, how to modify the factor exposures to make them comparable is a difficult problem. Secondly, as the sample size is small, the model might not be applicable on a wider range of time since we only trained and tested on the most recent five years. One possible way to improve this model is to use daily factors such as volume, close price as input, and convert fundamental factors to daily frequency by the corresponding quarter. Then we would have a sample size of approximately 1250 for each sector and over 13000 samples for training. However, the model might depends more on the daily factors rather than fundamental factors since their exposures would be the same value for each quarter. 1. Returns to Buying Winners and Selling Losers: Implications for Stock Market Efficiency Narasimhan Jegadeesh; Sheridan Titman\nThe Journal of Finance, Vol. 48, No. 1. (Mar., 1993), pp. 65-91.\n2.The Global Industry Classification Standard, MSCI (1999)"
    },
    {
        "id": 2,
        "title": "Prompt emission of relativistic protons up to GeV energies from M6.4-class solar flare on July 17, 2023",
        "corpus": "We show evidence of particle acceleration at GEV energies associated directly with protons from the prompt emission of a long-duration M6-class solar flare on July 17, 2023, rather than from protons acceleration by shocks from its associated Coronal Mass Ejection (CME), which erupted with a speed of 1342 km/s. Solar Energetic Particles (SEP) accelerated by the blast have reached Earth, up to an almost S3 (strong) category of a radiation storm on the NOAA scale.\nAlso, we show a temporal correlation between the fast rising of GOES-16 proton and muon excess at ground level in the count rate of the New-Tupi muon detector at the central SAA region.\nA Monte Carlo spectral analysis based on muon excess at New-Tupi is consistent with the acceleration of electrons and protons (ions) up to relativistic energies (GeV energy range) in the impulsive phase of the flare. In addition, we present another two marginal particle excesses (with low confidence) at ground-level detectors in correlation with the solar flare prompt emission. Since 1950 the observation of solar energetic particles from the solar\nflares and coronal mass ejections (CMEs) have been done with ground-level experiments, such as the neutron monitors (NMs) (Meyer et\u00a0al., 1956; Simpson, 2000; Moraal et\u00a0al., 2000)\nas well as the solar neutron telescope network (Hu & Semones, 2022; Vald\u00e9s-Galicia et\u00a0al., 2009), all around the world.\nThese observations have yielded a lot of new information. For instance, the existence of a prompt and gradual emission of solar energetic particles (SEP) in flares and CMEs, respectively, the correlations of the cosmic ray intensity with CMEs and other solar disturbances crossing the Earth, etc.\n(Chupp et\u00a0al., 1987; Moraal et\u00a0al., 2000) Also, the solar modulation of galactic cosmic rays is inversely correlated with solar activity, inferred through the number of sunspots, which can be the key to understanding more about space weather (Cade\u00a0III & Chan-Park, 2015). Nowadays, particles accelerated to near the Sun can be detected by space-borne instruments such as the High-Energy Proton\nand Alpha Detector (HEPAD) on the Geostationary Operations Environmental Satellite (GOES) and the Advanced Composition Explorer (ACE) spacecraft at Lagrange L1 point, through the Electron Proton Alpha Monitor (EPAM) and the Solar Isotope Spectrometer (SIS), among others. Not all of the solar energetic particles can be measured at ground level. Even those SEPs from solar events with a good geoeffectiveness can be dissipated by the IMF, or deflected or captured by the Earth\u2019s magnetic field or until absorbed by atmosphere. On the other hand, ground-level enhancements (GLEs), typically in the MeV-GeV energy range, are sudden increases in cosmic ray intensities registered in most cases by NMs. GLEs are quite rare events, and fewer than 100 GLEs have been observed by NMs in the last 70 years. In most cases, the NMs that observed GLEs are located at regions with small geomagnetic rigidity cutoff, that is, at high latitudes (Shea & Smart, 2012). The GLEs follow the solar radiation storms, solar energetic particles (mostly protons) observed by GOES. They occur when a large-scale magnetic eruption, a coronal mass ejection and associated solar flare, accelerates charged particles in the solar atmosphere to high energies. However, in the present case, despite a radiation storm reaching above the S2-class on the NOAA scale on July 18, 2023, it did not generate a GLE, only a prompt emission of relativistic protons (ions) above GeV energies, during the phase eruptive, and observed by ground-level detectors strategically located, within the SAA central region (New-Tupi muon detector) and by the (Yangbagin muon telescope) at the Yangbajing Cosmic Ray Observatory (Tibet 4440 m a.s.l) (Zhang et\u00a0al., 2010). Also, we looked for any signal in the counting rate at the Neutron Monitor\u2019s (NM) network around the world from Neutron Monitor Data Base (NMDB)\nhttps://www.nmdb.eu/nest/, with negative results. However, we found a low confidence signal only at Kerguelen NM, at geographical coordinates (49.3S, 70.3E), altitude of 33 m a.s.l, and an effective vertical cutoff rigidity of 1.14 GV.\nWe present details of these observations. The New-Tupi muon detector is completely\nunmoderated (without no surrounding lead or other material). The muon detection energy threshold is about 200 MeV (see Appendix A). That contrasts with other muon detectors that have, in most cases, a surrounding lead material with a thickness of up to 5 cm. The shielding effect of the Earth\u2019s magnetic field on cosmic ray particles is quantified by the magnetic rigidity cutoff from a specific location (Smart & Shea, 2009). The smaller the rigidity cutoff, the lower the energy cosmic ray particles penetrate the magnetosphere.\nOn the other hand, a restricted area between latitudes 20 and 40 of the southern hemisphere, over South America\nand the Atlantic Ocean poses a geomagnetic field\nwith an anomalously lower intensity (around 22,000\nnT). The region is known as the South Atlantic Anomaly\n(SAA) (Pav\u00f3n-Carrasco & De\u00a0Santis, 2016). According to Swarm\u2019s satellite observations\n(Finlay et\u00a0al., 2020), the SAA appears splitting into two, a smaller area\nover the Atlantic Ocean in southwest Africa and a larger\narea over eastern South America. Fig.\u00a01 (top panel) summarizes\nthe situation. We would like to point out that\nthe location of the New-Tupi telescope coincides with the central\npart of the SAA indicated by the arrow on the left\nof Fig.\u00a01 (top panel). The main effect of the SAA is on the satellites since\nthe \u201970s. We know the frequent failures when they pass\nthrough the SAA region. A large amount of charged\nparticles precipitation in this region damages and perturbates\nthe satellites\u2019 electronics. Also, according to\nthe results from the PAMELA detector at satellite\u2019s altitudes\n(Casolino et\u00a0al., 2009), the effect of geomagnetic cutoff on low-energy\nparticles is present in high latitudes close to the poles\nand also in the SAA region, composed mostly of low energy\ncosmic protons (E <<< 200 MeV ). In other words, the\nPamella satellite has shown that the SAA introduces a\nsub-cutoff in the magnetic rigidity, below the Stormer\u2019s\nmagnetic rigidity cutoff.\nWe show that the SAA also affects secondary cosmic\nrays detected at ground level. As the horizontal magnetic\ncomponent on Earth\u2019s surface is smaller on the\nSAA, the magnetic lateral dispersion of the secondary\nparticles forming an air shower is smaller too. The effect\nincreases the number of particles reaching a detector. In\nother words, this behavior mimics a magnetic rigidity\nsub-cutoff below the Stormer\u2019s rigidity cutoff.\nWe show that effect through a Monte Carlo simulation\nbased on CORSIKA-Fluka code (Heck et\u00a0al., 2012; Battistoni et\u00a0al., 2008), where 1.0\u00d71061.0superscript1061.0\\times 10^{6}1.0 \u00d7 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT proton\nair-showers are simulated, taking into account the magnetic\ncoordinates (latitude, longitude) and height of several\nplaces where detectors are installed (mostly neutron\nmonitors). Fig.\u00a01 bottom left panel shows the lateral particle distribution\nin air-showers of cosmic rays, as detected from\nseveral ground-level detectors. In all cases, there is a fast\nrise of particles with the shower lateral development until\nreach um maximum value that happens for different\nvalues of R, called hereafter as Rm\u2062a\u2062xsubscript\ud835\udc45\ud835\udc5a\ud835\udc4e\ud835\udc65R_{max}italic_R start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT\nWe can see that the number of shower particles at\nRm\u2062a\u2062xsubscript\ud835\udc45\ud835\udc5a\ud835\udc4e\ud835\udc65R_{max}italic_R start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT in the SAA central region (SAA-CR) rigidity 9.6\nGV is higher than at Rome and Athens, both with the\nrigidity of 6.3 GV, and 8.5 GV, respectively, i.e., minors\nthan the SAA-CR.\nAlready Fig. 1 bottom right panel, shows a correlation\nbetween Rm\u2062a\u2062xsubscript\ud835\udc45\ud835\udc5a\ud835\udc4e\ud835\udc65R_{max}italic_R start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT versus the geomagnetic Stormer rigidity\ncutoff of six different places (black circles), including the\nSAA-CR (blue square). The solid red line is a linear fit, and the two dotted red lines delimit the region with significance of \u00b11\u2062\u03c3plus-or-minus1\ud835\udf0e\\pm 1\\sigma\u00b1 1 italic_\u03c3.\nOnly two places are out from the \u00b11.0\u2062\u03c3plus-or-minus1.0\ud835\udf0e\\pm 1.0\\sigma\u00b1 1.0 italic_\u03c3 significance region, the Thule (Groenlandia) in the lowest rigidity region\nand SAA-CR in the highest rigidity region. The\nhigh Stormer\u2019s rigidity of SAA-CR does not correspond\nto the high value of Rm\u2062a\u2062xsubscript\ud835\udc45\ud835\udc5a\ud835\udc4e\ud835\udc65R_{max}italic_R start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT expected by the correlation.\nFrom an interpolation, it is possible to see that the small\nvalue of Rm\u2062a\u2062xsubscript\ud835\udc45\ud835\udc5a\ud835\udc4e\ud835\udc65R_{max}italic_R start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT at SAA-CR correspond to the rigidity of\nonly 3.1\u22121.7+3.0subscriptsuperscript3.13.01.73.1^{+3.0}_{-1.7}3.1 start_POSTSUPERSCRIPT + 3.0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 1.7 end_POSTSUBSCRIPT GV, within a confidence of \u00b11.0\u2062\u03c3plus-or-minus1.0\ud835\udf0e\\pm 1.0\\sigma\u00b1 1.0 italic_\u03c3.\nThis behavior of having a location close to the Equator,\nwith a nominal lower magnetic rigidity cutoff, favors the\nobservation of phenomena such as the SEPs. On July 17, 2023, at \u223csimilar-to\\sim\u223c18h UT, the active region AR 13363 had an explosion, reaching an M6-class solar flare followed by a resplendent coronal mass ejection. Fig.\u00a02 left panel shows the image from the Solar Dynamo observatory of the blaze of fire responsible for the X-ray flux reaching M6-class flare. Already the right panel shows the LASCO-C2 coronograph image of its associated CME on July 18, 2023, at 00:42 UT. NOAA prediction models confirmed that a CME originated in the powerful M6-class flare from sunspot AR3363 would pass through the magnetosphere on July 20, triggering at least a G1-class (minor) geomagnetic storm. However, no magnetic storms were observed. Fig.\u00a03 shows the GOES-18 X-ray flux (upper panel) and the GOES-16 proton flux (bottom panel). The X-ray flux peaks at 18:00 UT, while the proton flux has two peaks. The first (in orange) is due to the acceleration of protons during the impulsive fast-rising phase of the flare peaking at 18:09 UT. The delay between the X-ray and proton flux peaks is because the proton velocity is slightly less than c, and the proton path is longer. The second peak are the protons accelerated by CME shocks, peaking at 18:14 UT, and it\u2019s the so-called gradual phase and is characterized by its long duration, up to several days. Fig.\u00a04 shows the temporal coincidence between the GOES proton flux in the impulsive phase and New-Tupi muon excess. Particles (mostly proton) are accelerated in this phase exclusively by the flare, during the fast-rising until to reach the first peak (orange sector) in Fig.\u00a04. However, in the so-called gradual phase, protons accelerated by CME\u2019s shocks, the proton flux does not reach the GeV energy range because there are no excess muons at ground level. We perform a Monte Carlo simulation of air showers initiated by SEP (protons) using the CORSIKA code (Heck et\u00a0al., 2012), together with the FLUKA interaction model (Battistoni et\u00a0al., 2008), that works well at GeV and sub-GeV energies, including secondary particle decay. The surviving particles are tracked through the atmosphere until they reach ground level (sea level). Most particles are muons with a small contribution of electrons and nucleons. The aim is to obtain the yield function, S\u03bc\u2062(EP)subscript\ud835\udc46\ud835\udf07subscript\ud835\udc38\ud835\udc43S_{\\mu}(E_{P})italic_S start_POSTSUBSCRIPT italic_\u03bc end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ), that is, the number of muons at sea level per primary proton, for an estimate of the upper limit of the integral proton flux in the GeV energy range, associated with the impulsive phase of M-6-class flare with onset on July 17, 2023, at \u223csimilar-to\\sim\u223c 18 UT. Fig.\u00a06 (black squares) shows the Monte Carlo output under the New-Tupi geomagnetic conditions and vertical proton incidence, and fitting as where A\u03bc=(6.8\u00b11.4)\u00d710\u22123subscript\ud835\udc34\ud835\udf07plus-or-minus6.81.4superscript103A_{\\mu}=(6.8\\pm 1.4)\\times 10^{-3}italic_A start_POSTSUBSCRIPT italic_\u03bc end_POSTSUBSCRIPT = ( 6.8 \u00b1 1.4 ) \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, \u03bd=1.18\u00b10.24\ud835\udf08plus-or-minus1.180.24\\nu=1.18\\pm 0.24italic_\u03bd = 1.18 \u00b1 0.24, and E0=10.2\u00b12.1subscript\ud835\udc380plus-or-minus10.22.1E_{0}=10.2\\pm 2.1italic_E start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 10.2 \u00b1 2.1 GeV. Fig.\u00a06 shows the fits (red dot line). In addition, we assume here that the energy spectrum of solar protons in the GeV energy range, which is in the high-energy tail of the SEP spectrum, can be fitted by a single power-law function. There are two unknown quantities in the above power-law function: the coefficient APsubscript\ud835\udc34\ud835\udc43A_{P}italic_A start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT and the spectral index \u03b2\ud835\udefd\\betaitalic_\u03b2. A convolution between the yield function S\u03bc\u2062(EP)subscript\ud835\udc46\ud835\udf07subscript\ud835\udc38\ud835\udc43S_{\\mu}(E_{P})italic_S start_POSTSUBSCRIPT italic_\u03bc end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ) and the proton spectrum JP\u2062(EP)subscript\ud835\udc3d\ud835\udc43subscript\ud835\udc38\ud835\udc43J_{P}(E_{P})italic_J start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ) gives the response function (Augusto et\u00a0al., 2016b), which is the number of muons in the excess signal at New-Tupi detector generated by the SEP during the period T. We express this convolution as where F\u2062(\u03b8)\u223cexp\u2061(\u03b8/C)similar-to\ud835\udc39\ud835\udf03\ud835\udf03\ud835\udc36F(\\theta)\\sim\\exp(\\theta/C)italic_F ( italic_\u03b8 ) \u223c roman_exp ( italic_\u03b8 / italic_C ) is the pitch angle distribution (Shea & Smart, 1982; Miroshnichenko et\u00a0al., 2005). In the central region of SAA (New-Tupi), the transverse geomagnetic component is only B\u27c2=18.3subscript\ud835\udc35perpendicular-to18.3B_{\\perp}=18.3italic_B start_POSTSUBSCRIPT \u27c2 end_POSTSUBSCRIPT = 18.3 mT, that is, almost 80% smaller than the transverse component, at the same latitude, but outside from the SAA region, favoring the focusing factor of the geomagnetic parallel geomagnetic on the incident solar protons (small pitch angles).\nFor the present event, we found exp\u2061(\u03b8/C)\u223c1similar-to\ud835\udf03\ud835\udc361\\exp(\\theta/C)\\sim 1roman_exp ( italic_\u03b8 / italic_C ) \u223c 1. The muon excess associated with protons emitted during the impulsive phase (see Fig.\u00a04), and considering an effective angular aperture of 60 degrees around the zenith of the New-Tupi detector, the counting rate excess is Furthermore, we also obtain the integrated time primary\nfluence as For the present case, the GOES-proton fluence in the high-energy region (Ep\u2265\\geq\u226550) MeV is The terms on the left side of Eq.\u00a01 and Eq.\u00a05 are known. Thus, we can consider all possible values of \u03b2\ud835\udefd\\betaitalic_\u03b2 and APsubscript\ud835\udc34\ud835\udc43A_{P}italic_A start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT compatible with the observed muon counting rate excess, J\u03bcsubscript\ud835\udc3d\ud835\udf07J_{\\mu}italic_J start_POSTSUBSCRIPT italic_\u03bc end_POSTSUBSCRIPT, and the integrated GOES-proton fluence F\ud835\udc39Fitalic_F. Fig.\u00a07 summarizes the situation. Giving:\nA\u2062p=(1.20\u00b10.96)\u00d710\u22123/(c\u2062m2\u2062s\u2062s\u2062r\u2062G\u2062e\u2062V)\ud835\udc34\ud835\udc5dplus-or-minus1.200.96superscript103\ud835\udc50superscript\ud835\udc5a2\ud835\udc60\ud835\udc60\ud835\udc5f\ud835\udc3a\ud835\udc52\ud835\udc49Ap=(1.20\\pm 0.96)\\times 10^{-3}/(cm^{2}s\\;sr\\;GeV)italic_A italic_p = ( 1.20 \u00b1 0.96 ) \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT / ( italic_c italic_m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_s italic_s italic_r italic_G italic_e italic_V )\nand \u03b2=1.89\u00b11.10\ud835\udefdplus-or-minus1.891.10\\beta=1.89\\pm 1.10italic_\u03b2 = 1.89 \u00b1 1.10. To make a comparison with satellite GOES data, we obtain the integral proton flux in the GeV energy range as Fig.\u00a08 shows the results of the integral proton flux obtained from the New-Tupi muon excess observed in coincidence with the radiation. The red circles represent the GOES-16 data, and the black squares represent the expected proton flux in the GeV energy range obtained from Monte Carlo, muon excess at the New-Tupi detector, and the GOES-proton fluence.\nThe origin of this transient event was the solar eruption, an M6-class flare (prompt emission), accelerating protons (ions) up to relativistic energies, GeV energy range. We have reported evidence of SEPs accelerated up to GeV energies during the eruptive phase of the M6-class solar flare on July 17, 2023. The result comes from a timing analysis of a muon excess from the New-Tupi detector at the SAA central region. Muons at New-Tupi are produced by protons (ions) interaction in the upper atmosphere reaching the Earth with a magnetic rigidity above 3 GV (\u223csimilar-to\\sim\u223c 3 GeV for protons). In most cases, SEP (mostly protons) detected by the GOES-16 spacecraft shows two steps. An impulsive phase, where the acceleration of protons (ions) is by the prompt emission of flare, followed by a gradual phase of long duration, where the acceleration of protons (ions) is by the associated CME shock waves. We want to point out that the muon excess produced by SEPs with an effective rigidity above the cutoff (\u223csimilar-to\\sim\u223c 3 GV) at the New-Tupi muon detector is in temporal coincidence only with the GOES proton flux from the impulsive phase (see Fig.\u00a04) . Consequently, in the gradual phase, the protons accelerated by CME\u2019s shocks do not reach the GeV energy range because a muon excess is absent at ground level. A marginal muon excess also appears on the Yan ba Jing S-21(pointing 21 degrees south) muon telescope (in Tibet). Also, a marginal particle excess is seen only in the French Kerguel NM (close to the South polar region).\nIn both cases, the excesses are in (temporal) coincidence with the GOES proton flux (impulsive phase). However, it is hard to verify whether these excesses are genuine due to low confidence or simply fluctuations in the detectors\u2019 count rate. From a Monte Carlo analysis,\nwe show that the SAA central region is favourable to the observation of transient solar events, especially SEP, because\nthe magnetosphere has a \u201ddip\u00b4\u00b4 in this region,\nweakening the geomagnetic field strength and allowing the entrance of charged particles at large deeps in a region not far from the geographic Equator, giving a rigidity sub-cutoff around 3.1 GV in a place where the conventional Stormer geomagnetic rigidity cutoff is around 10 GV. This work is supported by the Rio de Janeiro Research Foundation (FAPERJ) under Grant E-26/010.101128/2018. We thank to NMDB Database (www.nmdb.eu), founded under the European Union FP7 Program (Contract No. 213007)\nby provide NMs data and the Space Weather Prediction Center\nfrom NOAA for its open data policy. The New-Tupi telescope is built with four identical particle detectors, forming two telescopes, as shown in Fig. 8 from Augusto et\u00a0al. (2016a). Each detector consisting of an Eljen EJ-208\nplastic scintillator slab of 150 cm x 75 cm x 5 cm and a Hamamatsu R877 photomultiplier of 127\nmillimeters in diameter, packaged in a pyramidal box.\nThe PMT high voltage divider, amplifier, and high voltage power supplier are in the ORTEC ScintiPackTM Photomultiplier Base 296. From February 6, 2023, we have implemented a data acquisition system using a VERTILON high-speed pulse counting system (MCPC618-8 Channel). allowing for direct connection with the PMTs without the need for external preamplifiers,\nwith a 250 MHz count rate per channel. Now the detector is working only in scaler mode or\nsingle particle technique (Aglietta et\u00a0al., 1996), where the single hit rates of all four PMTs, are recorded once a second.\nHowever, so far, only two detectors are working. The coincidences among these detectors of each telescope will be implanted. Also, the barometric coefficients for cosmic muon fluxes at the Earth\u2019s surface can be obtained using the CORSICA code in Kovylyaeva et\u00a0al. (2013). For New-Tupi detector conditions and at sea level, the barometric coefficient is about -0.14% per mb, about eight to nine times less than the typical barometric coefficient in NMs."
    },
    {
        "id": 3,
        "title": "Generative Inverse Design of Metamaterials with Functional Responses by Interpretable Learning",
        "corpus": "Metamaterials with functional responses, such as wave-based responses or deformation-induced property variation under external stimuli, can exhibit varying properties or functionalities under different conditions. Herein, we aim at rapid inverse design of these metamaterials to meet target qualitative functional behaviors. This inverse problem is challenging due to its intractability and the existence of non-unique solutions. Past works mainly focus on deep-learning-based methods that are data-demanding, require time-consuming training and hyperparameter tuning, and are non-interpretable. To overcome these limitations, we propose the Random-forest-based Interpretable Generative Inverse Design (RIGID), a single-shot inverse design method to achieve the fast generation of metamaterial designs with on-demand functional behaviors. Unlike most existing methods, by exploiting the interpretability of the random forest, we eliminate the need to train an inverse model mapping responses to designs. Based on the likelihood of target satisfaction derived from the trained forward model, one can sample design solutions using Markov chain Monte Carlo methods. The RIGID method therefore functions as a generative model that captures the conditional distribution of satisfying solutions given a design target. We demonstrate the effectiveness and efficiency of RIGID on both acoustic and optical metamaterial design problems where only small datasets (less than 250 training samples) are available. Synthetic design problems are created to further illustrate and validate the mechanism of likelihood estimation in RIGID. This work offers a new perspective on solving on-demand inverse design problems, showcasing the potential for incorporating interpretable machine learning into generative design and eliminating its large data requirement. Metamaterials with functional responses are engineered materials that exhibit varying properties or behaviors under different conditions. One example is metamaterials whose electromagnetic, acoustic, or elastic wave propagation behaviors change with wavelengths or frequencies\u00a0[1]. Another example is metamaterials that exhibit changing properties or functionalities due to deformation in response to external stimuli like temperature\u00a0[2] and magnetic fields\u00a0[3].\nTailoring functional responses of these metamaterials is of interest to applications such as sound and vibration control, analog computing, medical imaging, sensing, communication, and soft robotics. In many use cases, rather than precisely controlling the complete functional responses, we only care about qualitative behaviors under certain conditions. For example, acoustic metamaterials were usually designed to have bandgaps at specified frequencies to achieve functionalities like wave-guiding\u00a0[4, 5], focusing\u00a0[6, 7], and vibration mitigation\u00a0[8, 9, 10]. However, it is unnecessary and computationally expensive to design for the whole dispersion relation\u00a0[11, 12, 13, 14, 15]. Similarly, we may design optical metamaterials to qualitatively manipulate optical properties (e.g., high or low absorption/reflection/transmission) under certain wavelengths, without requiring the entire spectral response to match an exact target\u00a0[16, 17]. Identifying metamaterial designs from a given target forms an inverse design problem. Unlike many forward problems where one can obtain solutions (e.g., spectral responses or material properties under external stimuli) by modeling the physics or conducting experiments, inverse design problems are usually intractable. Traditionally, these problems are solved by iterative optimization (i.e., minimizing the difference between the actual quantity of interest and the target)\u00a0[11, 12, 14]. This, however, requires repeatedly updating the design solution and solving forward problems. When the design target changes, one needs to rerun the entire optimization process. Thus, inverse design by iterative optimization becomes impractical if solving the forward problem (by simulations or experiments) is time-consuming or if the design target needs to change frequently. To accelerate the optimization approach, prior works replaced simulations or experiments with machine learning models\u00a0[18, 19]. However, the efficiency and quality of final solutions are highly dependent on both the machine learning model and the optimization algorithm. On the other hand, a single run of optimization usually only returns one final solution, although multiple designs might satisfy a given target (i.e., the non-uniqueness of solutions). For example, multiple acoustic metamaterial designs may have bandgaps within the same target frequency range. This non-uniqueness nature of inverse design problems was also shown for optical metasurfaces\u00a0[20, 21, 22]. The optimization approach eliminates the opportunity to explore diverse alternative solutions. To avoid iterative optimization and enable fast on-demand inverse design, prior research attempted to realize single-shot (iteration-free) inverse design using machine learning. There are three mainstream models (their schematic diagrams are shown in Appendix, Fig.\u00a07). The most straightforward approach is to learn a direct inverse mapping from the response to design variables. Neural networks are the most commonly used machine learning model for this purpose, due to their high flexibility in approximating arbitrary nonlinear input-output relationships\u00a0[23, 13]. Despite the simplicity of the direct inverse mapping, its underlying assumption of the response-design mapping being one-to-one does not hold in many cases due to the non-uniqueness of solutions, as mentioned earlier. Such non-uniqueness will cause conflicting training instances where the same input (response) is associated with distinct outputs (designs), which will destabilize the convergence during neural network training\u00a0[20, 24]. To avoid this issue, past work proposed the Tandem Neural Network (T-NN) that cascades an inverse-design network with a forward-modeling network\u00a0[20, 25, 26, 27, 28]. Its training is split into two steps: (1)\u00a0pretraining the forward-modeling network to approximate the design-response mapping and (2)\u00a0training the cascaded network by freezing the weights of the pretrained forward-modeling network. There is no loss function that forces designs at the intermediate layer to match data (which contains conflicting instances), hence the training convergence issue is avoided. Nonetheless, the original T-NNs still learn a one-to-one response-design mapping and cannot account for the non-uniqueness of design solutions. To fundamentally solve this problem, one needs to learn a one-to-many mapping. Bastek et al.\u00a0[28] integrated stochastic sampling into the inverse-design network to allow the generation of multiple feasible solutions. A large body of recent works achieved the goal of learning one-to-many mapping by using conditional generative models, typically conditional generative adversarial networks (cGANs)\u00a0[29, 30, 31, 32, 22], conditional variational autoencoders (cVAEs)\u00a0[21], and conditional diffusion models\u00a0[33]. These models can generate multiple designs given a target response by learning the distribution of designs conditioned on the response. Different generative models have distinct ways of learning conditional distributions. In general, this is realized by training neural networks to transform responses and random noise (or latent variables) into designs, so that the trained network can generate a non-deterministic design solution from a given target response and randomly sampled noise, which is equivalent to sampling from a conditional distribution. Although conditional generative models have demonstrated success in solving inverse design problems, they still have issues, such as high data demand, exhaustive hyperparameter tuning, slow training, and low interpretability, especially compared to traditional machine learning models like decision trees and random forests. On the other hand, Elzouka et al.\u00a0[34] proposed to use the decision tree as a more interpretable model to solve both the forward prediction and inverse design problem. After training a decision tree for forward prediction, one can identify explicit design rules (i.e., feasible regions in the design space) by tracing from target leaf nodes to the root node. This approach also captures the one-to-many mapping nature of inverse design problems since it gives feasible design variable ranges rather than a single solution. However, there remain some limitations. Firstly, for solutions identified by the design rules, the method does not differentiate their likelihood of target satisfaction. Yet in reality, solutions always have different likelihoods due to the uncertainty of model estimation. Secondly, the method has to train two models: a random forest was trained first to ensure model accuracy and robustness, and then a large decision tree was trained to emulate the performance of the random forest and provide design rules. This is due to the challenge of deriving explicit design rules from an ensemble model like the random forest. Finally, the method was demonstrated on a problem with more than 104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT training data, while the effectiveness on smaller datasets (i.e., data with orders of magnitude smaller sample sizes) was not studied. This work aims to address the aforementioned problems by proposing a method called Random-forest-based Interpretable Generative Inverse Design (RIGID).\nFigure\u00a01 shows an overview of this method. Specifically, we first train a forward prediction random forest. Then given a design target, we can probe the trained random forest to infer the likelihood of any design satisfying the target. To generate new designs tailored to the target, we can sample from the design space according to the likelihood. Compared to the most widely studied neural-network-based methods, RIGID has a much lower cost in training and hyperparameter tuning, and works more robustly on small-size datasets (as random forests are less prone to overfitting). Similar to deep generative models, it can generate a desired number of solutions, allowing one to explore alternative solutions that might have desired properties or functionalities beyond the ones considered as the target. The explicit likelihood estimation also offers an interpretable characterization of a design\u2019s target satisfaction probability and allows an exploitation-exploration trade-off when selecting generated designs. We validate the RIGID method on two metamaterial design examples\u00a0\u2014\u00a0an acoustic metamaterial design example, where the target is to generate metamaterials with specific bandgaps, and an optical metasurface design example, where the target is to generate metasurfaces with high absorbance at specified wavelengths. Our contributions are three-fold. First, we propose a single-shot inverse design method that is fast, generative, interpretable, and small-data-compatible. Secondly, we demonstrate the effectiveness of the proposed method on acoustic and optical metamaterial design examples, and propose both qualitative and quantitative ways of assessing our method. Finally, we create two synthetic test cases for fast examination and validation of model performance. These test cases can be used for future benchmarking studies of related methods. The functional response of metamaterials can be modeled as y=f\u2062(\ud835\udc31,s)\ud835\udc66\ud835\udc53\ud835\udc31\ud835\udc60y=f(\\mathbf{x},s)italic_y = italic_f ( bold_x , italic_s ), where \ud835\udc31\ud835\udc31\\mathbf{x}bold_x denotes metamaterial design variables (e.g., materials and geometry parameters), s\ud835\udc60sitalic_s is an auxiliary variable representing the independent variable (or the \u201cx\ud835\udc65xitalic_x-axis\u201d) of the response (e.g., the frequency/wavelength or the external stimuli such as temperature), and y\ud835\udc66yitalic_y indicates the value of the response associated with our design target. In this paper, we assume y\u2208{0,1}\ud835\udc6601y\\in\\{0,1\\}italic_y \u2208 { 0 , 1 } since we only focus on qualitative behaviors at specified frequencies (e.g., for an acoustic metamaterial or an optical metamaterial design, whether a bandgap exists or whether the energy absorbance is higher than a threshold within a range of frequencies). We leave the more challenging problem of tailoring quantitative behaviors as future work. We use a random forest to approximate the function f\ud835\udc53fitalic_f. A random forest is an ensemble learning method that combines the predictions of multiple decision trees to improve accuracy and reduce overfitting\u00a0[35]. The trained random forest serves as a forward prediction model that predicts the outcome y\ud835\udc66yitalic_y given design variables \ud835\udc31\ud835\udc31\\mathbf{x}bold_x and the auxiliary variable s\ud835\udc60sitalic_s. Compared to the widely used neural networks, the random forest as a forward prediction model offers (1)\u00a0significantly faster training, (2)\u00a0less hyperparameters to tune, (3)\u00a0less susceptible to overfitting on small data, and (4)\u00a0interpretability (i.e., the decision-making of each tree in the random forest is transparent). More importantly, this interpretability also allows us to realize inverse design without training a separate inverse model. Figure\u00a02 shows how, by probing the trained random forest, one can estimate a likelihood distribution for target satisfaction of solutions over the entire design space and sample (generate) new designs based on this likelihood distribution. Since we target qualitative (binary) behaviors at specified s\ud835\udc60sitalic_s (e.g., a bandgap in 3-4 MHz frequency or high absorption at a wavelength of 400-500 nm), we first identify the leaf nodes (on each decision tree in the random forest) that are relevant to the s\ud835\udc60sitalic_s in the target (Fig.\u00a02, Step 1). We do this by tracing down each tree, checking only the nodes that use s\ud835\udc60sitalic_s as the splitting feature, and pruning the branches that are irrelevant to the s\ud835\udc60sitalic_s in the target. For example, as shown in Fig.\u00a02, there are two tree nodes using s\ud835\udc60sitalic_s as the splitting feature, with splitting criteria at s\u22645\ud835\udc605s\\leq 5italic_s \u2264 5 and s\u22647\ud835\udc607s\\leq 7italic_s \u2264 7. Given the target frequency range of 3\u2264s\u226443\ud835\udc6043\\leq s\\leq 43 \u2264 italic_s \u2264 4, we can remove the right branches of both nodes as these branches are only relevant to s>5\ud835\udc605s>5italic_s > 5 and s>7\ud835\udc607s>7italic_s > 7, respectively, which conflicts with the target range of 3\u2264s\u226443\ud835\udc6043\\leq s\\leq 43 \u2264 italic_s \u2264 4. After pruning these branches, we end up with a set of leaves relevant to the target (highlighted in Fig.\u00a02, Step 1). When we have a combined target (e.g., bandgaps in both 3-4 MHz and 6-7 MHz, as shown in Fig.\u00a02), we need to get the intersection of all the sets of relevant leaves and use that as the final set of relevant leaves (highlighted in Fig.\u00a02, Step 2). Note that a combined target includes cases where there are multiple nonadjacent target ranges (e.g., 3-4 MHz and 6-7 MHz) or when a target range is split by a tree node (e.g., a target range of 4-6 MHz can be split by the node \u201cs\u22645\ud835\udc605s\\leq 5italic_s \u2264 5\u201d, thus we need to consider it as the combination of two target ranges\u00a0\u2014\u00a04-5 MHz and 5-6 MHz). A more detailed discussion of this step is in Appendix, Sec.\u00a0B. The next step is to trace up the tree from the N\ud835\udc41Nitalic_N relevant leaves, obtained by Step 2, to the root node (Fig.\u00a02, Step 3). This will result in N\ud835\udc41Nitalic_N decision paths, along which are nodes indicating splitting criteria for design variables \ud835\udc31\ud835\udc31\\mathbf{x}bold_x. Thus, each decision path represents a set of design variable ranges, or in other words, a region in the design space. We assign each region a score equal to the predicted probability at each corresponding leaf. This probability is learned from the training data and equals the proportion of positive data in a leaf. It indicates the tree\u2019s belief in the probability of a design \ud835\udc31\ud835\udc31\\mathbf{x}bold_x satisfying the target \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T if the design falls in the design space region corresponding to the leaf. Therefore, with a single decision tree i\ud835\udc56iitalic_i, we already have the map of likelihood \u2112m\u2062(\ud835\udc31|\ud835\udcaf)=\u2119m\u2062(\ud835\udcaf|\ud835\udc31)subscript\u2112\ud835\udc5aconditional\ud835\udc31\ud835\udcafsubscript\u2119\ud835\udc5aconditional\ud835\udcaf\ud835\udc31\\mathcal{L}_{m}(\\mathbf{x}|\\mathcal{T})=\\mathbb{P}_{m}(\\mathcal{T}|\\mathbf{x})caligraphic_L start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ( bold_x | caligraphic_T ) = blackboard_P start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ( caligraphic_T | bold_x ) for target satisfaction: each of the N\ud835\udc41Nitalic_N regions has a uniformly distributed likelihood equal to the predicted probability at the corresponding leaf, and the rest of the design space has a likelihood of 0 (Fig.\u00a02, Step 3). Since a single decision tree usually lacks accuracy, robustness, and a way to quantify estimation uncertainty, we still want to take advantage of the random forest as an ensemble model for inverse design. We use Steps 1-3 to derive the likelihood distribution for each of the M\ud835\udc40Mitalic_M trees in the random forest, and simply use the average of these M\ud835\udc40Mitalic_M likelihood distributions as the final likelihood for target satisfaction, \u2112\u2062(\ud835\udc31|\ud835\udcaf)=\u2211mM\u2112m\u2062(\ud835\udc31|\ud835\udcaf)/M\u2112conditional\ud835\udc31\ud835\udcafsuperscriptsubscript\ud835\udc5a\ud835\udc40subscript\u2112\ud835\udc5aconditional\ud835\udc31\ud835\udcaf\ud835\udc40\\mathcal{L}(\\mathbf{x}|\\mathcal{T})=\\sum_{m}^{M}\\mathcal{L}_{m}(\\mathbf{x}|%\n\\mathcal{T})/Mcaligraphic_L ( bold_x | caligraphic_T ) = \u2211 start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ( bold_x | caligraphic_T ) / italic_M, which is a more complex and smooth function (Fig.\u00a02, Step 4). If more trees believe a design \ud835\udc31\ud835\udc31\\mathbf{x}bold_x has a higher likelihood of satisfying the target, then the design will have a higher likelihood \u2112\u2062(\ud835\udc31|\ud835\udcaf)\u2112conditional\ud835\udc31\ud835\udcaf\\mathcal{L}(\\mathbf{x}|\\mathcal{T})caligraphic_L ( bold_x | caligraphic_T ). Finally, to generate new designs, we can sample from \u2112\u2062(\ud835\udc31|\ud835\udcaf)\u2112conditional\ud835\udc31\ud835\udcaf\\mathcal{L}(\\mathbf{x}|\\mathcal{T})caligraphic_L ( bold_x | caligraphic_T ) using Markov chain Monte Carlo (MCMC) methods such as Metropolis-Hastings\u00a0[36] (Fig.\u00a02, Step 5). Compared to prior works, RIGID provides the following unique benefits: It is effective on small data problems as the random forest is less susceptible to overfitting. The training is fast (in seconds of wall time) and does not require computationally-demanding hyperparameter tuning. Once the training is done, no further training or iterative optimization is required to generate designs for different targets. The model is interpretable as one can easily probe the trained model to understand its reasoning behind any decision-making. It estimates the explicit likelihood of target satisfaction for every possible solution in the design space. Given a design target of specific functional behavior, we can generate an unlimited number of solutions based on the likelihood, allowing us to explore alternative solutions that might have desired properties or functionalities beyond the ones considered as the target. When generating design solutions, one can use a single parameter\u00a0\u2014\u00a0the sampling threshold\u00a0\u2014\u00a0to easily tune the trade-off between exploitation (i.e., generated designs have higher chances of satisfying the target) and exploration (i.e., generated designs cover a broader area of the design space), as we will demonstrate in Results. We demonstrate our RIGID method on an acoustic metamaterial design problem, an optical metasurface design problem, and two synthetic design problems. Based on a recent review article by Lee et al.\u00a0[24] and other related works (e.g., [28]), existing single-shot inverse design methods were demonstrated on training data size ranging from 103superscript10310^{3}10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT to 106superscript10610^{6}10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT in scale. Here we show that our method can work with much smaller-scale datasets (less than 250 training samples). For all the test problems, we used the same random forest hyperparameter settings and did not perform hyperparameter tuning. Specifically, each random forest contains 1,000 trees with a minimum of 2 samples required to split an internal node and a minimum of 1 sample required to be at a leaf node. Gini impurity\u00a0[37] was used as the splitting criterion at tree nodes.\nThe train-test split ratio was 4:1. Since the positive/negative training data can be highly imbalanced (e.g., the frequency ranges with bandgaps are much narrower than those without), we used the Synthetic Minority Over-sampling TEchnique (SMOTE)\u00a0[38] to over-sample the positive class. For all the case studies, the random forest training took less than 10 seconds on an Intel Core i5-9300H CPU 2.4GHz and 8GB memory. After training, we generate new designs by sampling from the resulting likelihood distribution using Metropolis-Hastings. In practice, Metropolis-Hastings can generate identical samples, which provides no benefits for design purposes. Thus in this work, we reject the designs identical to previous ones during sampling. Here we consider acoustic metamaterials that can control elastic wave propagation at ultrasound (MHz) frequencies. Varying the microscale geometries of acoustic metamaterials changes the dynamic properties of a material, such as bandgaps\u00a0[10] (i.e., forbidden frequency ranges of a material) and wave propagation direction\u00a0[4].\nThese materials promise applications in waveguides\u00a0[4, 5], lenses\u00a0[6, 7], and vibration mitigation\u00a0[9].\nWe present the braced cubic design framework (Fig. 3A-B) as a method to tune the size and location of bandgaps (Fig.\u00a03C).\nIn particular, spherical micro-inertia are added to the center and corner of a braced cubic unit cell with strut radius rstrutsubscript\ud835\udc5fstrutr_{\\text{strut}}italic_r start_POSTSUBSCRIPT strut end_POSTSUBSCRIPT.\nMicro-inertia placed at the center of the brace has radius rcentersubscript\ud835\udc5fcenterr_{\\text{center}}italic_r start_POSTSUBSCRIPT center end_POSTSUBSCRIPT while micro-inertia placed at the corner of the cubic unit cell has radius rcornersubscript\ud835\udc5fcornerr_{\\text{corner}}italic_r start_POSTSUBSCRIPT corner end_POSTSUBSCRIPT. We randomly created 284 sets of geometric parameters \ud835\udc31=(rstrut,rcenter,rcorner)\ud835\udc31subscript\ud835\udc5fstrutsubscript\ud835\udc5fcentersubscript\ud835\udc5fcorner\\mathbf{x}=(r_{\\text{strut}},r_{\\text{center}},r_{\\text{corner}})bold_x = ( italic_r start_POSTSUBSCRIPT strut end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT center end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT corner end_POSTSUBSCRIPT ) with 4 \u2264rstrut\u2264absentsubscript\ud835\udc5fstrutabsent\\leq r_{\\text{strut}}\\leq\u2264 italic_r start_POSTSUBSCRIPT strut end_POSTSUBSCRIPT \u2264 6.41, 0 \u2264rcenter\u2264absentsubscript\ud835\udc5fcenterabsent\\leq r_{\\text{center}}\\leq\u2264 italic_r start_POSTSUBSCRIPT center end_POSTSUBSCRIPT \u2264 20, and 0 \u2264rcorner\u2264absentsubscript\ud835\udc5fcornerabsent\\leq r_{\\text{corner}}\\leq\u2264 italic_r start_POSTSUBSCRIPT corner end_POSTSUBSCRIPT \u2264 20 (unit: \u00b5m). The unit cell size was set at a=60\ud835\udc4e60a=60italic_a = 60 \u00b5m. For each of these designs, we performed Bloch-wave analysis to compute its acoustic dispersion relation.\nBandgap location and width were extracted for each design based on its dispersion relation. Out of the 284 sets of design variables and bandgap data, we used 227 samples as training data. We first discretized the entire frequency range into 100 intervals, and trained a random forest to predict bandgap existence y\u2208{0,1}\ud835\udc6601y\\in\\{0,1\\}italic_y \u2208 { 0 , 1 } at a specific interval s\ud835\udc60sitalic_s for a given design \ud835\udc31\ud835\udc31\\mathbf{x}bold_x. The trained model has a test F1 score of 0.82. The resulting confusion matrix on test data is shown in Appendix, Tab.\u00a01. To test the inverse design capability of RIGID, we randomly created 10 targets, each containing 1-2 frequency ranges in which bandgap(s) should exist.\nWe generated 30 designs for each target by sampling from the resulting likelihood distribution over the design space111Note that it is possible for the likelihood to be zero everywhere in the design space when the model believes the target is unachievable. We ignore these cases as it is meaningless and impossible to sample designs from such likelihood distribution.. Bandgaps were identified from dispersion relations computed using Bloch-wave analysis.\nFigure\u00a03D shows the kernel density estimation (KDE) for the likelihood of the 300 generated designs, conditioned on their target satisfaction.\nWe use \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D and \ud835\udc9ffeassubscript\ud835\udc9ffeas\\mathcal{D}_{\\text{feas}}caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT to represent the complete set of generated designs and the set of generated designs that actually satisfy the target, respectively. Then \ud835\udc9f\\\ud835\udc9ffeas\\\ud835\udc9fsubscript\ud835\udc9ffeas\\mathcal{D}\\backslash\\mathcal{D}_{\\text{feas}}caligraphic_D \\ caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT denotes the set of generated designs that cannot fulfill the target in reality.\nIn an ideal scenario, all solutions in \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D would satisfy the target, which means \ud835\udc9f=\ud835\udc9ffeas\ud835\udc9fsubscript\ud835\udc9ffeas\\mathcal{D}=\\mathcal{D}_{\\text{feas}}caligraphic_D = caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT, and their density profiles should coincide. However, this ideal scenario is not possible due to limited model accuracy. Conveniently, the estimation of target satisfaction likelihood offers us an indicator of what solution is more likely to violate the target. For a reasonable model, most designs in \ud835\udc9f\\\ud835\udc9ffeas\\\ud835\udc9fsubscript\ud835\udc9ffeas\\mathcal{D}\\backslash\\mathcal{D}_{\\text{feas}}caligraphic_D \\ caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT should have low estimated likelihood values. Consequently, the density of \ud835\udc9ffeassubscript\ud835\udc9ffeas\\mathcal{D}_{\\text{feas}}caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT\u2019s likelihood is a result of shifting some of \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D\u2019s density from left (low likelihood) to right (high likelihood). This expectation aligns with the observation in Fig.\u00a03D. When sampling new designs or selecting solutions from generated designs, we can put a sampling threshold \u03c4\u2208(0,1)\ud835\udf0f01\\tau\\in(0,1)italic_\u03c4 \u2208 ( 0 , 1 ) on the likelihood values to filter out \u201cless promising\u201d solutions. To further examine model behavior and quantify how \u03c4\ud835\udf0f\\tauitalic_\u03c4 affects the inverse design outcome, we define the following metrics: where \ud835\udc9f\u03d5\u2265\u03c4subscript\ud835\udc9fitalic-\u03d5\ud835\udf0f\\mathcal{D}_{\\phi\\geq\\tau}caligraphic_D start_POSTSUBSCRIPT italic_\u03d5 \u2265 italic_\u03c4 end_POSTSUBSCRIPT is the set of generated designs with the likelihood of at least \u03c4\ud835\udf0f\\tauitalic_\u03c4 (i.e., the selected designs) and qisubscript\ud835\udc5e\ud835\udc56q_{i}italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT denotes the percentage overlap between the target and the actual behavior of selected designs.\nThe satisfaction rate evaluates how many selected designs satisfy the target based on a binary criterion (i.e., whether or not a design satisfies the complete target), whereas the average score provides a soft measure where partial satisfaction is also counted. The average score is lower-bounded by the satisfaction rate. As shown in Fig.\u00a03E, the selection rate decreases when \u03c4\ud835\udf0f\\tauitalic_\u03c4 increases since more solutions are filtered out. On the other hand, both the satisfaction rate and the average score increase with \u03c4\ud835\udf0f\\tauitalic_\u03c4, which indicates a high correlation between the estimated likelihood of a solution and its probability of actually achieving the target. As \u03c4\ud835\udf0f\\tauitalic_\u03c4 reaches 0.6, the satisfaction rate and the average score reach 1, indicating that all generated designs satisfy their targets. When sampling or selecting new solutions, we can use the sample threshold \u03c4\ud835\udf0f\\tauitalic_\u03c4 to tune the trade-off between exploitation and exploration\u00a0\u2014\u00a0a low \u03c4\ud835\udf0f\\tauitalic_\u03c4 favors exploration as sampled solutions will cover a larger area of the design space, while a high \u03c4\ud835\udf0f\\tauitalic_\u03c4 favors exploitation as sampled solutions will have a higher chance of satisfying the target. Figure\u00a03F visualizes the geometries and dispersion relations of designs generated based on a randomly created bandgap target. Only the top five designs with the highest likelihood values are shown.\nIn this example, our method generates geometrically different designs that have a high probability of achieving target bandgaps, each yielding a slightly different dispersion relation. This is promising in design applications requiring other material properties, such as dynamic wave velocity or quasi-static stiffness, in which the user can select from a menu of designs with the same target bandgap but other varying properties. Generated designs based on the other nine bandgap targets can be found in Appendix, Figs.\u00a08-10. Optical metasurfaces are artificially engineered systems that can support exotic light propagation building on subwavelength inclusions\u00a0[39, 40, 41, 42, 43, 44]. Among a diverse array of devices, metamaterial absorbers\u00a0[45, 46, 47, 48, 49, 50, 51] have been intensely studied for medical imaging, sensing, and wireless communications. In this case study, we consider four types of cross-sections (c\u2208{1,2,3,4}\ud835\udc501234c\\in\\{1,2,3,4\\}italic_c \u2208 { 1 , 2 , 3 , 4 }) chosen from the literature (Fig.\u00a04B). It is assumed that a 3D geometric instance is composed of a stack of three layers of prismatic unit cells, each of which is vertically extruded and stacked (Fig.\u00a04A). The geometries constructed in this way can be regarded as an instantiation of multilayered metasurfaces\u00a0[52, 53, 54, 55, 56], which offer richer design freedom than the single-layer counterpart. The height of each layer (hl,l=1,2,3formulae-sequencesubscript\u210e\ud835\udc59\ud835\udc59123h_{l},l=1,2,3italic_h start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT , italic_l = 1 , 2 , 3) is allowed to continuously vary between 50 and 150 nm. Herein we do not consider parametric variations of a given type of unit cell cross-section; yet those can be trivially incorporated in the proposed design framework if necessary. We also design the material of each layer (ml,l=1,2,3formulae-sequencesubscript\ud835\udc5a\ud835\udc59\ud835\udc59123m_{l},l=1,2,3italic_m start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT , italic_l = 1 , 2 , 3). Three dielectric materials of interest, each of which is assigned to a different color in Fig.\u00a04A, are Ti (red), Si (blue), and Ge (yellow). In general, a dielectric material is characterized through a complex refractive index n~\u2208\u2102~\ud835\udc5b\u2102\\tilde{n}\\in\\mathbb{C}over~ start_ARG italic_n end_ARG \u2208 blackboard_C defined as n~=n+j\u2062k~\ud835\udc5b\ud835\udc5b\ud835\udc57\ud835\udc58\\tilde{n}=n+jkover~ start_ARG italic_n end_ARG = italic_n + italic_j italic_k, where j=\u22121\ud835\udc571j=\\sqrt{-1}italic_j = square-root start_ARG - 1 end_ARG is the imaginary unit, n\u2208\u211d\ud835\udc5b\u211dn\\in\\mathbb{R}italic_n \u2208 blackboard_R involves the speed at which the light propagates through the material, and k\u2208\u211d\ud835\udc58\u211dk\\in\\mathbb{R}italic_k \u2208 blackboard_R is the extinction coefficient that dictates the energy loss due to the material.\nWithin the frequency regime of interest, those exhibit nonlinear dispersion; both the real and imaginary terms in general are a non-analytic function of excitation wavelength s\ud835\udc60sitalic_s, i.e., n\u2062(s)\ud835\udc5b\ud835\udc60n(s)italic_n ( italic_s ) and k\u2062(s)\ud835\udc58\ud835\udc60k(s)italic_k ( italic_s ). In addition, the impact of the same material choice on the spectral response A\u2062(s)\ud835\udc34\ud835\udc60A(s)italic_A ( italic_s ) varies depending on the layer location at which the material is placed. Thus the highlight of this case study is the combinatorial nature of design, whose spectral responses are affected by the joint contributions of geometry and material. Based on the above configuration, we randomly sampled 258 sets of design variables \ud835\udc31=(c,h1,h2,h3,m1,m2,m3)\ud835\udc31\ud835\udc50subscript\u210e1subscript\u210e2subscript\u210e3subscript\ud835\udc5a1subscript\ud835\udc5a2subscript\ud835\udc5a3\\mathbf{x}=(c,h_{1},h_{2},h_{3},m_{1},m_{2},m_{3})bold_x = ( italic_c , italic_h start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) and computed their corresponding absorbance spectra using wave analysis. We set t=0.9\ud835\udc610.9t=0.9italic_t = 0.9 as the absorbance threshold, so that \u201chigh\u201d absorbance means the absorbance A\u2062(s)\ud835\udc34\ud835\udc60A(s)italic_A ( italic_s ) is no less than 0.9. We trained a random forest on 206 training data (i.e., 80% of the 258 designs and corresponding absorbance spectra) to predict whether \u201chigh\u201d absorbance is presented (i.e., the binary indicator y=1\ud835\udc661y=1italic_y = 1) at a wavelength s\ud835\udc60sitalic_s for a given design \ud835\udc31\ud835\udc31\\mathbf{x}bold_x. The trained random forest has a test F1 score of 0.83. The confusion matrix on test data is shown in Appendix, Tab.\u00a02. Note that this problem involves inverse design with both continuous and categorical variables, which common optimization and generative modeling-based inverse design cannot handle well without special treatment\u00a0[57, 58, 59]. On the other hand, our random forest-based method can naturally address such mixed-variable problems without any issues. Similar to the acoustic metamaterial design problem, we use 10 randomly created targets to evaluate the inverse design performance of RIGID, except that here a target is represented as the wavelength range(s) within which absorbance should be at least 0.9. We generated 100 designs for each target by sampling from the estimated likelihood distribution. Among the 1,000 generated solutions, we successfully conducted wave analysis for 911 designs and obtained their absorbance spectra. Figure\u00a04D shows the KDE for the likelihood of these 911 designs, conditioned on their target satisfaction. The densities share similar behavior as in the acoustic problem (Fig.\u00a03D)\u00a0\u2014unsatisfied/infeasible designs \ud835\udc9f\\\ud835\udc9ffeas\\\ud835\udc9fsubscript\ud835\udc9ffeas\\mathcal{D}\\backslash\\mathcal{D}_{\\text{feas}}caligraphic_D \\ caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT are concentrated at low likelihood regions, which causes the likelihood density of satisfied/feasible designs \ud835\udc9ffeassubscript\ud835\udc9ffeas\\mathcal{D}_{\\text{feas}}caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT to be a result of shifting some of \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D\u2019s density from left (low likelihood) to right (high likelihood). The sampling threshold and metrics relation shown in Fig.\u00a04E also follow the same trend as in the acoustic problem (Fig.\u00a03E), which again demonstrates a strong positive correlation between the estimated likelihood and the probability of generated designs actually achieving their targets. Figure\u00a04F shows generated optical metasurface designs with the top five likelihood estimations for a randomly created target. While the materials, cross-section geometries, and layer heights of generated designs can be different, all the designs satisfy the target (Fig.\u00a04F, right panel). To further enhance the diversity of final solutions, we can use sampling strategies such as the one proposed in Ref.\u00a0[60, 61] to identify a subset (of generated solutions) that simultaneously exhibits high likelihood and high diversity. Generated designs based on the other nine targets can be found in Appendix, Figs.\u00a011-12. While the above metamaterial design problems represent practical use cases, the validation study is time-consuming due to the expensive computation of metamaterials\u2019 responses such as dispersion relations and absorbance spectra. To allow fast validation of the proposed method and easier inspection of the estimated likelihood in the design space, we create two synthetic case studies. Both problems have 2-dimensional \u201cdesign spaces\u201d that allow easy visualization. To construct the first synthetic problem, we used a squared exponential function with tunable parameters a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b to mimic the quantitative functional response of metamaterials. The qualitative response (e.g., \u201chigh\u201d or \u201clow\u201d energy absorption at a wavelength) is defined as: where z\ud835\udc67zitalic_z represents quantitative response and t\ud835\udc61titalic_t is a threshold that converts z\ud835\udc67zitalic_z into a qualitative response I\u2062(a,b;s)\ud835\udc3c\ud835\udc4e\ud835\udc4f\ud835\udc60I(a,b;s)italic_I ( italic_a , italic_b ; italic_s ). Specifically, I\u2062(a,b;s)=1\ud835\udc3c\ud835\udc4e\ud835\udc4f\ud835\udc601I(a,b;s)=1italic_I ( italic_a , italic_b ; italic_s ) = 1 can mean the existence of a bandgap or high absorbance at a frequency s\ud835\udc60sitalic_s. Then {s|I\u2062(a,b;s)=1}conditional-set\ud835\udc60\ud835\udc3c\ud835\udc4e\ud835\udc4f\ud835\udc601\\{s|I(a,b;s)=1\\}{ italic_s | italic_I ( italic_a , italic_b ; italic_s ) = 1 } represents a range of s\ud835\udc60sitalic_s that mimics our design targets, such as the bandgap or the frequency range of high absorbance. By varying a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b, we can produce different synthetic responses and ranges. Therefore, we can use a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b as synthetic design variables. There is a clear relation between these design variables and the range that Eq.\u00a02 creates\u00a0\u2014\u00a0a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b control the center location and the width of the range, respectively. In this design problem, we sampled 100 sets of a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b uniformly at random. We set t\ud835\udc61titalic_t as 0.9. Based on Eq.\u00a02, we obtained the corresponding responses (Fig.\u00a05A). These sets of a\ud835\udc4eaitalic_a, b\ud835\udc4fbitalic_b, and responses constitute a dataset for training and testing our model. Another synthetic design problem was constructed by replacing\nthe squared exponential function in the SqExp problem with a superposed sine function. Given synthetic design variables a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b, we can produce qualitative responses using the following equation: Same as in the SqExp problem, we set t=0.9\ud835\udc610.9t=0.9italic_t = 0.9 and created a dataset with 100 sets of synthetic design variables and corresponding ranges derived from synthetic responses (Fig.\u00a05B).\nUnlike the squared exponential function, the superposed sine function can be multimodal, which means it can result in multiple synthetic ranges to mimic, for example, multiple bandgaps. The bandgap locations are controlled by a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b. For each synthetic example, we split the data into 80 training data and 20 test data, and trained a random forest, with the same hyperparameter settings as the other problems, to predict the binary indicators I\u2062(a,b;s)\ud835\udc3c\ud835\udc4e\ud835\udc4f\ud835\udc60I(a,b;s)italic_I ( italic_a , italic_b ; italic_s ). The F1 scores are 0.85 and 0.86 for the SqExp and the SupSin problems, respectively. The resulting confusion matrices are shown in Appendix, Tables\u00a03-4. We evaluated the inverse design performance with the trained models. Due to the fast evaluation of Equations\u00a02 and 3, we can exhaust all the possible solutions in the design space to obtain the ground-truth feasible region(s) for a target. Figure\u00a06A shows the estimated likelihood values and the ground-truth feasible regions under randomly created targets. In general, high-likelihood regions match actual feasible regions well, which further demonstrates the effectiveness of RIGID. We can also observe that feasible regions in the SqExp and the SupSin problems follow distinct patterns. In the SqExp problem, a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b control the center location and the width of the output range, respectively. Therefore, the position of the feasible region along the a\ud835\udc4eaitalic_a-axis moves with the location of the target range, while the feasible region gradually shrinks as b\ud835\udc4fbitalic_b decreases since the decrease of b\ud835\udc4fbitalic_b (i.e., output range width) causes the choice of a\ud835\udc4eaitalic_a (i.e., output range center location) to be more restricted to fit the target range. In the SupSin problem, there might be multiple bandgaps appearing at the peaks of the superposed sine function in Eq.\u00a03. Design variables a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b control bandgap locations by translating each sine function. Due to the sine function\u2019s periodicity, we can obtain multiple feasible regions along both a\ud835\udc4eaitalic_a- and b\ud835\udc4fbitalic_b-axes.\nFigure\u00a06A shows that the likelihood estimation by RIGID successfully captured the above-mentioned patterns of feasible regions. Figure\u00a06B demonstrates how the estimated likelihood varies when increasing the number of trees in a random forest. With a single decision tree, the estimated likelihood function is almost a binary function and highly inaccurate. The likelihood in the SqExp case is even zero everywhere, which makes it impossible to sample designs based on the likelihood. As the number of trees increases, the likelihood function becomes smoother and eventually converges. Besides these qualitative visual inspections, we also calculated the metrics proposed in Eq.\u00a01, as shown in Fig.\u00a06C. For each of the two synthetic problems, these metrics were computed on 500 designs generated by giving five random target ranges. Again, the satisfaction rate and the average score increase with the sampling threshold, indicating a strong correlation between the sampling threshold and the probability of generated designs actually achieving their targets. In both problems, all the selected designs satisfy their targets (i.e., the satisfaction rates and average scores reach 1) when the sampling threshold reaches 0.8. We proposed RIGID, a single-shot inverse design method that generates metamaterials to satisfy qualitative behaviors of functional responses. Such qualitative behaviors are important design targets in many applications such as tailoring bandgaps of acoustic metamaterials for wave-guiding, focusing, and vibration mitigation, or tailoring the absorption level of optical metasurfaces at certain wavelengths for medical sensing, imaging, and communication applications. Unlike most existing inverse design methods that require training an inverse model to map targets to designs, the RIGID method takes advantage of the random forest\u2019s interpretability and derives the likelihood of target satisfaction by probing the trained forward model. Incorporated with MCMC, one can sample a desired number of new designs based on the estimated likelihood. Therefore, RIGID functions as a generative model that can capture the conditional distribution of satisfying designs given a target, or in other words, the one-to-many mapping from the target to satisfying designs. Using both real-world and synthetic design problems, we demonstrated that RIGID is efficient and effective on datasets with training sample sizes smaller than 250. Thus, RIGID is particularly useful when data collection is expensive, as in many cases where high-fidelity simulation or experimental data are needed. We used both qualitative and quantitative approaches to validate the proposed method. The quantitative results revealed a strong correlation between the estimated likelihood of a solution and its probability of actually achieving the target, which demonstrated the effectiveness of the likelihood estimation. Due to the fast evaluation of output responses and the transparency of ground-truth solutions, the proposed synthetic problems can be used for future benchmarking studies of metamaterial design problems. While we address qualitative design targets in this study, the idea of using random forest-based models for inverse design has the potential to generalize to quantitative targets. Such problems can be, for example, generating optical metasurface designs with specific optical spectra\u00a0[62, 21], generating functional materials with target nonlinear constitutive relations\u00a0[33, 63], or generating programmable metamaterials with prescribed functional responses\u00a0[64, 65]. It is also straightforward to adjust the target to achieve multifunctionality (e.g., negative/positive Poisson\u2019s ratio under low/high compression rate\u00a0[66]). Although this study only demonstrates the RIGID method on parametric design (i.e., designs are represented by geometric and/or material parameters), the method also applies to shape or topological design problems where the shape or topology of designs can vary without being restricted to a limited number of geometric parameters\u00a0[62, 29, 21, 31, 67]. In those cases, as valid designs only lie on a lower-dimensional manifold of the design space, the likelihood of target satisfaction will be zero almost everywhere in the original design space. Thus before applying RIGID, we need to obtain a latent representation that compactly captures the manifold of valid designs\u00a0[68, 69], and use the latent representation as design variables for inverse design. This work was supported by the startup funds from the J. Mike Walker \u201966 Department of Mechanical Engineering at Texas A&M University, the National Science Foundation (NSF) BRITE Fellow program (CMMI 2227641), the NSF CSSI program (OAC 1835782), the Kansas City National Security Campus (PDRD #705288), and NSF CAREER Award (CMMI-2142460). R.S. acknowledges financial support from the NSF Graduate Research Fellowship Program. Figure\u00a07 shows the schematic diagrams of three mainstream machine learning models for single-shot inverse design of metamaterials. The purpose of Step 2 is to obtain the intersection of relevant design space regions for all the ranges of s\ud835\udc60sitalic_s in a target. We are approximating this goal by simply obtaining the intersection of relevant leaves. However, some non-intersecting leaves may still have intersecting design space regions. When assigning the probability to the intersecting region of two non-intersecting leaves A\ud835\udc34Aitalic_A and B\ud835\udc35Bitalic_B, we need to consider the predicted probabilities at both leaves (PAsubscript\ud835\udc43\ud835\udc34P_{A}italic_P start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT and PBsubscript\ud835\udc43\ud835\udc35P_{B}italic_P start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT). Specifically, the assigned probability at this intersecting region should be PA\u2062PBsubscript\ud835\udc43\ud835\udc34subscript\ud835\udc43\ud835\udc35P_{A}P_{B}italic_P start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_P start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT, which can be small. Therefore, we adopt the simplification of only considering the intersection of relevant leaves and ignoring the intersecting regions associated with non-intersecting leaves. The results also demonstrate that this is a reasonable approximation. We performed Bloch-wave analysis in COMSOL Multiphysics to compute the dispersion relations of acoustic metamaterials. Poisson\u2019s ratio of 0.49, Young\u2019s modulus of 2.7 GPa, and density of 1170 kg/m33{{}^{3}}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT were set as material properties with \u223c1.5\u00d7104similar-toabsent1.5superscript104\\sim 1.5\\times 10^{4}\u223c 1.5 \u00d7 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT mesh elements per unit cell.\nWe used Floquet-Bloch periodic boundary conditions to obtain the first 60 eigenfrequencies along all symmetry domains of the cubic irreducible Brillouin zone (Fig. 3B) for all lattices, thus generating a dispersion relation. We computed the absorbance spectra for optical metasurfaces using wave analysis inspired by Zhang et al.\u00a0[56]. The RF Module of COMSOL Multiphysics\u00ae\u00a0[70] was used to evaluate the spectral response of concern, which is the energy absorbance A\u2062(s)\ud835\udc34\ud835\udc60A(s)italic_A ( italic_s ) in the visible regime (380-700 nm). An absorbance spectrum is computed with respect to 33 wavelength components sksubscript\ud835\udc60\ud835\udc58s_{k}italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT that are uniformly discretized over the specified range. An incident plane wave is assumed to be given from the port, located at the top face of the analysis domain. We set the periodicity of the analysis domain as 400 nm. The periodic boundary condition on electromagnetic fields is imposed on the lateral faces of the analysis domain. A substrate made of SiO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT is placed right below a given unit cell instance (the black layers in Fig.\u00a04A-B). With full electric fields computed through the wave analysis, the energy absorbance at a single wavelength s\ud835\udc60sitalic_s is quantified as A\u2062(s)=1\u2212|S11\u2062(s)|2\ud835\udc34\ud835\udc601superscriptsubscript\ud835\udc4611\ud835\udc602A(s)=1-|S_{11}(s)|^{2}italic_A ( italic_s ) = 1 - | italic_S start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT ( italic_s ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, where Si\u2062jsubscript\ud835\udc46\ud835\udc56\ud835\udc57S_{ij}italic_S start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT is the component of the S\ud835\udc46Sitalic_S-parameter matrix that specifies energy transfer between ports. We use the data presented in Ref.\u00a0[71] to set the material dispersion of the dielectric. Test data for all the design problems are designs \ud835\udc31\ud835\udc31\\mathbf{x}bold_x (that the random forests have never seen during training) and their corresponding qualitative behaviors y\u2208{0,1}\ud835\udc6601y\\in\\{0,1\\}italic_y \u2208 { 0 , 1 } based on functional responses. In the acoustic metamaterial design problem, we have 57 test designs, yielding 5,700 test points as the entire frequency range of dispersion relations is discretized into 100 intervals for each design. In the optical metasurface design problem, we have 52 test designs, with each functional response discretized into 33 points, which yields 1,716 test points in total. In each of the synthetic design problems, we have 20 synthetic test designs, with each synthetic response discretized into 100 points. This results in 2,000 test data points in total. Confusion matrices showing test performances are in Tables\u00a01-4. Figures\u00a08-12 show the rest of generated designs and their corresponding responses in addition to those in Figures\u00a03F and 4F."
    },
    {
        "id": 4,
        "title": "Building Open-Ended Embodied Agent via Language-Policy \nBidirectional Adaptation",
        "corpus": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on. Authors: achieve the best HTML results from your LaTeX submissions by selecting from this list of supported packages. Building open-ended learning agents involves challenges in pre-trained language model (LLM) and reinforcement learning (RL) approaches. LLMs struggle with context-specific real-time interactions, while RL methods face efficiency issues for exploration. To this end, we propose OpenContra, a co-training framework that cooperates LLMs and GRL to construct an open-ended agent capable of comprehending arbitrary human instructions.\nThe implementation comprises two stages: (1) fine-tuning an LLM to translate human instructions into structured goals, and curriculum training a goal-conditioned RL policy to execute arbitrary goals; (2) collaborative training to make the LLM and RL policy learn to adapt each, achieving open-endedness on instruction space.\nWe conduct experiments on Contra, a battle royale FPS game with a complex and vast goal space.\nThe results show that an agent trained with OpenContra comprehends arbitrary human instructions and completes goals with a high completion ratio, which proves that OpenContra may be the first practical solution for constructing open-ended embodied agents. \\ul The challenge of building general-capable agents in the field of AI remains a significant endeavor\u00a0(Stanley et\u00a0al., 2017; Parker-Holder, 2022). This challenge necessitates the development of agents with the ability to continuously learn new skills and even create novel ones, a domain commonly referred to as open-ended learning. The research in open-ended learning is broadly categorized into two main factions: (1) pre-trained LLM agents for open-ended planning\u00a0(Wang et\u00a0al., 2023; Ouyang et\u00a0al., 2022), and (2) RL agents for open-ended control\u00a0(Team et\u00a0al., 2021; Balduzzi et\u00a0al., 2019). LLM-based methods, particularly those with closed source architectures, focus on planning based on general knowledge acquired during the pre-training stage\u00a0(Wang et\u00a0al., 2023). However, they may struggle to comprehend agent interactions in specific contexts and be impossible to learn in the case of real-time interaction. In contrast, RL methods conduct open-ended learning in an end-to-end manner, developing in diverse methodologies such as population-based training\u00a0(Jaderberg et\u00a0al., 2019; Team et\u00a0al., 2021) and curriculum reinforcement learning\u00a0(Wang et\u00a0al., 2019; Samvelyan et\u00a0al., 2022). While RL methods naturally learn contextual understanding by enabling agents to interact directly with environments, these approaches can be inefficient when aiming for open-endedness over the entire goal space, especially under tight computation budgets. Additionally, achieving meaningful open-endedness is essential under practical conditions, grounded by human instructions. To address these challenges, we propose a collaborative training framework that combines LLM and RL. In this framework, the LLM is responsible for contextual understanding and translating human instructions into structured goals, while the RL agent makes decisions to execute these goals. While some attempts have been made in this direction, existing studies often focus on single-sided learning, where one module is frozen while the other is trainable. This overlooks the potential cooperation between the LLM and RL agent. More specifically, existing efforts typically aim to improve training efficiency or reduce module interaction costs\u00a0(Hu et\u00a0al., 2023; Du et\u00a0al., 2023). To substantiate our proposal, we present OpenContra, a two-stage implementation. In the first stage, OpenContra conducts independent training, enabling the LLM to generate goals corresponding to natural language instructions and environment contexts and RL agents to be capable of completing as many goals as possible. The LLM is initially trained with human-annotated datasets to generate formatted goal descriptions, followed by multi-step fine-tuning to enhance the precision of goal generation.\nA warm-up from non-goal RL is performed for RL training to master basic skills.\nSubsequently, a curriculum GRL procedure\u00a0(Liu et\u00a0al., 2022; Narvekar et\u00a0al., 2020) is introduced to train a goal-conditioned policy for goal execution, starting from the well-trained non-goal RL agent.\nIn the second stage, we collaboratively train the LLM and the RL agent to adapt to each other and complete goals corresponding to human instructions. Specifically, we create a dataset of instructions from diverse sources and then random sample instructions to combine with environment states to generate goals with the LLM. These goals are further used to train the goal-conditioned RL agent as in the previous stage. Simultaneously, for the training of the LLM, we introduce Reinforcement Learning with Agent Feedback (RLAF), which considers both environmental feedback and instruction completion.\nThus, the LLM will be optimized towards comprehending agent interactions. We employ Contra as a testbed, a Battle Royale FPS game requiring high-frequency skill operation, with a high-dimensional goal space. Our evaluation includes human-instructed tests to validate open-endedness, wherein arbitrary human instructions are given to the LLM module, and the generated goals\u2019 quality and completion ratio is examined (Figure\u00a01). Formally, the goal-conditioned reinforcement learning (GRL) could be formulated as a goal-augmented Markov Decision Process \u2133\u2133\\mathcal{M}caligraphic_M\u00a0(Liu et\u00a0al., 2022) as follows.\nDenoting \u2133\u2133\\mathcal{M}caligraphic_M a tuple \u27e8\ud835\udcae,\ud835\udc9c,\ud835\udca2,\ud835\udcab,\u211b,\u03b3\u27e9\ud835\udcae\ud835\udc9c\ud835\udca2\ud835\udcab\u211b\ud835\udefe\\langle\\mathcal{S},\\mathcal{A},\\mathcal{G},\\mathcal{P},\\mathcal{R},\\gamma\\rangle\u27e8 caligraphic_S , caligraphic_A , caligraphic_G , caligraphic_P , caligraphic_R , italic_\u03b3 \u27e9, where \ud835\udcae\ud835\udcae\\mathcal{S}caligraphic_S, \ud835\udc9c\ud835\udc9c\\mathcal{A}caligraphic_A, \ud835\udca2\ud835\udca2\\mathcal{G}caligraphic_G the state space, action space and goal space, respectively.\nIn general, \ud835\udca2\ud835\udca2\\mathcal{G}caligraphic_G is a projection of \ud835\udcae\ud835\udcae\\mathcal{S}caligraphic_S, i.e., \ud835\udca2=P\u2062r\u2062o\u2062j\u2062(\ud835\udcae)\ud835\udca2\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc57\ud835\udcae\\mathcal{G}=Proj(\\mathcal{S})caligraphic_G = italic_P italic_r italic_o italic_j ( caligraphic_S ).\n\ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P defines the state transition function that given a state and action tuple (st,at)subscript\ud835\udc60\ud835\udc61subscript\ud835\udc4e\ud835\udc61(s_{t},a_{t})( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) at timestep t\ud835\udc61titalic_t, i.e., \ud835\udcab:\ud835\udcae\u00d7\ud835\udc9c\u2192\u0394\u2062(\ud835\udcae):\ud835\udcab\u2192\ud835\udcae\ud835\udc9c\u0394\ud835\udcae\\mathcal{P}:\\mathcal{S}\\times\\mathcal{A}\\rightarrow\\Delta(\\mathcal{S})caligraphic_P : caligraphic_S \u00d7 caligraphic_A \u2192 roman_\u0394 ( caligraphic_S ), where \u0394\u2062(\u22c5)\u0394\u22c5\\Delta(\\cdot)roman_\u0394 ( \u22c5 ) denotes a distribution.\n\u211b:\ud835\udcae\u00d7\ud835\udc9c\u00d7\ud835\udca2\u2192\u211d:\u211b\u2192\ud835\udcae\ud835\udc9c\ud835\udca2\u211d\\mathcal{R}:\\mathcal{S}\\times\\mathcal{A}\\times\\mathcal{G}\\rightarrow\\mathbb{R}caligraphic_R : caligraphic_S \u00d7 caligraphic_A \u00d7 caligraphic_G \u2192 blackboard_R defines the reward function r\u2062(s,a,g)\ud835\udc5f\ud835\udc60\ud835\udc4e\ud835\udc54r(s,a,g)italic_r ( italic_s , italic_a , italic_g ) with a given state, action, and goal.\nAt the beginning of an episode \u03c4\ud835\udf0f\\tauitalic_\u03c4, a goal g\ud835\udc54gitalic_g will be sampled from a distribution Pgsubscript\ud835\udc43\ud835\udc54P_{g}italic_P start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT, which generally defines a target for the agent to solve \u2133\u2133\\mathcal{M}caligraphic_M.\nWe could further formulate a policy function for the agent that denotes the decision-making at each time step as \u03c0:\ud835\udcae\u00d7\ud835\udca2\u2192\u0394\u2062(\ud835\udc9c):\ud835\udf0b\u2192\ud835\udcae\ud835\udca2\u0394\ud835\udc9c\\pi:\\mathcal{S}\\times\\mathcal{G}\\rightarrow\\Delta(\\mathcal{A})italic_\u03c0 : caligraphic_S \u00d7 caligraphic_G \u2192 roman_\u0394 ( caligraphic_A ), which is a distribution over the action space.\nTo solving a \u2133\u2133\\mathcal{M}caligraphic_M, the agent with policy \u03c0\ud835\udf0b\\piitalic_\u03c0 should maximize its accumulative reward over the goal space as where Pssubscript\ud835\udc43\ud835\udc60P_{s}italic_P start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT the state distribution determines the sampling of s0subscript\ud835\udc600s_{0}italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, \u03b3\u2208[0,1)\ud835\udefe01\\gamma\\in[0,1)italic_\u03b3 \u2208 [ 0 , 1 ) discounted the reward at each time step to guarantee the convergence of policy learning.\nNormally, r\u2062(st,at,g)\ud835\udc5fsubscript\ud835\udc60\ud835\udc61subscript\ud835\udc4e\ud835\udc61\ud835\udc54r(s_{t},a_{t},g)italic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_g ) is binary to denote whether g\ud835\udc54gitalic_g has been completed, i.e., r\u2062(st,at,g)\ud835\udc5fsubscript\ud835\udc60\ud835\udc61subscript\ud835\udc4e\ud835\udc61\ud835\udc54r(s_{t},a_{t},g)italic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_g ) values 0 or 1 according to whether st+1\u223c\ud835\udcab(\u22c5|st,at)s_{t+1}\\sim\\mathcal{P}(\\cdot|s_{t},a_{t})italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT \u223c caligraphic_P ( \u22c5 | italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) satisfies g\ud835\udc54gitalic_g, i.e., To approximate the accumulative reward related to the policy \u03c0(\u22c5|st,g)\\pi(\\cdot|s_{t},g)italic_\u03c0 ( \u22c5 | italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_g ), GRL suggests using the Universal Value Function Approximator (UVFA) V\u2062(st,g)\ud835\udc49subscript\ud835\udc60\ud835\udc61\ud835\udc54V(s_{t},g)italic_V ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_g ) to replace the state value function in traditional RL\u00a0(Schaul et\u00a0al., 2015a).\nThe goal representation is still an open question, generally determined by the task to be resolved.\nWe summarize the most popular categories as vector-based\u00a0(Florensa et\u00a0al., 2018; Ren et\u00a0al., 2019; Nair et\u00a0al., 2018; Fang et\u00a0al., 2019; Pitis et\u00a0al., 2020), vision-based\u00a0(Campero et\u00a0al., 2020; Nair & Finn, 2019; Warde-Farley et\u00a0al., 2018; Mendonca et\u00a0al., 2021; Bousmalis et\u00a0al., 2023; Groth et\u00a0al., 2021) and text-based\u00a0(Brohan et\u00a0al., 2023; Lynch & Sermanet, 2020).\nIn this work, we model the goal space as a structured vector corresponding to multiple sub-goal spaces.\nOne research direction of goal-conditioned RL is to learn a policy (or agent) that completes as many goals as possible, which could be regarded as achieving open-endedness in the goal space \ud835\udca2\ud835\udca2\\mathcal{G}caligraphic_G.\nHowever, it is almost impossible to traverse all goals from \ud835\udca2\ud835\udca2\\mathcal{G}caligraphic_G as (1) Pgsubscript\ud835\udc43\ud835\udc54P_{g}italic_P start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT may be agnostic to an agent, and (2) \ud835\udca2\ud835\udca2\\mathcal{G}caligraphic_G may be uncountable and continuous.\nTo satisfy the open-endedness requirements, a popular solution is leveraging curriculum reinforcement learning\u00a0(Weng, 2020), i.e., automatically discovering novel goals from past training.\nDespite numerous curriculum approaches for achieving open-endedness, a critical challenge hinders the progress, i.e., sample inefficiency, due to the setting of binary reward signals (Equation\u00a02).\nAs a solution to this problem, existing research is central on reward shaping\u00a0(Ng et\u00a0al., 1999; Ecoffet et\u00a0al., 2021; Ding et\u00a0al., 2023; Trott et\u00a0al., 2019) and hindsight goal relabelling\u00a0(Andrychowicz et\u00a0al., 2017; Fang et\u00a0al., 2019; Zheng et\u00a0al., 2022).\nReward shaping is a straightforward and efficient idea to address the sparse rewarding problem, while it relies on domain knowledge and complex feature engineering.\nHindsight relabelling is inspired by (Schaul et\u00a0al., 2015b), which introduces a prioritized replay mechanism to improve the sample efficiency of RL methods. LLMs a class of networks that execute in auto-regressive for text generation tasks.\nAssuming a given sequence of text tokens is x1:t=(x1,\u2026,xt)subscript\ud835\udc65:1\ud835\udc61subscript\ud835\udc651\u2026subscript\ud835\udc65\ud835\udc61x_{1:t}=(x_{1},\\dots,x_{t})italic_x start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT = ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ), and the generation of a next token xt+1subscript\ud835\udc65\ud835\udc611x_{t+1}italic_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT is formulated as a probabilistic model: xt+1=arg\u2061maxx\u2208\ud835\udc9f\u2061P\u2062(x|x1:t)subscript\ud835\udc65\ud835\udc611subscript\ud835\udc65\ud835\udc9f\ud835\udc43conditional\ud835\udc65subscript\ud835\udc65:1\ud835\udc61x_{t+1}=\\arg\\max_{x\\in\\mathcal{D}}P(x|x_{1:t})italic_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT = roman_arg roman_max start_POSTSUBSCRIPT italic_x \u2208 caligraphic_D end_POSTSUBSCRIPT italic_P ( italic_x | italic_x start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT ), which satisfies the derivation of Markov chain.\nAs for the training of LLMs, the target is equivalently to find a parameter set \u03b8LLMsubscript\ud835\udf03LLM\\theta_{\\text{LLM}}italic_\u03b8 start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT which satisfies the optimal generation, i.e., \u03b8LLM=arg\u2061max\u03b8\u2061P\u2062(xt+1|x1:t;\u03b8)subscript\ud835\udf03LLMsubscript\ud835\udf03\ud835\udc43conditionalsubscript\ud835\udc65\ud835\udc611subscript\ud835\udc65:1\ud835\udc61\ud835\udf03\\theta_{\\text{LLM}}=\\arg\\max_{\\theta}P(x_{t+1}|x_{1:t};\\theta)italic_\u03b8 start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT = roman_arg roman_max start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT italic_P ( italic_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT ; italic_\u03b8 ).\nWith the booming of LLM research\u00a0(Brown et\u00a0al., 2020; Touvron et\u00a0al., 2023; OpenAI, 2023), it is feasible to leverage LLMs as an interface or human behavior model to interact with autonomous agents.\nThis research lies in human-AI interaction (or human-AI coordination/collaboration), and lots of work focuses on achieving collaboration by planning and learning with human behavior models\u00a0(Nikolaidis & Shah, 2013; Sadigh et\u00a0al., 2016; Swamy et\u00a0al., 2020; Carroll et\u00a0al., 2020).\nOur work is also related to this direction, as our evaluation is conducted with human-given instructions, so the LLM module in our work acts as an interface for the human-AI interaction.\nThe generalization capability could be a key to human-AI interaction, as we want an agent to collaborate with arbitrary humans.\nThus, there is a part of existing work focuses on training a best-response policy to a diverse set of human-like policies so that the agent may generalize to new coming humans\u00a0(Cui et\u00a0al., 2023; Strouse et\u00a0al., 2022; Charakorn et\u00a0al., 2022).\nIn our work, an agent acquires the generalization capability by achieving open-endedness in the goal space. Contra seamlessly merges the last-man-standing gameplay dynamics with the survival, exploration, and scavenging elements inherent in first-person shooting games\u00a0(Choi & Kim, ; Gautam et\u00a0al., 2021). The game unfolds with multiple hostile teams, necessitating players to collaborate with teammates, withstand adversaries, and strive to outlast others in the ever-changing arena. The agent\u2019s objectives encompass individual survival and the elimination of encountered enemies. An agent in Contra mandates a sequential acquisition of skills, starting from fundamental abilities like walking, jumping, running, and item collection. As the learning proceeds, an agent must master more intricate skills such as evading enemy projectiles and coordinating tactics with teammates. This characteristic defines an open-ended learning process where the agent continually explores the game environment to refine mastered skills and acquire new ones. Before delving into the detailed introduction of OpenContra, it is necessary to highlight two critical engineering designs to enhance training efficiency. The training inefficiency is often exacerbated in the context of open-ended learning and large-scale tasks where extensive rollouts are required for experience data collection and evaluations. To address this challenge, OpenContra incorporates a distributed RL framework inspired by AlphaStar\u00a0(Vinyals et\u00a0al., 2019) with modifications, resulting in the formation of the Actor-League-Learner architecture. In this architecture, the League is responsible for distributing rollout tasks to a cluster of Actors (CPU nodes) for data collection and evaluation, while optimization tasks are delegated to the Learner (GPU node) for policy updates. This distributed approach significantly enhances rollout throughput, thereby improving overall training efficiency.\nAnother efficiency challenge stems from the iterative development of Contra. Unlike most of RL research that often relies on a fixed environment for algorithm development, Contra\u2019s environmental attributes continuously change over an eight-month development period. To mitigate the burden of retraining caused by these dynamic changes, we employ surgery\u00a0(Berner et\u00a0al., 2019) to retain learned skills at the lowest training cost, enabling adaptation to a changing observation/goal space while ensuring compatibility with network inputs. Detailed information on the distributed RL framework can be found in Appendix\u00a0F, and version changes are documented in Table\u00a08. This section focuses on the algorithmic design aspects of OpenContra. In the realm of GRL, the prevalent approach involves curriculum learning a goal-conditioned policy from scratch. However, achieving goal completion requires an agent to first master basic skills in interacting with the environment. This necessity imposes an additional computational burden on policy learning due to the extensive exploration required. Given the challenges posed by high-dimensional goal exploration, this work diverges from the common practice of leveraging goal decomposition to alleviate the issue. Instead, we opt for an explicit separation of basic skill learning and goal-conditioned learning.\nA key element in achieving this separation is ensuring that the agent acquires basic skills through non-goal RL before engaging in goal-conditioned learning. To fulfill this objective, we employ Proximal Policy Optimization (PPO)\u00a0(Schulman et\u00a0al., 2017), a highly efficient Actor-Critic algorithm\u00a0(Sutton & Barto, 2018). Furthermore, we introduce a multi-head state value function designed to enhance the efficiency of policy learning, as depicted in Figure\u00a04. This design encompasses two distinct heads: (1) a head dedicated to skill learning and (2) a head focused on learning to avoid obstacles when navigating. In the context of encouraging the agent to learn and achieve arbitrary goals in Contra, we define a goal space \ud835\udca2\ud835\udca2\\mathcal{G}caligraphic_G as a Cartesian product of 68 sub-goal spaces: \ud835\udca2=\ud835\udca21\u00d7\u22ef\u00d7\ud835\udca268\ud835\udca2superscript\ud835\udca21\u22efsuperscript\ud835\udca268\\mathcal{G}=\\mathcal{G}^{1}\\times\\cdots\\times\\mathcal{G}^{68}caligraphic_G = caligraphic_G start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT \u00d7 \u22ef \u00d7 caligraphic_G start_POSTSUPERSCRIPT 68 end_POSTSUPERSCRIPT. Each \ud835\udca2isuperscript\ud835\udca2\ud835\udc56\\mathcal{G}^{i}caligraphic_G start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT (i\u2208[1,68]\ud835\udc56168i\\in[1,68]italic_i \u2208 [ 1 , 68 ]) is a set {gi|\u2205,g1i,\u2026,g|\ud835\udca2i|\u22121i}conditional-setsuperscript\ud835\udc54\ud835\udc56subscriptsuperscript\ud835\udc54\ud835\udc561\u2026subscriptsuperscript\ud835\udc54\ud835\udc56superscript\ud835\udca2\ud835\udc561\\{g^{i}|\\emptyset,g^{i}_{1},\\dots,g^{i}_{|\\mathcal{G}^{i}|-1}\\}{ italic_g start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT | \u2205 , italic_g start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_g start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT | caligraphic_G start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT | - 1 end_POSTSUBSCRIPT }, where \u2205\\emptyset\u2205 indicates that a sub-goal is not selected as a valid value. For a given goal g\u2208\ud835\udca2\ud835\udc54\ud835\udca2g\\in\\mathcal{G}italic_g \u2208 caligraphic_G, it is represented as g=(g1,g2,\u2026,g68)\ud835\udc54superscript\ud835\udc541superscript\ud835\udc542\u2026superscript\ud835\udc5468g=(g^{1},g^{2},\\dots,g^{68})italic_g = ( italic_g start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_g start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , \u2026 , italic_g start_POSTSUPERSCRIPT 68 end_POSTSUPERSCRIPT ), with gi\u2208\ud835\udca2isuperscript\ud835\udc54\ud835\udc56superscript\ud835\udca2\ud835\udc56g^{i}\\in\\mathcal{G}^{i}italic_g start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT \u2208 caligraphic_G start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT. The composition of each goal considers two types of features: unit features corresponding to the agent and other players, and environment features that can be determined or affected by agent interactions. Refer to Table\u00a07 for detailed specifications.\nTo encode a goal instance, we use a Residual-Network\u00a0(He et\u00a0al., 2016), denoted as ResNet\u2062(\u22c5)ResNet\u22c5\\textsc{ResNet}(\\cdot)ResNet ( \u22c5 ), resulting in ResNet\u2062(g)ResNet\ud835\udc54\\textsc{ResNet}(g)ResNet ( italic_g ). This encoded goal is then concatenated with the corresponding state embedding of g\ud835\udc54gitalic_g and used as input for the policy and value networks. In the realm of curriculum learning, we explore both automatic and manual paradigms. Automatic curricula, such as Unsupervised Environment Design (UED)\u00a0(Dennis et\u00a0al., 2020), were tested with slight modifications, but the agent struggled to explore efficiently. This may be attributed to our goal space being significantly vaster than those tested in previous works, resulting in a sparse regret distribution unsuitable for scheduling goal learning. Consequently, we opt for a manual curriculum, staging goal-conditioned learning through curriculum random and hindsight goal-generation. This approach aims to warm up the agent, facilitating exploration and better comprehension of goal input. Given the expensive cost of exploring the high-dimensional goal space, we gradually activate five dimensions until the full set is activated. Activation for new dimensions is determined by whether the agent has converged on the completion ratio. While random goal-generation aids exploration, it introduces challenges, including generating many unreasonable goals comprising contradictory sub-goals (Table\u00a03) and encouraging the agent to explore more complex goals. The former arises because random goal-generation is independent of a specified environment context, and the latter is due to the goal-generation independent of the agent policy. To address these issues and promote open-endedness, we propose training a goal generator with Hindsight Replay Buffer (HER)\u00a0(Andrychowicz et\u00a0al., 2017), as summarized in Algorithm\u00a02 (refer to Appendix\u00a0H). As introduced in the aforementioned, sparse rewarding is a critical issue in Goal-RL, exacerbating inefficient exploration. To mitigate this, we extend the multi-head value function with a goal-completion value head to encourage the agent to complete goals. The corresponding reward is calculated as the Euclidean norm difference between two consecutive states and a goal: where \u2225\u22c5\u2225p\\|\\cdot\\|_{p}\u2225 \u22c5 \u2225 start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT indicates the p\ud835\udc5dpitalic_p-norm. This reward provides a denser signal to the agent about its proximity to the goal, offering more nuanced information than a binary signal indicating whether it has reached the goal or not. In our current implementation, we set p=1\ud835\udc5d1p=1italic_p = 1. To further address degeneration, a KL-divergence distance between non-goal and goal-conditioned policies is introduced as a regularizer. The policy learning objective is reformulated as: where \u03c0\u22c6superscript\ud835\udf0b\u22c6\\pi^{\\star}italic_\u03c0 start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT represents the optimized non-goal policy, J\u2062(\u03c0\u03b8)\ud835\udc3dsubscript\ud835\udf0b\ud835\udf03J(\\pi_{\\theta})italic_J ( italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ) is the return, and \ud835\udfd9g=\u2205subscript1\ud835\udc54\\mathbb{1}_{g=\\emptyset}blackboard_1 start_POSTSUBSCRIPT italic_g = \u2205 end_POSTSUBSCRIPT indicates that the KL-divergence term is only activated for an empty goal. We fine-tune a pre-trained LLM to enable the LLM to generate goals with natural language instructions from set \u2110\u2110\\mathcal{I}caligraphic_I and abstracted environmental states from set \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O as input. To construct the training dataset \ud835\udc9f:=\u2110\u00d7\ud835\udcaa\u00d7\ud835\udca2assign\ud835\udc9f\u2110\ud835\udcaa\ud835\udca2\\mathcal{D}:=\\mathcal{I}\\times\\mathcal{O}\\times\\mathcal{G}caligraphic_D := caligraphic_I \u00d7 caligraphic_O \u00d7 caligraphic_G, we first build \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O a dataset of abstracted state from trajectories collected by the RL agent, where each abstraction o\u2208\ud835\udcaa\ud835\udc5c\ud835\udcaao\\in\\mathcal{O}italic_o \u2208 caligraphic_O contains essential features of all players and the present environment state (Appendix\u00a0B). By accompanying \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O with a instruction set \u2110\u2110\\mathcal{I}caligraphic_I, we form a temporary dataset \ud835\udc9fx={(o,i)|(o,i)\u2208\ud835\udcaa\u00d7\u2110}subscript\ud835\udc9f\ud835\udc65conditional-set\ud835\udc5c\ud835\udc56\ud835\udc5c\ud835\udc56\ud835\udcaa\u2110\\mathcal{D}_{x}=\\left\\{(o,i)|(o,i)\\in\\mathcal{O}\\times\\mathcal{I}\\right\\}caligraphic_D start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT = { ( italic_o , italic_i ) | ( italic_o , italic_i ) \u2208 caligraphic_O \u00d7 caligraphic_I }. Then, we leverage GPT-4\u00a0(OpenAI, 2023) to generate appropriate goals for \ud835\udc9fxsubscript\ud835\udc9f\ud835\udc65\\mathcal{D}_{x}caligraphic_D start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT to construct \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D. To ensure the goals generated by GPT-4 conform to the format we want, a comprehensive prompt engineering endeavor was conducted to establish a set of predetermined rules for GPT-4. The rule-based prompts that guide GPT-4\u2019s responses are meticulously documented in Table\u00a010, and the examples of prompts for generation are listed in Table\u00a017. As for the source of instruction set \u2110\u2110\\mathcal{I}caligraphic_I, we leverage multiple types of goal generations to ensure its diversity and scale. Specifically, we consider four types, including (1) HI (Human Instructions): constructed with human-annotated commands; (2) SI (State Instructions): GPT-4-generated instructions by giving a pair of states where the first comes from agent trajectories and the second is generated by modifying features of the first item; (3) AI (Agent Instructions): GPT-4-generated instructions by giving agent trajectory and the corresponding initial state; and (4) RI (Random Instructions): a mixture of previous three datasets to form a supplementary dataset. For more details, refer to Appendix\u00a0E. With these datasets, we conduct fine-tuning for a ChatGLM-6B\u00a0(Zeng et\u00a0al., 2023; Du et\u00a0al., 2022) with LoRA\u00a0(Hu et\u00a0al., 2021) in three steps, as illustrated in Figure\u00a07, including (1) CoT-assisted fine-tuning (CoFT): each question as a task to fine-tune the LLM, aiming to expand the training data volume, enhancing the reasoning and understanding to \ud835\udc9fxsubscript\ud835\udc9f\ud835\udc65\\mathcal{D}_{x}caligraphic_D start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT; (2) Supervised Fine-tuning (SFT): to format the LLM-generated goals strictly, and further enhancing the accuracy; and (3) Ensemble Fine-tuning (EFT): multiple model checkpoints are used to generate goal candidates for each (o,i)\u2208\ud835\udc9fx\ud835\udc5c\ud835\udc56subscript\ud835\udc9f\ud835\udc65(o,i)\\in\\mathcal{D}_{x}( italic_o , italic_i ) \u2208 caligraphic_D start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT, then sub-goals with top counts will be used to reconstruct as ground truth to fine-tune the model to improve the precision of goal generation. After the training in previous steps, the RL agent obtained the capability to complete assigned goals, while the LLM learned to interpret human instructions and translate them into goals in the correct format.\nIn the next stage, we aim to enhance the goal completion ratio corresponding to arbitrary human instructions, thereby achieving open-endedness of human instructions.\nSince the RL agent and LLM are independently trained, the LLM lacks execution feedback to tune the goal generation, which may result in unreasonability (Table\u00a03), and the RL agent may perform a low completion ratio to the goals generated by the LLM if they were not or less explored in previous training.\nThus, introducing co-training aims to resolve the above limitations and make the goals generated by the LLM linguistically sound and not be divorced from the agent\u2019s ability to execute them. The implementation of RLAF relies on PPO with a multi-factor reward that considers multiple aspects to ensure the LLM-based goal generation toward a high completion ratio and consistency with given human instructions.\nSpecifically, they are (1) the evaluation of goal completion: the higher the completion ratio, the higher the reward value; (2) the evaluation of crucial sub-goal completion: for each batch of training data, we set the intersection of instructions in the batch and SI as the examination cases, and pairing each examination instruction with a preset target sub-goal required for successful execution, if the LLM outputs without such a sub-goal, then reward \u221222-2- 2, and +22+2+ 2 in vice, and further positive rewards are bestowed if a target sub-goal has been achieved; and (3) the evaluation of outputting the proper goal format: we punish the LLM according to edit distance. For more details, refer to Appendix\u00a0K. We observed continual training making the LLM and the RL agent tend to compromise to a local optimal, i.e., the LLM outputs goals tend to comfort a high completion ratio for the agent but neglect consistency with human instructions, and the RL agent simultaneously rewards the LLM with a high completion ratio. To fix this issue, we propose a periodic reset of the LLM training, i.e., the parameters of the LLM will be reset for every set number of steps so that the two components can avoid being trapped in a local convergence, achieving enhanced goal completion, and keeping goals consistent with human instructions.\nConsidering the training efficiency of LLMs, we conduct LoRA\u00a0(Hu et\u00a0al., 2021) to update the model weights. Figure\u00a07 illustrates the whole training process, and Algorithm\u00a01 summarizes the corresponding pseudo-code. We conduct empirical experiments to evaluate the efficacy of both stages of our proposed OpenContra. To make the Contra satisfy the learning requirements, we give well-designed\nspaces and reward functions as follows. The observation space encompasses many factors, including unit features detailing the agent\u2019s status, those of other players, and monsters. It also encompasses environmental features capturing interaction events and changes in the safe zone. Additionally, an agent-centric RGB bird\u2019s-eye-view of the local environment is considered. Due to the heterogeneity in the shape and data type of these features, we process them independently and concatenate them as inputs to both the policy and value network. Detailed information is available in Table\u00a04. The action space is implemented on top of Contra\u2019s micro-operation API, comprising a collection of multi-grained actions. These actions range from fine-grained movements, such as six-degrees-of-freedom movement and weapon usage, to compound actions in coarse-grained categories, such as firing at a target. The total size of the action space is 54. Further details in Table\u00a06. A comprehensive representation is employed for the reward function, considering various factors contributing to policy learning and goal completion. These factors are organized as a linear combination to formulate the reward function. The determination of weights for this combination follows a two-fold principle: (1) assigning weights to reward items based on their scales and emphasizing important factors; (2) dynamically adjusting weights in response to learning feedback, such as decreasing or increasing the weights of corresponding factors. Additional information is available in Appendix\u00a0A. We evaluate the curriculum GRL within the OpenContra from three distinct perspectives: (1) the completion ratio, (2) generalization capability concerning unseen goals, and (3) robustness when integrating goal-conditioned learning atop non-goal learning. Given that the curriculum GRL in OpenContra comprises random and hindsight stages, our evaluation involves a comparative analysis with two baselines, namely, (1) Random: training the RL agent with randomly generated goals, and (2) Hindsight: training the RL agent with hindsight goal generation. For clarity, we refer to our method as Hindsight from Random. LABEL:fig:rl_pretrain_goal_train presents a comparison of the goal completion ratio across different pretraining methods on a validation dataset where goals are generated using random and hindsight goal generators. As depicted in LABEL:fig:rl_pretrain_goal_train, Hindsight from Random surpasses all baselines by 4% and 1%, respectively.\nLABEL:fig:rl_pretrain_goal_test evaluates the generalization on unseen goals, addressing the second aspect mentioned earlier. It is noteworthy that the unseen goals are re-combinations of goals obtained with Hindsight and LLM. As indicated in LABEL:fig:rl_pretrain_goal_test, Hindsight from Random excels over the other two baselines in terms of completion ratio.\nLABEL:fig:degradation_reward_kil answers the third point by comparing the use of KL-divergence regularizer for policy learning, considering changes in overall performance and the ability to eliminate enemies. Three metrics are designed for evaluation: (1) Mean basic reward per step, which indicates whether the current policy degenerates in performing basic skills per step against a well-trained non-goal policy, and intentional to emphasize the agent\u2019s immediate responsiveness over final results; (2) #Enemies killed, representing the average number of enemies killed by the agent per episode; and (3) #Enemies knocked down, representing the average number of enemies knocked down by the agent per episode. We assessed the performance of the LLM through two comparative experiments on a GPT-4 generated instruction dataset, aiming to investigate the impact of different dataset construction and fine-tuning paradigms. Evaluation metrics employed include precision, recall, and F1 score. It\u2019s worth noting that determining the precision of LLM outputs for certain sub-goals, such as associating the sub-goal \u201cmoving speed\u201d with \u201cvery fast\u201d versus \u201cfast\u201d poses challenges, as it might be perceived as a negative instance under precision measurement. Consequently, we assert that generating such sub-goals should weigh more heavily in performance evaluation than specific values, necessitating the introduction of corresponding metrics. As a solution, we propose three choice-based metrics: precision (choice), recall (choice), and F1 (choice), to address this requirement. Table\u00a01 provides a comparison of five types of training datasets used in the three-stage fine-tuning process for the LLM, with \u201cALL\u201d representing the proportional mixture of the four base datasets. The comparison reveals that utilizing a mixture significantly outperforms individual base datasets, which indicates a mixture aids the LLM in capturing human command habits, understanding the implications of each abstracted state, and refining the initial execution capability of the policy from various perspectives, thereby enhancing goal generation. Table\u00a02 compares four kinds of fine-tuning approaches with the three-staged fine-tuning introduced in Section\u00a04.3, including (1) SFT: only use the target prompt without CoT data to supervised fine-tuning, which can be regarded as a baseline for a general SFT approach; (2) CoTF: only CoT-assisted fine-tuning; (3) CoTF \u2192\u2192\\rightarrow\u2192 SFT: further SFT target prompt after CoTF; (4) CoTF \u2192\u2192\\rightarrow\u2192 SFT\u2192\u2192\\rightarrow\u2192EFT: further ensemble fine-tuning target prompt after CoTF.\nWith the comparison results, we conclude that CoTF and SFT can improve each other and achieve better performance.\nFurthermore, ensemble fine-tuning significantly enhances precision while marginally decreasing recall, making it more suitable for generating accurate concise goals. We conducted an analysis of the completion ratio corresponding to different goal dimensions during the co-training process, as illustrated in LABEL:fig_co-training_reset_a. It is evident that the completion ratio for human instructions is relatively low when the agent and the LLM have not been co-trained initially. However, as the co-training proceeds, the completion ratio gradually improves, particularly for goals with dimensions ranging from 2 to 4. This indicates that co-training effectively enhances the LLM\u2019s understanding of the agent\u2019s capabilities and preferences. Conversely, as depicted in LABEL:fig_co-training_reset_b, the initial completion ratio for each training loop increases with each reset, suggesting that co-training enhances the policy\u2019s ability to execute the language model\u2019s preferred outputs. Furthermore, the combined improvements in the LLM and the agent effectively enhance the ability to execute human instructions. Additionally, we investigated the change in sub-goal distribution during co-training, as depicted in LABEL:fig_co-training_reset_c and LABEL:tab_state_distributionB. The former illustrates changes within a loop, while the latter indicates changes across loops. The associated explanations for each Gisubscript\ud835\udc3a\ud835\udc56G_{i}italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are provided in Table\u00a014. As training progresses, the probabilities associated with each sub-goal undergo gradual modifications. For instance, sub-goals with augmented probabilities include variables such as movement speed and the prone state due to their relatively attainable nature and influence in directing the agent toward accomplishing other objectives. Conversely, sub-goals with diminished probabilities encompass inter-agent distances and enemy visibility, which are linked to interactions with other agents and are not directly related to fulfilling linguistic instructions. The language model tends to generate outputs for these sub-goals only when absolutely necessary. As a case study, we have identified various instances in which objectives have been modified following the co-training process, as shown in Table\u00a03.\nEvidently, after collaborative training, the LLM demonstrates its capacity to eliminate contradictory and irrational elements within the initial objectives. Furthermore, it exhibits the ability to introduce new objective components, thereby rendering the overall goal more attainable, all while retaining its exceptional semantic comprehension capabilities. These findings underscore the deepened comprehension of the linguistic model regarding the environment achieved through collaborative training. In this paper, we implement a co-training framework named OpenContra experts on learning an open-ended embodied agent, which leverages large language models, goal-conditioned reinforcement learning, and distributed learning to fill the blank of cooperating LLM and RL for efficient open-ended learning.\nWe take a battle royale FPS game, Contra, as its testbed to support our claim, and the empirical results represent that OpenContra shows the potential as a practical solution.\nDespite the positive results, we admit there are still some limitations to our work that would be expected to be researched in the future\u2014for instance, a truly open-ended goal description instead of the handcrafted goal space in the current version; supporting multi-modality input/output to free from expensive feature engineering. The authors confirm their contribution as follows: Shaopeng Zhai: team leadership, open-ended learning, LLM/RLAF training, agent analysis, architecture design\nJie Wang: infrastructure/framework engineering, non-goal agent training, open-ended learning, ablation studies, feature engineering\nTianyi Zhang: non-goal agent training, open-ended learning, feature engineering\nFuxian Huang: non-goal agent training, paper writing, open-ended learning\nQi Zhang: LLM training, RLAF training, paper writing, ablation studies\nMing Zhou: co-training framework, curriculum research, paper writing\nJing Hou: LLM training, paper writing Contra seamlessly merges the last-man-standing gameplay dynamics with the survival, exploration, and scavenging elements inherent in first-person shooting games\u00a0(Choi & Kim, ; Gautam et\u00a0al., 2021). The game unfolds with multiple hostile teams, necessitating players to collaborate with teammates, withstand adversaries, and strive to outlast others in the ever-changing arena. The agent\u2019s objectives encompass individual survival and the elimination of encountered enemies. An agent in Contra mandates a sequential acquisition of skills, starting from fundamental abilities like walking, jumping, running, and item collection. As the learning proceeds, an agent must master more intricate skills such as evading enemy projectiles and coordinating tactics with teammates. This characteristic defines an open-ended learning process where the agent continually explores the game environment to refine mastered skills and acquire new ones.\nFigure\u00a02 illustrates a map of Contra, which has diverse terrains such as plains, deserts, and snow-capped mountains. The observation space encompasses various factors, comprising unit features delineating the agent\u2019s status, as well as that of other players. Additionally, it includes environmental features characterizing interaction events and alterations in safe-zone configurations. Furthermore, an agent-centric RGB bird\u2019s-eye-view of the local environment is incorporated. Given the heterogeneity in the shapes and data types of these features, we adopt an independent processing approach, subsequently concatenating them to serve as input for the policy and value networks. Figure\u00a03 illustrates the network for preprocessing an observation instance in our cases, where an observation includes four types of features as listed in Table\u00a04, and we leverage independent encoding for each of them. Furthermore, considering the iterative development of the environment, it is convenient to leverage surgery with this network architecture to handle these changes. As introduced in Table\u00a06, the instantiation of the action space is achieved through the utilization of the micro-operation API within the Contra framework. This process gives rise to a compilation of actions characterized by diverse levels of granularity, including fine-grained actions, alongside a suite of compound actions encompassing coarse-grained activities. In a detailed breakdown, the action space comprises several distinct types, namely movement direction, yaw direction, pitch direction, body action, basic action, and switch weapon. The movement direction action provides 16 discrete choices, each evenly distributed across a 360-degree spectrum. Likewise, the yaw direction action offers 16 choices with an equitable division of the 360-degree range. The pitch direction action encompasses three distinct values: -45, 0, 45. The body action incorporates nine diverse values: slide, stop, crouch, run, jump, ground, open or close door, rescue, and none. The basic action presents seven different values: fire, reloading, treat, pick up supply, drop supply, stop and fire, stop adjust and fire. Finally, the switch weapon action manifests three values: switch slot 0, switch slot 1, and none. The aggregated dimensionality of the action space is quantified at 54 in total. The primary objective of our training regimen is to equip the agent with the ability to play with other players in Contra while concurrently optimizing its success in overcoming opponents. To achieve this objective, we have formulated a diverse array of rewards designed to guide the agent\u2019s learning trajectory. However, the complexity involved in designing and fine-tuning these rewards is evident. Thus, our approach to reward weight design is characterized by a two-fold set of principles. Firstly, we allocate weights based on the expected value of each reward, ensuring a proportionate influence on the learning process. Secondly, we integrate a mechanism for smooth weight adjustments, facilitating dynamic and gradual modifications to the reward weightings.\nThese principles collectively contribute to the construction of the reward function, learning an agent policy conducive to the desired optimal performance against opponents.\nIn accordance with the first principle, we assume a referenced maximum return of 20, with different rewards assigned proportions based on their relative importance. For critical actions such as knocking down or killing an enemy, their values are set to approximately 4 (20% out of 20). Conversely, for less critical actions like scouting or incurring time penalties, their values are set to less than 1 (5% out of 20). It is crucial to highlight that the value estimation is derived through the discounted reward, with a discounting coefficient (\u03b3\ud835\udefe\\gammaitalic_\u03b3) set to 0.995.\nConcerning the second principle, throughout the training process, emphasis may be placed on learning specific skills during certain periods. For instance, the coefficient associated with a skill can be gradually amplified before mastery and subsequently reduced after proficiency is achieved. Detailed specifications are outlined in Table\u00a05.\nIn accordance with the aforementioned principles, the reward function has been constructed to systematically amalgamate multiple factors in a linear combination, facilitating their collaborative influence on guiding policy learning. As delineated in Algorithm\u00a02, these factors are broadly classified into three categories: fundamental rewards rb\u2062a\u2062s\u2062i\u2062csuperscript\ud835\udc5f\ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc56\ud835\udc50r^{basic}italic_r start_POSTSUPERSCRIPT italic_b italic_a italic_s italic_i italic_c end_POSTSUPERSCRIPT, obstacle avoidance rewards ro\u2062asuperscript\ud835\udc5f\ud835\udc5c\ud835\udc4er^{oa}italic_r start_POSTSUPERSCRIPT italic_o italic_a end_POSTSUPERSCRIPT, and goal achievement reward rgsuperscript\ud835\udc5f\ud835\udc54r^{g}italic_r start_POSTSUPERSCRIPT italic_g end_POSTSUPERSCRIPT. The fundamental rewards are primarily directed at steering the agent towards enhanced game-playing performance, encompassing collaborative engagement with teammates and eliminating adversaries, etc. In the case of ro\u2062asuperscript\ud835\udc5f\ud835\udc5c\ud835\udc4er^{oa}italic_r start_POSTSUPERSCRIPT italic_o italic_a end_POSTSUPERSCRIPT, the objective is to promote natural navigation and forestall the agent from encountering obstacles, such as stones and trees. Regarding the implementation, penalties are imposed on the agent for deviations from the optimal path. This optimal trajectory is determined by assessing the cosine similarity between the agent\u2019s current movement direction, a 3D unit vector, provided as an environmental signal, and the ideal obstacle-free trajectory derived from the action sequence in the trajectory: where \ud835\udc1dte\u2062n\u2062vsubscriptsuperscript\ud835\udc1d\ud835\udc52\ud835\udc5b\ud835\udc63\ud835\udc61\\mathbf{d}^{env}_{t}bold_d start_POSTSUPERSCRIPT italic_e italic_n italic_v end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT the actual movement direction of the agent, \ud835\udc1dti\u2062d\u2062e\u2062a\u2062lsubscriptsuperscript\ud835\udc1d\ud835\udc56\ud835\udc51\ud835\udc52\ud835\udc4e\ud835\udc59\ud835\udc61\\mathbf{d}^{ideal}_{t}bold_d start_POSTSUPERSCRIPT italic_i italic_d italic_e italic_a italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT the ideal movement direction, which is derived by combining the ideal movement direction from the previous moment with the movement action taken at the current moment: To address the issue of the agent getting stuck on obstacles due to short-term action sequences, we employ a smaller \u03b3\ud835\udefe\\gammaitalic_\u03b3 for the corresponding value head. Specifically, we set the \u03b3\ud835\udefe\\gammaitalic_\u03b3 value to 0.92. This adjustment helps mitigate the impact of the obstacle avoidance reward on long-term credit assignment, allowing for a more balanced consideration of immediate and future rewards in the agent\u2019s decision-making process. As for the goal-achieving reward, we\u2019ve introduced in the main text, please refer to Section\u00a04.2. For a comprehensive understanding of the game environment, a language model undergoes a fine-tuning process due to the scarcity of textual information within the simulation environment. The need arises to articulate non-linguistic elements, and the interaction between an agent and the simulation environment is centered on continuously observing the environment\u2019s state and generating corresponding actions. Therefore, the key aspects requiring verbalization primarily involve the state and actions of the agent.\nHowever, given the abundance of possible observation states in the simulation environment, it is impractical to use all of these states directly as prompts for the language model, especially considering token limitations. Consequently, there is a crucial need to extract and linguistically transform the most significant meta-states to facilitate successful model interaction.\nIt is noteworthy that smaller language models have limitations in comprehending and manipulating numerical values effectively. To address this challenge, a deliberate effort is made to minimize the use of numerical values during the environmental linguistics process. For example, instead of specifying an agent\u2019s speed with specific numeric metrics like \u201cspeed: 1m/s \u2192\u2192\\rightarrow\u2192 3m/s\u201d a qualitative representation such as \u201cspeed: slower \u2192\u2192\\rightarrow\u2192 faster\u201d is adopted. This technique transforms the original continuous state into a limited, discrete meta-state, thereby enhancing the language model\u2019s understanding. Similarly, for expediting language model understanding, a discrete action space is adopted, with each action accompanied by a succinct artificial language description. This discreet articulation of actions contributes to the overall interpretability of the language model within the simulation environment. We list the details in Table\u00a07. Figure\u00a04 shows the network architecture used for reinforcement learning. On top of observation preprocessing in Appendix\u00a0A, we introduce a backbone implemented with a fully-connected layer followed by three Residual Blocks. As for the policy head and three value heads, we implemented each of them as two connected Residual Blocks.\nIt is noteworthy that the invisible enemy information, such as the nearest enemy\u2019s location, has also been introduced as an input to the value estimation, for the consideration of stabilizing the policy learning\u00a0(Vinyals et\u00a0al., 2019). As the project proceeded, Contra was continuously improved to satisfy richer featured environment dynamics. However, such an iterative development poses some challenges to the research of open-ended learning in an embodied situation, as the changes in API and environment attributes will make the training be non-stationary. A popular solution to resolve this issue is the surgery introduced by (Berner et\u00a0al., 2019), which significantly reduces training time by maximizing retention of previously learned abilities. Similarly, we leverage surgery in four aspects to ensure the training adapts to the new changes, including model architecture, observation space, action space, and reward functions.\nTable\u00a08 illustrates the main changes we conducted and the corresponding parameters. For the surgery of observation space and model architecture, we have introduced a decoupled encoding in Appendix\u00a0A; for the surgery of action space, we directly extend the policy head in width to satisfy the new action space; for the reward functions, the essentials are to include the newly introduced features which can contribute to the learning, as we introduced in Appendix\u00a0A, a linear combination has been considered to satisfy this requirement.\nIn our experiment, we propose three novel surgery methods, where two for model architecture and one for observation space.\nThe game environment has changed several times since the training started.\nThe changes are mainly about adding player characters, adding player skills, adding weapon, modifying the map, etc.\nFor all these changes, the proportion of new environments in which we train our policy grows slowly from 0%percent00\\%0 % to 100%percent100100\\%100 %.\nIn this case, the variance is relatively small and the performance would quickly recover in the new environment. Figure\u00a05 evaluates the utility of surgery, illustrating the changes in basic value during the training.\nIt can be seen that the values change smoothly for most surgeries.\nMeanwhile, the values remain stable after the surgeries.\nThese results prove the effectiveness of our surgery. The process of fine-tuning the language model is operationalized through a question and answer paradigm. In this framework, we provide the language model with a comprehensive depiction of the present conditions pertaining to the agent, its companions, and adversaries. Additionally, we furnish the model with the linguistic instructions furnished by its teammates. Subsequently, the language model is tasked with generating the agent\u2019s subsequent target meta state in accordance with the specifics outlined in the question and answer dataset, as elucidated in Table\u00a017.\nThe response is generated by GPT-4 and subsequently subjected to parsing and formatting processes facilitated by the rule-based coding mechanism. To ensure alignment between the responses generated by GPT-4 and the targeted meta-state format, a comprehensive prompt engineering endeavor was conducted to establish a set of predetermined rules for GPT-4. The rule-based prompts, which were employed to guide GPT-4\u2019s responses, are meticulously documented in Table\u00a010. 1. Analyze the verbal orders of teammates and players, what do you want to do? According to the command, also analysis the relevant states of teammates and enemies that need attention. The verbal command of the teammate player is \u2018You should lie in wait\u2019, which means teammate player wants the agent to set up an ambush or take a hiding position. 2. Analyze which states of the agents are most relevant to the verbal commands of teammate player. The agents in the unselected states will adjust themselves to complete your plan. According to the teammate\u2018S command: 2.1. Need to hide: \u2018Whether prone position\u2019, \u2018Whether crouch position\u2019 2.2. Reduce movement to stay unnoticed: \u2018Average velocity\u2019, \u2018Length of distance moved\u2019 2.3. Ensure readiness for potential attack: \u2018Whether hold a gun\u2019 3. Plan how these key states need to be adjusted. According to the teammate\u2018S command: 3.1. \u2018Whether prone position\u2019: Need to hide: \u2018False\u2019 -> \u2018True\u2019 3.2. \u2018Whether crouch position\u2019: Alternative hiding posture if not prone: \u2018False\u2019 -> \u2018True\u2019 3.3. \u2018Average velocity\u2019: Reduce movement: \u2018Fast\u2019 -> \u2018Static\u2019 3.4. \u2018Length of distance moved\u2019: Reduce movement: \u2018Short\u2019 -> \u2018No movement\u2019 3.5. \u2018Whether hold a gun\u2019: Ensure readiness for potential attack: \u2018True\u2019 -> \u2018True\u2019 4. Modify the adjustment that may be wrong, and refer to the Rules to analyze which state adjustments may conflict, repeat or be unnecessary, and output the modified adjustment plan: According to the states adjustments in 3: 4.1. \u2018Whether prone position\u2019: \u2018False\u2019 -> \u2018True\u2019 4.2. \u2018Average velocity\u2019: \u2018Fast\u2019 -> \u2018Static\u2019 4.3. \u2018Length of distance moved\u2019: \u2018Short\u2019 -> \u2018No movement\u2019 4.4. \u2018Whether hold a gun\u2019: \u2018True\u2019 -> \u2018True\u2019 (Removed \u2018Whether crouch position\u2019 as it conflicts with \u2018Whether prone position\u2019 and prone position gives better cover for an ambush.) 5. According to the analyze and the planing of the verbal command, further analyze the behavior tendency required in the adjustment process. Mobile: Need to stop all movement: 0% Offense: Must be ready to attack if necessary: 20% Waiting: The main goal is to set up an ambush and wait: 70% Supplies: No need for supplies during this phase: 0% Scouting: Need to observe the surroundings, but not actively scout: 10% 6. Analyze how long the current command needs to be kept. According to the command of the teammate, taking a hiding position or setting up an ambush is usually done with the intention of waiting for an opportune moment to strike or observe the enemy\u2018S movement: The current command needs to be kept by \u2018long term\u2019. 1.Only select the most relevant and necessary states for planning, and the unplanned states will be adjusted by the agent itself 2.[Choose 1, Choose 2, \u2026] indicates the values that can be selected for the state. When you plan, you can only choose the value of the state from it, and do not invent new value not listed in [Choice1, Choice2, \u2026]. 3.The selected state can change the current value or maintain the current value. The agent will try to achieve and maintain the value of the state you choose after you give the plan. 4.Agents don\u2019t voluntarily discard items (for example guns, bullets, medical kits) unless items are reduced or set as False in your plan, so there is no need to keep them, only to choose when making changes. 5.Do not plan and adjust the states of teammates and enemies, they can move freely and cannot be controlled. 6.Avoid conflicts of states planing. For example, agent unable to move quickly when lying down, and unable to see enemies when length of distance from agent to enemy is far away. 7.Avoid the repetition of states planing. For example, if the Average velocity has been adjusted to be Fast, there is no need to adjust the Whether prone position to False, because the agent can automatically adjust state to fit overlapping meanings. 8.When it is necessary to refer to enemy or teammate information for planing, describe the specific state value during analysis. In an effort to mitigate the risk of overfitting our model to concise formatted outputs, thereby preserving its capacity for environmental reasoning, we augmented our dataset with a substantial volume of Chain of Thought data. This augmentation approach entails a systematic procedure whereby the large language model is guided through a step-by-step ideation process, ultimately culminating in the attainment of the intended target state.\nConcretely, our methodology commences with an initial inquiry into the semantic interpretation of the given instruction, followed by the identification of pertinent states, contemplation of state adjustments, analysis of action propensities, and an estimation of the requisite temporal considerations. Comprehensive documentation of the detailed prompts and ensuing responses derived from the Chain of Thought procedure can be found in Tables 16 and 9.\nIt is noteworthy that traditional Chain of Thought processes in existing large language models often generate sequential thoughts, a method characterized by a relatively protracted temporal trajectory. This sequential reasoning approach may not be well-suited to the high real-time demands typically encountered in first-person shooter (FPS) games. Furthermore, the singular-step reasoning capabilities inherent in smaller language models are intrinsically modest and prone to errors. Consequently, the amplification of error probabilities within the Chain of Thought reasoning process may not yield superior outcomes.\nIn light of these considerations, we have undertaken a strategy that amalgamates Chain of Thought data with the final target state data, thereby enhancing the fine-tuning of our language model. In the course of test reasoning exercises, the language model promptly generates the ultimate target state, with the Chain of Thought information being implicitly encoded within the neural network parameters. To cover a comprehensive range of instruction types and state distributions, we generated four types of instruction sets, which, when combined with states sampled from the environment, result in four different datasets. These are the HI (Human Instruction) dataset, constructed based on human-annotated commands; the SI (State Instruction) dataset, built by reverse-generating commands based on state transitions specified by the intelligent agent; the AI (Agent Instruction) dataset, constructed by main kinds of instruction which can be complete by pre-trained Agent; and the RI (Random Instruction) dataset, generated through random sampling of agent state transitions and random commands. Human Instruction Dataset. In this dataset, we generate open-ended instructions manually, while the corresponding states are sampled from the intelligent agent\u2019s interaction logs. These are combined and annotated using GPT-4 based on the prompting method previously described. We found that due to varying frequencies of state changes during the agent\u2019s interactions, some states are difficult to capture comprehensively only using random sampling. To ensure a more comprehensive distribution of states in the data and to facilitate better understanding by the language model, we employ a multi-round rejection sampling approach to construct state set. Let S\ud835\udc46Sitalic_S be the set of states waiting to be sampled. We perform multiple rounds of sampling on S\ud835\udc46Sitalic_S, with Sig\u2062e\u2062tsubscriptsuperscript\ud835\udc46\ud835\udc54\ud835\udc52\ud835\udc61\ud835\udc56S^{get}_{i}italic_S start_POSTSUPERSCRIPT italic_g italic_e italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT representing the set of states sampled in the i\ud835\udc56iitalic_i-th round, initially empty. Next, we sample a state s\ud835\udc60sitalic_s from S\ud835\udc46Sitalic_S without replacement and check whether s\ud835\udc60sitalic_s has any state values not present in Sig\u2062e\u2062tsubscriptsuperscript\ud835\udc46\ud835\udc54\ud835\udc52\ud835\udc61\ud835\udc56S^{get}_{i}italic_S start_POSTSUPERSCRIPT italic_g italic_e italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. If it does, we accept it and add it to Sig\u2062e\u2062tsubscriptsuperscript\ud835\udc46\ud835\udc54\ud835\udc52\ud835\udc61\ud835\udc56S^{get}_{i}italic_S start_POSTSUPERSCRIPT italic_g italic_e italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, otherwise we reject it. Once all states in S\ud835\udc46Sitalic_S have been sampled, one round is completed. Sig\u2062e\u2062tsubscriptsuperscript\ud835\udc46\ud835\udc54\ud835\udc52\ud835\udc61\ud835\udc56S^{get}_{i}italic_S start_POSTSUPERSCRIPT italic_g italic_e italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is the result of i\ud835\udc56iitalic_i-th round\u2019s sampling, and S\ud835\udc46Sitalic_S will be reset for the next round. This sampling method is employed to enhance the comprehensiveness of state coverage in all datasets except the Random Instruction dataset. State Instruction Dataset. In this dataset, we aim to cover a broader range of state changes in the instructions to enhance the language model\u2019s understanding of various state transitions. To achieve this, we design corresponding goals and instructions for all states. Specifically, for each value of each state, we generate a series of instructions that require the corresponding state and value. These are then annotated using GPT-4 based on the prompting methods previously described. The annotated results are checked; if they do not have corresponding states and values, manual annotation and modification are performed to include the relevant states. Agent Instruction. In this dataset, we aim to initially align the planning capabilities of the language model with the pre-trained abilities of an intelligent agent based on reinforcement learning policies. To do so, we generate potential corresponding instructions based on actual state changes in agent interactions. Specifically, we first sample a series of agent state pairs at 5-second intervals. For a subset of these, we manually annotate possible corresponding instructions. We then use these manual annotations as a knowledge base and employ the \"langchain\" method to use these examples to guide the annotation of the remaining data using ChatGPT-3.5. Finally, we represent all the instructions as vectors using OpenAI\u2019s embedding API and perform clustering. We select the 14 most representative types of instructions and pair them cyclically with two rounds of sampled states, ultimately constructing a dataset that better reflects the fundamental execution capabilities of the intelligent agent. Random Instruction. This dataset is primarily designed to enrich the data distribution. It is constructed by randomly generating instructions and fully randomly sampling states, and then annotated using GPT-4 based on the prompting methods previously described. The quantaty of the aforementioned four types of datasets is 507 for HI, 1098 for SI, 1441 for AI and 1382 for RI. Moreover, the test dataset construct instructions that differ from those used in the training data, then utilize GPT-4 to generate draft labels of goals and modified with manually filtered and annotated. This test dataset used for evaluating the model\u2019s ability to plan reasonably in response to instructions.\nAnd the size of dataset for each tuning step is 26,568 for CoT-assited fine-tuning, 4,428 for supervised fine-tuning, and 4,994 for ensembling fine-tuning. To improve the training efficiency, we adopt a distributed training system, shown in Figure\u00a06.\nIn this system, the Actors run over CPU nodes to collect training data, then send the collected data to the Learner which is deployed on a GPU node. We further take a LLM server to enable multiple replicas of LLM for goal generation, which improve the throughput of rollout when the RL training is switch to goal-conditioned cases. The hyperparameters used in our experiment are illustrated in Table\u00a011.\nSome of them are set by following the official implementation of PPO\u00a0(Schulman et\u00a0al., 2017).\nDue to the limitation of compute resource, we did not tune these hyperparameters.\nOther dynamic hyperparameters are introduced their corresponding parts. Algorithm\u00a02 lists the pseudo-code of goal-conditioned RL procedures in Stage I, where Gtb\u2062a\u2062s\u2062i\u2062csubscriptsuperscript\ud835\udc3a\ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc56\ud835\udc50\ud835\udc61G^{basic}_{t}italic_G start_POSTSUPERSCRIPT italic_b italic_a italic_s italic_i italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, Gto\u2062asubscriptsuperscript\ud835\udc3a\ud835\udc5c\ud835\udc4e\ud835\udc61G^{oa}_{t}italic_G start_POSTSUPERSCRIPT italic_o italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and Gtgsubscriptsuperscript\ud835\udc3a\ud835\udc54\ud835\udc61G^{g}_{t}italic_G start_POSTSUPERSCRIPT italic_g end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT represent the basic return, obstacle avoidance return and goal-reaching return from time step t\ud835\udc61titalic_t till the termination, respectively. Inspired by Hindsight Experience Replay (HER) (Andrychowicz et\u00a0al., 2017), we adopt a similar method to utilize the collected trajectories for learning a goal generator GH\u2062E\u2062Rsubscript\ud835\udc3a\ud835\udc3b\ud835\udc38\ud835\udc45G_{HER}italic_G start_POSTSUBSCRIPT italic_H italic_E italic_R end_POSTSUBSCRIPT which accepts a state as input.\nWe conclude its training in two steps:\n(1) constructing (s,g)\ud835\udc60\ud835\udc54(s,g)( italic_s , italic_g ) pairs with collected trajectories as illustrated in LABEL:fig:hindsight_goal_generation;\n(2) supervised training GH\u2062E\u2062Rsubscript\ud835\udc3a\ud835\udc3b\ud835\udc38\ud835\udc45G_{HER}italic_G start_POSTSUBSCRIPT italic_H italic_E italic_R end_POSTSUBSCRIPT with the above pairs and an MSE loss between the labeled goals and predicted goals.\nFor step (1), we split trajectories into many segments with length of 200 timesteps. Then, we randomly sample a state s\ud835\udc60sitalic_s from the first 150 steps and sample a state s\u2032superscript\ud835\udc60\u2032s^{\\prime}italic_s start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT from the last 20 steps to derive a goal g=P\u2062r\u2062o\u2062j\u2062(s\u2032)\ud835\udc54\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc57superscript\ud835\udc60\u2032g=Proj(s^{\\prime})italic_g = italic_P italic_r italic_o italic_j ( italic_s start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ), with a distribution proportional to their basic value V\u2062(s\u2032)\ud835\udc49superscript\ud835\udc60\u2032V(s^{\\prime})italic_V ( italic_s start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ).\nFor step (2), we train GH\u2062E\u2062Rsubscript\ud835\udc3a\ud835\udc3b\ud835\udc38\ud835\udc45G_{HER}italic_G start_POSTSUBSCRIPT italic_H italic_E italic_R end_POSTSUBSCRIPT with s\ud835\udc60sitalic_s, \u0394\u2062t\u0394\ud835\udc61\\Delta troman_\u0394 italic_t, Vb\u2062a\u2062s\u2062i\u2062c\u2062(s)superscript\ud835\udc49\ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc56\ud835\udc50\ud835\udc60V^{basic}(s)italic_V start_POSTSUPERSCRIPT italic_b italic_a italic_s italic_i italic_c end_POSTSUPERSCRIPT ( italic_s ) and Vg\u2062(s)superscript\ud835\udc49\ud835\udc54\ud835\udc60V^{g}(s)italic_V start_POSTSUPERSCRIPT italic_g end_POSTSUPERSCRIPT ( italic_s ) as input to generate goals, where \u0394\u2062t\u0394\ud835\udc61\\Delta troman_\u0394 italic_t the time slot of goal completion, Vg\u2062(s)superscript\ud835\udc49\ud835\udc54\ud835\udc60V^{g}(s)italic_V start_POSTSUPERSCRIPT italic_g end_POSTSUPERSCRIPT ( italic_s ) the goal-achieving value, Vb\u2062a\u2062s\u2062i\u2062c\u2062(s)superscript\ud835\udc49\ud835\udc4f\ud835\udc4e\ud835\udc60\ud835\udc56\ud835\udc50\ud835\udc60V^{basic}(s)italic_V start_POSTSUPERSCRIPT italic_b italic_a italic_s italic_i italic_c end_POSTSUPERSCRIPT ( italic_s ) the basic state value. We evaluate the impact of the rank parameter on performance during Lora fine-tuning of large language model neural networks. Generally speaking, the larger the rank parameter, the more comprehensive and thorough the fine-tuning of the neural network, but the corresponding training time and model footprint will be larger. The experimental results are shown in Table 12. The size of lora rank has little impact on model performance indicators, but a large rank will cause the model training time and the size of the saved parameter file to increase dramatically. We next verified which neural networks in fine-tuning the ChatGLM-6B large language model can achieve the best performance.\nThe experimental results are shown in Table\u00a013.\nIt is worth noting that only fine-tuning the MLP network without fine-tuning the attention network can achieve the best training results.\nAlthough generally speaking, the mainstream fine-tuning task of large language models is to fine-tune the attention layer network, but that task usually focuses more on answer semantics. In our task, we pay more attention to the format to meet the metastate parsing requirements, so fine-tuning the MLP network can achieve better results. We conduct experiments of various models with four percentages of fine-tuning train set, i.e., 100%, 30%, 10%, 3%, on the goal generation task.\nThe results are shown in Table\u00a015.\nIt can be seen that as the amount of data gradually decreases, the performance of various training indicators gradually deteriorates under various settings.\nHowever, the smaller the amount of data, the greater the improvement brought by pre-training of our proposed CoTF method.\nThe results show that the CoTF method we proposed can effectively collect and expand the chain of thought data related to the final goal, thereby avoiding overfitting of the training set in the case of small data. The calculation of the agent feedback reward is multifaceted, aiming to reflect the degree of completion as feedback for the training of the LLM. Specifically, three aspects are considered to satisfy the requirements, and the total agent feedback reward is given by the sum of them: rgfsubscriptsuperscript\ud835\udc5f\ud835\udc53\ud835\udc54r^{f}_{g}italic_r start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT - Minimal Distance to a Goal When Satisfying Environment Termination. As depicted by Equation\u00a07, the agent progressively reduces the distance between the initial state and the goal, scaling it by the magnitude of the initial state-goal difference: rk\u2062e\u2062e\u2062pfsubscriptsuperscript\ud835\udc5f\ud835\udc53\ud835\udc58\ud835\udc52\ud835\udc52\ud835\udc5dr^{f}_{keep}italic_r start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k italic_e italic_e italic_p end_POSTSUBSCRIPT - Reward Indicating How Long the Goal Can Be Kept. As depicted by Equation\u00a08, upon accomplishing the goal, the agent receives a reward proportional to the cumulative number of steps taken to sustain the goal state, scaled by the count of distinct sub-goals between the initial state s0subscript\ud835\udc600s_{0}italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and the goal g\ud835\udc54gitalic_g, i.e. n\u2062(g\u2229P\u2062r\u2062o\u2062j\u2062(s0))\ud835\udc5b\ud835\udc54\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc57subscript\ud835\udc600n(g\\cap Proj(s_{0}))italic_n ( italic_g \u2229 italic_P italic_r italic_o italic_j ( italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) ): rr\u2062n\u2062dfsubscriptsuperscript\ud835\udc5f\ud835\udc53\ud835\udc5f\ud835\udc5b\ud835\udc51r^{f}_{rnd}italic_r start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_r italic_n italic_d end_POSTSUBSCRIPT - Reward Indicating Whether the Generated Goal Satisfies the Projection of the Current State. As shown in Figure\u00a09, an RND network is deployed for the evaluation of a state-goal pair. The calculation of rr\u2062n\u2062dfsubscriptsuperscript\ud835\udc5f\ud835\udc53\ud835\udc5f\ud835\udc5b\ud835\udc51r^{f}_{rnd}italic_r start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_r italic_n italic_d end_POSTSUBSCRIPT indicates that frequently appearing state-goal pairs are feasible, while those that never appear tend to be infeasible in the environment: where \u03c6\u22c6superscript\ud835\udf11\u22c6\\varphi^{\\star}italic_\u03c6 start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT a target network which shares the same architecture as the RND predictor but the network is non-trainable. The examination reward function is introduced as an intrinsic signal to encourage the LLM to generate goals with essential sub-goals. We use the SI dataset as the examination set \u2110Ssubscript\u2110\ud835\udc46\\mathcal{I}_{S}caligraphic_I start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT. For each training iteration, a batch of instructions \u2110t\u2062r\u2062a\u2062i\u2062nsubscript\u2110\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b\\mathcal{I}_{train}caligraphic_I start_POSTSUBSCRIPT italic_t italic_r italic_a italic_i italic_n end_POSTSUBSCRIPT is randomly sampled from the full instruction dataset \u2110\u2110\\mathcal{I}caligraphic_I, and corresponding goals g\ud835\udc54gitalic_g are generated. After the agent finishes its rollout, the examination reward for each batch is computed based on the intersection \u2110\u2229=\u2110S\u2229\u2110t\u2062r\u2062a\u2062i\u2062nsubscript\u2110subscript\u2110\ud835\udc46subscript\u2110\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b\\mathcal{I}_{\\cap}=\\mathcal{I}_{S}\\cap\\mathcal{I}_{train}caligraphic_I start_POSTSUBSCRIPT \u2229 end_POSTSUBSCRIPT = caligraphic_I start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT \u2229 caligraphic_I start_POSTSUBSCRIPT italic_t italic_r italic_a italic_i italic_n end_POSTSUBSCRIPT. For non-empty \u2110\u2229subscript\u2110\\mathcal{I}_{\\cap}caligraphic_I start_POSTSUBSCRIPT \u2229 end_POSTSUBSCRIPT, an examination reward for each instruction in \u2110\u2229subscript\u2110\\mathcal{I}_{\\cap}caligraphic_I start_POSTSUBSCRIPT \u2229 end_POSTSUBSCRIPT is computed as: Then, Resuperscript\ud835\udc45\ud835\udc52R^{e}italic_R start_POSTSUPERSCRIPT italic_e end_POSTSUPERSCRIPT is calculated as Re=1|\u2110\u2229|\u2062\u2211i\u2208\u2110\u2229re\u2062(i,g,gs\u2062u\u2062b|g=L\u2062L\u2062M\u2062(i,s))superscript\ud835\udc45\ud835\udc521subscript\u2110subscript\ud835\udc56subscript\u2110superscript\ud835\udc5f\ud835\udc52\ud835\udc56\ud835\udc54conditionalsubscript\ud835\udc54\ud835\udc60\ud835\udc62\ud835\udc4f\ud835\udc54\ud835\udc3f\ud835\udc3f\ud835\udc40\ud835\udc56\ud835\udc60R^{e}=\\frac{1}{|\\mathcal{I}_{\\cap}|}\\sum_{i\\in\\mathcal{I}_{\\cap}}r^{e}(i,g,g_{%\nsub}|g=LLM(i,s))italic_R start_POSTSUPERSCRIPT italic_e end_POSTSUPERSCRIPT = divide start_ARG 1 end_ARG start_ARG | caligraphic_I start_POSTSUBSCRIPT \u2229 end_POSTSUBSCRIPT | end_ARG \u2211 start_POSTSUBSCRIPT italic_i \u2208 caligraphic_I start_POSTSUBSCRIPT \u2229 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_r start_POSTSUPERSCRIPT italic_e end_POSTSUPERSCRIPT ( italic_i , italic_g , italic_g start_POSTSUBSCRIPT italic_s italic_u italic_b end_POSTSUBSCRIPT | italic_g = italic_L italic_L italic_M ( italic_i , italic_s ) ). The formatting reward for each generated goal is calculated by computing an edit distance, utilizing the Wagner-Fischer algorithm\u00a0(Wagner & Fischer, 1974). With the defined reward functions, RLAF is applied with a reward function R=Rf+Re+Rm\ud835\udc45superscript\ud835\udc45\ud835\udc53superscript\ud835\udc45\ud835\udc52superscript\ud835\udc45\ud835\udc5aR=R^{f}+R^{e}+R^{m}italic_R = italic_R start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT + italic_R start_POSTSUPERSCRIPT italic_e end_POSTSUPERSCRIPT + italic_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT and Proximal Policy Optimization (PPO) for each data point in a batch. In order to complete the command \u2018You should lie in wait\u2019, let us plan the states of the agent step by step using the following template: 1. Analyze the verbal orders of teammates and players, what do you want to do? According to the command, also analysis the relevant states of teammates and enemies that need attention. The verbal command of the teammate player is [Command], which means teammate player wants the agent\u2026 2. Analyze which states of the agents are most relevant to the verbal commands of teammate player. The agents in the unselected states will adjust themselves to complete your plan (analyze the reason first, then select key states one by one as few as possible and as important as possible according to the degree of importance)? According to the teammate\u2019s command: 2.1. [Reason1]: [State1] 2.2. [Reason2]: [State2] \u2026 3. Plan how these key states need to be adjusted (analyze the reason first, and then make adjustments one state by one state, the state can be changed or remain the same, and must be selected from the value range of the game state [Choice 1, Choice 2, \u2026])? According to the teammate\u2019s command: 3.1. [State1]: [Reason1]: [Current_value1] ->[Target_value2] 3.2. [State2]: [Reason2]: [Current_value1] ->[Target_value2] \u2026 4. Modify the adjustment that may be wrong, and refer to the Rules to analyze which state adjustments may conflict, repeat or be unnecessary, and output the modified adjustment plan: According to the states adjustments in 3\u2026 4.1. [State1]: [Current_value1] ->[Target_value2] 4.2. [State2]: [Current_value1] ->[Target_value2] \u2026 5. According to the analyze and the planing of the verbal command, further analyze the behavior tendency required in the adjustment process (the proportion of Mobile, Offense, Waiting, Supplies, Scouting, first analyze the reason, and then calculate the percentage) Mobile: [Reason1]: [Percent1] Offense: [Reason2]: [Percent2] Waiting: [Reason3]: [Percent3] Supplies: [Reason4]: [Percent4] Scouting: [Reason5]: [Percent5] 6. Analyze how long the current command needs to be kept (for example, the command of \u2018killing the enemy\u2019 needs to be kept for a \u2018short term\u2019, and the command of \u2018pay attention to reconnaissance\u2019 needs to be kept for a \u2018long term\u2019. First analyze the reason and then make a judgment). According to the command of the teammate, [Analysis]: The current command needs to be kept by \u2018[XX term]\u2019. If you see phrases like [Context] in answer template, replace the entire phrase according to the meaning of the Context, do not repeat the content; make analogy expansion for \u2018\u2026\u2019; keep \u2018:\u2019; absolutely do not modify others in template."
    },
    {
        "id": 5,
        "title": "Turing\u2019s Test, a Beautiful Thought Experiment",
        "corpus": "In the wake of large language models, there has been a resurgence of claims and questions about the Turing test and its value for AI, which are reminiscent of decades of practical \u201cTuring\u201d tests. If AI were quantum physics, by now several \u201cSchr\u00f6dinger\u2019s\u201d cats could have been killed. Better late than never, it is time for a historical reconstruction of Turing\u2019s beautiful thought experiment. In this paper I present a wealth of evidence, including new archival sources, give original answers to several open questions about Turing\u2019s 1950 paper, and address the core question of the value of Turing\u2019s test. In recent decades, the Turing test has been used as a practical experiment for publicity purposes and aptly criticized (Shieber, 1994a, b; Vardi, 2014), and has been the whipping boy of AI (Hayes and Ford, 1995), cognitive sciences and analytic philosophy (Shieber, 2004), and increasingly, with the rise of AI, the humanities and social sciences (Brynjolfsson, 2022). It is not uncommon for criticism coming from all these areas to take Turing\u2019s test literally, assuming that he encouraged deception as a criterion and/or proposed a crucial experiment to establish the existence of machine intelligence. Now, in the wake of large language models, science and technology outlets ask whether Turing\u2019s test can be a \u2018benchmark\u2019 for AI (Biever, 2023), and whether it is \u2018dead\u2019 (Wells, 2023).\nBased on recent primary research (Gon\u00e7alves, 2023e, a, b, c, d), in this paper I present a mass of evidence, including newly discovered archival sources, and a new perspective on Turing\u2019s test. I address a few problems that we will keep track as we go along: (P1subscript\ud835\udc431P_{1}italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT) Why would Turing design a test based on imitation, which can be seen as encouraging deception? (P2subscript\ud835\udc432P_{2}italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT) Why to present multiple versions of a test, as opposed to a well-defined, controlled experiment? (P3subscript\ud835\udc433P_{3}italic_P start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT) Why gender imitation in a test of machine intelligence, and why conversation for an intelligence task? (P4subscript\ud835\udc434P_{4}italic_P start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT) Why are practical \u201cTuring\u201d tests circular, as Hayes and Ford (Hayes and Ford, 1995) claimed? Finally, the core problem, (P5subscript\ud835\udc435P_{5}italic_P start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT) What is the value of Turing\u2019s test for AI? Section\u00a02 presents a reading of Turing\u2019s 1950 paper. Section\u00a03 introduces newly discovered archival sources and examines Turing\u2019s concept of imitation, addressing P1subscript\ud835\udc431P_{1}italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Section\u00a04 shows that his presentation of the imitation game fits \u201cthe basic method of thought experiments\u201d (Mach, 1897), addressing P2subscript\ud835\udc432P_{2}italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Section\u00a05 reconstructs the historical conditions of Turing\u2019s proposal, addressing P3subscript\ud835\udc433P_{3}italic_P start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. Section\u00a06 draws a parallel with the history of \u201cthe most beautiful experiment in the history of science\u201d (Palmieri, 2005), addressing P4subscript\ud835\udc434P_{4}italic_P start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT. Finally, Section\u00a07 revisits the history of AI, addressing P5subscript\ud835\udc435P_{5}italic_P start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT, and Section\u00a08 concludes the paper. In 1950, Alan Turing (Fig.\u00a01)\npublished the second of his three seminal papers, \u2018Computing machinery and intelligence\u2019 (Turing, 1950).\nThe text has 27 pages, divided into seven sections, \u00a71 to \u00a77. Three main logical steps can be identified in his argument: the proposal (\u00a71 to \u00a73), the science (\u00a74 to \u00a75), and the discussion (\u00a76 to \u00a77). The proposal sought to replace the question \u201cCan machines think?,\u201d which he considered \u201ctoo meaningless to deserve discussion\u201d (p.\u00a0442),111Turing was coming from unstructured multidisciplinary debates in at least two editions of a seminar, \u201cMind and Machine,\u201d held at the Philosophy Department of Manchester University in October and December, 1949. Of the latter, one participant wrote in a Christmas postcard sent to Warren McCulloch: \u201cI wish you had been with us a few days ago we had an amusing evening discussion with Thuring [sic], Williams, Max Newman, Polyani [sic], Jefferson, J Z Young & myself \u2026\u2026\\ldots\u2026 An electronic analyser and a digital computer (universal type) might have sorted the arguments out a bit.\u201d Jules Y. Bogue to McCulloch, c. December 1949. American Philosophical Society, Warren S. McCulloch Papers, Mss.B.M139_005. Thanks to J. Swinton for this archival finding.\nwith the imitation game.\nThe purpose was to change the common meaning of the word \u2018machine\u2019 (e.g., a steam engine, a bulldozer) in light of the new mathematical science of \u2018universal\u2019 digital computing. The imitation game would allow for a grounded discussion of \u2018machine\u2019 and \u2018thinking,\u2019 seeking to expand the meaning of \u2018thinking\u2019 and detach it from the human species, much as the meaning of \u2018universe\u2019 was once detached from the Earth. In 1950, one of the OED definitions of \u2018machine\u2019 was:222New English Dictionary. Oxford, Vol. VI, Part II, M-N, p.\u00a07.\n\u201ca combination of parts moving mechanically as contrasted with a being having life, consciousness and will \u2026\u2026\\ldots\u2026 Hence applied to a person who acts merely from habit or obedience to a rule, without intelligence, or to one whose actions have the undeviating precision and uniformity of a machine.\u201d\nThus, by definition, common sense did not allow the meanings of \u2018machine\u2019 and \u2018thinking\u2019 to overlap. Despite Turing\u2019s emphasis in his opening paragraph that he did not intend to discuss how these words were \u201ccommonly used\u201d (p.\u00a0433), the hostility to his proposal can be seen from one of the first reactions, from a participant in the 1949 Manchester seminars, who quoted the above OED definition to appeal to common sense (Mays, 1952). The new question, which Turing considered to have a \u201cmore accurate form\u201d (Turing, 1950, p.\u00a0442), would be based on a vivid image, his \u201ccriterion for \u2018thinking\u201d\u2019 (p.\u00a0436), which he called interchangeably the \u2018imitation game\u2019 and his \u2018test.\u2019333For Turing\u2019s exact references to his test in all known sources, see (Gon\u00e7alves, 2023e, p.\u00a02).\nThe new question is whether a machine, playing A, the deceiver, can imitate a woman, a man, a human being, or another machine, playing B, the assistant, in a remotely played conversation game, and deceive an average interrogator, playing C, the judge, about its machine condition. However, the details and exact conditions of the imitation game as an experiment slipped through Turing\u2019s text in a series of variations that defies interpretation. A structural reading of the text identifies four different conditions of the game with respect to players A-B, namely, man-woman (p.\u00a0433), machine-woman (p.\u00a0434), machine-machine (p.\u00a0441), and machine-man (p.\u00a0442).\nThese different conditions relate to four variants of the \u201cnew\u201d question that Turing posed to replace his \u201coriginal\u201d question (see Box\u00a01).\nIn addition to varying the genus/species (types) of the players, he also increased the storage and speed of the machine and provided it with a hypothetically appropriate program (Q\u2032\u2032\u2032superscript\ud835\udc44\u2032\u2032\u2032Q^{\\prime\\prime\\prime}italic_Q start_POSTSUPERSCRIPT \u2032 \u2032 \u2032 end_POSTSUPERSCRIPT), and suggested a base time for the interrogation session (Q\u2032\u2032\u2032\u2032superscript\ud835\udc44\u2032\u2032\u2032\u2032Q^{\\prime\\prime\\prime\\prime}italic_Q start_POSTSUPERSCRIPT \u2032 \u2032 \u2032 \u2032 end_POSTSUPERSCRIPT). Other seemingly relevant parameters were not mentioned, such as the number of interrogators used to arrive at a statistically sound conclusion, although their profile is mentioned \u2014 they should be \u201caverage\u201d \u2014, and later reiterated \u2014 they \u201cshould not be expert about machines.\u201d444\u2018Can automatic calculating machines be said to think?\u2019, Broadcast on BBC Third Programme, 14 and 23 Jan. 1952. Archives Centre, King\u2019s College, Cambridge, AMT/B/6. Because the machine must imitate stereotypes of what it is not,\nTuring\u2019s proposal has often been criticized for encouraging fakes and tricks. But this is part of the literal reading that Turing would have meant his test as a practical experiment about short conversations, gendered machines, and how to fine-tune them to fool average human interrogators. It misses the point of Turing\u2019s irony (Gon\u00e7alves, 2023b) and that his notion of imitation in 1950 was largely in continuity with his 1936 paper (Turing, 1936), as hinted at in his 1947 lecture,555\u2018Lecture to L.M.S. Feb. 20 1947.\u2019 Archive Centre, King\u2019s College, Cambridge, AMT/B/1.\nand as newly discovered correspondence with the Mexican-Canadian computer pioneer Beatrice Worsley (1921-1972) helps to clarify (see Box\u00a02). In his letter to Worsley, Turing seems to be more interested in the relations between \u201cthe motions\u201d of Turing machines and infinite computers, whose behavior can be non-periodic. Perhaps he thought of the living human brain as an infinite computer, in the sense that it has a continuous interface with its environment, which constantly intervenes and changes its logical structure.666Cf. \u201cIntelligent Machinery\u201d, written in 1948 as a technical report to the National Physical Laboratory. Archives Centre, King\u2019s College, Cambridge, AMT/C/11.\nNow, the imitation game puts into empirical form the relation between digital computers, whose behavior is ultimately periodic, and the behavior of the human players. Can the behavior of their brains be approximated by a digital computer? Turing pursued this question. For his May 1951 broadcast, he wrote: \u201cthe view which I hold myself, that it is not altogether unreasonable to describe digital computers as brains \u2026\u2026\\ldots\u2026 If it is accepted that real brains, as found in animals, and in particular in men, are a sort of machine it will follow that our digital computer, suitably programmed, will behave like a brain.\u201d777\u2018Can digital computers think?\u2019, broadcast on BBC Third Programme, 15 May 1951. Archives Centre, King\u2019s College, Cambridge, AMT/B/5. Even if the human brain can only be compared to an infinite computer, could it not be simulated by a digital computer equipped with a sufficiently large memory? An excerpt of another newly discovered Turing letter to Worsley from mid-1951 can give more contour and provide further insight into Turing\u2019s views (see Box\u00a03). A highlight in this excerpt is Turing\u2019s view that to the extent that the behavior of a neuron can be described as a stochastic process, it would be possible to \u201ccalculate random samples\u201d of the mechanism that embodies the brain and then imitate it.999Note the connection with the imitation game and his wartime experience studying and imitating the behavior of the Enigma machines used by the Nazi forces (Hodges, 1983).\nAn effective imitation of the brain by a machine would require knowledge of the anatomy and physiology of the brain to inspire an appropriate program, as well as much more storage and speed than was available to the Ferranti Mark I at the time (see Fig.\u00a02).\nAnother important element in the excerpt is Turing\u2019s point that, even if a thinking machine is possible, the relation he has in mind is not one of identity but one of analogy: \u201cIt\u2019ll just be another species of the thinking genus.\u201d An original answer to problem P1subscript\ud835\udc431P_{1}italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, why design a test based on imitation, which can be seen as encouraging deception, is as follows. Actually, imitation was Turing\u2019s fundamental principle of the new science of universal digital computing. He conceived his 1950 paper largely in continuity with his 1936 paper. Both were based on his core concepts of machine and imitation, i.e., what it takes for a machine to imitate another machine. A point of difference is that by 1950 he had generalized the machine architecture and how \u2018universal\u2019 imitation can be achieved. Using Turing\u2019s 1948 language,101010\u201cIntelligent Machinery,\u201d op. cit.\nuniversality can be achieved by starting with an \u2018organized\u2019 machine (1936), or with an \u2018unorganized\u2019 machine (1948/1950). Whereas in 1936 the machine would be given an a priori, well-defined and fixed table of instructions for each task, in 1950 it would also be capable of performing a new task by changing its logical structure as a result of learning from experience, much as the brain does, \u201cby changing its neuron circuits by the growth of axons and dendrites.\u201d111111Turing to Ross Ashby, circa November 19, 1946. British Library, Collection \u2018W. Ross Ashby: correspondence of W. Ross Ashby\u2019, Add MS 89153/26. The kind of forgery and trickery that occurs in commercial and publicity-based practical \u201cTuring\u201d tests has nothing to do with Turing\u2019s 1950 proposal. In 1951, he warned: \u201cIt would be quite easy to arrange the [machine\u2019s] experiences in such a way that they automatically caused the structure of the machine to build up into a previously intended form, and this would obviously be a gross form of cheating, almost on a par with having a man inside the machine.\u201d121212\u2018Intelligent machinery, a heretical theory\u2019, a lecture given to \u201851 Society\u2019 at Manchester, c. 1951. Archives Centre, King\u2019s College, Cambridge, AMT/B/4.\nThe \u201chuman fallibility\u201d that Turing encouraged the machine to show was meant to be a by-product of learning from experience. This 1950 passage clarifies:\n\u201cAnother important result of preparing our machine for its part in the imitation game by a process of teaching and learning is that \u2018human fallibility\u2019 is likely to be [mimicked] in a rather natural way, i.e., without special \u2018coaching\u2019\u2006\u201d (Turing, 1950, p.\u00a0459). That is, for a machine to be a valid player of Turing\u2019s test, it cannot be specially prepared for it. This means that we have never seen a practical Turing test. The various rhetorical questions Turing posed, Q\u2032\u2062\u2026\u2062Q\u2032\u2032\u2032\u2032superscript\ud835\udc44\u2032\u2026superscript\ud835\udc44\u2032\u2032\u2032\u2032Q^{\\prime}\\ldots Q^{\\prime\\prime\\prime\\prime}italic_Q start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2026 italic_Q start_POSTSUPERSCRIPT \u2032 \u2032 \u2032 \u2032 end_POSTSUPERSCRIPT, to replace the original question, Q\ud835\udc44Qitalic_Q, can be generalized as follows (Gon\u00e7alves, 2023e): Question Q\u22c6superscript\ud835\udc44\u22c6Q^{\\star}italic_Q start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT: could player A imitate intellectual stereotypes associated with player B\u2019s type successfully (well enough to deceive player C), despite A and B\u2019s physical differences? It has been largely unnoticed that the various questions instantiating Q\u22c6superscript\ud835\udc44\u22c6Q^{\\star}italic_Q start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT follow a case-control methodology, applied in two stages.\nAt the more obvious intra-game level, A plays the case, and B plays the control. However, at the inter-game level, two variants set the case (machine-woman and the machine-man) and the other two set the control (man-woman and the machine-machine). While the first two are open, creating suspense around the test, the latter two are resolved as follows.\nIt is known that a man (A) can possibly imitate gender stereotypes associated with a woman (B) to successfully deceive an interrogator (C) despite their physical differences. This is the very premise of the parlor games that existed at the time. Further, regarding the machine-machine variant, it is also known that a digital computer (A), because of its universality property, as Turing explained in the paper (Turing, 1950, \u00a7\u00a74, 5), can successfully imitate any discrete-state machine (B), despite their physical differences. We can now explore how Turing\u2019s presentation of his test conforms to Ernst Mach\u2019s conception of \u201cthe basic method of thought experiments,\u201d which is variation, continuously if possible.\nMach is the author of perhaps the most classic text on thought experiments in the modern scientific tradition (Mach, 1897), in which he developed keen observations and insights based on countless examples from the history of modern physics, mathematics, and common sense experience. He wrote: \u201cBy varying the conditions (continuously if possible), the scope of ideas (expectations) tied to them is extended: by modifying and specializing the conditions we modify and specialize the ideas, making them more determinate, and the two processes alternate\u201d (p.\u00a0139).\nMach illustrated his point with the process of discovery of universal gravitation (Mach, 1897, pp. 138-139): A stone falls to the ground. Increase the stone\u2019s distance from the earth, and it would go against the grain to expect that this continuous increase would lead to some discontinuity. Even at lunar distance the stone will not suddenly lose its tendency to fall. Moreover, big stones fall like small ones: the moon tends to fall to the earth. Our ideas would lose the requisite determination if one body were attracted to the other but not the reverse, thus the attraction is mutual and remains so with unequal bodies, for the cases merge into one another continuously \u2026\u2026\\ldots\u2026 discontinuities are quite conceivable, but it is highly improbable that their existence would not have betrayed itself by some experience. Besides, we prefer the point of view that causes less mental exertion, so long as it is compatible with experience. The conditions, i.e., the distance of the fall and the size of the stones, are continuously varied in the physicist\u2019s mind and eventually stretched to the celestial scale. Reciprocally, the concept of a celestial body, such as the Earth or the Moon, becomes interchangeable with the concept of a stone, and quite unequal stones can then become mutually attracted. The cases continuously merge into one another, and a conceptual integration is established that connects near-earth bodies to celestial bodies under a unified concept. Turing\u2019s imitation game extended the scope of ideas and expectations established earlier in his 1936 paper, moving from machine-machine and restricted human-machine imitation in 1936151515\u201cWe may compare a man in the process of computing a real number to a machine which is only capable of a finite number of conditions\u201d (Turing, 1936, p.\u00a0231).\nto more general human-machine imitation in 1950. To understand this better, let us take a brief look at Turing\u2019s 1948 report \u201cIntelligent Machinery\u201d (op. cit.).\nIn section (\u00a73) \u2018Varieties of machinery,\u2019 he noted: \u201cAll machinery can be regarded as continuous, but when it is possible to regard it as discrete it is usually best to do so.\u201d\nA brain, he wrote, \u201cis probably\u201d a \u2018continuous controlling\u2019 machine, but in light of the digital nature of neural impulses, it \u201cis very similar to much discrete machinery.\u201d\nIn section (\u00a76) \u2018Man as Machine,\u2019 he referred to the imitation of \u201cany small part of a man\u201d by machines: \u201cA great positive reason for believing in the possibility of making thinking machinery is the fact that it is possible to make machinery to imitate any small part of a man\u201d (p.\u00a0420). In light of this, he argued:\n\u201cOne way of setting about our task of building a \u2018thinking machine\u2019 would be to take a man as a whole and to try to replace all the parts of him by machinery.\u201d But Turing dismissed such a method as \u201caltogether too slow and impracticable,\u201d and later alluded to moral and aesthetic reasons as well.161616For the May 1951 broadcast (op. cit.), he wrote: \u201cI certainly hope and believe that no great efforts will be put into making machines with the most distinctively human, but non-intellectual characteristics such as the shape of the human body; it appears to me to be quite futile to make such attempts and their results would have something like the unpleasant quality of artificial flowers.\u201d We can now follow Turing\u2019s use of the method of continuous variation in the design of his imitation tests. The essential question (Q\u22c6superscript\ud835\udc44\u22c6Q^{\\star}italic_Q start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT) Turing asks is whether the intellectual and cultural performances (the stereotypes)171717S. Sterrett first emphasized the importance of stereotypes in the imitation game (Sterrett, 2000).\nassociated with woman, man, machine (the types) could be imitated, and thus softly transposed.\nNote that for any arbitrarily chosen type, say, a woman, further specific subtypes can be continuously conceived and considered as varied conditions of the imitation game: women having property p\ud835\udc5dpitalic_p, women having subproperty p\u2032\u2282psuperscript\ud835\udc5d\u2032\ud835\udc5dp^{\\prime}\\subset pitalic_p start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2282 italic_p, and so on. For any two arbitrarily chosen types, a new type can be conceived, whether as a specialization or a modification (\u201cany small part of a man\u201d). Because concepts are fluid entities, there is an evolving continuum of levels and types. The question across the various versions of the game can be posed this way: how does C\u2019s perception of A\u2019s performance against B\u2019s performance change as the game\u2019s conditions are (continuously) varied?\nWill it change if gendered verbal behavior is required as a subtype of human verbal behavior? Will it change if the machine\u2019s hardware is increased and/or its learning program is modified?\nFor Turing, there is no conceptual discontinuity among the various conditions that instantiate his thought experiment. From 1948 to 1952, Turing presented various imitation tests based on both the game of chess and conversation. A historically sound problem, because it does not struggle with the materiality of Turing\u2019s texts and their chronological coherence, does not erase some of his tests in favor of others, does not ignore the historical conditions of his proposal, is (P2subscript\ud835\udc432P_{2}italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT) Why would Turing present multiple versions of his test, as opposed to a well-defined, controlled experiment? I have presented an answer by reconstructing Turing\u2019s use of the method of thought experiments, and this will be reinforced in the next section. Turing\u2019s purpose in his 1950 paper was not to propose a \u2018benchmark\u2019 for the non-existent field of AI, but to respond to critics. Especially in 1949, he felt compelled to point out that the new science of universal digital computing would eventually have an impact and expand our view of \u2018thinking.\u2019 As is often the case with thought experiments, Turing proposed his test out of a controversy (Gon\u00e7alves, 2023d). He was coming from his continuing disputes with the physicist and computer pioneer, Fellow of the Royal Society (FRS), Douglas Hartree (1897-1958), over the meaning of the newly existing digital computers, which had started in 1946 (Gon\u00e7alves, 2023c). Now, in mid-1949, new opponents had arrived, notably the neurosurgeon Geoffrey Jefferson (1886-1961), and the chemist and philosopher Michael Polanyi (1891-1976), both also FRS and based at the same institution as Turing, the University of Manchester, where Turing had spent a year as a Reader in the Department of Mathematics (Hodges, 1983).\nThese three thinkers challenged Turing\u2019s claims about the future possibilities and limitations of digital computers. In June 1949, Hartree published his Calculating Instruments and Machines (Hartree, 1949), in which Ada Lovelace\u2019s work was acknowledged seemingly for the first time by a twentieth-century computer pioneer (Gon\u00e7alves, 2023c). Since November 1946, Hartree had been opposing the use of the term \u2018electronic brain.\u2019 He wrote in a letter to the Times: \u201cThese machines can only do precisely what they are instructed to do by the operators who set them up.\u201d181818\u201cThe \u2018Electronic Brain\u2019: A Misleading Term; No Substitute for Thought,\u201d Times, November 7, 1946.\nNow in 1949, Hartree added strength to his argument by quoting the words of Ada Lovelace from the 1840s about Charles Babbage\u2019s machine: \u201cThe Analytical Engine has no pretensions to originate anything \u2026\u2026\\ldots\u2026 It can do whatever we know how to order it to perform\u201d (her emphasis) (Hartree, 1949, p.\u00a070). Noting Hartree\u2019s anachronism in taking Lovelace\u2019s words out of their time and place, Turing further developed his earlier, 1947 response to Hartree\u2019s challenge,191919\u2018Lecture to L.M.S. Feb. 20 1947\u2019, op. cit., p.\u00a022.\nnow calling it \u2018(6) Lady Lovelace\u2019s objection\u2019 (Turing, 1950, p.\u00a0450). Turing argued that intelligent behavior is the result of learning, a capability he had no problem attributing to future digital computers.\nHe also questioned the implicit assumption of Hartree\u2019s challenge: \u201cWho can be certain that \u2018original work\u2019 that he has done was not simply the growth of the seed planted in him by teaching, or the effect of following well-known general principles\u201d (p.\u00a0450).\nIn the imitation game, Turing suggested, the interrogator would be able to evaluate the machine\u2019s ability to learn: \u201cThe game (with the player B omitted) is frequently used in practice under the name of viva voce to discover whether some one really understands something or has \u2018learnt it parrot fashion\u2019\u2006\u201d (p.\u00a0446). But then we might ask, what is player B doing in the imitation game? Following the 1949 events will suggest an answer. On June 9, in London, Jefferson delivered his prestigious Lister Oration on \u2018The Mind of Mechanical Man,\u2019 which was published in the debuting British Medical Journal on June 25 (Jefferson, 1949). His lecture was headlined in the Times on June 10,202020\u2018No Mind For Mechanical Man.\u2019 Times, 10 June 1949, p. 2.\nemphasizing his claim that \u201cNot until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt, and not by the chance fall of symbols, could we agree that machine equals brain\u201d (p.\u00a01110).\nThis rendered Turing\u2019s famous response: \u201cI do not think you can even draw the line about sonnets, though the comparison is perhaps a little bit unfair because a sonnet written by a machine will be better appreciated by another machine.\u201d212121\u2018The Mechanical Brain.\u2019 Times, 11 June 1949, p. 4.\nIn October and December 1949, two seminars on \u2018Mind and Machine\u2019 were organized by Polanyi et al., and attended by Jefferson, Turing et al., at the Philosophy Department in Manchester (Polanyi, 1958, p.\u00a0275; cf.\u00a0also\u00a0note\u00a01\u00a0above). These seminar discussions, followed by Jefferson giving Turing an offprint of his Lister Oration,222222This may have happened in the evening of the December meeting of the Manchester seminar (op. cit.), when, according to a later letter from Jefferson to Ethel S. Turing, Turing and J.Z. Young went to dinner at Jefferson\u2019s house (Turing, 1959, p.\u00a0xx).\nwhich Turing read and marked with a pencil,232323Off-print, \u2018The mind of mechanical man\u2019 by Geoffrey Jefferson. Archives Centre, King\u2019s College, Cambridge, AMT/B/44.\nled him to write his 1950 paper and propose his test (Gon\u00e7alves, 2023d). In his Lister Oration (Jefferson, 1949), Jefferson had characterized intelligence as an emergent property of the animal nervous system.\nHe emphasized that \u201csex hormones introduce peculiarities of behaviour often as inexplicable as they are impressive\u201d (p.\u00a01107).\nBecause \u201cmodern automata\u201d are not moved by male and female sex hormones, they could not exhibit such peculiarities to imitate the actions of animals or \u2018men.\u2019 Specifically, he used a thought experiment to criticize Grey Walter\u2019s mechanical turtles by suggesting that gendered behavior is causally related to the physiology of sex hormones (ibid.): [\u2026It] should be possible to construct a simple animal such as a tortoise (as Grey Walter ingeniously proposed) that would show by its movements that it disliked bright lights, cold, and damp, and be apparently frightened by loud noises, moving towards or away from such stimuli as its receptors were capable of responding to.\nIn a favourable situation the behaviour of such a toy could appear to be very lifelike \u2014 so much so that a good demonstrator might cause the credulous to exclaim \u2018This is indeed a tortoise.\u2019 I imagine, however, that another tortoise would quickly find it a puzzling companion and a disappointing mate. Jefferson thus brought forward the image of a genuine individual of a kind, which is placed side by side with the artificial one so that the latter\u2019s artificiality is emphasized. The function of the genuine individual is to expose the artificiality of the impostor. The means of exposure is to fail at demonstrating interesting (sexual) behavior. This can explain Turing\u2019s introduction of a (gendered) control player B, who appears in Turing\u2019s 1950 test, whose design was prompted by his reading of Jefferson, but not in Turing\u2019s 1948, 1951, and 1952 tests. In discussing \u201c(4) The Argument from Consciousness,\u201d Turing addressed Jefferson directly and quoted in full his conditions for agreeing \u201cthat machine equals brain,\u201d including \u201cbe warmed by flattery\u201d and \u201cbe charmed by sex\u201d (Turing, 1950, pp.\u00a0445-446).\nIn discussing the \u201c(5) Argument from Various Disabilities,\u201d Turing again mentioned Jefferson and argued that to say that a machine could never \u201cfall in love\u201d or \u201cmake someone fall in love with it\u201d was a flawed scientific induction from the capabilities of present machines. Thus, an answer to the first part of problem P3subscript\ud835\udc433P_{3}italic_P start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, why gender imitation in a test of machine intelligence, is that Turing\u2019s design of his test was an ironic response to Jefferson\u2019s association of sex and gender with intelligence, particularly his suggestion that gendered behavior is causally related to the physiology of male and female sex hormones.\nIt remains to address the second part of problem P3subscript\ud835\udc433P_{3}italic_P start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, why Turing chose conversation as the intelligence task of his test. Surviving minutes of the \u2018Mind and Machine\u2019 seminar held on October 27, 1949, were published in 2000 by a participant, Wolfe Mays.242424W. Mays, \u2018Turing and Polanyi on minds and machines.\u2019 Appraisal, 3(2), 55-62. Andrew Hodges also published it on his website: https://www.turing.org.uk/sources/wmays1.html. Accessed December 6, 2023.\nIn the first session, Polanyi presented a statement, \u2018Can the mind be represented by a machine?,\u2019252525Polanyi, Michael. Papers, Box 22, Folder 19, Hanna Holborn Gray Special Collections Research Center, University of Chicago Library.\nwhich was a G\u00f6delian argument that humans can do things that machines cannot. Although Turing had already addressed this argument in his 1947 lecture (op. cit.), Polanyi\u2019s insistence may help explain Turing\u2019s inclusion of \u201c(3) The Mathematical Objection\u201d (Turing, 1950). Further, the minutes (op. cit.) show that Polanyi tried to distinguish the formal \u201crules of the logical system\u201d from the informal \u201crules which determine our own behaviour,\u201d and this helps explain Turing\u2019s inclusion of \u201c(8) The Argument from Informality of Behaviour\u201d (Turing, 1950). Years later (Polanyi, 1958, p.\u00a0275), Polanyi remembered \u201ca communication to a Symposium held on \u2018Mind and Machine\u2019 at Manchester University in October, 1949,\u201d in which \u201cA.M. Turing has shown\nthat it is possible to devise a machine which will both construct and assert as new axioms an indefinite sequence of G\u00f6delian sentences.\u201d262626Polanyi added that \u201cthis is foreshadowed\u201d in Turing\u2019s 1938 paper based on his Ph.D. thesis, \u2018Systems of Logic Based on Ordinals,\u2019 J. London Math. Soc. s2-45(1), 161-228.\nPolanyi resumed, showing that he assimilated the punch: \u201cAny heuristic process of a routine character\u2014for which in the deductive sciences the G\u00f6delian process is an example\u2014could likewise be carried out automatically.\u201d\nHowever, Polanyi used the same argument to dismiss the game of chess as a testbed for machine intelligence, noting: \u201cA routine game of chess can be played automatically by a machine, and indeed, all arts can be performed automatically to the extent to which the rules of the art can be specified.\u201d Chess, not conversation, had been Turing\u2019s chosen field to illustrate, develop, and test machine intelligence since at least February 1946.272727\u2018Proposed electronic calculator,\u2019 February 1946. Archives Centre, King\u2019s College, Cambridge, AMT/C/32. On p.\u00a016, Turing asks: \u201cCan the machine play chess?\u201d\nIn his 1948 \u2018Intelligent Machinery\u2019 report (op. cit.), Turing had discussed a tradeoff between convenient and impressive intellectual fields for exploring machine intelligence. After discussing \u201cvarious games e.g. chess,\u201d Turing wrote: \u201cOf the above possible fields the learning of languages would be the most impressive, since it is the most human of these activities.\u201d\nHowever, he avoided language learning because it seemed \u201cto depend rather too much on sense organs and locomotion to be feasible,\u201d stuck with chess, and ended up describing a chess-based imitation game.\nNow in October 1949, he saw chess being dismissed as an unimpressive to make the case for machine intelligence because its rules could be specified. Some time later, probably around Christmas 1949, Turing will read Jefferson\u2019s Lister Oration (Jefferson, 1949) and mark the passage quoting Ren\u00e9 Descartes (p.\u00a01106), which starts: \u201cDescartes made the point, and a basic one it is, that a parrot repeated only what it had been taught and only a fragment of that; it never used words to express its own thoughts.\u201d Overall, Jefferson suggested \u2018speech\u2019 to be the distinguishing feature of human intelligence compared to other kinds of animal intelligence: \u201cGranted that much that goes on in our heads is wordless \u2026\u2026\\ldots\u2026 we certainly require words for conceptual thinking as well as for expression \u2026\u2026\\ldots\u2026 It is here that there is the sudden and mysterious leap from the highest animal to man, and it is in the speech areas of the dominant hemisphere \u2026\u2026\\ldots\u2026 that Descartes should have put the soul, the highest intellectual faculties\u201d (p.\u00a01109). Unlike chess, which is governed by definite rules, good performance in conversation cannot be easily specified. Turing\u2019s 1950 choice for \u2018the learning of languages\u2019 as the intellectual field addressed in his test can be best understood as yet another concession to Jefferson and, in this case, to Polanyi as well. In summary, Turing varied the design of his imitation tests to respond to the challenges posed by Hartree, Polanyi, and Jefferson. This fits neatly into Popper\u2019s methodological rule for \u201cthe use of imaginary experiments in critical argumentation\u201d (Popper, 1959): \u201cthe idealizations made must be concessions to the opponent, or at least acceptable to the opponent\u201d (p.\u00a0466, no emphasis added). On August 2, 1971, more than three centuries after Galileo\u2019s death, a live anecdotal demonstration of Galileo\u2019s legendary tower experiment was performed for the television cameras by astronaut David Scott during the final Apollo 15 moonwalk (Fig.\u00a03). Far from the Earth\u2019s atmosphere, essentially in a vacuum, the astronaut simultaneously released a heavy object (an aluminum geological hammer) and a light object (a falcon feather) from approximately the same height, which fell to the ground at the same rate to the naked eye. The performer, who attributed their successful mission in part to \u201ca rather significant discovery about falling objects in gravity fields\u201d made long ago by \u201ca gentleman named Galileo,\u201d celebrated: \u201cHow about that! Mr Galileo was correct in his findings.\u201d282828For footage and a technical description of the demonstration, see \u00a1http://nssdc.gsfc.nasa.gov/planetary/lunar/apollo_15_feather_drop.html\u00bf. Accessed December 6, 2023. Variants of Galileo\u2019s falling-bodies experiment first appeared in his De motu drafts written in the 1590s. Decades later came the punchy presentation of his 1638 Two New Sciences (Galilei, 1638, pp.\u00a066-67): SALVIATI: But without experiences, by a short and conclusive demonstration, we can prove clearly that it is not true that a heavier moveable is moved more swiftly than another, less heavy, these being of the same material, and in a word, those of which Aristotle speaks. Tell me, Simplicio, whether you assume that for every heavy falling body there is a speed determined by nature such that this cannot be increased or diminished except by using force or opposing some impediment to it \u2026\u2026\\ldots\u2026 [SIMPLICIO agrees]\n\n\n\nThen if we had two moveables whose natural speeds were unequal, it is evident that were we to connect the slower to the faster, the latter would be partly retarded by the slower, and this would be partly speeded up by the faster \u2026\u2026\\ldots\u2026 From the outset, Galileo makes Simplicio accept Salviati\u2019s carefully formulated assumption that for every heavy falling body there is a natural speed that cannot be altered except by external intervention. However, the Aristotelian could have found a way out by noting the imprecision and denying that weight and natural speed are physically determinate for connected but not unified bodies (Gendler, 1998). Could Galileo have run a variant of this experiment from the Leaning Tower of Pisa and obtained the results claimed in the story?\nPhysicists went to the laboratory and concluded that it is doubtful (Adler and Coulter, 1978).\nDecades earlier, it was found (Cooper, 1935) that the only source for the legendary story was actually an apologetic biography written by Galileo\u2019s disciple Vincenzo Viviani 12 years after Galileo\u2019s death and first published in 1717. For centuries, Galileo was largely considered \u201cthe first true empiricist,\u201d but the role of experiment in Galilean science was more complex than previously thought (Segre, 1989; Palmieri, 2005). Galileo\u2019s falling-bodies experiment suggests an anomaly in Aristotle\u2019s theory of motion under certain idealized conditions, the existence of motion in a void, which was unacceptable at the time. Testing such an existential hypothesis was in infinite regress with the conditions it required, and creating those conditions would require long-term scientific and technological progress. The Galilean impasse could only be broken by the power of his thought experiments as propaganda292929\u2018Propaganda\u2019 is meant here in its pre-Nazi, neutral sense of propagating, spreading.\nfor a next generation of scientists (Gon\u00e7alves, 2023a).\nRobert Boyle (1627-1692) was one of them. As a teenager, he visited Florence shortly before Galileo\u2019s death and was impressed by \u201cthe new paradoxes of the great star-gazer Galileo\u201d (Fulton, 1960, p.\u00a0119).\nIn his career, Boyle built air pumps and special chambers to study vertical fall in small evacuated environments, and became an exponent of experimental philosophy in the Royal Society. There is no record of Boyle interpreting Galilean science literally and performing any tower experiments. The value of Galileo\u2019s thought experiments was to lay conceptual foundations and to conjecture a class of idealized phenomena to be pursued by progressive science and technology.\nThere is a path that connects Galileo\u2019s thought experiments and Boyle\u2019s vacuum chambers to the space programs of the 1950s and finally to the anecdotal confirmation of Galileo\u2019s hypothesis by the crew of the Apollo 15 mission to the moon. Now note the analogy with the Turing test (Gon\u00e7alves, 2023a). As Hayes and Ford claimed: \u201cThe tests are circular: they define the qualities they are claiming to be evidence for\u201d (p.\u00a0974). Turing\u2019s existential hypothesis of a Turing test-passing machine is in infinite regress with the conditions assumed by the test: an idealized computer equipped with a hypothetically appropriate program (Box\u00a01). But if these conditions exist, why do we need a Turing test at all? This shows that practical Turing tests can serve at best as anecdotal confirmation of Turing\u2019s hypothesis, and at worst, as we have seen for decades, as publicity stunts. The value of Turing\u2019s test must lie elsewhere. By May 1953, John McCarthy and Claude Shannon were working on their collection Automata Studies (McCarthy and\nShannon, 1956), which revolved around \u201cthe theory of Turing machines\u201d (p.\u00a0vii), and to which they invited Turing to contribute.303030Shannon and McCarthy to Turing, May 18, 1953. Alan Turing Papers (Additional), University of Manchester Library, GB133 TUR/Add/123. Turing declined the invitation, saying that he had been working for the last two years on \u201cthe mathematics of morphogenesis,\u201d although he expected \u201cto get back to cybernetics very shortly.\u201d313131Turing to Shannon, June 3, 1953 (ibid.).\nOne year and four days later, Turing was dead, and early AI would not note his biological turn.\nCommenting on \u201cthe Turing definition of thinking\u201d (p.\u00a0vi), McCarthy and Shannon found it \u201cinteresting\u201d because it \u201chas the advantages of being operational or, in the psychologists\u2019 term, behavioristic \u2026\u2026\\ldots\u2026 No metaphysical notions of consciousness, ego and the like are involved.\u201d They also thought that this very strength could be a weakness, because it has \u201cthe disadvantage\u201d of being susceptible to a memorizing machine playing the imitation game by looking up \u201ca suitable dictionary.\u201d McCarthy and Shannon referred interchangeably to \u2018definition\u2019 and to a word that Turing actually used, \u2018criterion:\u2019\n\u201cWhile certainly no machines at the present time can even make a start at satisfying this rather strong criterion, Turing has speculated that within a few decades it will be possible to program general purpose computers in such a way as to satisfy this test\u201d (McCarthy and\nShannon, 1956, p.\u00a0v, emphasis added). In 1955, before the publication of Automata Studies, McCarthy and Shannon, together with Marvin Minsky and Nathaniel Rochester, co-authored their well-known \u2018Proposal\u2019 for AI research (McCarthy et\u00a0al., 1955). Unlike Turing himself, they seem to have thought of machine intelligence in terms of Turing machines, as their opening paragraph suggests: \u201cThe study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\u201d Whether or not they followed Turing on the \u2018how,\u2019 they certainly followed him on the \u2018what,\u2019 in writing:\n\u201cFor the present purpose the artificial intelligence problem is taken to be that of making a machine behave in ways that would be called intelligent if a human were so behaving\u201d (p.\u00a07). This definition \u2014 compare it with \u201cthe Turing definition of thinking\u201d \u2014 would stay. In the early 1960s, Edward Feigenbaum and Julian Feldman noted in Computers and Thought (Feigenbaum and\nFeldman, 1963) that Turing\u2019s 1950 paper \u201cappeared five years before concrete developments in intelligent behavior by machine began to occur;\u201d and \u201cyet,\u201d they continued, \u201cit remains today one of the most cogent and thorough discussions in the literature on the general question \u201cCan a machine think?\u201d (pp.\u00a09-10). They observed Turing\u2019s \u201cbehavioristic posture relative to the question,\u201d which \u201cis to be decided by an unprejudiced comparison of the alleged \u2018thinking behavior\u2019 of the machine with normal \u2018thinking behavior\u2019 in human beings\u201d (emphasis added). They concluded: \u201cHe proposes an experiment \u2014 commonly called \u2018Turing\u2019s test\u2019 \u2014 in which the unprejudiced comparison could be made \u2026\u2026\\ldots\u2026 Though the test has flaws, it is the best that has been proposed to date.\u201d Minsky, in the preface to his 1967 collection (Minsky, 1968), reiterates the definition of AI as \u201cthe science of making machines do things that would require intelligence if done by men\u201d (p.\u00a0v).\nAround the same time, Minsky collaborated with Stanley Kubrick and Arthur Clarke on their 1968 screenplay, also written as a novel, 2001: A Space Odyssey (Clarke, 1968), which featured a futuristic computer named HAL: Whether HAL could actually think was a question which had been settled by the British mathematician Alan Turing back in the 1940s. Turing had pointed out that, if one could carry out a prolonged conversation with a machine \u2014 whether by typewriter or microphone was immaterial \u2014 without being able to distinguish between its replies and those that a man might give, then the machine was thinking, by any sensible definition of the word. HAL could pass the Turing test with ease. The \u201cTuring definition of thinking\u201d was to become legendary. Stuart Shieber studied McCarthy and Shannon\u2019s memorizing machine objection in depth, elaborated on its assumptions, and concluded that it is invalid (Shieber, 2014). But McCarthy\u2019s concept of \u2018memorizing\u2019 may have been more elastic, as his later comment on Deep Blue\u2019s defeat of Gary Kasparov seems to suggest (McCarthy, 1997). He expressed disappointment that it was mostly an achievement of computational power rather than thinking, and gave a clear argument why he thought so. Essentially, McCarthy pointed out, computer chess advanced by replacing heuristic techniques, which relied on the expertise of human players to prune the search space of possible moves, with brute force computing. \u201c[I]t is a measure of our limited understanding of the principles of artificial intelligence,\u201d McCarthy wrote, \u201cthat this level of play requires many millions of times as much computing as a human chess player does.\u201d It may be, but that the problem was \u201clargely a quantitative matter\u201d was hinted at by Turing in his letter to Worsley of c. June 1951 (Box\u00a03). Ten years after Deep Blue vs. Kasparov, McCarthy referred to Turing\u2019s 1947 lecture (op. cit.)\nas \u201cthe first scientific discussion of human level machine intelligence,\u201d and to Turing\u2019s 1950 paper as \u201camplifying\u201d that discussion into a \u201cgoal\u201d (McCarthy, 2007, p.\u00a01174). In 1992, Minsky co-authored a work of fiction, The Turing Option (Warner, New York), in which Turing\u2019s test is featured in the preface. In 1995, Minsky took a stand against Loebner\u2019s Weinzenbaum experiments, pleading to \u201crevoke his stupid prize, save himself some money, and spare us the horror of this obnoxious and unproductive annual publicity campaign.\u201d323232\u2018Annual Minsky Loebner Prize Revocation Prize 1995 Announcement,\u2019 2 March 1995. Available at: https://groups.google.com/g/comp.ai/c/dZtU8vDD_bk/m/QYaYB18qAToJ. Accessed 25 Nov 2023.\nIn 2013, when asked about the Turing test in a taped interview, Minsky said: \u201cThe Turing test is a joke, sort of, about saying \u2018A machine would be intelligent if it does things that an observer would say must be being done by a human\u2019 \u2026\u2026\\ldots\u2026 it was suggested by Alan Turing as one way to evaluate a machine but he had never intended it as being the way to decide whether a machine was really intelligent.\u201d333333\u2018Marvin Minsky on AI: the Turing test is a joke!\u2019, from 23\u2019 35\u201d to 24\u201945\u201d. Available at https://www.singularityweblog.com/marvin-minsky/. Accessed Dec. 6, 2023.\nThis materially connects McCarthy et al.\u2019s definition of \u201cthe AI problem\u201d with Turing\u2019s test, if material evidence were still needed. Overall, it seems that all of these AI pioneers understood and were inspired by Turing\u2019s test at the level of conceptual foundations. Even if some of them also used the term \u2018experiment,\u2019 none of them took it literally as a practical experiment, which would indeed imply an astonishing lack of imagination on their part. Turing\u2019s test moved the burgeoning field of AI away from unproductive debates about the meaning of words, for example, allowing Minsky to write in 1967 (Minsky, 1967): \u201cTuring discusses some of these issues in his brilliant article, \u2018Comput\u00ading Machines and Intelligence\u201d [sic], and I will not recapitulate his arguments \u2026\u2026\\ldots\u2026 They amount, in my view, to a satisfactory refutation of many such objections\u201d (p.\u00a0107). The value of Turing\u2019s test (P5subscript\ud835\udc435P_{5}italic_P start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT) is that it has long been and still is a unifying \u2018definition,\u2019 a \u2018criterion,\u2019 a \u2018goal\u2019 for, in the words of McCarthy et al., the science and engineering of \u201cmaking a machine behave in ways that would be called intelligent if a human were so behaving.\u201d Every time AI succeeds in automating a new task that was once reserved for humans because it requires intelligence, \u201cthe Turing definition\u201d conquers new territory, and the significance of Turing\u2019s early message to his contemporaries becomes clearer. In this paper, I presented a mass of evidence, including newly discovered archival sources, and a new perspective on Turing\u2019s test. New light was shed on Turing\u2019s concept of imitation, emphasizing that it does not give a license for deception in AI. Rather, it is a mathematical concept, largely in continuity with his 1936 paper. I also showed that Turing\u2019s presentation of the various versions of his test fits what Mach characterized as \u201cthe basic method of thought experiments\u201d in science. I reconstructed the historical conditions of Turing\u2019s proposal, explaining that gender imitation was his ironic response to Jefferson, and conversation was yet another concession to his opponents. Further, I paralleled Turing\u2019s test with Galileo\u2019s falling-bodies experiment, showing that the problem of circularity is inherent in existential hypotheses, and that the solution may lie in propaganda and the progressive scientific and technological developments of a next generation of scientists. I then revisited the history of AI, showing that Turing\u2019s test provided McCarthy, Minsky, and others with a definition of the AI problem that, at the level of conceptual foundations, still drives AI research today. But whatever its utility, Turing\u2019s test has secured its place as one of the most beautiful thought experiments in the history of science."
    },
    {
        "id": 6,
        "title": "Professional Network Matters:\nConnections Empower Person-Job Fit",
        "corpus": "Online recruitment platforms typically employ Person-Job Fit models in the core service that automatically match suitable job seekers with appropriate job positions. While existing works leverage historical or contextual information, they often disregard a crucial aspect: job seekers\u2019 social relationships in professional networks. This paper emphasizes the importance of incorporating professional networks into the Person-Job Fit model. Our innovative approach consists of two stages: (1) defining a Workplace Heterogeneous Information Network (WHIN) to capture heterogeneous knowledge, including professional connections and pre-training representations of various entities using a heterogeneous graph neural network; (2) designing a Contextual Social Attention Graph Neural Network (CSAGNN) that supplements users\u2019 missing information with professional connections\u2019 contextual information. We introduce a job-specific attention mechanism in CSAGNN to handle noisy professional networks, leveraging pre-trained entity representations from WHIN. We demonstrate the effectiveness of our approach through experimental evaluations conducted across three real-world recruitment datasets from LinkedIn, showing superior performance compared to baseline models. With the rapid development of the Internet, online recruitment platforms (e.g., LinkedIn111https://www.linkedin.com, Indeed222https://www.indeed.com, and ZipRecruiter333https://www.ziprecruiter.com) are becoming essential for recruiting and job seeking. A considerable number of talent profiles and job descriptions are posted on these platforms. Taking LinkedIn as an example, more than 900 million members have registered, and 90 jobs were posted every second by the first quarter of 2023444https://news.linkedin.com/about-us#Statistics. Considering such a large number of options, Person-Job Fit (PJF) (Malinowski et\u00a0al., 2006) has become a critical research topic for improving the efficiency of recruitment and job seeking. Person-Job Fit aims to automatically link the right talents to the right job positions according to talent competencies and job requirements. Previous works on Person-Job Fit mainly focus on leveraging two types of information, namely, (1) historical job application information and (2) textual information in profiles and job descriptions. Collaborative filtering-based methods (Shalaby et\u00a0al., 2017; Bian et\u00a0al., 2020) are applied to capture co-apply relations between job seekers and co-applied relations between job positions in the historical application information. Manually-engineered textual features and deep language models have been widely adopted to leverage the textual information (Bian et\u00a0al., 2019; Qin et\u00a0al., 2018; Yan et\u00a0al., 2019; Lu et\u00a0al., 2013). However, workplace social connections among members, commonly called professional networks, have been overlooked as a pivotal source of information. A survey reported on the Official LinkedIn Blog555https://blog.linkedin.com/2017/june/22/the-best-way-to-land-your-next-job-opportunity showed that out of more than 15,000 LinkedIn members, 80% believed that professional networking could help find new job opportunities, an even more striking 70% gained job opportunities directly through their connections. As an important source for achieving employment relationships, professional networks have great potential for helping with Person-Job Fit. Incorporating professional networks into the models can offer two main benefits: (1) Professional networks directly improve Person-Job Fit by bridging the gap between job seekers and potential job opportunities. A Person-Job Fit model enriched with professional network information can suggest job opportunities to users based on their professional connections. (2) Professional networks can also help complete job seekers\u2019 profiles. Often job seekers\u2019 online profiles lack comprehensive details, yet one\u2019s professional experience and skills can be, to some extent, discernible through their professional connections. While professional networks offer advantages, they often contain a lot of noise. This noise includes connections that aren\u2019t relevant and information from relevant connections that don\u2019t help improve Person-Job Fit. To illustrate, irrelevant connections might involve job seekers\u2019 former classmates or recruiters from unrelated industries. Even when the connections are relevant to the job seeker, they could still have information unrelated to the job seeker\u2019s aspirations for the role. To tackle these noises, a promising strategy involves using heterogeneous knowledge, such as job seekers\u2019 skills, work experience, and educational background, to gauge professional connections\u2019 relevance and extract pertinent information to elevate Person-Job Fit. In this paper, we propose a graph neural network-based framework that utilizes heterogeneous knowledge to integrate professional networks into Person-Job Fit. We address the challenge of social noise in professional networks by designing a job-specific attention mechanism. Initially, we define a Workplace Heterogeneous Information Network (WHIN) that captures heterogeneous knowledge, including professional connections. We employ a heterogeneous graph pre-training technique to learn the representations of various entities in the WHIN. Subsequently, we introduce the Contextual Social Attention Graph Neural Network (CSAGNN), designed to supplement users\u2019 lacking information with contextual information from their professional connections. To tackle the social noise in the workplace social network, we infuse a job-specific attention mechanism into CSAGNN, capitalizing on the pre-trained entity representations from WHIN. The main contributions of this study are as follows: To our knowledge, we are the first to define a heterogeneous information network that incorporates heterogeneous knowledge in the Person-Job Fit scenario. We systematically utilize professional networks in a two-stage approach, WHIN pre-training and CSAGNN, to address the Person-Job Fit task. We present a novel Contextual Social Attention Graph Neural Network (CSAGNN) specifically designed to handle noisy professional networks, effectively mitigating the impact of irrelevant information while focusing on related professional connections and contexts for Person-Job Fit. We evaluate our approach on three real-world datasets across diverse industries. Experimental results show that our model outperforms baseline models. The related work of our study can be grouped into two main categories, namely, Person-Job Fit and Heterogeneous Information Network-based Recommendation. As a core function of the online recruitment platform, Person-Job Fit (Malinowski et\u00a0al., 2006) has received widespread attention. Mainstream works view Person-Job Fit as a text-matching problem between member profiles and job descriptions to fully use the rich contextual knowledge. For example, JLMIA (Shen et\u00a0al., 2018) is a latent variable model to model job descriptions and member profiles jointly. PJFNN (Zhu et\u00a0al., 2018) encodes member profiles and job descriptions by hierarchical CNN. BPJFNN (Qin et\u00a0al., 2018) leverage BiLSTM to get the semantic representation of each word in member profiles and job descriptions. APJFNN (Qin et\u00a0al., 2018) automatically weighs abilities mentioned in textual information based on historical recruitment results. A transferable deep global match network (Bian et\u00a0al., 2019) is proposed to solve the domain adaptation problem in three levels for Person-Job Fit. JRMPM (Yan et\u00a0al., 2019) proposes a matching network with preference modeled to explore the latent preference given the history of the matching process. Some works take structure knowledge into consideration. For example, MV-CoN (Bian et\u00a0al., 2020) adopts a co-teaching mechanism to capture semantic and structure knowledge at the same time. DPGNN (Yang et\u00a0al., 2022) explicitly models the two-way selection preference for PJF using GCN. KGRM (Yao et\u00a0al., 2022) model members and jobs as two graphs and fuse prior external knowledge, e.g., skill knowledge graph, into the graph representations. Previous studies have made good use of textual information, skill entity, and direct interaction between members and jobs to help with Person-Job Fit. However, these studies often overlook the importance of workplace social relations and the incorporation of diverse, heterogeneous knowledge. Recommender systems have been widely deployed on the Internet to alleviate information overload (Jacoby, 1984). Due to the excellent ability to model complex auxiliary information, Heterogeneous Information Network (i.e., HIN) has become one of the mainstream approaches in recommendation tasks. Depending on the training method, HIN-based models can be divided into two-stage training-based models and end-to-end training-based models (Liu et\u00a0al., 2022). Two-stage training-based models learn low-dimensional representations of nodes and graph structure using unsupervised tasks and use these representations on various downstream tasks (Du et\u00a0al., 2022; Bi et\u00a0al., 2022; Huang et\u00a0al., 2023; Bi et\u00a0al., 2023). Inspired by DeepWalk (Perozzi et\u00a0al., 2014) and node2Vec (Grover and Leskovec, 2016), metapath2vec (Dong et\u00a0al., 2017) leverages metapath-based random walks to construct a heterogeneous neighborhood of nodes and leverages skip-gram model to generate node representations. Similarly, HIN2Vec (Fu et\u00a0al., 2017) defines an unsupervised metapath prediction task and jointly learns metapath predictors and node representations. Many models are proposed based on the graph representation methods such as those above. For example, HERec generates node sequences with metapath-based random walks, uses node2vec to learn node representations, and completes recommendations by representation similarity. MAGNN (Fu et\u00a0al., 2020) leverages node content features and information of intermediate nodes along the metapath by node content transformation, intra- and inter-metapath aggregation. Besides, there are some methods not relying on manual metapath, such as HRLHG (Jiang et\u00a0al., 2018), NREP (Yang et\u00a0al., 2019), and ECHCDR (Li et\u00a0al., 2020b). Compared with two-stage training-based models, end-to-end-based models can use supervision signals directly while training. Thus, they are more customized to specific downstream tasks. For HINs with rich relations, relation-aware graph neural networks can achieve great results. For example, RGCN (Schlichtkrull et\u00a0al., 2018) assigns a weight matrix to each type of relation, thus extending GCN (Welling and Kipf, 2016) to multi-relation graphs. DisenHAN (Wang et\u00a0al., 2020) projects nodes into different subspaces using type-specific transformation and uses intra- and inter-aggregation to learn node representations. HAN (Wang et\u00a0al., 2019) uses a dual attention mechanism to aggregate information from different metapaths. HPN (Ji et\u00a0al., 2021) designs a semantic fusion mechanism for learning the importance of metapath and fusing them judiciously. By using only its immediate connections as input, HGT (Hu et\u00a0al., 2020) can learn and extract relevant metapaths for various tasks through its automatic and implicit attention mechanism without requiring manual metapath design. In this paper, we adopt the two-stage training-based paradigm. During the pre-training stage, we integrate heterogeneous knowledge specific to the Person-Job Fit scenario to obtain diverse entity representations that encompass both structural and textual information. In the downstream stage, we design a novel model that leverages the information from the pre-training stage to filter out noise within professional networks. As a point of comparison, we have also selected two end-to-end-based models as baselines. Here we introduce our two-stage approach to improve the performance of the Person-Job Fit task by incorporating professional networks. The task and notation are formally defined in Section 3.1. In the first stage, we pre-train on the Workplace Heterogeneous Information Network (WHIN), which is detailed in Section 3.2. We introduce the pre-training approach on WHIN in Section 3.3. To overcome the noise in professional networks, we propose the contextual social attention graph neural network (CSAGNN) in the second stage, as described in Section 3.4. Person-Job Fit aims to match a set of job seekers with a set of job opportunities. Assume that there is a set of members \u2133={m1,m2,\u2026,mn}\u2133subscript\ud835\udc5a1subscript\ud835\udc5a2\u2026subscript\ud835\udc5a\ud835\udc5b\\mathcal{M}=\\left\\{m_{1},m_{2},\\dots,m_{n}\\right\\}caligraphic_M = { italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_m start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } who may be seeking job opportunities and a set of jobs \ud835\udca5={j1,j2,\u2026,jm}\ud835\udca5subscript\ud835\udc571subscript\ud835\udc572\u2026subscript\ud835\udc57\ud835\udc5a\\mathcal{J}=\\left\\{j_{1},j_{2},\\dots,j_{m}\\right\\}caligraphic_J = { italic_j start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_j start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_j start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT }. Formally, given a candidate pair (mj,jk)subscript\ud835\udc5a\ud835\udc57subscript\ud835\udc57\ud835\udc58(m_{j},j_{k})( italic_m start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ), the model is required to learn a function \u2131\u2131\\mathcal{F}caligraphic_F to predict the probability of whether the member applied for the job. The set of candidate pairs can be defined as . In addition to the sets of members (\u2133\u2133\\mathcal{M}caligraphic_M) and jobs (\ud835\udca5\ud835\udca5\\mathcal{J}caligraphic_J), there exist three other sets of entities that are strongly related to members and jobs: skills (\ud835\udcae\ud835\udcae\\mathcal{S}caligraphic_S), companies (\ud835\udc9e\ud835\udc9e\\mathcal{C}caligraphic_C), and schools (\u210b\u210b\\mathcal{H}caligraphic_H). These entities are referred as auxiliary information and can be leveraged to improve the model\u2019s accuracy. Given an entity e\ud835\udc52eitalic_e and a relation r\ud835\udc5fritalic_r, an interaction map \ud835\udc9cersuperscriptsubscript\ud835\udc9c\ud835\udc52\ud835\udc5f\\mathcal{A}_{e}^{r}caligraphic_A start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT is used to specify the destination entities related to e\ud835\udc52eitalic_e through r\ud835\udc5fritalic_r. For example, \ud835\udc9cmia\u2062p\u2062p\u2062l\u2062ysuperscriptsubscript\ud835\udc9csubscript\ud835\udc5a\ud835\udc56\ud835\udc4e\ud835\udc5d\ud835\udc5d\ud835\udc59\ud835\udc66\\mathcal{A}_{m_{i}}^{apply}caligraphic_A start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a italic_p italic_p italic_l italic_y end_POSTSUPERSCRIPT represents the set of jobs applied by misubscript\ud835\udc5a\ud835\udc56m_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. If misubscript\ud835\udc5a\ud835\udc56m_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT has not applied for any jobs, \ud835\udc9cmia\u2062p\u2062p\u2062l\u2062y=\u2205superscriptsubscript\ud835\udc9csubscript\ud835\udc5a\ud835\udc56\ud835\udc4e\ud835\udc5d\ud835\udc5d\ud835\udc59\ud835\udc66\\mathcal{A}_{m_{i}}^{apply}=\\emptysetcaligraphic_A start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a italic_p italic_p italic_l italic_y end_POSTSUPERSCRIPT = \u2205. The Person-Job Fit scenario contains a wide range of heterogeneous knowledge, including various entities such as skills, companies, and schools, as well as relationships such as professional connections and skill requirements. We define a Workplace Heterogeneous Information Network (WHIN) to model this knowledge. As shown in Figure 1, WHIN is a heterogeneous information network consisting of five types of entities, namely Member, Job, Skill, Company, and School. It also contains nine types of relations, which are introduced to capture the different types of connections between the entities. The Workplace Heterogeneous Information Network primarily consists of natural relations among diverse entities. Besides, two additional metapaths have been artificially constructed. The first metapath, co-apply (\u2133\u2133\\mathcal{M}caligraphic_M-\ud835\udca5\ud835\udca5\\mathcal{J}caligraphic_J-\u2133\u2133\\mathcal{M}caligraphic_M), connects members who have applied for the same job. The second metapath, co-applied (\ud835\udca5\ud835\udca5\\mathcal{J}caligraphic_J-\u2133\u2133\\mathcal{M}caligraphic_M-\ud835\udca5\ud835\udca5\\mathcal{J}caligraphic_J), connects multiple jobs that have been applied for by the same member. These metapaths were constructed based on prior knowledge and have proven to be useful in enhancing the performance of the WHIN pre-training process (Fu et\u00a0al., 2020). We utilize a heterogeneous graph neural network with a link-level pre-training task to acquire node representations with rich structural knowledge. To improve the scalability of the pre-training process, we create mini-batches by sampling subgraphs from the entire Workplace Heterogeneous Information Network (WHIN), as illustrated in Figure 2 (a) and (b). Specifically, a batch of candidate pairs is selected as the source nodes. From these source nodes, their k-hop neighbors are sampled to construct a subgraph based on each direct relation or metapath. These identified relations and metapaths serve as positive samples. In addition, to introduce negative samples, we randomly select pairs of entities that do not exhibit the expected relationships. The link-level pre-training task revolves around determining the existence of the given samples. We employ an encoder-decoder structure, as illustrated in Figure 2 (c). The encoder learns node representations within each subgraph, while the decoder predicts link existence. During the pre-training phase, we select a fixed number of tokens from the textual content of each entity type. These selected tokens are then processed through the BERT model (Devlin et\u00a0al., 2019). The resulting BERT outputs are averaged to create initial representations for each entity. In a formal context, when working with a textual representation associated with an entity denoted as ei\u2208\u2130subscript\ud835\udc52\ud835\udc56\u2130e_{i}\\in\\mathcal{E}italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2208 caligraphic_E, we construct a corresponding initial embedding referred to as zi(0)superscriptsubscript\ud835\udc67\ud835\udc560z_{i}^{(0)}italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT by utilizing BERT. Specifically, We leverage member profiles, job descriptions, skill names, and other textual descriptions to initialize entity representations, thereby enhancing the initial embeddings for each entity type. After obtaining an initialized representation with semantic information, we utilize an encoder, RGCN (Schlichtkrull et\u00a0al., 2018), to integrate the information between entities. The message-passing process in the RGCN encoder is represented by the following equation: where Wr(l)superscriptsubscript\ud835\udc4a\ud835\udc5f\ud835\udc59W_{r}^{(l)}italic_W start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_l ) end_POSTSUPERSCRIPT is a parameter matrix at the l\ud835\udc59litalic_l-th layer of relation r\ud835\udc5fritalic_r, W0(l)superscriptsubscript\ud835\udc4a0\ud835\udc59W_{0}^{(l)}italic_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_l ) end_POSTSUPERSCRIPT is used for self-loop at the l\ud835\udc59litalic_l-th layer and ci,r=|\ud835\udc9ceir|subscript\ud835\udc50\ud835\udc56\ud835\udc5fsuperscriptsubscript\ud835\udc9csubscript\ud835\udc52\ud835\udc56\ud835\udc5fc_{i,r}=\\left|\\mathcal{A}_{e_{i}}^{r}\\right|italic_c start_POSTSUBSCRIPT italic_i , italic_r end_POSTSUBSCRIPT = | caligraphic_A start_POSTSUBSCRIPT italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT | is a normalization constant. We employ L\ud835\udc3fLitalic_L encoder layers for Link Prediction, utilizing the final representation zi(L)superscriptsubscript\ud835\udc67\ud835\udc56\ud835\udc3fz_{i}^{(L)}italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_L ) end_POSTSUPERSCRIPT for entity eisubscript\ud835\udc52\ud835\udc56e_{i}italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. We apply a multi-layer perceptron (MLP) to score each relation or metapath risubscript\ud835\udc5f\ud835\udc56r_{i}italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, represented by vector Mrisubscript\ud835\udc40subscript\ud835\udc5f\ud835\udc56M_{r_{i}}italic_M start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT. The score for a particular link (s,r,d)\ud835\udc60\ud835\udc5f\ud835\udc51(s,r,d)( italic_s , italic_r , italic_d ) is determined as follows: We employ cross entropy as the loss function for optimizing the pre-training model. Notably, the described pre-training process incorporates professional network information into entity embeddings. As discussed earlier, professional networks are inherently noisy. To capture job-specific insights from the profiles of misubscript\ud835\udc5a\ud835\udc56m_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT\u2019s professional connections, a multi-head attention (MHA) mechanism (Vaswani et\u00a0al., 2017) is employed. As shown in Eq. 4, cisubscript\ud835\udc50\ud835\udc56c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is the profile representation of member misubscript\ud835\udc5a\ud835\udc56m_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT obtained from a pre-trained BERT model. The MHA mechanism uses each required skill embedding zsksubscript\ud835\udc67subscript\ud835\udc60\ud835\udc58z_{s_{k}}italic_z start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT as the query, and cisubscript\ud835\udc50\ud835\udc56c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT as both the key and value. It computes attention weights between cisubscript\ud835\udc50\ud835\udc56c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and the required skill embeddings. The weighted sum averages these attention outputs for all required skills. This results in the job-specific contextual feature Fmic\u2062(jk)superscriptsubscript\ud835\udc39subscript\ud835\udc5a\ud835\udc56\ud835\udc50subscript\ud835\udc57\ud835\udc58F_{m_{i}}^{c}(j_{k})italic_F start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT ( italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) that captures relevant information from misubscript\ud835\udc5a\ud835\udc56m_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT\u2019s connections for job jksubscript\ud835\udc57\ud835\udc58j_{k}italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT. As shown in Eq. 5, contextual feature Fmic\u2062(jk)superscriptsubscript\ud835\udc39subscript\ud835\udc5a\ud835\udc56\ud835\udc50subscript\ud835\udc57\ud835\udc58F_{m_{i}}^{c}(j_{k})italic_F start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT ( italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) is concatenated with the WHIN pre-trained feature Fmissuperscriptsubscript\ud835\udc39subscript\ud835\udc5a\ud835\udc56\ud835\udc60F_{m_{i}}^{s}italic_F start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT to form member\u2019s jksubscript\ud835\udc57\ud835\udc58j_{k}italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT-specific initial feature. The relevance degree of professional connections to the job jksubscript\ud835\udc57\ud835\udc58j_{k}italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT needs to be considered in the messaging process. Here, we use the distance between WHIN pre-trained representations of skills mastered by members and the skills required by jobs as the weights during message passing. Given a set of skills S^^\ud835\udc46\\hat{S}over^ start_ARG italic_S end_ARG, average embedding can be described in Eq. 6 and distance between members\u2019 and jobs\u2019 skills dmi\u2062(jk)subscript\ud835\udc51subscript\ud835\udc5a\ud835\udc56subscript\ud835\udc57\ud835\udc58d_{m_{i}}(j_{k})italic_d start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) can be described in Eq. 7. Further, due to some members or jobs may have hundreds of related skills, we sampled the skill set like \ud835\udc9cmim\u2062a\u2062s\u2062t\u2062e\u2062rsuperscriptsubscript\ud835\udc9csubscript\ud835\udc5a\ud835\udc56\ud835\udc5a\ud835\udc4e\ud835\udc60\ud835\udc61\ud835\udc52\ud835\udc5f\\mathcal{A}_{m_{i}}^{master}caligraphic_A start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m italic_a italic_s italic_t italic_e italic_r end_POSTSUPERSCRIPT and \ud835\udc9cjkr\u2062e\u2062q\u2062u\u2062i\u2062r\u2062esuperscriptsubscript\ud835\udc9csubscript\ud835\udc57\ud835\udc58\ud835\udc5f\ud835\udc52\ud835\udc5e\ud835\udc62\ud835\udc56\ud835\udc5f\ud835\udc52\\mathcal{A}_{j_{k}}^{require}caligraphic_A start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_r italic_e italic_q italic_u italic_i italic_r italic_e end_POSTSUPERSCRIPT in Eq. 4 and Eq. 7. The number of sampled skills, nssubscript\ud835\udc5b\ud835\udc60n_{s}italic_n start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT, is a hyperparameter of CSAGNN. We will discuss the influence of nssubscript\ud835\udc5b\ud835\udc60n_{s}italic_n start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT in Section 4.3. As shown in Eq. 8, we can get the messaging function of professional network enhanced GNN by text attention and skill distance attention where \u03b1mj\u2062(jk)subscript\ud835\udefcsubscript\ud835\udc5a\ud835\udc57subscript\ud835\udc57\ud835\udc58\\alpha_{m_{j}}(j_{k})italic_\u03b1 start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) is normalized message aggregation weight described in Eq. 9. We use the average of each layer\u2019s representation as the final representation of misubscript\ud835\udc5a\ud835\udc56m_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT: Compared with member profiles, job descriptions provided by recruiters often have a high quality. Thus, we directly use contextual features and WHIN pre-trained features as the final representation for all job entities. hjk\u2062(mi)subscript\u210esubscript\ud835\udc57\ud835\udc58subscript\ud835\udc5a\ud835\udc56h_{j_{k}}(m_{i})italic_h start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and hmi\u2062(jk)subscript\u210esubscript\ud835\udc5a\ud835\udc56subscript\ud835\udc57\ud835\udc58h_{m_{i}}(j_{k})italic_h start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) will be concatenated and passed through a vanilla multi-layer Perceptron (MLP) to get the predicted value ymi,jksubscript\ud835\udc66subscript\ud835\udc5a\ud835\udc56subscript\ud835\udc57\ud835\udc58y_{m_{i},j_{k}}italic_y start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT, and the cross entropy loss could be formulated as Eq. 13, where ymi,jk\u2032superscriptsubscript\ud835\udc66subscript\ud835\udc5a\ud835\udc56subscript\ud835\udc57\ud835\udc58\u2032y_{m_{i},j_{k}}^{\\prime}italic_y start_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is the ground truth: In this section, we will validate the performance of the CSAGNN model on three real datasets and answer the following research questions: RQ1: Can CSAGNN outperform existing models on real-world datasets? RQ2: What are the effects of different components in our model? RQ3: Are professional networks helpful for the Person-Job Fit task? RQ4: Does the WHIN pre-training provide meaningful representations of skills for CSAGNN? We validate our model on three large real-world datasets from LinkedIn, a well-known workplace social platform. Datasets are divided by the industry to which the members and jobs belong. The first two datasets contain members and jobs from the technology and finance industries. Due to the singularity of the industry, social noise is limited. The third dataset, which includes members and jobs from various industries such as healthcare, education, and semiconductors, is intended to test the ability of CSAGNN to filter noise in professional networks. This hybrid dataset implies more complex social relationships and a wider range of job opportunities. The WHINs constructed from these three datasets all contain about 200,000 entities and 10 million links. Table 2 displays the statistics of the datasets. The skills, schools, and companies in the dataset all come from explicit annotations by members or jobs on LinkedIn. We cannot provide further detailed information about the datasets to protect the users\u2019 privacy. Each candidate pair within the datasets is labeled as either positive or negative based on the feedback provided by members. We compare our model with the following baseline models. LightGCN (He et\u00a0al., 2020) is a simplified Graph Convolutional Network model for collaborative filtering with competitive performance and less complexity. PJFNN (Zhu et\u00a0al., 2018) is a method based on a convolutional neural network (CNN). Hierarchical CNN encodes Resumes and job descriptions independently, and the matching degree is calculated by cosine similarity. BPJFNN (Qin et\u00a0al., 2018) leverages bidirectional LSTM to learn the representations of resumes and job descriptions. APJFNN (Qin et\u00a0al., 2018) leverages bidirectional LSTM and hierarchical attention mechanism to learn the representations of resumes and job descriptions. MV-CoN (Bian et\u00a0al., 2020) combines text matching model and RGCN to learn representations of resumes and job descriptions. HAN (Wang et\u00a0al., 2019) uses a dual attention mechanism to aggregate neighbor information via different metapaths. HGT (Hu et\u00a0al., 2020) designs node- and edge-type dependent parameters to characterize the heterogeneous attention over each edge. These baselines can be divided into three groups: (1) context-based models that treat Person-Job Fit as a text match problem and use contextual knowledge from members\u2019 profiles and jobs\u2019 descriptions: PJFNN, BPJFNN, APJFNN, and MV-CoN. In particular, MV-CoN additionally introduces structural information to enhance model performance. (2) collaborative filtering-based model that uses direct interactions between members and jobs: LightGCN. (3) end-to-end heterogeneous graph neural network models: HAN, HGT. We use four widely used metrics to evaluate the ranking performance: AUC, accuracy (ACC), F1, and average precision (AP). The Person-Job Fit models, namely PJFNN, BPJFNN, and APJFNN, are implemented using RecBole\u2014an established open-source recommendation library (Zhao et\u00a0al., 2021). The MV-CoN model leverages the original code provided in their respective paper (Bian et\u00a0al., 2020). Other models are implemented with PyTorch Geometric (Fey and Lenssen, 2019). We have employed BERT-Tiny666https://huggingface.co/prajjwal1/bert-tiny to reduce computational costs. The embedding dimensions for all models are standardized at 32. As discussed in Section 3.3.1, subgraph sampling for mini-batch WHIN pre-training is executed using the PyTorch Geometric subgraph sampler (Fey and Lenssen, 2019). Subgraph construction starts from nodes within a batch of candidate pairs, and each hop samples five neighbors via relations (or metapaths). Reconnecting all relations (and metapaths) between the sampled nodes follows this. We set the number of sampled hops to 3. The number of sampled hops is fixed at 3. In CSAGNN, the count of sampled skills (nssubscript\ud835\udc5b\ud835\udc60n_{s}italic_n start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT) is designated as 10, and CSAGNN comprises two layers. The first 128 tokens from all text inputs are captured for all models. All models are optimized using the Adam optimizer (Kingma and Ba, 2014), with a learning rate adjusted from 0.01 to 0.0001. For the purpose of evaluation, the dataset utilized across all models is randomly partitioned into a ratio of 8:1:1 for training, validation, and testing respectively. Three independent experiments are conducted, each one repeated, to ascertain consistent and reliable outcomes. Table 1 shows the performance of all baseline models and our model, CSAGNN. The results indicate better performance on the hybrid dataset than on individual industry datasets, possibly because jobs within the same industry are more similar and thus harder to distinguish. End-to-end heterogeneous graph neural network models have shown superior performance on all three datasets compared to context-based and CF-based models. HGT, utilizing heterogeneous knowledge, has improved AUC scores by 3.20%, 3.31%, and 1.55% compared to the best baseline MV-CoN, which employs homogeneous knowledge. CSAGNN further improved AUC scores by 1.39%, 1.71%, and 2.37% compared to HGT. Our approach employs two main techniques: WHIN pre-training, which integrates heterogeneous knowledge, including professional networks, and CSAGNN, which incorporates professional networks with an attention mechanism. We conducted ablation studies to analyze the effectiveness of different techniques, where we considered the following variants of CSAGNN: (1) CSAGNN w/o S removes messages from professional connections but retains the job-specific attention mechanism for members themselves. (2) CSAGNN w/o A removes the job-specific attention mechanism. (3) CSAGNN w/o CSA removes both professional connections and job-specific attention mechanisms, using only structural knowledge from the WHIN pre-train approach. (4) CSAGNN w/o CSA&H removes WHIN pre-trained embeddings and CSA mechanism, only using text information as input and leverages MLP to predict. As detailed in Table 3, within single industry datasets with low social noise, the job-specific attention mechanism and professional connections\u2019 messages yielded limited benefits. However, WHIN pre-training embeddings were crucial for enhancing performance. On hybrid datasets with high social noise, where candidate pairs may span different industries, the job-specific attention mechanism, along with the WHIN pre-training embedding, significantly improved the model. To investigate the specific roles of professional networks and job-specific attention mechanisms in our model, we performed hyperparameter tuning experiments by fixing one module and varying the other to observe its impact on performance. Specifically, we first fixed the number of CSAGNN layers to 1 and tested the model\u2019s performance with different numbers of sampled skills (nssubscript\ud835\udc5b\ud835\udc60n_{s}italic_n start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT), as described in Section 3.4. We then fixed nssubscript\ud835\udc5b\ud835\udc60n_{s}italic_n start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT to 10 and tested the model with different numbers of CSAGNN layers. The results on all datasets showed that, compared to the neighbor sampling range, the gain in model performance from the attention mechanism saturates when the number of sampled skills is relatively small. This observation led us to explore the balance between model performance and efficiency by selecting a smaller value for nssubscript\ud835\udc5b\ud835\udc60n_{s}italic_n start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT. The value of utilizing professional networks is illustrated in the example shown in Figure 5. In this case, we have rephrased the information to preserve the users\u2019 privacy while retaining its essential meaning. Even though the member\u2019s profile contains minimal information, the CSAGNN model adeptly predicts their classification by harnessing job-related insights from the member\u2019s professional connections. This contrasts sharply with the incorrect predictions made by the collaborative filtering-based LightGCN and context-based PJFNN models. This specific example accentuates the vital role of professional connections in the classification process and underlines the CSAGNN model\u2019s distinctive capability to leverage such relationships for precise predictions. To demonstrate the effectiveness of WHIN pre-training in capturing meaningful skill representations for CSAGNN, we analyzed the pre-trained embeddings of selected skills in the embedding space. Utilizing Principal Component Analysis (PCA) as our method of dimensional reduction (Jolliffe and Cadima, 2016), we were able to visualize the WHIN pre-trained embeddings for various skills. Figure 6 reveals that skills closely related to programming, such as C++ and Python, are grouped together in the embedding space. In contrast, skills associated with healthcare form a distinct cluster. It is noteworthy that these classifications were achieved using only the skill names as initialization. Yet, our WHIN pre-training method successfully distinguishes between skill categories by learning from heterogeneous knowledge, highlighting the capability of WHIN to recognize and differentiate skills across multiple domains. This paper introduces a novel two-stage approach for leveraging professional networks in Person-Job Fit, including the formation of the Workplace Heterogeneous Information Network (WHIN). WHIN encompasses various entities such as members, jobs, skills, companies, and schools, with an emphasis on the professional connections among members. By employing heterogeneous graph pre-training techniques, the approach acquires representations that integrate professional connections and other diverse information for different entities. These representations are subsequently applied to the CSAGNN model, helping to filter out social noise. Experimental results show that professional connections provide valuable job-specific insights. The WHIN pre-training method is also promising for applications like skill completion and professional connection recommendations, opening new research avenues. Furthermore, for large-scale applications of CSAGNN, a key area of future work involves reducing the model\u2019s computational overhead (Lin et\u00a0al., 2020; Li et\u00a0al., 2020a, 2021). The integration of professional networks into Person-Job Fit models offers significant potential for enriching recommendations. However, we must recognize and address two vital ethical considerations that may lead to adverse societal implications: Firstly, the core of our approach involves accessing members\u2019 professional connections and corresponding profiles, which raises privacy concerns. In our research, we ensured that the data collection and processing respected privacy by adhering to proper consent mechanisms and limiting access to pertinent information. Future users should follow suit, being mindful of the need for clear and voluntary consent from members and carefully controlling access to connection information. Additionally, connections often exhibit demographic clustering, which could introduce biases favoring certain groups within networks. The models might infer sensitive attributes like race, gender, or age. Future users should conduct audits to ensure demographic equity and prohibit direct utilization of protected class information. In summary, while the enhancement of Person-Job Fit models through professional network data brings advancements, it also introduces risks concerning privacy and fairness. These ethical challenges call for a concerted effort from platforms to resolve, ensuring that the innovations foster an environment that is both respectful of individual rights and free from discriminatory biases."
    },
    {
        "id": 7,
        "title": "1002 km Twin-Field Quantum Key Distribution with Finite-Key Analysis",
        "corpus": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on. Authors: achieve the best HTML results from your LaTeX submissions by selecting from this list of supported packages. Quantum key distribution (QKD) holds the potential to establish secure keys over long distances. The distance of point-to-point QKD secure key distribution is primarily impeded by the transmission loss inherent to the channel. In the quest to realize a large-scale quantum network, increasing the QKD distance under current technology is of great research interest. Here we adopt the 3-intensity sending-or-not-sending twin-field QKD (TF-QKD) protocol with the actively-odd-parity-pairing method. The experiment demonstrates the feasibility of secure QKD over a 1002 km fibre channel considering the finite size effect. The secure key rate is 3.11\u00d710\u2212123.11superscript10123.11\\times 10^{-12}3.11 \u00d7 10 start_POSTSUPERSCRIPT - 12 end_POSTSUPERSCRIPT per pulse at this distance. Furthermore, by optimizing parameters for shorter fiber distances, we conducted performance tests on key distribution for fiber lengths ranging from 202 km to 505 km. Notably, the secure key rate for the 202 km, the normal distance between major cities, reached 111.74 kbps. Quantum key distribution (QKD) \u00a0Bennett\u00a0and\u00a0Brassard (1984); Ekert (1991); Gisin\u00a0et\u00a0al. (2002); Scarani\u00a0et\u00a0al. (2009); Gisin (2015); Xu\u00a0et\u00a0al. (2020a); Pirandola\u00a0et\u00a0al. (2020) ensures secure key distribution using the principles of quantum mechanics. An active research frontier in practical quantum cryptography is exploring the distribution distance achievable with the present technology. The main challenge in extending the distribution distance of QKD is the channel loss that occurs when transmitting single-photon level quantum signals. Unlike classical communication, quantum signals cannot be amplified, posing a significant hurdle\u00a0Wootters\u00a0and\u00a0Zurek (1982). The exponentially decreased transmission of the optical fibre channel results in a vanishing secure key rate at long distances. Importantly, the limited number of detected signals over long distances also constrains the secure key rate due to the finite-key effect. In the quest for achieving long-distance QKD, twin-field QKD (TF-QKD) is proposed\u00a0Lucamarini\u00a0et\u00a0al. (2018) recently. TF-QKD may achieve a secure key rate in spirit similar to that of a single-repeater QKD scenario, significantly increasing the ultimate distance. Within a few years, TF-QKD has already been experimentally demonstrated in lab\u00a0Minder\u00a0et\u00a0al. (2019); Wang\u00a0et\u00a0al. (2019); Liu\u00a0et\u00a0al. (2019); Zhong\u00a0et\u00a0al. (2019); Fang\u00a0et\u00a0al. (2020); Chen\u00a0et\u00a0al. (2020); Liu\u00a0et\u00a0al. (2021); Chen\u00a0et\u00a0al. (2021, 2022); Pittaluga\u00a0et\u00a0al. (2021); Wang\u00a0et\u00a0al. (2022); Liu\u00a0et\u00a0al. (2023) through up to 1002 km spooled fibre\u00a0Liu\u00a0et\u00a0al. (2023), and in the field test over 511 km deployed fibre across metropolitans\u00a0Chen\u00a0et\u00a0al. (2021). However, the previous 1002 km distribution distance\u00a0Liu\u00a0et\u00a0al. (2023) was achieved under an asymptotic assumption. The longest distribution distance considering the finite size effect was reported to be 952 km\u00a0Liu\u00a0et\u00a0al. (2023). The finite-size effect has to be taken into account in a practical QKD system since there are only a finite number of pulses. This consideration allows us to quantify the security level, i.e., the security coefficient; and apply the composable security framework. In this work, we demonstrate TF-QKD over 1002 km fibre channel considering the finite size effect. We adopt the sending-or-not-sending (SNS) protocol\u00a0Wang\u00a0et\u00a0al. (2018) with advanced 3-intensity decoy-state method\u00a0Hu\u00a0et\u00a0al. (2022) and the actively-odd-parity-pairing (AOPP)\u00a0Xu\u00a0et\u00a0al. (2020b); Jiang\u00a0et\u00a0al. (2020) to improve the distribution distance. The ultra-low-noise superconducting nanowire single-photon detectors (SNSPDs) and dual-band phase estimation method are developed to suppress the system noise, thus achieving long distribution distance. Furthermore, the system is optimized for the normal distance between major cities of a fibre distance of 202 km. A secure key rate of 111.74 kbps is achieved at this distance, better than any reported results to our best knowledge. In this work, we adopt the 3-intensity SNS protocol developed by Wang et al.\u00a0Wang\u00a0et\u00a0al. (2018). By placing the error correction process ahead of the decoy-state analysis process\u00a0Hu\u00a0et\u00a0al. (2022), we can utilize all the heralded time windows for decoy-state analysis, resulting in an enhanced key rate. Furthermore, we also apply the AOPP\u00a0Xu\u00a0et\u00a0al. (2020b) method to reduce the bit-flip error rate. The source parameters are symmetric for Alice and Bob: there are three sources on each side which are the vacuum source v\ud835\udc63vitalic_v, the decoy source x\ud835\udc65xitalic_x, and the signal source y\ud835\udc66yitalic_y with intensities \u03bcv=0,\u03bcx,\u03bcysubscript\ud835\udf07\ud835\udc630subscript\ud835\udf07\ud835\udc65subscript\ud835\udf07\ud835\udc66\\mu_{v}=0,\\mu_{x},\\mu_{y}italic_\u03bc start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT = 0 , italic_\u03bc start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT , italic_\u03bc start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT and probabilities p0,px,pysubscript\ud835\udc5d0subscript\ud835\udc5d\ud835\udc65subscript\ud835\udc5d\ud835\udc66p_{0},p_{x},p_{y}italic_p start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT respectively. In each time window, Alice (Bob) randomly prepares and sends out a pulse from the three candidate sources to Charlie who is assumed to measure the interference result of the incoming pulse pair and announce the measurement results to Alice and Bob. In this work, the raw keys in the time windows, while Alice and Bob choose the sources v\ud835\udc63vitalic_v or y\ud835\udc66yitalic_y, are used to extract the secure keys. After Alice and Bob send N\ud835\udc41Nitalic_N pulse pairs to Charlie, and Charlie announces all measurement results, Alice and Bob distill the secure keys according to the following formula\u00a0Jiang\u00a0et\u00a0al. (2020, 2021); Hu\u00a0et\u00a0al. (2022): where R\ud835\udc45Ritalic_R is the key rate of per sending-out pulse pair; n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is the lower bound of the number of survived untagged bits after AOPP and e1p\u2062hsuperscriptsubscript\ud835\udc521\ud835\udc5d\u210ee_{1}^{ph}italic_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p italic_h end_POSTSUPERSCRIPT is the upper bound of the phase-flip error rate of those survived untagged bits after AOPP; ntsubscript\ud835\udc5b\ud835\udc61n_{t}italic_n start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the number of survived bits after AOPP and Etsubscript\ud835\udc38\ud835\udc61E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the corresponding bit-flip error rate in those survived bits; f\ud835\udc53fitalic_f is the error correction inefficiency which is set to f=1.16\ud835\udc531.16f=1.16italic_f = 1.16; H\u2062(x)=\u2212x\u2062log2\u2061x\u2212(1\u2212x)\u2062log2\u2061(1\u2212x)\ud835\udc3b\ud835\udc65\ud835\udc65subscript2\ud835\udc651\ud835\udc65subscript21\ud835\udc65H(x)=-x\\log_{2}x-(1-x)\\log_{2}(1-x)italic_H ( italic_x ) = - italic_x roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_x - ( 1 - italic_x ) roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_x ) is the Shannon entropy. And Rtailsubscript\ud835\udc45tailR_{\\mbox{tail}}italic_R start_POSTSUBSCRIPT tail end_POSTSUBSCRIPT is where \u03b5c\u2062o\u2062rsubscript\ud835\udf00\ud835\udc50\ud835\udc5c\ud835\udc5f\\varepsilon_{cor}italic_\u03b5 start_POSTSUBSCRIPT italic_c italic_o italic_r end_POSTSUBSCRIPT is the failure probability of error correction, \u03b5P\u2062Asubscript\ud835\udf00\ud835\udc43\ud835\udc34\\varepsilon_{PA}italic_\u03b5 start_POSTSUBSCRIPT italic_P italic_A end_POSTSUBSCRIPT is the failure probability of privacy amplification, \u03b5^^\ud835\udf00\\hat{\\varepsilon}over^ start_ARG italic_\u03b5 end_ARG is the coefficient while using the chain rules of smooth min- and max- entropy\u00a0Vitanov\u00a0et\u00a0al. (2013), and 2\u2062log2\u2061(nv\u2062y+ny\u2062v)2subscript2subscript\ud835\udc5b\ud835\udc63\ud835\udc66subscript\ud835\udc5b\ud835\udc66\ud835\udc632\\log_{2}(n_{vy}+n_{yv})2 roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_n start_POSTSUBSCRIPT italic_v italic_y end_POSTSUBSCRIPT + italic_n start_POSTSUBSCRIPT italic_y italic_v end_POSTSUBSCRIPT ) is the extra cost of the advanced decoy state analysis\u00a0Hu\u00a0et\u00a0al. (2022) (nv\u2062ysubscript\ud835\udc5b\ud835\udc63\ud835\udc66n_{vy}italic_n start_POSTSUBSCRIPT italic_v italic_y end_POSTSUBSCRIPT is the number of raw keys while Alice chooses the source v\ud835\udc63vitalic_v and Bob chooses the source y\ud835\udc66yitalic_y, and the definition of ny\u2062vsubscript\ud835\udc5b\ud835\udc66\ud835\udc63n_{yv}italic_n start_POSTSUBSCRIPT italic_y italic_v end_POSTSUBSCRIPT is similar with that of nv\u2062ysubscript\ud835\udc5b\ud835\udc63\ud835\udc66n_{vy}italic_n start_POSTSUBSCRIPT italic_v italic_y end_POSTSUBSCRIPT ). The experimental setup is shown in Fig.\u00a01. The seed lasers (\u03bb1subscript\ud835\udf061\\lambda_{1}italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT=1548.51 nm and \u03bb2subscript\ud835\udf062\\lambda_{2}italic_\u03bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT=1550.12 nm) are frequency stabilized using the Pound-Drever-Hall (PDH) technique\u00a0Pound (1946); Drever\u00a0et\u00a0al. (1983); Clivati\u00a0et\u00a0al. (2022) with an ultra-stable cavity serving as the reference. The light is then sent to Alice\u2019s and Bob\u2019s stations through 450 km single-mode fibres respectively, incorporating 4 erbium-doped fibre amplifiers (EDFAs) in each path to stabilize the intensity. At Alice\u2019s (Bob\u2019s) station, the \u03bb1subscript\ud835\udf061\\lambda_{1}italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT light from Charlie is modulated to a 400 ns pulse in each 1 \u03bc\ud835\udf07\\muitalic_\u03bcs period, functioning as the \u201cstrong phase reference\u201d. The \u03bb2subscript\ud835\udf062\\lambda_{2}italic_\u03bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT light serves as the frequency reference for the optical phase-locked loop (OPLL). The locally produced \u03bb2subscript\ud835\udf062\\lambda_{2}italic_\u03bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT laser is locked to the frequency reference from Charlie, and then modulated to \u201cdim phase reference\u201d and \u201cquantum signals\u201d. As shown in Fig.\u00a02, the intensity of the 40 ms \u201cdim phase reference\u201d is generally higher than the 60 ms \u201cquantum signals\u201d light. In each 1 \u03bc\ud835\udf07\\muitalic_\u03bcs period, the pulse train is modulated to the same random pattern in the first 400 ns for Alice and Bob, serving as the \u201cdim phase reference\u201d. In the remaining 600 ns, the pulse train is modulated to generate random quantum signals based on their respective local random numbers. Note that only the detections occurring within the first 400 ns in each 1 \u03bc\ud835\udf07\\muitalic_\u03bcs period, and within the first 40 ms in the 100 ms period, are utilized as the \u201ddim phase reference\u201d. Similarly, the detections in the last 600 ns of each 1 \u03bc\ud835\udf07\\muitalic_\u03bcs period, and the last 60 ms of the 100 ms period, are used as the \u201dquantum signals\u201d. For both the \u201cstrong phase reference\u201d and \u201cdim phase reference\u201d, the relative phases between Alice and Bob are set to four relative phases \u03b4A\u2062B={0,\u03c0/2,\u03c0,3\u2062\u03c0/2}subscript\ud835\udeff\ud835\udc34\ud835\udc350\ud835\udf0b2\ud835\udf0b3\ud835\udf0b2\\delta_{AB}=\\{0,\\pi/2,\\pi,3\\pi/2\\}italic_\u03b4 start_POSTSUBSCRIPT italic_A italic_B end_POSTSUBSCRIPT = { 0 , italic_\u03c0 / 2 , italic_\u03c0 , 3 italic_\u03c0 / 2 } within a 1 \u03bc\ud835\udf07\\muitalic_\u03bcs period. We implemented the 3-intensity SNS-TF-QKD protocol in the experiment. The \u03bb2subscript\ud835\udf062\\lambda_{2}italic_\u03bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT quantum signals are modulated to 3 intensities with 16 different phases using intensity modulators (IMs) and phase modulators. The IMs are stabilized at Alice\u2019s (Bob\u2019s) station to ensure the quantum signals\u2019 intensities are stable. The \u03bb1subscript\ud835\udf061\\lambda_{1}italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u201cstrong phase reference\u201d is then filtered and combined with the quantum signals. An electronic polarization controller is installed within the secure zone to control the polarization drift. A dispersion compensation module is employed to pre-compensate for the chromatic dispersion of the fibre channel. The signals are then attenuated to the predetermined intensities and subsequently transmitted to Charlie via the quantum channels. The polarization of different wavelengths may evolute differently. At Charlie\u2019s measurement station, a polarization feedback algorithm is utilized to optimize the \u03bb1subscript\ud835\udf061\\lambda_{1}italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT detections to between 75 kHz and 300 kHz, while minimizing the \u03bb2subscript\ud835\udf062\\lambda_{2}italic_\u03bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. The relative delay between Alice\u2019s and Bob\u2019s signals is monitored and compensated using the rising edges of the \u03bb1subscript\ud835\udf061\\lambda_{1}italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT pulses. The light from Alice and Bob is interfered at the beam splitter and subsequently demultiplexed to \u03bb1subscript\ud835\udf061\\lambda_{1}italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \u03bb2subscript\ud835\udf062\\lambda_{2}italic_\u03bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT wavelengths. This light is then filtered by DWDMs, measured with SNSPDs, and recorded with a Time Tagger. The recorded signals are categorized into the \u201cstrong phase reference\u201d, \u201cdim phase reference\u201d and the quantum signal for subsequent data processing. The ultra-low loss fibre is utilized to minimize channel loss. The fibre is manufactured with \u201cpure silica core\u201d technology to reduce the doped Ge in the core and with decreased fictive temperature. The average attenuation of the fibres is measured to be less than 0.157 dB/km. The ultra-low dark count SNSPDs are developed to reduce detection-related noise. The noise suppression includes stages of filtering. The long-wavelength (>>>2 \u03bc\ud835\udf07\\muitalic_\u03bcm) filtering is achieved using the 28 mm diameter fibre coils at the 40 K cold plate. Narrowband wavelength filtering is carried out utilizing a cryogenic bandpass filter (BPF) with a 5 nm bandwidth and an 85% transmittance at 2.2 K cold plate\u00a0Zhang\u00a0et\u00a0al. (2018). The dark count rate is measured to be as low as 0.02 Hz. Additionally, the detection efficiency is optimized to be around 60% with a distributed Bragg reflector (DBR) based optical cavity\u00a0Zhang\u00a0et\u00a0al. (2017). The time-multiplexed dual-band stabilization method is employed to reduce the re-Rayleigh scattering noise induced in previously reported time-multiplexed phase estimation procedures. With dual-band stabilization, the wavelength of the \u201cstrong phase reference\u201d of \u03bb1subscript\ud835\udf061\\lambda_{1}italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is different from the quantum signal of \u03bb2subscript\ud835\udf062\\lambda_{2}italic_\u03bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. The induced re-Rayleigh scattering is filtered with DWDMs. Furthermore, circulators are implemented in Charlie to eliminate noise resulting from the SNSPDs. Additionally, the \u03bb1subscript\ud835\udf061\\lambda_{1}italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u201dstrong phase reference\u201d is time-multiplexed with the quantum signal, effectively mitigating disturbance caused by spontaneous Raman scattering noise induced by the strong phase reference light. The combination of wavelength- and time-multiplexing ensures that the noise introduced by the strong phase reference signal is less than 0.01 Hz. Moreover, the intensity of the weak \u201ddim phase reference\u201d signal, which is also time-multiplexed with the quantum signal, remains low enough to not generate perceptible noise. The data post-processing-based phase estimation method Liu\u00a0et\u00a0al. (2023) is adopted. First, the phase drift of the \u03bb1subscript\ud835\udf061\\lambda_{1}italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT wavelength is estimated using the \u201cstrong phase reference\u201d. Then, the wavelength difference is taken into account to estimate the phase of the \u03bb2subscript\ud835\udf062\\lambda_{2}italic_\u03bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT light, with the accumulated phase drift of the \u201cstrong phase reference\u201d. Lastly, the initial phase difference \u03d5s\u2062(0)\u2212\u03d5r\u2062(0)subscriptitalic-\u03d5\ud835\udc600subscriptitalic-\u03d5\ud835\udc5f0\\phi_{s}(0)-\\phi_{r}(0)italic_\u03d5 start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( 0 ) - italic_\u03d5 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( 0 ) is computed using the phase difference between the \u201cdim phase reference\u201d and the \u201cstrong phase reference\u201d. In the experiment, this phase difference is computed and refreshed every 500 ms, to circumvent any accumulation of errors stemming from inaccurate wavelength settings, high-order residual phase errors, and errors in phase estimation. Result.\u2014 We first test the performance of 1002 km fibres (the \u201c+++\u201d-shape points in Fig.\u00a03). The fibre distances between Alice-Charlie and Bob-Charlie are measured to be 500 km and 502 km. The decoy intensities are optimized as \u03bcx=0.08,\u03bcy=0.445formulae-sequencesubscript\ud835\udf07\ud835\udc650.08subscript\ud835\udf07\ud835\udc660.445\\mu_{x}=0.08,\\ \\mu_{y}=0.445italic_\u03bc start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT = 0.08 , italic_\u03bc start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT = 0.445, with the time ratios pv\u2062a\u2062c=0.52,px=0.28,py=0.20formulae-sequencesubscript\ud835\udc5d\ud835\udc63\ud835\udc4e\ud835\udc500.52formulae-sequencesubscript\ud835\udc5d\ud835\udc650.28subscript\ud835\udc5d\ud835\udc660.20p_{vac}=0.52,\\ p_{x}=0.28,\\ p_{y}=0.20italic_p start_POSTSUBSCRIPT italic_v italic_a italic_c end_POSTSUBSCRIPT = 0.52 , italic_p start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT = 0.28 , italic_p start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT = 0.20 (Parameter #1). The finite size effect\u00a0Jiang\u00a0et\u00a0al. (2021) is taken into consideration for all the experimental tests, considering composable security under any coherent attack\u00a0Jiang\u00a0et\u00a0al. (2019, 2021). The error correction inefficiency is set to f=1.16\ud835\udc531.16f=1.16italic_f = 1.16 in the calculation; the failure probability of Chernoff bound in finite-size estimation is set to \u03b5=10\u221210\ud835\udf00superscript1010\\varepsilon=10^{-10}italic_\u03b5 = 10 start_POSTSUPERSCRIPT - 10 end_POSTSUPERSCRIPT; the failure probability of the error correction, and the privacy amplification is set to \u03b5c\u2062o\u2062r=\u03b5P\u2062A=10\u221210subscript\ud835\udf00\ud835\udc50\ud835\udc5c\ud835\udc5fsubscript\ud835\udf00\ud835\udc43\ud835\udc34superscript1010\\varepsilon_{cor}=\\varepsilon_{PA}=10^{-10}italic_\u03b5 start_POSTSUBSCRIPT italic_c italic_o italic_r end_POSTSUBSCRIPT = italic_\u03b5 start_POSTSUBSCRIPT italic_P italic_A end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT - 10 end_POSTSUPERSCRIPT; the coefficient of the chain rules of smooth min- and max- entropies is set to \u03b5^=10\u221210^\ud835\udf00superscript1010\\hat{\\varepsilon}=10^{-10}over^ start_ARG italic_\u03b5 end_ARG = 10 start_POSTSUPERSCRIPT - 10 end_POSTSUPERSCRIPT. The system frequency is set to 1 GHz, with the signal pulse width set to 120 ps. The quantum signals are sent in the last 600 ns of the 1 \u03bc\ud835\udf07\\muitalic_\u03bcs period where the \u201cstrong phase reference\u201d is switched off. The quantum signals are time-multiplexed with the \u201cdim phase reference\u201d in the last 60 ms of the 100 ms period. The detections near the strong light are also dropped to avoid potential noises. As a result, the effective signal frequency is 351 MHz for the long-distance scenario. The total noises in the \u03bb2subscript\ud835\udf062\\lambda_{2}italic_\u03bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are measured to be 0.019 Hz and 0.035 Hz in the working conditions. We attribute the noise mainly contributed by the SNSPD dark count and the spontaneous Raman scattering noise induced by the \u03bb1subscript\ud835\udf061\\lambda_{1}italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT light. The SNSPD detection efficiencies are measured to be 60% and 55%. The additional optical losses in Charlie are measured to be around 1.4 dB. In data processing, a 200 ps window is defined to filter out noises, with an efficiency of about 65%. Owing to the significant optical attenuation experienced over long-distance fibre, it is necessary to send a larger number of quantum signals in order to generate secure keys considering the finite size effect. A total of 1.00\u00d710151.00superscript10151.00\\times 10^{15}1.00 \u00d7 10 start_POSTSUPERSCRIPT 15 end_POSTSUPERSCRIPT quantum signal pulses are dispatched, resulting in 9.81\u00d71059.81superscript1059.81\\times 10^{5}9.81 \u00d7 10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT valid detections that fall within the effective window. The quantum bit error rate (QBER) in Z basis is measured to be 9.44\u00d710\u221239.44superscript1039.44\\times 10^{-3}9.44 \u00d7 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT after AOPP; the QBER in X basis is measured to be 4.20%. The final secure key is 3.11\u00d710\u2212123.11superscript10123.11\\times 10^{-12}3.11 \u00d7 10 start_POSTSUPERSCRIPT - 12 end_POSTSUPERSCRIPT, which equates to 0.0011 bps considering the effective signal frequency. A total of 3112 bits of final secure keys are accumulated during the test. The detailed experimental results are summarized in Tab.\u00a02 and Fig.\u00a03. Next, we test the performance of fibre distances between 202 km and 505 km (the \u201c\u00d7\\times\u00d7\u201d-shape points in Fig.\u00a03). The intensities of the decoy states are optimized for short distances as \u03bcx=0.05,\u03bcy=0.482formulae-sequencesubscript\ud835\udf07\ud835\udc650.05subscript\ud835\udf07\ud835\udc660.482\\mu_{x}=0.05,\\ \\mu_{y}=0.482italic_\u03bc start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT = 0.05 , italic_\u03bc start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT = 0.482, with the time ratios pv\u2062a\u2062c=0.68,px=0.04,py=0.28formulae-sequencesubscript\ud835\udc5d\ud835\udc63\ud835\udc4e\ud835\udc500.68formulae-sequencesubscript\ud835\udc5d\ud835\udc650.04subscript\ud835\udc5d\ud835\udc660.28p_{vac}=0.68,\\ p_{x}=0.04,\\ p_{y}=0.28italic_p start_POSTSUBSCRIPT italic_v italic_a italic_c end_POSTSUBSCRIPT = 0.68 , italic_p start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT = 0.04 , italic_p start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT = 0.28 (Parameter #2). The \u201cstrong phase reference\u201d period is reduced to 100 ns in the 1 \u03bc\u2062s\ud835\udf07\ud835\udc60\\mu sitalic_\u03bc italic_s signal period; the intensity of the \u201cdim phase reference\u201d is set to the same as the quantum signal through the 100 ms period. As a result, the effective signal frequency is increased to 900 MHz. Besides, we used SNSPDs with >>>80% detection efficiency and a relatively higher dark count rate of about 10 Hz. The time window in data processing is set to 500 ps, yielding an almost unity efficiency. A total of 3.24\u00d710123.24superscript10123.24\\times 10^{12}3.24 \u00d7 10 start_POSTSUPERSCRIPT 12 end_POSTSUPERSCRIPT quantum signal pulses are sent for each distance, which equals to one hour of experimental time. The secure key rate is measured to be 1.24\u00d710\u221241.24superscript1041.24\\times 10^{-4}1.24 \u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT, 2.60\u00d710\u221252.60superscript1052.60\\times 10^{-5}2.60 \u00d7 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT, 3.11\u00d710\u221263.11superscript1063.11\\times 10^{-6}3.11 \u00d7 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT, and 3.76\u00d710\u221273.76superscript1073.76\\times 10^{-7}3.76 \u00d7 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT which corresponds to 111.74 kbps, 23.44 kbps, 2.80 kbps, and 338 bps for the 202 km, 303 km, 404 km, and 505 km fibre distances, respectively. The secure key rates exceed the absolute PLOB bound\u00a0Pirandola\u00a0et\u00a0al. (2017) for the tests with the fibre distances equal to or longer than 404 km, where the PLOB bound is calculated as \u2212log2\u2061(1\u2212\u03b7)subscript21\ud835\udf02-\\log_{2}(1-\\eta)- roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_\u03b7 ) with the optical and detection efficiency in Charlie set to \u03b7o\u2062p\u2062t=100%subscript\ud835\udf02\ud835\udc5c\ud835\udc5d\ud835\udc61percent100\\eta_{opt}=100\\%italic_\u03b7 start_POSTSUBSCRIPT italic_o italic_p italic_t end_POSTSUBSCRIPT = 100 %. In conclusion, we have demonstrated the first experiment of SNS-TF-QKD over a remarkable distance of 1002 km, while considering the finite size effect. The result has been made possible by employing several key components, including the ultra-low-loss fiber, ultra-low-noise SNSPD, dual-band phase stabilization method, and moderate data size. The achieved secure key rates over fiber distances ranging from 202 km to 505 km were highly practical, indicating the potential for supporting a wide range of applications. In addition to improving the performance, TF-QKD is also expected to be implemented in chip-scale systems in the future, based on recent advancements in chip-scale systems implementing BB84 and MDI-QKD protocols\u00a0Paraiso\u00a0et\u00a0al. (2021); Zhu\u00a0et\u00a0al. (2022); Wei\u00a0et\u00a0al. (2020); Cao\u00a0et\u00a0al. (2020). Y.L. and W.-J.Z. contributed equally. The experimental results are summarized in Tab.\u00a02.\nIn the table, we denote N\ud835\udc41Nitalic_N as the total number of signal pulses, ntsubscript\ud835\udc5b\ud835\udc61n_{t}italic_n start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT(After AOPP) as the remaining pairs after AOPP, n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT(Before AOPP) and n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT(After AOPP) as the number of the untagged bits before and after AOPP; e1p\u2062hsuperscriptsubscript\ud835\udc521\ud835\udc5d\u210ee_{1}^{ph}italic_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p italic_h end_POSTSUPERSCRIPT(Before AOPP) and e1p\u2062hsuperscriptsubscript\ud835\udc521\ud835\udc5d\u210ee_{1}^{ph}italic_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p italic_h end_POSTSUPERSCRIPT(After AOPP) as the phase-flip error rate before and after AOPP, Etsubscript\ud835\udc38\ud835\udc61E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT(Before AOPP) and Etsubscript\ud835\udc38\ud835\udc61E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT(After AOPP) as the bit-flip error rate before and after the bit error rejection by active odd parity pairing (AOPP). With all the parameters in the table, the final key rate per pulse and in one second is calculated as R\ud835\udc45Ritalic_R (per pulse) and R\ud835\udc45Ritalic_R (bps), Exsubscript\ud835\udc38\ud835\udc65E_{x}italic_E start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT as the phase-flip error rate of the sifted bits. We note that the ultra-low QBER E(After AOPP) allows us to use a practical error correction inefficiency f=1.16\ud835\udc531.16f=1.16italic_f = 1.16 in calculating the secure key rate. In the following rows, we list the numbers of pulses Alice and Bob sent in different decoy states, labelled as \u201cSent-AB\u201d, where \u201cA\u201d (\u201cB\u201d) is \u201c0\u201d, \u201c1\u201d, or \u201c2\u201d, indicating the intensity Alice (Bob) has chosen within \u201cvacuum\u201d, \u201c\u03bcxsubscript\ud835\udf07\ud835\udc65\\mu_{x}italic_\u03bc start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT\u201d, or \u201c\u03bcysubscript\ud835\udf07\ud835\udc66\\mu_{y}italic_\u03bc start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT\u201d. With the same rule, the numbers of detections are listed as \u201cDetected-AB\u201d. The total valid detections reported by Charlie is denoted as \u201cDetected-Valid-ch\u201d, where \u201cch\u201d can be \u201cDet1\u201d or \u201cDet2\u201d indicating the responsive detector of the recorded counts. The valid events falls in the preset Ds angle range is denoted as \u201cDetected-11-Ds\u201d, the numbers of correct detections in this range is denoted as \u201cCorrect-11-Ds\u201d."
    },
    {
        "id": 8,
        "title": "Li-Yau Estimates for a Nonlinear Parabolic Equation on Finsler Manifolds",
        "corpus": "Abstract. In this paper, we explore the positive solutions to the\nFinslerian nonlinear equation which is related to Ricci solitons and serves as the Euler-Lagrange equation to the Finslerian log-energy functional. We then obtain the global gradient estimate of its positive solution on a compact Finsler metric measure space with the weighted Ricci curvature bounded below. Furthermore, using a new comparison theorem developed by the first author, we also establish a local gradient estimate on a non-compact forward complete Finsler metric measure spaces with the mixed weighted Ricci curvature bounded below, as well as finite bounds of misalignment and some non-Riemannian curvatures. Lastly, we prove the Harnack inequalities and a Liouville-type theorem of such solutions.\n\nMathematics Subject Classification: 35K55, 53C60, 58J35\n\nKeywords: Finslerian nonlinear equation, Mixed weighted Ricci curvature,\nGradient estimate, Metric measure space Log-Sobolev inequalities were first introduced and studied by L. Gross [7] for Gaussian probability measure. More recently, S. Ohta [13] and S. Yin [23] proved that in the Finsler measure space (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ), for any f\u2208C0\u221e\u2062(M)\ud835\udc53subscriptsuperscript\ud835\udc360\ud835\udc40f\\in C^{\\infty}_{0}(M)italic_f \u2208 italic_C start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_M ) such that \u222bMf2\u2062\ud835\udc51\u03bc=Vold\u2062\u03bc\u2061(M)subscript\ud835\udc40superscript\ud835\udc532differential-d\ud835\udf07subscriptVol\ud835\udc51\ud835\udf07\ud835\udc40\\int_{M}f^{2}d\\mu=\\operatorname{Vol}_{d\\mu}(M)\u222b start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d italic_\u03bc = roman_Vol start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT ( italic_M ), where C\ud835\udc36Citalic_C is a constant that depends on different curvature conditions. In order to find the sharp constant in (1.1), as F. R. K. Chung and S.-T. Yau [4] did in the Riemannian case, we can also define the Finslerian log-Sobolev constant by Assume that u\ud835\udc62uitalic_u is a minimizer of the functional in (1.2), then by the variational calculation, u\ud835\udc62uitalic_u satisfies the Euler-Lagrange equation that which inspires us to consider this type of nonlinear parabolic equation where a\ud835\udc4eaitalic_a and b\ud835\udc4fbitalic_b are two real constants, \u0394\u2207usuperscript\u0394\u2207\ud835\udc62\\Delta^{\\nabla u}roman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT is nonlinear Finslerian Laplacian.\n\nAnother motivation is to understand the Ricci soliton defined by R. Hamilton [8], which is a Riemannian manifold (M,g)\ud835\udc40\ud835\udc54(M,g)( italic_M , italic_g ) with a smooth\nfunction f\u2208C\u221e\u2062(M)\ud835\udc53superscript\ud835\udc36\ud835\udc40f\\in C^{\\infty}(M)italic_f \u2208 italic_C start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT ( italic_M ), such that for some constant c\u2208\u211d\ud835\udc50\u211dc\\in\\mathbb{R}italic_c \u2208 blackboard_R, it satisfies where \u22072superscript\u22072\\nabla^{2}\u2207 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT and RicRic\\operatorname{Ric}roman_Ric are the Hessian tensor and Ricci tensor of the metric g\ud835\udc54gitalic_g, respectively.\nThe Finslerian Ricci solitons have been investigated by H. Zhu [24] and some other results of rigidity and characterizations can be seen in [25, 3].\n\n\nSetting u=ef\ud835\udc62superscript\ud835\udc52\ud835\udc53u=e^{f}italic_u = italic_e start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT in (1.5), one can deduce that where A0subscript\ud835\udc340A_{0}italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is a constant (see [11]). For this kind of elliptic equation, L. Ma [11] established a Li-Yau estimate on a complete Riemannian manifold with Ricci curvature bounded below by a negative constant. Afterwards, Y. Yang [22] generalized the estimate to the parabolic equation \u2202tu=\u0394\u2062u+a\u2062u\u2062log\u2061u+b\u2062usubscript\ud835\udc61\ud835\udc62\u0394\ud835\udc62\ud835\udc4e\ud835\udc62\ud835\udc62\ud835\udc4f\ud835\udc62\\partial_{t}u=\\Delta u+au\\log u+bu\u2202 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_u = roman_\u0394 italic_u + italic_a italic_u roman_log italic_u + italic_b italic_u. Then G. Huang and B. Ma [9] also considered the weighted Laplacian \u0394f=\u0394\u2212\u2207f\u2062\u2207subscript\u0394\ud835\udc53\u0394\u2207\ud835\udc53\u2207\\Delta_{f}=\\Delta-\\nabla f\\nablaroman_\u0394 start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT = roman_\u0394 - \u2207 italic_f \u2207, and replaced curvature condition with the N\ud835\udc41Nitalic_N-Bakry-Emery Ricci tensor. Apart from Li-Yau esitimates, some other types of gradient estimates like Souplet-Zhang esitimates have been obtained on this nonlinear equation by X. Fu [6] and N. Dung [5].\n\nAlthough numerous studies have been carried out on gradient estimates for equations on Riemannian manifolds, there are not many results on Finsler manifolds yet. S. Ohta and K.-T. Sturm have introduced the weighted Ricci curvature on a Finsler manifold as a generalization of Bakry-Emery Ricci curvature in Riemannian geometry (cf. [14] and [12]) and proved a Finslerian version of Bochner\u2013Weitzenb\u00f6ck formula (cf. [15]), which they applied to derive Li-Yau estimate for heat equation on a compact Finsler manifold. Following their serial work, we can generalize the results in [11], [22] and [9] to the nonlinear parabolic equation (1.4) on Finsler manifold. The first main result in compact Finslerian case is the following: Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be an n\ud835\udc5bnitalic_n-dimensional compact Finsler manifold . For some integer N\u2208(n,\u221e)\ud835\udc41\ud835\udc5bN\\in(n,\\infty)italic_N \u2208 ( italic_n , \u221e ), suppose the weighted Ricci curvature R\u2062i\u2062cN\u2265\u2212K\ud835\udc45\ud835\udc56superscript\ud835\udc50\ud835\udc41\ud835\udc3eRic^{N}\\geq-Kitalic_R italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2265 - italic_K where K\ud835\udc3eKitalic_K is a nonnegative constant. If u\u2062(x,t)\ud835\udc62\ud835\udc65\ud835\udc61u(x,t)italic_u ( italic_x , italic_t ) is a positive smooth global solution to equation (1.4) on M\u00d7[0,+\u221e)\ud835\udc400M\\times[0,+\\infty)italic_M \u00d7 [ 0 , + \u221e ) where a\u22600\ud835\udc4e0a\\neq 0italic_a \u2260 0, let f\u2062(x,t)=log\u2061u\u2062(x,t)\ud835\udc53\ud835\udc65\ud835\udc61\ud835\udc62\ud835\udc65\ud835\udc61f(x,t)=\\log u(x,t)italic_f ( italic_x , italic_t ) = roman_log italic_u ( italic_x , italic_t ) and \u03b1=max\u2061{a/2,\u2212a/4}\ud835\udefc\ud835\udc4e2\ud835\udc4e4\\alpha=\\max\\{a/2,-a/4\\}italic_\u03b1 = roman_max { italic_a / 2 , - italic_a / 4 }. Then, for any \u03b2>1\ud835\udefd1\\beta>1italic_\u03b2 > 1, x\u2208M\ud835\udc65\ud835\udc40x\\in Mitalic_x \u2208 italic_M and t>0\ud835\udc610t>0italic_t > 0, we have In particular, as a\u21920\u2192\ud835\udc4e0a\\to 0italic_a \u2192 0 and b=0\ud835\udc4f0b=0italic_b = 0 , the equation (1.4) simplifies to a common heat equation on a Finsler manifold. In this special case, the gradient estimate (1.7) would be the same as the result by Ohta and Sturm (cf. Theorem 4.4 in [15]). It is remarkable that S. Ohta [12] showed that the lower curvature bound (RicN\u2a7e\u2212KsuperscriptRic\ud835\udc41\ud835\udc3e\\operatorname{Ric}^{N}\\geqslant-Kroman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2a7e - italic_K) is equivalent to the\ncurvature-dimension condition C\u2062D\u2062(\u2212K,N)\ud835\udc36\ud835\udc37\ud835\udc3e\ud835\udc41CD(-K,N)italic_C italic_D ( - italic_K , italic_N ) defined by Lott-Villani-Sturm [10, 18, 19].\n\n\n\nFurther challenge, however, arose in the case of complete but non-compact Finsler manifold. Although Q. Xia [21] gave a gradient estimate on non-compact case, that method is feasible only for Finslerian heat equation. Due to the latest progress in comparison theorem made in [16], we have demonstrated the following gradient estimate. Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a forward complete n\ud835\udc5bnitalic_n-dimensional Finsler metric measure space without boundary. Denote by Bp\u2062(2\u2062R)subscript\ud835\udc35\ud835\udc5d2\ud835\udc45B_{p}(2R)italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 2 italic_R ) the forward geodesic ball centering p\u2208M\ud835\udc5d\ud835\udc40p\\in Mitalic_p \u2208 italic_M with radius 2\u2062R2\ud835\udc452R2 italic_R, and by r\u2062(x):=d\u2062(p,x)assign\ud835\udc5f\ud835\udc65\ud835\udc51\ud835\udc5d\ud835\udc65r(x):=d(p,x)italic_r ( italic_x ) := italic_d ( italic_p , italic_x ) the distance function from p\ud835\udc5dpitalic_p. Suppose for some N\u2208(n,\u221e)\ud835\udc41\ud835\udc5bN\\in(n,\\infty)italic_N \u2208 ( italic_n , \u221e ), the mixed weighted Ricci curvature Ric\u2207rNmsuperscriptsuperscriptsubscriptnormal-Ricnormal-\u2207\ud835\udc5f\ud835\udc41\ud835\udc5a{}^{m}\\operatorname{Ric}_{\\nabla r}^{N}start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT roman_Ric start_POSTSUBSCRIPT \u2207 italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT is bounded below by constant \u2212K\u2062(2\u2062R)\ud835\udc3e2\ud835\udc45-K(2R)- italic_K ( 2 italic_R ) (R>0\ud835\udc450R>0italic_R > 0 and K\u2062(2\u2062R)\u2a7e0\ud835\udc3e2\ud835\udc450K(2R)\\geqslant 0italic_K ( 2 italic_R ) \u2a7e 0) in Bp\u2062(2\u2062R)subscript\ud835\udc35\ud835\udc5d2\ud835\udc45B_{p}(2R)italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 2 italic_R ). Suppose M\ud835\udc40Mitalic_M has finite upper bounds of misalignment and non-Riemannian tensors by A\u2062(2\u2062R)\ud835\udc342\ud835\udc45A(2R)italic_A ( 2 italic_R ) and K0subscript\ud835\udc3e0K_{0}italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT respectively. If u\u2062(x,t)\ud835\udc62\ud835\udc65\ud835\udc61u(x,t)italic_u ( italic_x , italic_t ) is a positive solution to equation (1.4) on M\u00d7[0,+\u221e)\ud835\udc400M\\times[0,+\\infty)italic_M \u00d7 [ 0 , + \u221e ) where a\u22600\ud835\udc4e0a\\neq 0italic_a \u2260 0, by setting f\u2062(x,t)=log\u2061u\u2062(x,t)\ud835\udc53\ud835\udc65\ud835\udc61\ud835\udc62\ud835\udc65\ud835\udc61f(x,t)=\\log u(x,t)italic_f ( italic_x , italic_t ) = roman_log italic_u ( italic_x , italic_t ) and \u03b1=max\u2061{a/2,\u2212a/4}\ud835\udefc\ud835\udc4e2\ud835\udc4e4\\alpha=\\max\\{a/2,-a/4\\}italic_\u03b1 = roman_max { italic_a / 2 , - italic_a / 4 }, then, for any \u03b2>1\ud835\udefd1\\beta>1italic_\u03b2 > 1, 0<\u03b4<10\ud835\udeff10<\\delta<10 < italic_\u03b4 < 1, x\u2208Bp\u2062(R)\ud835\udc65subscript\ud835\udc35\ud835\udc5d\ud835\udc45x\\in B_{p}(R)italic_x \u2208 italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_R ) and t>0\ud835\udc610t>0italic_t > 0, we have where c1subscript\ud835\udc501c_{1}italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, c2subscript\ud835\udc502c_{2}italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and c3\u2062(N,A,K0)subscript\ud835\udc503\ud835\udc41\ud835\udc34subscript\ud835\udc3e0c_{3}(N,A,K_{0})italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_N , italic_A , italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) are all positive constants. When dealing with non-compactness, the curvature conditions necessitate the bounds of misalignment and non-Riemannian quantities (further elaborated in Section 2 or [16]). Our conditions are marginally stronger in contrast to those presented in [21]. Nevertheless, our method can be adopted to other Finslerian equations. It is also worth noting that if the manifold degenerates to a Riemannian one, these conditions are just equivalent to the (N\u2212n)\ud835\udc41\ud835\udc5b(N-n)( italic_N - italic_n )-Bakry-Emery Ricci curvature bounded from below. Hence the gradient estimate (1.8) is more general than the one in [9].\n\nBased on the aforementioned estimates, there are several noteworthy results including Harnack\u2019s inequalities and the Liouville-type theorem for a positive smooth solution, on which we will give a detailed elaboration in Section 5. Under the same conditions in Theorem 1.1, we have where for any \u03b2>1\ud835\udefd1\\beta>1italic_\u03b2 > 1, 0<t1<t2<T0subscript\ud835\udc611subscript\ud835\udc612\ud835\udc470<t_{1}<t_{2}<T0 < italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < italic_T and x1subscript\ud835\udc651x_{1}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, x2\u2208Msubscript\ud835\udc652\ud835\udc40x_{2}\\in Mitalic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2208 italic_M. Taking a\u21920\u2192\ud835\udc4e0a\\to 0italic_a \u2192 0 and b=0\ud835\udc4f0b=0italic_b = 0 in (1.9), one will find that the Harnack inequality derived from the heat equation in [15] is also a special case of (1.9). Moreover, it can also be extended to non-compact Finsler manifold. Under the assumption in Theorem 1.2, we have where for any 0<\u03b4<10\ud835\udeff10<\\delta<10 < italic_\u03b4 < 1, \u03b2>1\ud835\udefd1\\beta>1italic_\u03b2 > 1, 0<t1<t2<T0subscript\ud835\udc611subscript\ud835\udc612\ud835\udc470<t_{1}<t_{2}<T0 < italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < italic_T and x1subscript\ud835\udc651x_{1}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, x2\u2208Bp\u2062(R)subscript\ud835\udc652subscript\ud835\udc35\ud835\udc5d\ud835\udc45x_{2}\\in B_{p}(R)italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2208 italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_R ) . In particular, assume that the solution u\ud835\udc62uitalic_u is independent of t\ud835\udc61titalic_t, that is, u\ud835\udc62uitalic_u solves the elliptic equation where a\u22600\ud835\udc4e0a\\neq 0italic_a \u2260 0, We then have the following Liouville-type theorem. Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a forward complete n\ud835\udc5bnitalic_n-dimensional Finsler metric measure space without boundary, with misalignment and non-Riemannian tensors bounded by A\ud835\udc34Aitalic_A and K0subscript\ud835\udc3e0K_{0}italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, respectively. Let u\ud835\udc62uitalic_u be a positive solution to (1.11) on M\ud835\udc40Mitalic_M and f=log\u2061u\ud835\udc53\ud835\udc62f=\\log uitalic_f = roman_log italic_u. Suppose mixed weighted Ricci curvature RicNm\u2a7e\u2212Ksuperscriptsuperscriptnormal-Ric\ud835\udc41\ud835\udc5a\ud835\udc3e{}^{m}\\operatorname{Ric}^{N}\\geqslant-Kstart_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT roman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2a7e - italic_K for some N\ud835\udc41Nitalic_N and K\ud835\udc3eKitalic_K satisfying where \u03b1=max\u2061{a/2,\u2212a/4}\ud835\udefc\ud835\udc4e2\ud835\udc4e4\\alpha=\\max\\{a/2,-a/4\\}italic_\u03b1 = roman_max { italic_a / 2 , - italic_a / 4 }. If there exists an x0\u2208Msubscript\ud835\udc650\ud835\udc40x_{0}\\in Mitalic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2208 italic_M such that or we then have f\u2062(x)\u22610\ud835\udc53\ud835\udc650f(x)\\equiv 0italic_f ( italic_x ) \u2261 0 on M\ud835\udc40Mitalic_M. When b=0\ud835\udc4f0b=0italic_b = 0, K=0\ud835\udc3e0K=0italic_K = 0 and M\ud835\udc40Mitalic_M is complete non-compact Riemannian manifold, Y. Yang [22] has proved that for a>0\ud835\udc4e0a>0italic_a > 0, u\u2062(x)\u2a7den/2\ud835\udc62\ud835\udc65superscript\ud835\udc52\ud835\udc5b2u(x)\\leqslant e^{n/2}italic_u ( italic_x ) \u2a7d italic_e start_POSTSUPERSCRIPT italic_n / 2 end_POSTSUPERSCRIPT, and for a<0,w\u2062(x)\u2a7ee\u2212n/4formulae-sequence\ud835\udc4e0\ud835\udc64\ud835\udc65superscript\ud835\udc52\ud835\udc5b4a<0,w(x)\\geqslant e^{-n/4}italic_a < 0 , italic_w ( italic_x ) \u2a7e italic_e start_POSTSUPERSCRIPT - italic_n / 4 end_POSTSUPERSCRIPT, indicating that u\u2062(x)\ud835\udc62\ud835\udc65u(x)italic_u ( italic_x ) has a gap when a<0\ud835\udc4e0a<0italic_a < 0. Then X. Cao, et al. [2] further improved the gap to u\u2062(x)\u2a7ee\u2212n/16\ud835\udc62\ud835\udc65superscript\ud835\udc52\ud835\udc5b16u(x)\\geqslant e^{-n/16}italic_u ( italic_x ) \u2a7e italic_e start_POSTSUPERSCRIPT - italic_n / 16 end_POSTSUPERSCRIPT when M\ud835\udc40Mitalic_M is non-compact and u\u2062(x)\u2a7e1\ud835\udc62\ud835\udc651u(x)\\geqslant 1italic_u ( italic_x ) \u2a7e 1 when M\ud835\udc40Mitalic_M is closed.\nBy Theorem 1.5 above, we supplement that when b>n\u2062\u03b1/2\ud835\udc4f\ud835\udc5b\ud835\udefc2b>n\\alpha/2italic_b > italic_n italic_\u03b1 / 2, u\u2062(x)\ud835\udc62\ud835\udc65u(x)italic_u ( italic_x ) also has a gap u\u2062(x)\u2a7e1\ud835\udc62\ud835\udc651u(x)\\geqslant 1italic_u ( italic_x ) \u2a7e 1.\n\nThis manuscript is structured as follows. In Section 2, we offer a brief interpretation of the notions in Finsler geometry. Furthermore, we introduce the Finslerian log-energy functional, the Finslerian log-Sobolev constant and related variational equation. Then in Section 3, we demonstrate global gradient estimates of positive solutions with the C\u2062D\u2062(\u2212K,N)\ud835\udc36\ud835\udc37\ud835\udc3e\ud835\udc41CD(-K,N)italic_C italic_D ( - italic_K , italic_N ) condition. In Section 4, we show local gradient estimates with the mixed weighted Ricci curvature condition. Finally, Section 5 is devoted to presenting some applications such as Harnack inequalities and a Liouville-type theorem. In this section, we briefly review some definitions and theorems in Finsler geometry (see [1] and [17]). A Finsler manifold is a pair (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ), where M\ud835\udc40Mitalic_M is an n\ud835\udc5bnitalic_n-dimensional connected smooth manifold and F:T\u2062M\u2192[0,\u221e):\ud835\udc39\u2192\ud835\udc47\ud835\udc400F:TM\\rightarrow[0,\\infty)italic_F : italic_T italic_M \u2192 [ 0 , \u221e ), called Finsler structure, is a nonnegative function satisfying F\u2208C\u221e\u2062(T\u2062M\\\ud835\udfce)\ud835\udc39superscript\ud835\udc36\\\ud835\udc47\ud835\udc400F\\in{C}^{\\infty}(TM\\backslash\\mathbf{0})italic_F \u2208 italic_C start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT ( italic_T italic_M \\ bold_0 ), where \ud835\udfce0\\mathbf{0}bold_0 is the zero section; F\u2062(x,c\u2062v)=c\u2062F\u2062(x,v)\ud835\udc39\ud835\udc65\ud835\udc50\ud835\udc63\ud835\udc50\ud835\udc39\ud835\udc65\ud835\udc63F(x,cv)=cF(x,v)italic_F ( italic_x , italic_c italic_v ) = italic_c italic_F ( italic_x , italic_v ) for all (x,v)\u2208T\u2062M\ud835\udc65\ud835\udc63\ud835\udc47\ud835\udc40(x,v)\\in TM( italic_x , italic_v ) \u2208 italic_T italic_M and c\u2a7e0\ud835\udc500c\\geqslant 0italic_c \u2a7e 0 The n\u00d7n\ud835\udc5b\ud835\udc5bn\\times nitalic_n \u00d7 italic_n matrix is positive-definite for all (x,v)\u2208T\u2062M\\\ud835\udfce\ud835\udc65\ud835\udc63\\\ud835\udc47\ud835\udc400(x,v)\\in TM\\backslash\\mathbf{0}( italic_x , italic_v ) \u2208 italic_T italic_M \\ bold_0. In term of Finsler structure F\ud835\udc39Fitalic_F, any vector field V\u2208T\u2062M\\\ud835\udfce\ud835\udc49\\\ud835\udc47\ud835\udc400V\\in TM\\backslash\\mathbf{0}italic_V \u2208 italic_T italic_M \\ bold_0 induces a Riemannian structure gVsubscript\ud835\udc54\ud835\udc49g_{V}italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT by and a norm FV\u2062(\u22c5)subscript\ud835\udc39\ud835\udc49\u22c5F_{V}(\\cdot)italic_F start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( \u22c5 ) by In particular, the norm of reference vector is FV\u2062(V)=F\u2062(V)subscript\ud835\udc39\ud835\udc49\ud835\udc49\ud835\udc39\ud835\udc49F_{V}(V)=F(V)italic_F start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_V ) = italic_F ( italic_V ).\n\nThere is an almost g\ud835\udc54gitalic_g-compatible and torsion-free connection DVsuperscript\ud835\udc37\ud835\udc49D^{V}italic_D start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT called Chern connection on the pull-back tangent bundle \u03c0*\u2062T\u2062Msuperscript\ud835\udf0b\ud835\udc47\ud835\udc40\\pi^{*}TMitalic_\u03c0 start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_T italic_M. Namely, for any X\ud835\udc4bXitalic_X, Y\ud835\udc4cYitalic_Y, Z\u2208T\u2062M\ud835\udc4d\ud835\udc47\ud835\udc40Z\\in TMitalic_Z \u2208 italic_T italic_M, where the Cartan tensor CVsubscript\ud835\udc36\ud835\udc49C_{V}italic_C start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT is one of non-Riemannian tensors given by Also letting \u0393j\u2062ki\u2062(V)subscriptsuperscript\u0393\ud835\udc56\ud835\udc57\ud835\udc58\ud835\udc49\\Gamma^{i}_{jk}(V)roman_\u0393 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT ( italic_V ) denote the coefficients of Chern connection, one defines the spray coefficients as and the spray where \u03b4\u03b4\u2062xi=\u2202\u2202xi\u2212Nij\u2062\u2202\u2202vj\ud835\udeff\ud835\udeffsuperscript\ud835\udc65\ud835\udc56superscript\ud835\udc65\ud835\udc56subscriptsuperscript\ud835\udc41\ud835\udc57\ud835\udc56superscript\ud835\udc63\ud835\udc57\\frac{\\delta}{\\delta x^{i}}=\\frac{\\partial}{\\partial x^{i}}-N^{j}_{i}\\frac{%\n\\partial}{\\partial v^{j}}divide start_ARG italic_\u03b4 end_ARG start_ARG italic_\u03b4 italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG = divide start_ARG \u2202 end_ARG start_ARG \u2202 italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG - italic_N start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT divide start_ARG \u2202 end_ARG start_ARG \u2202 italic_v start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG and Nij=\u2202Gj\u2202visubscriptsuperscript\ud835\udc41\ud835\udc57\ud835\udc56superscript\ud835\udc3a\ud835\udc57superscript\ud835\udc63\ud835\udc56N^{j}_{i}=\\frac{\\partial G^{j}}{\\partial v^{i}}italic_N start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = divide start_ARG \u2202 italic_G start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG start_ARG \u2202 italic_v start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG.\nCustomarily, we denote the horizontal and vertical Chern derivatives by \u201c||||\u201d and \u201c; \u201d, respectively. For example, for some tensor T=Ti\u2062d\u2062xi\ud835\udc47subscript\ud835\udc47\ud835\udc56\ud835\udc51superscript\ud835\udc65\ud835\udc56T=T_{i}dx^{i}italic_T = italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_d italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT on the pull-back bundle, The spray coefficients could induce the geodesic, a curve \u03b3\ud835\udefe\\gammaitalic_\u03b3 on M\ud835\udc40Mitalic_M satisfying A forward geodesic ball centered at p\ud835\udc5dpitalic_p with\nradius R\ud835\udc45Ritalic_R can be represented by Here the forward distance from p\ud835\udc5dpitalic_p to q\ud835\udc5eqitalic_q is given by where the infimum is taken over all the C1superscript\ud835\udc361C^{1}italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT\ncurves \u03b3\ud835\udefe\\gammaitalic_\u03b3 : [0,1]\u2192M\u219201\ud835\udc40[0,1]\\to M[ 0 , 1 ] \u2192 italic_M such that \u03b3\u2062(0)=p\ud835\udefe0\ud835\udc5d\\gamma(0)=pitalic_\u03b3 ( 0 ) = italic_p\nand \u03b3\u2062(1)=q\ud835\udefe1\ud835\udc5e\\gamma(1)=qitalic_\u03b3 ( 1 ) = italic_q. Different from Riemannian manifold, the distance function is not necessarily symmetric between p\ud835\udc5dpitalic_p and q\ud835\udc5eqitalic_q.\nAdopting the exponential map, a Finsler manifold (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ) is said to be forward complete if the exponential map is defined over T\u2062M\ud835\udc47\ud835\udc40TMitalic_T italic_M. Thus, any two points in a forward complete manifold M\ud835\udc40Mitalic_M can be connected by a minimal geodesic. Additionally, the forward closed ball Bp+\u2062(R)\u00af\u00afsubscriptsuperscript\ud835\udc35\ud835\udc5d\ud835\udc45\\overline{B^{+}_{p}(R)}over\u00af start_ARG italic_B start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_R ) end_ARG is compact.\n\nThe curvature form \u03a9\u03a9\\Omegaroman_\u03a9 induced by Chern connection can be divided into Chern Riemannian curvature R\ud835\udc45Ritalic_R and Chern non-Riemannian connection P\ud835\udc43Pitalic_P as The flag curvature with pole v\ud835\udc63vitalic_v is locally expressed by for any two linearly independent vectors u,v\u2208Tx\u2062M\\\ud835\udfce\ud835\udc62\ud835\udc63\\subscript\ud835\udc47\ud835\udc65\ud835\udc400u,v\\in T_{x}M\\backslash\\mathbf{0}italic_u , italic_v \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M \\ bold_0, which span a tangent plane \u03a0=span\u2061{u,v}\u03a0span\ud835\udc62\ud835\udc63\\Pi=\\operatorname{span}\\{u,v\\}roman_\u03a0 = roman_span { italic_u , italic_v }. Then the Finslerian Ricci curvature is defined by where {e1,\u2026\u2062en\u22121,v/F\u2062(v)}subscript\ud835\udc521\u2026subscript\ud835\udc52\ud835\udc5b1\ud835\udc63\ud835\udc39\ud835\udc63\\{e_{1},...e_{n-1},v/F(v)\\}{ italic_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 italic_e start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT , italic_v / italic_F ( italic_v ) } is an orthonormal basis of Tx\u2062Msubscript\ud835\udc47\ud835\udc65\ud835\udc40T_{x}Mitalic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M with respect to gvsubscript\ud835\udc54\ud835\udc63g_{v}italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT. The T-curvature is another non-Riemannian quantity, given by where v\u2208Tx\u2062M,V\ud835\udc63subscript\ud835\udc47\ud835\udc65\ud835\udc40\ud835\udc49v\\in T_{x}M,Vitalic_v \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M , italic_V is a vector field with V\u2062(x)=v\ud835\udc49\ud835\udc65\ud835\udc63V(x)=vitalic_V ( italic_x ) = italic_v, and D^^\ud835\udc37\\hat{D}over^ start_ARG italic_D end_ARG denotes the Levi-Civita connection of the induced Riemannian metric g^=gY^\ud835\udc54subscript\ud835\udc54\ud835\udc4c\\hat{g}=g_{Y}over^ start_ARG italic_g end_ARG = italic_g start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT. The T-curvature vanishes if and only if the Chern non-Riemannian curvature P\ud835\udc43Pitalic_P vanishes. To find the trace of T-curvature, let {ei}subscript\ud835\udc52\ud835\udc56\\left\\{e_{i}\\right\\}{ italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } be an orthonormal basis with respect to metric gVsubscript\ud835\udc54\ud835\udc49g_{V}italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT at point x\ud835\udc65xitalic_x, where V\ud835\udc49Vitalic_V is a fixed reference vector field. Moreover, Let {Ei}subscript\ud835\udc38\ud835\udc56\\left\\{E_{i}\\right\\}{ italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } be the local vector fields obtained by moving {ei}subscript\ud835\udc52\ud835\udc56\\left\\{e_{i}\\right\\}{ italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } in parallel in a neighborhood of x\ud835\udc65xitalic_x on M\ud835\udc40Mitalic_M. define the tensor U\ud835\udc48Uitalic_U as for any local vector field W\ud835\udc4aWitalic_W, with We introduce an important constant on a Finsler manifold defined in [16], called the misalignment. (misalignment)\nFor a Finsler manifold (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ), the misalignment of a Finsler metric at x\u2208M\ud835\udc65\ud835\udc40x\\in Mitalic_x \u2208 italic_M is defined by and the global misalignment of the Finsler metric by In particular, a Finsler manifold (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ) is Riemannian if and only if \u03b1\u2062(x)\u22611\ud835\udefc\ud835\udc651\\alpha(x)\\equiv 1italic_\u03b1 ( italic_x ) \u2261 1. More characterizations of the misalignment can be found in [16]. The Legendre transform \u2112*:T*\u2062M\u2192T\u2062M:superscript\u2112\u2192superscript\ud835\udc47\ud835\udc40\ud835\udc47\ud835\udc40\\mathcal{L}^{*}:T^{*}M\\rightarrow TMcaligraphic_L start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT : italic_T start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_M \u2192 italic_T italic_M maps \u03b1\u2208Tx*\u2062M\ud835\udefcsuperscriptsubscript\ud835\udc47\ud835\udc65\ud835\udc40\\alpha\\in T_{x}^{*}Mitalic_\u03b1 \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_M to the unique element v\u2208Tx\u2062M\ud835\udc63subscript\ud835\udc47\ud835\udc65\ud835\udc40v\\in T_{x}Mitalic_v \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M such that \u03b1\u2062(v)=F*\u2062(\u03b1)2\ud835\udefc\ud835\udc63superscript\ud835\udc39superscript\ud835\udefc2\\alpha(v)=F^{*}(\\alpha)^{2}italic_\u03b1 ( italic_v ) = italic_F start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_\u03b1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT where F*\u2062(\u03b1):=F\u2062(v)assignsuperscript\ud835\udc39\ud835\udefc\ud835\udc39\ud835\udc63F^{*}(\\alpha):=F(v)italic_F start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_\u03b1 ) := italic_F ( italic_v ) is the dual norm of F\ud835\udc39Fitalic_F. For a differentiable function f:M\u2192\u211d:\ud835\udc53\u2192\ud835\udc40\u211df:M\\rightarrow\\mathbb{R}italic_f : italic_M \u2192 blackboard_R, the gradient vector of u\ud835\udc62uitalic_u at x\ud835\udc65xitalic_x is defined by \u2207u\u2062(x):=\u2112*\u2062(D\u2062u\u2062(x))\u2208Tx\u2062Massign\u2207\ud835\udc62\ud835\udc65superscript\u2112\ud835\udc37\ud835\udc62\ud835\udc65subscript\ud835\udc47\ud835\udc65\ud835\udc40\\nabla u(x):=\\mathcal{L}^{*}(Du(x))\\in T_{x}M\u2207 italic_u ( italic_x ) := caligraphic_L start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_D italic_u ( italic_x ) ) \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M. If D\u2062u\u2062(x)=0\ud835\udc37\ud835\udc62\ud835\udc650Du(x)=0italic_D italic_u ( italic_x ) = 0, then clearly \u2207u\u2062(x)=0\u2207\ud835\udc62\ud835\udc650\\nabla u(x)=0\u2207 italic_u ( italic_x ) = 0. If D\u2062u\u2062(x)\u22600\ud835\udc37\ud835\udc62\ud835\udc650Du(x)\\neq 0italic_D italic_u ( italic_x ) \u2260 0, and we can write in coordinates On Mu:={x\u2208M:D\u2062u\u2062(x)\u2260\ud835\udfce}assignsubscript\ud835\udc40\ud835\udc62conditional-set\ud835\udc65\ud835\udc40\ud835\udc37\ud835\udc62\ud835\udc650M_{u}:=\\{x\\in M:Du(x)\\neq\\mathbf{0}\\}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT := { italic_x \u2208 italic_M : italic_D italic_u ( italic_x ) \u2260 bold_0 }, we also define the Hessian of u\ud835\udc62uitalic_u by The symmetricity of Hessian tensor can be shown in [15].\n\nA Finsler metric measure space (M,F,d\u2062\u03bc)\ud835\udc40\ud835\udc39\ud835\udc51\ud835\udf07(M,F,d\\mu)( italic_M , italic_F , italic_d italic_\u03bc ) is a Finsler manifold equipped with an given measure \u03bc\ud835\udf07\\muitalic_\u03bc. In local coordinates {xi}i=1nsuperscriptsubscriptsuperscript\ud835\udc65\ud835\udc56\ud835\udc561\ud835\udc5b\\left\\{x^{i}\\right\\}_{i=1}^{n}{ italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, the volume form can be expressed as d\u2062\u03bc=\u03c3\u2062(x)\u2062d\u2062x1\u2227\u22ef\u2227d\u2062xn\ud835\udc51\ud835\udf07\ud835\udf0e\ud835\udc65\ud835\udc51superscript\ud835\udc651\u22ef\ud835\udc51superscript\ud835\udc65\ud835\udc5bd\\mu=\\sigma(x)dx^{1}\\wedge\\cdots\\wedge dx^{n}italic_d italic_\u03bc = italic_\u03c3 ( italic_x ) italic_d italic_x start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT \u2227 \u22ef \u2227 italic_d italic_x start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. For any y\u2208Tx\u2062M\\{0}\ud835\udc66\\subscript\ud835\udc47\ud835\udc65\ud835\udc400y\\in T_{x}M\\backslash\\{0\\}italic_y \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M \\ { 0 }, define\nthe distortion by For any point x\u2208M\ud835\udc65\ud835\udc40x\\in Mitalic_x \u2208 italic_M, let \u03b3=\u03b3\u2062(t)\ud835\udefe\ud835\udefe\ud835\udc61\\gamma=\\gamma(t)italic_\u03b3 = italic_\u03b3 ( italic_t ) be a forward geodesic from x\ud835\udc65xitalic_x with the initial tangent vector \u03b3\u02d9\u2062(0)=v\u02d9\ud835\udefe0\ud835\udc63\\dot{\\gamma}(0)=vover\u02d9 start_ARG italic_\u03b3 end_ARG ( 0 ) = italic_v. The S\ud835\udc46Sitalic_S-curvature of (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) is Modeling the definition of T-curvature, Shen [16] defined another non-Riemannian curvature for vector fields V\ud835\udc49Vitalic_V, W\ud835\udc4aWitalic_W on M\ud835\udc40Mitalic_M. Intuitively, S\ud835\udc46Sitalic_S-curvature is the changing of distortion along the geodesic in direction v\ud835\udc63vitalic_v and \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T is the difference of \u2207\u03c4\u2207\ud835\udf0f\\nabla\\tau\u2207 italic_\u03c4 on the tangent sphere.\n\nIn local coordinates {xi}superscript\ud835\udc65\ud835\udc56\\{x^{i}\\}{ italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT }, let d\u2062\u03bc=e\u03a6\u2062d\u2062x1\u2062\u2026\u2062d\u2062xn\ud835\udc51\ud835\udf07superscript\ud835\udc52\u03a6\ud835\udc51superscript\ud835\udc651\u2026\ud835\udc51superscript\ud835\udc65\ud835\udc5bd\\mu=e^{\\Phi}dx^{1}...dx^{n}italic_d italic_\u03bc = italic_e start_POSTSUPERSCRIPT roman_\u03a6 end_POSTSUPERSCRIPT italic_d italic_x start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT \u2026 italic_d italic_x start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT express the volume form, then the divergence of a smooth vector field V\ud835\udc49Vitalic_V can be written as The Finslerian Laplacian of a function f\ud835\udc53fitalic_f on M\ud835\udc40Mitalic_M could now be given by On Mf:={x\u2208M:\u2207f\u2260\ud835\udfce}assignsubscript\ud835\udc40\ud835\udc53conditional-set\ud835\udc65\ud835\udc40\u2207\ud835\udc530M_{f}:=\\{x\\in M:\\nabla f\\neq\\mathbf{0}\\}italic_M start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT := { italic_x \u2208 italic_M : \u2207 italic_f \u2260 bold_0 }, one notices that \u0394d\u2062\u03bc\u2207f\u2062f=\u0394d\u2062\u03bc\u2062fsuperscriptsubscript\u0394\ud835\udc51\ud835\udf07\u2207\ud835\udc53\ud835\udc53subscript\u0394\ud835\udc51\ud835\udf07\ud835\udc53\\Delta_{d\\mu}^{\\nabla f}f=\\Delta_{d\\mu}froman_\u0394 start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT italic_f = roman_\u0394 start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT italic_f\nwhere \u0394d\u2062\u03bc\u2207fsuperscriptsubscript\u0394\ud835\udc51\ud835\udf07\u2207\ud835\udc53\\Delta_{d\\mu}^{\\nabla f}roman_\u0394 start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT is the weighted Laplacian defined by \u0394d\u2062\u03bc\u2207f\u2062f:=divd\u2062\u03bc\u2061(\u2207\u2207ff)assignsuperscriptsubscript\u0394\ud835\udc51\ud835\udf07\u2207\ud835\udc53\ud835\udc53subscriptdiv\ud835\udc51\ud835\udf07superscript\u2207\u2207\ud835\udc53\ud835\udc53\\Delta_{d\\mu}^{\\nabla f}f:=\\operatorname{div}_{d\\mu}\\left(\\nabla^{\\nabla f}f\\right)roman_\u0394 start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT italic_f := roman_div start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT ( \u2207 start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT italic_f )\nwhere for a non-vanishing vector field V\ud835\udc49Vitalic_V. In particular, \u2207\u2207ff=\u2207fsuperscript\u2207\u2207\ud835\udc53\ud835\udc53\u2207\ud835\udc53\\nabla^{\\nabla f}f=\\nabla f\u2207 start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT italic_f = \u2207 italic_f also holds on Mfsubscript\ud835\udc40\ud835\udc53M_{f}italic_M start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT. So it is valid to use \u2207=\u2207\u2207f\u2207superscript\u2207\u2207\ud835\udc53\\nabla=\\nabla^{\\nabla f}\u2207 = \u2207 start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT and \u0394=\u0394\u2207f=\u0394d\u2062\u03bc\u2207f\u0394superscript\u0394\u2207\ud835\udc53subscriptsuperscript\u0394\u2207\ud835\udc53\ud835\udc51\ud835\udf07\\Delta=\\Delta^{\\nabla f}=\\Delta^{\\nabla f}_{d\\mu}roman_\u0394 = roman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT = roman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT for short, when f\ud835\udc53fitalic_f is exactly the function that \u2207\u2207\\nabla\u2207 or \u0394\u0394\\Deltaroman_\u0394 act on.\nOne also observes for later frequent use that, given functions f\ud835\udc53fitalic_f, f1subscript\ud835\udc531f_{1}italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and f2subscript\ud835\udc532f_{2}italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT on Mfsubscript\ud835\udc40\ud835\udc53M_{f}italic_M start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT, Let H1\u2062(M):=W1,2\u2062(M)assignsuperscript\ud835\udc3b1\ud835\udc40superscript\ud835\udc4a12\ud835\udc40H^{1}(M):=W^{1,2}(M)italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ) := italic_W start_POSTSUPERSCRIPT 1 , 2 end_POSTSUPERSCRIPT ( italic_M ) be the Sobolev space under norm where F\u2190\u2062(x,v):=F\u2062(x,\u2212v)assign\u2190\ud835\udc39\ud835\udc65\ud835\udc63\ud835\udc39\ud835\udc65\ud835\udc63\\overleftarrow{F}(x,v):=F(x,-v)over\u2190 start_ARG italic_F end_ARG ( italic_x , italic_v ) := italic_F ( italic_x , - italic_v ) is the reverse Finsler metric and \u2207\u2190\u2190\u2207\\overleftarrow{\\nabla}over\u2190 start_ARG \u2207 end_ARG is the gradient with respect to the reverse metric F\u2190\u2190\ud835\udc39\\overleftarrow{F}over\u2190 start_ARG italic_F end_ARG. Then H1\u2062(M)superscript\ud835\udc3b1\ud835\udc40H^{1}(M)italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ) is in fact a Banach space with respect to \u2225\u22c5\u2225H1\u2062(M)\\|\\cdot\\|_{H^{1}(M)}\u2225 \u22c5 \u2225 start_POSTSUBSCRIPT italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ) end_POSTSUBSCRIPT, and H01\u2062(M)superscriptsubscript\ud835\udc3b01\ud835\udc40H_{0}^{1}(M)italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ) is also the closure of C0\u221e\u2062(M)subscriptsuperscript\ud835\udc360\ud835\udc40C^{\\infty}_{0}(M)italic_C start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_M ) under the norm defined in (2.25).\n\nDue to the lack of regularity, Finslerian Laplacian is usually viewed in distributional sense (or weak sense) that for any nonnegative function \u03c6\u2208H01\u2062(M)\u2229L\u221e\u2062(M)\ud835\udf11superscriptsubscript\ud835\udc3b01\ud835\udc40superscript\ud835\udc3f\ud835\udc40\\varphi\\in H_{0}^{1}(M)\\cap L^{\\infty}(M)italic_\u03c6 \u2208 italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ) \u2229 italic_L start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT ( italic_M ).\n\nEmploying S\ud835\udc46Sitalic_S-curvature, we present the definition of the weighted Ricci curvature introduced by S. Ohta [15] as follows. ([15])\nGiven a unit vector v\u2208Tx\u2062M\ud835\udc63subscript\ud835\udc47\ud835\udc65\ud835\udc40v\\in T_{x}Mitalic_v \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M and an integer\nN\u2208[n,+\u221e]\ud835\udc41\ud835\udc5bN\\in[n,+\\infty]italic_N \u2208 [ italic_n , + \u221e ], the weighted Ricci curvature is defined by Ricn\u2061(x,v):={Ric\u2061(x,v)+S\u02d9\u2062(x,v)\u00a0if\u00a0\u2062S\u2062(x,v)=0;\u2212\u221e\u00a0if\u00a0\u2062S\u2062(x,v)\u22600.assignsuperscriptRic\ud835\udc5b\ud835\udc65\ud835\udc63casesRic\ud835\udc65\ud835\udc63\u02d9\ud835\udc46\ud835\udc65\ud835\udc63\u00a0if\u00a0\ud835\udc46\ud835\udc65\ud835\udc630\u00a0if\u00a0\ud835\udc46\ud835\udc65\ud835\udc630\\operatorname{Ric}^{n}(x,v):=\\begin{cases}\\operatorname{Ric}(x,v)+\\dot{S}(x,v)%\n&\\text{ if }{S}(x,v)=0;\\\\\n-\\infty&\\text{ if }{S}(x,v)\\neq 0.\\end{cases}roman_Ric start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_x , italic_v ) := { start_ROW start_CELL roman_Ric ( italic_x , italic_v ) + over\u02d9 start_ARG italic_S end_ARG ( italic_x , italic_v ) end_CELL start_CELL if italic_S ( italic_x , italic_v ) = 0 ; end_CELL end_ROW start_ROW start_CELL - \u221e end_CELL start_CELL if italic_S ( italic_x , italic_v ) \u2260 0 . end_CELL end_ROW RicN\u2061(x,v):=Ric\u2061(x,v)+S\u02d9\u2062(x,v)\u2212S2\u2062(x,v)N\u2212nassignsuperscriptRic\ud835\udc41\ud835\udc65\ud835\udc63Ric\ud835\udc65\ud835\udc63\u02d9\ud835\udc46\ud835\udc65\ud835\udc63superscript\ud835\udc462\ud835\udc65\ud835\udc63\ud835\udc41\ud835\udc5b\\operatorname{Ric}^{N}(x,v):=\\operatorname{Ric}(x,v)+\\dot{S}(x,v)-\\frac{S^{2}(%\nx,v)}{N-n}roman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ( italic_x , italic_v ) := roman_Ric ( italic_x , italic_v ) + over\u02d9 start_ARG italic_S end_ARG ( italic_x , italic_v ) - divide start_ARG italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_x , italic_v ) end_ARG start_ARG italic_N - italic_n end_ARG when n<N<\u221e\ud835\udc5b\ud835\udc41n<N<\\inftyitalic_n < italic_N < \u221e. Ric\u221e\u2061(x,v):=Ric\u2061(x,v)+S\u02d9\u2062(x,v)assignsuperscriptRic\ud835\udc65\ud835\udc63Ric\ud835\udc65\ud835\udc63\u02d9\ud835\udc46\ud835\udc65\ud835\udc63\\operatorname{Ric}^{\\infty}(x,v):=\\operatorname{Ric}(x,v)+\\dot{S}(x,v)roman_Ric start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT ( italic_x , italic_v ) := roman_Ric ( italic_x , italic_v ) + over\u02d9 start_ARG italic_S end_ARG ( italic_x , italic_v ). Here S\u02d9\u2062(x,v)\u02d9\ud835\udc46\ud835\udc65\ud835\udc63\\dot{S}(x,v)over\u02d9 start_ARG italic_S end_ARG ( italic_x , italic_v ) is the derivative along the geodesic from x\ud835\udc65xitalic_x in the direction of v\ud835\udc63vitalic_v. B. Wu [20] defined the weighted flag curvature when k\u2260n\ud835\udc58\ud835\udc5bk\\neq nitalic_k \u2260 italic_n and B. Shen [16] completed this concept for any k\ud835\udc58kitalic_k. ([20][16])\nGiven two linearly independent vectors v\ud835\udc63vitalic_v, w\u2208Tx\u2062M\ud835\udc64subscript\ud835\udc47\ud835\udc65\ud835\udc40w\\in T_{x}Mitalic_w \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M and an integer\nk\u2208[n,+\u221e]\ud835\udc58\ud835\udc5bk\\in[n,+\\infty]italic_k \u2208 [ italic_n , + \u221e ], the weighted Ricci curvature is defined by Kn\u2061(v,w):={K\u2061(v,w)+S\u02d9\u2062(x,v)(n\u22121)\u2062F2\u2062(v)\u00a0if\u00a0\u2062S\u2062(x,v)=0;\u2212\u221e\u00a0if\u00a0\u2062S\u2062(x,v)\u22600.assignsuperscriptK\ud835\udc5b\ud835\udc63\ud835\udc64casesK\ud835\udc63\ud835\udc64\u02d9\ud835\udc46\ud835\udc65\ud835\udc63\ud835\udc5b1superscript\ud835\udc392\ud835\udc63\u00a0if\u00a0\ud835\udc46\ud835\udc65\ud835\udc630\u00a0if\u00a0\ud835\udc46\ud835\udc65\ud835\udc630\\operatorname{K}^{n}(v,w):=\\begin{cases}\\operatorname{K}(v,w)+\\frac{\\dot{S}(x,%\nv)}{(n-1)F^{2}(v)}&\\text{ if }{S}(x,v)=0;\\\\\n-\\infty&\\text{ if }{S}(x,v)\\neq 0.\\end{cases}roman_K start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_v , italic_w ) := { start_ROW start_CELL roman_K ( italic_v , italic_w ) + divide start_ARG over\u02d9 start_ARG italic_S end_ARG ( italic_x , italic_v ) end_ARG start_ARG ( italic_n - 1 ) italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_v ) end_ARG end_CELL start_CELL if italic_S ( italic_x , italic_v ) = 0 ; end_CELL end_ROW start_ROW start_CELL - \u221e end_CELL start_CELL if italic_S ( italic_x , italic_v ) \u2260 0 . end_CELL end_ROW Kk\u2061(v,w):=K\u2061(v,w)+S\u02d9\u2062(x,v)(n\u22121)\u2062F2\u2062(v)\u2212S2\u2062(x,v)(n\u22121)\u2062(k\u2212n)\u2062F2\u2062(v)assignsuperscriptK\ud835\udc58\ud835\udc63\ud835\udc64K\ud835\udc63\ud835\udc64\u02d9\ud835\udc46\ud835\udc65\ud835\udc63\ud835\udc5b1superscript\ud835\udc392\ud835\udc63superscript\ud835\udc462\ud835\udc65\ud835\udc63\ud835\udc5b1\ud835\udc58\ud835\udc5bsuperscript\ud835\udc392\ud835\udc63\\operatorname{K}^{k}(v,w):=\\operatorname{K}(v,w)+\\frac{\\dot{S}(x,v)}{(n-1)F^{2%\n}(v)}-\\frac{S^{2}(x,v)}{(n-1)(k-n)F^{2}(v)}roman_K start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_v , italic_w ) := roman_K ( italic_v , italic_w ) + divide start_ARG over\u02d9 start_ARG italic_S end_ARG ( italic_x , italic_v ) end_ARG start_ARG ( italic_n - 1 ) italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_v ) end_ARG - divide start_ARG italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_x , italic_v ) end_ARG start_ARG ( italic_n - 1 ) ( italic_k - italic_n ) italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_v ) end_ARG when n<k<\u221e\ud835\udc5b\ud835\udc58n<k<\\inftyitalic_n < italic_k < \u221e. K\u221e\u2061(x,v):=K\u2061(v,w)+S\u02d9\u2062(x,v)(n\u22121)\u2062F2\u2062(v)assignsuperscriptK\ud835\udc65\ud835\udc63K\ud835\udc63\ud835\udc64\u02d9\ud835\udc46\ud835\udc65\ud835\udc63\ud835\udc5b1superscript\ud835\udc392\ud835\udc63\\operatorname{K}^{\\infty}(x,v):=\\operatorname{K}(v,w)+\\frac{\\dot{S}(x,v)}{(n-1%\n)F^{2}(v)}roman_K start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT ( italic_x , italic_v ) := roman_K ( italic_v , italic_w ) + divide start_ARG over\u02d9 start_ARG italic_S end_ARG ( italic_x , italic_v ) end_ARG start_ARG ( italic_n - 1 ) italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_v ) end_ARG. Moreover, B. Shen [16] have also defined the mixed weighted Ricci curvature. ([16])\nGiven two linearly independent vectors v\ud835\udc63vitalic_v, w\u2208Tx\u2062M\ud835\udc64subscript\ud835\udc47\ud835\udc65\ud835\udc40w\\in T_{x}Mitalic_w \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M and an integer\nk\u2208[n,+\u221e]\ud835\udc58\ud835\udc5bk\\in[n,+\\infty]italic_k \u2208 [ italic_n , + \u221e ], the mixed weighted Ricci curvature is defined by Ricwnm\u2061(x,v):={trw\u2061Rv\u2062(v)+S\u02d9\u2062(x,v)\u00a0if\u00a0\u2062S\u2062(x,v)=0;\u2212\u221e\u00a0if\u00a0\u2062S\u2062(x,v)\u22600.assignsuperscriptsubscriptsuperscriptRic\ud835\udc5b\ud835\udc64\ud835\udc5a\ud835\udc65\ud835\udc63casessubscripttr\ud835\udc64subscript\ud835\udc45\ud835\udc63\ud835\udc63\u02d9\ud835\udc46\ud835\udc65\ud835\udc63\u00a0if\u00a0\ud835\udc46\ud835\udc65\ud835\udc630\u00a0if\u00a0\ud835\udc46\ud835\udc65\ud835\udc630{}^{m}\\operatorname{Ric}^{n}_{w}(x,v):=\\begin{cases}\\operatorname{tr}_{w}R_{v}%\n(v)+\\dot{S}(x,v)&\\text{ if }{S}(x,v)=0;\\\\\n-\\infty&\\text{ if }{S}(x,v)\\neq 0.\\end{cases}start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT roman_Ric start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ( italic_x , italic_v ) := { start_ROW start_CELL roman_tr start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_R start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_v ) + over\u02d9 start_ARG italic_S end_ARG ( italic_x , italic_v ) end_CELL start_CELL if italic_S ( italic_x , italic_v ) = 0 ; end_CELL end_ROW start_ROW start_CELL - \u221e end_CELL start_CELL if italic_S ( italic_x , italic_v ) \u2260 0 . end_CELL end_ROW Ricwkm\u2061(x,v):=trw\u2061Rv\u2062(v)+S\u02d9\u2062(x,v)\u2212S2\u2062(x,v)k\u2212nassignsuperscriptsubscriptsuperscriptRic\ud835\udc58\ud835\udc64\ud835\udc5a\ud835\udc65\ud835\udc63subscripttr\ud835\udc64subscript\ud835\udc45\ud835\udc63\ud835\udc63\u02d9\ud835\udc46\ud835\udc65\ud835\udc63superscript\ud835\udc462\ud835\udc65\ud835\udc63\ud835\udc58\ud835\udc5b{}^{m}\\operatorname{Ric}^{k}_{w}(x,v):=\\operatorname{tr}_{w}R_{v}(v)+\\dot{S}(x%\n,v)-\\frac{S^{2}(x,v)}{k-n}start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT roman_Ric start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ( italic_x , italic_v ) := roman_tr start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_R start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_v ) + over\u02d9 start_ARG italic_S end_ARG ( italic_x , italic_v ) - divide start_ARG italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_x , italic_v ) end_ARG start_ARG italic_k - italic_n end_ARG when n<N<\u221e\ud835\udc5b\ud835\udc41n<N<\\inftyitalic_n < italic_N < \u221e. Ricw\u221em\u2061(x,v):=trw\u2061Rv\u2062(v)+S\u02d9\u2062(x,v)assignsuperscriptsubscriptsuperscriptRic\ud835\udc64\ud835\udc5a\ud835\udc65\ud835\udc63subscripttr\ud835\udc64subscript\ud835\udc45\ud835\udc63\ud835\udc63\u02d9\ud835\udc46\ud835\udc65\ud835\udc63{}^{m}\\operatorname{Ric}^{\\infty}_{w}(x,v):=\\operatorname{tr}_{w}R_{v}(v)+\\dot%\n{S}(x,v)start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT roman_Ric start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ( italic_x , italic_v ) := roman_tr start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_R start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_v ) + over\u02d9 start_ARG italic_S end_ARG ( italic_x , italic_v ). where trw\u2061Rv\u2062(v):=gi\u2062j\u2062(w)\u2062gv\u2062(Rv\u2062(ei,v),ej)assignsubscripttr\ud835\udc64subscript\ud835\udc45\ud835\udc63\ud835\udc63superscript\ud835\udc54\ud835\udc56\ud835\udc57\ud835\udc64subscript\ud835\udc54\ud835\udc63subscript\ud835\udc45\ud835\udc63subscript\ud835\udc52\ud835\udc56\ud835\udc63subscript\ud835\udc52\ud835\udc57\\operatorname{tr}_{w}R_{v}(v):=g^{ij}(w)g_{v}(R_{v}(e_{i},v),e_{j})roman_tr start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_R start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_v ) := italic_g start_POSTSUPERSCRIPT italic_i italic_j end_POSTSUPERSCRIPT ( italic_w ) italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_R start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v ) , italic_e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) is the trace of flag curvature with respect to gwsubscript\ud835\udc54\ud835\udc64g_{w}italic_g start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT. Note that the weighted Ricci curvature is a special case of the mixed weighted Ricci curvature since Ricvkm\u2061(x,v)=Rick\u2061(x,v)superscriptsubscriptsuperscriptRic\ud835\udc58\ud835\udc63\ud835\udc5a\ud835\udc65\ud835\udc63superscriptRic\ud835\udc58\ud835\udc65\ud835\udc63{}^{m}\\operatorname{Ric}^{k}_{v}(x,v)=\\operatorname{Ric}^{k}(x,v)start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT roman_Ric start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_x , italic_v ) = roman_Ric start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_x , italic_v ).\n\nNext we introduce two important tools: Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be an n\ud835\udc5bnitalic_n-dimensional Finsler metric measure space. Given u\u2208Hloc2\u2062(M)\u2229C1\u2062(M)\ud835\udc62superscriptsubscript\ud835\udc3bnormal-loc2\ud835\udc40superscript\ud835\udc361\ud835\udc40u\\in H_{\\mathrm{loc}}^{2}(M)\\cap{C}^{1}(M)italic_u \u2208 italic_H start_POSTSUBSCRIPT roman_loc end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_M ) \u2229 italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ) with \u0394\u2062u\u2208Hloc1\u2062(M)normal-\u0394\ud835\udc62superscriptsubscript\ud835\udc3bnormal-loc1\ud835\udc40\\Delta u\\in H_{\\mathrm{loc}}^{1}(M)roman_\u0394 italic_u \u2208 italic_H start_POSTSUBSCRIPT roman_loc end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ), for N\u2208[n,+\u221e]\ud835\udc41\ud835\udc5bN\\in[n,+\\infty]italic_N \u2208 [ italic_n , + \u221e ], we have in sense of distribution, that is, for all nonnegative functions \u03c6\u2208H01\u2062(M)\u2229L\u221e\u2062(M)\ud835\udf11superscriptsubscript\ud835\udc3b01\ud835\udc40superscript\ud835\udc3f\ud835\udc40\\varphi\\in H_{0}^{1}(M)\\cap L^{\\infty}(M)italic_\u03c6 \u2208 italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ) \u2229 italic_L start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT ( italic_M ). Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a forward complete n\ud835\udc5bnitalic_n-dimensional Finsler metric measure space. Denote the forward distance function by r\ud835\udc5fritalic_r and by V\ud835\udc49Vitalic_V a fixed vector field on M\ud835\udc40Mitalic_M. Suppose the misalignment of M\ud835\udc40Mitalic_M is finite with upper bound A\ud835\udc34Aitalic_A, and the mixed weighted Ricci curvature Ric\u2207rNm\u2061(V)superscriptsubscriptsuperscriptnormal-Ric\ud835\udc41normal-\u2207\ud835\udc5f\ud835\udc5a\ud835\udc49{}^{m}\\operatorname{Ric}^{N}_{\\nabla r}(V)start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT roman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u2207 italic_r end_POSTSUBSCRIPT ( italic_V ) of M\ud835\udc40Mitalic_M is bounded from below by \u2212K\ud835\udc3e-K- italic_K with K>0\ud835\udc3e0K>0italic_K > 0, for some N>n\ud835\udc41\ud835\udc5bN>nitalic_N > italic_n. Suppose the non-Riemannian curvatures U\ud835\udc48Uitalic_U, \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T (defined in (2.16) and (2.20) respectively) and div\u2061C\u2062(V):=Ck|ii\u2062j\u2062(V)\u2062Vk\u2062\u03b4\u03b4\u2062xjassignnormal-div\ud835\udc36\ud835\udc49subscriptsuperscript\ud835\udc36\ud835\udc56\ud835\udc57conditional\ud835\udc58\ud835\udc56\ud835\udc49superscript\ud835\udc49\ud835\udc58\ud835\udeff\ud835\udeffsuperscript\ud835\udc65\ud835\udc57\\operatorname{div}C(V):=C^{ij}_{~{}~{}k|i}(V)V^{k}\\frac{\\delta}{\\delta x^{j}}roman_div italic_C ( italic_V ) := italic_C start_POSTSUPERSCRIPT italic_i italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k | italic_i end_POSTSUBSCRIPT ( italic_V ) italic_V start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG italic_\u03b4 end_ARG start_ARG italic_\u03b4 italic_x start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG\nsatisfy the norm bounds by Then, by setting l=K/C\u2062(N,A)\ud835\udc59\ud835\udc3e\ud835\udc36\ud835\udc41\ud835\udc34l=K/C(N,A)italic_l = italic_K / italic_C ( italic_N , italic_A ) with C\u2062(N,A)=\ud835\udc36\ud835\udc41\ud835\udc34absentC(N,A)=italic_C ( italic_N , italic_A ) = N+(A\u22121)\u2062n\u2212A\ud835\udc41\ud835\udc341\ud835\udc5b\ud835\udc34N+(A-1)n-Aitalic_N + ( italic_A - 1 ) italic_n - italic_A, wherever r\ud835\udc5fritalic_r is C2superscript\ud835\udc362C^{2}italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, the nonlinear Laplacian of r\ud835\udc5fritalic_r with reference vector V\ud835\udc49Vitalic_V satisfies Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a Finsler measure space. For any function f\u2208H1\u2062(M)\ud835\udc53superscript\ud835\udc3b1\ud835\udc40f\\in H^{1}(M)italic_f \u2208 italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ) with \u222bMf2\u2062\ud835\udc51\u03bc=vold\u2062\u03bc\u2061(M)subscript\ud835\udc40superscript\ud835\udc532differential-d\ud835\udf07subscriptvol\ud835\udc51\ud835\udf07\ud835\udc40\\int_{M}f^{2}d\\mu=\\operatorname{vol}_{d\\mu}(M)\u222b start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d italic_\u03bc = roman_vol start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT ( italic_M ), define\nthe Finslerian log-energy functional by and Finslerian log-Sobolev constant CF\u2062L\u2062Ssubscript\ud835\udc36\ud835\udc39\ud835\udc3f\ud835\udc46C_{FLS}italic_C start_POSTSUBSCRIPT italic_F italic_L italic_S end_POSTSUBSCRIPT is the infimum of E\ud835\udc38Eitalic_E, we then have the following theorem: If u\ud835\udc62uitalic_u achieves log-Sobolev constant CF\u2062L\u2062Ssubscript\ud835\udc36\ud835\udc39\ud835\udc3f\ud835\udc46C_{FLS}italic_C start_POSTSUBSCRIPT italic_F italic_L italic_S end_POSTSUBSCRIPT in the constraint of \u222bMu2\u2062\ud835\udc51\u03bc=vold\u2062\u03bc\u2061(M)subscript\ud835\udc40superscript\ud835\udc622differential-d\ud835\udf07subscriptnormal-vol\ud835\udc51\ud835\udf07\ud835\udc40\\int_{M}u^{2}d\\mu=\\operatorname{vol}_{d\\mu}(M)\u222b start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT italic_u start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d italic_\u03bc = roman_vol start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT ( italic_M )\nthen the Euler-Lagrange equation is given by Choose any local function v\ud835\udc63vitalic_v with compact support M\ud835\udc40Mitalic_M and t\u2208\u211d\ud835\udc61\u211dt\\in\\mathbb{R}italic_t \u2208 blackboard_R. By a direction variational calculation, we have Since the definition of CF\u2062L\u2062Ssubscript\ud835\udc36\ud835\udc39\ud835\udc3f\ud835\udc46C_{FLS}italic_C start_POSTSUBSCRIPT italic_F italic_L italic_S end_POSTSUBSCRIPT, it follows that The conclusion holds for the arbitrariness of v\ud835\udc63vitalic_v.\n\u220e Analog to [14], one can define the global and local solutions to equation (1.4): For T>0\ud835\udc470T>0italic_T > 0, we say that a function u\ud835\udc62uitalic_u on M\u00d7[0,T]\ud835\udc400\ud835\udc47M\\times[0,T]italic_M \u00d7 [ 0 , italic_T ] is a global solution to the equation (1.4) if u\u2208L2\u2062([0,T],H01\u2062(M))\u2229H1\u2062([0,T],H\u22121\u2062(M))\ud835\udc62superscript\ud835\udc3f20\ud835\udc47superscriptsubscript\ud835\udc3b01\ud835\udc40superscript\ud835\udc3b10\ud835\udc47superscript\ud835\udc3b1\ud835\udc40u\\in L^{2}\\left([0,T],H_{0}^{1}(M)\\right)\\cap H^{1}\\left([0,T],H^{-1}(M)\\right)italic_u \u2208 italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( [ 0 , italic_T ] , italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ) ) \u2229 italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( [ 0 , italic_T ] , italic_H start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_M ) ) and holds for all t\u2208[0,T]\ud835\udc610\ud835\udc47t\\in[0,T]italic_t \u2208 [ 0 , italic_T ] and \u03c6\u2208C0\u221e\u2062(M)\ud835\udf11superscriptsubscript\ud835\udc360\ud835\udc40\\varphi\\in C_{0}^{\\infty}(M)italic_\u03c6 \u2208 italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT ( italic_M ) (or \u03c6\u2208H01\u2062(M)\ud835\udf11superscriptsubscript\ud835\udc3b01\ud835\udc40\\varphi\\in H_{0}^{1}(M)italic_\u03c6 \u2208 italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M )). Given an open interval I\u2282\u211d\ud835\udc3c\u211dI\\subset\\mathbb{R}italic_I \u2282 blackboard_R and an open set \u03a9\u2282M\u03a9\ud835\udc40\\Omega\\subset Mroman_\u03a9 \u2282 italic_M, we say that a function u\ud835\udc62uitalic_u is a local solution to the equation (1.4) on \u03a9\u00d7I\u03a9\ud835\udc3c\\Omega\\times Iroman_\u03a9 \u00d7 italic_I if u\u2208Lloc2\u2062(\u03a9),F\u2062(\u2207u)\u2208Lloc2\u2062(\u03a9)formulae-sequence\ud835\udc62superscriptsubscript\ud835\udc3floc2\u03a9\ud835\udc39\u2207\ud835\udc62superscriptsubscript\ud835\udc3floc2\u03a9u\\in L_{\\mathrm{loc}}^{2}(\\Omega),F(\\nabla u)\\in L_{\\mathrm{loc}}^{2}(\\Omega)italic_u \u2208 italic_L start_POSTSUBSCRIPT roman_loc end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( roman_\u03a9 ) , italic_F ( \u2207 italic_u ) \u2208 italic_L start_POSTSUBSCRIPT roman_loc end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( roman_\u03a9 ) and holds for all \u03c6\u2208C0\u221e\u2062(\u03a9\u00d7I)\ud835\udf11superscriptsubscript\ud835\udc360\u03a9\ud835\udc3c\\varphi\\in C_{0}^{\\infty}(\\Omega\\times I)italic_\u03c6 \u2208 italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT ( roman_\u03a9 \u00d7 italic_I )(or \u03c6\u2208H01\u2062(\u03a9\u00d7I)\ud835\udf11superscriptsubscript\ud835\udc3b01\u03a9\ud835\udc3c\\varphi\\in H_{0}^{1}(\\Omega\\times I)italic_\u03c6 \u2208 italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( roman_\u03a9 \u00d7 italic_I )). The elliptic and parabolic regularities in [14] and [16] guarantee that the global solution u\u2062(x,t)\ud835\udc62\ud835\udc65\ud835\udc61u(x,t)italic_u ( italic_x , italic_t ) of (1.4) enjoys the Hloc2subscriptsuperscript\ud835\udc3b2locH^{2}_{\\text{loc}}italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT loc end_POSTSUBSCRIPT-regularity in x\ud835\udc65xitalic_x and C1,\u03b2superscript\ud835\udc361\ud835\udefdC^{1,\\beta}italic_C start_POSTSUPERSCRIPT 1 , italic_\u03b2 end_POSTSUPERSCRIPT-regularity (0<\u03b2<10\ud835\udefd10<\\beta<10 < italic_\u03b2 < 1) in term of both t\ud835\udc61titalic_t and x\ud835\udc65xitalic_x, meanwhile \u2202tu\u2208Hloc1\u2062(M)\u2229C\u2062(M)subscript\ud835\udc61\ud835\udc62subscriptsuperscript\ud835\udc3b1loc\ud835\udc40\ud835\udc36\ud835\udc40\\partial_{t}u\\in H^{1}_{\\text{loc}}(M)\\cap C(M)\u2202 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_u \u2208 italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT loc end_POSTSUBSCRIPT ( italic_M ) \u2229 italic_C ( italic_M ).\nMoreover, for the local solution u\u2062(x,t)\ud835\udc62\ud835\udc65\ud835\udc61u(x,t)italic_u ( italic_x , italic_t ) on \u03a9\u00d7I\u03a9\ud835\udc3c\\Omega\\times Iroman_\u03a9 \u00d7 italic_I then u\u2208H2\u2062(\u03a9)\u2229C1,\u03b2\u2062(\u03a9\u00d7I)\ud835\udc62superscript\ud835\udc3b2\u03a9superscript\ud835\udc361\ud835\udefd\u03a9\ud835\udc3cu\\in H^{2}(\\Omega)\\cap C^{1,\\beta}(\\Omega\\times I)italic_u \u2208 italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( roman_\u03a9 ) \u2229 italic_C start_POSTSUPERSCRIPT 1 , italic_\u03b2 end_POSTSUPERSCRIPT ( roman_\u03a9 \u00d7 italic_I ), \u0394\u2062u\u2208H1\u2062(M)\u2229C\u2062(\u03a9)\u0394\ud835\udc62superscript\ud835\udc3b1\ud835\udc40\ud835\udc36\u03a9\\Delta u\\in H^{1}(M)\\cap C(\\Omega)roman_\u0394 italic_u \u2208 italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M ) \u2229 italic_C ( roman_\u03a9 ) and \u2202tu\u2208Hloc1\u2062(\u03a9)\u2229C\u2062(\u03a9)subscript\ud835\udc61\ud835\udc62subscriptsuperscript\ud835\udc3b1loc\u03a9\ud835\udc36\u03a9\\partial_{t}u\\in H^{1}_{\\text{loc}}(\\Omega)\\cap C(\\Omega)\u2202 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_u \u2208 italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT loc end_POSTSUBSCRIPT ( roman_\u03a9 ) \u2229 italic_C ( roman_\u03a9 ). In this section we will always assume that (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) is a compact n\ud835\udc5bnitalic_n-dimensional Finsler metric measure space, whose weighted Ricci curvature RicNsuperscriptRic\ud835\udc41\\operatorname{Ric}^{N}roman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT has lower bound of \u2212K\ud835\udc3e-K- italic_K (K\u2a7e0\ud835\udc3e0K\\geqslant 0italic_K \u2a7e 0) for some N\u2208(n,\u221e)\ud835\udc41\ud835\udc5bN\\in(n,\\infty)italic_N \u2208 ( italic_n , \u221e ).\nLet u\ud835\udc62uitalic_u be a positive solution to (1.4) on M\u00d7[0,+\u221e)\ud835\udc400M\\times[0,+\\infty)italic_M \u00d7 [ 0 , + \u221e ). For convenience, if one replaces u\ud835\udc62uitalic_u by e\u2212b/a\u2062usuperscript\ud835\udc52\ud835\udc4f\ud835\udc4e\ud835\udc62e^{-b/a}uitalic_e start_POSTSUPERSCRIPT - italic_b / italic_a end_POSTSUPERSCRIPT italic_u in (1.4), it suffices to consider the following equation: i.e. for any test function \u03c6\u2208H01\u2062(M\u00d7[0,T])\ud835\udf11superscriptsubscript\ud835\udc3b01\ud835\udc400\ud835\udc47\\varphi\\in H_{0}^{1}(M\\times[0,T])italic_\u03c6 \u2208 italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_M \u00d7 [ 0 , italic_T ] )\n\nBefore we begin the proof of Theorem 1.1, we shall introduce some lemmas: For any fixed T>0\ud835\udc470T>0italic_T > 0, Let u\ud835\udc62uitalic_u be a positive solution to (3.1) on M\u00d7[0,T]\ud835\udc400\ud835\udc47M\\times[0,T]italic_M \u00d7 [ 0 , italic_T ] and f:=log\u2061uassign\ud835\udc53\ud835\udc62f:=\\log uitalic_f := roman_log italic_u, then in the distributional sense that Since \u2207u=u\u2062\u2207f\u2207\ud835\udc62\ud835\udc62\u2207\ud835\udc53\\nabla u=u\\nabla f\u2207 italic_u = italic_u \u2207 italic_f and u>0\ud835\udc620u>0italic_u > 0 we have g\u2207u=g\u2207fsubscript\ud835\udc54\u2207\ud835\udc62subscript\ud835\udc54\u2207\ud835\udc53g_{\\nabla u}=g_{\\nabla f}italic_g start_POSTSUBSCRIPT \u2207 italic_u end_POSTSUBSCRIPT = italic_g start_POSTSUBSCRIPT \u2207 italic_f end_POSTSUBSCRIPT and hence \u0394\u2207u\u2062f=\u0394\u2207f\u2062f=\u0394\u2062fsuperscript\u0394\u2207\ud835\udc62\ud835\udc53superscript\u0394\u2207\ud835\udc53\ud835\udc53\u0394\ud835\udc53\\Delta^{\\nabla u}f=\\Delta^{\\nabla f}f=\\Delta froman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT italic_f = roman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT italic_f = roman_\u0394 italic_f on Mu=Mfsubscript\ud835\udc40\ud835\udc62subscript\ud835\udc40\ud835\udc53M_{u}=M_{f}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT = italic_M start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT.\nThen in weak sense on Musubscript\ud835\udc40\ud835\udc62M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT. Hence, Since \u0394\u2062u=0\u0394\ud835\udc620\\Delta u=0roman_\u0394 italic_u = 0 a.e. on M\\Mu\\\ud835\udc40subscript\ud835\udc40\ud835\udc62M\\backslash M_{u}italic_M \\ italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT, it completes the lemma.\n\u220e Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a Finsler metric measure space with weighted Ricci curvature RicN\u2a7e\u2212Ksuperscriptnormal-Ric\ud835\udc41\ud835\udc3e\\operatorname{Ric}^{N}\\geqslant-Kroman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2a7e - italic_K, where the constant K\u2a7e0\ud835\udc3e0K\\geqslant 0italic_K \u2a7e 0. Let f\ud835\udc53fitalic_f satisfy (3.4) and ft=\u2202tfsubscript\ud835\udc53\ud835\udc61subscript\ud835\udc61\ud835\udc53f_{t}=\\partial_{t}fitalic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = \u2202 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_f. Then for any constant \u03b2>1\ud835\udefd1\\beta>1italic_\u03b2 > 1, satisties that for any positive test function \u03c6\u2208C02\u2062([0,T])\u2229C02\u2062(M)\ud835\udf11superscriptsubscript\ud835\udc36020\ud835\udc47subscriptsuperscript\ud835\udc3620\ud835\udc40\\varphi\\in C_{0}^{2}([0,T])\\cap C^{2}_{0}(M)italic_\u03c6 \u2208 italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( [ 0 , italic_T ] ) \u2229 italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_M ), where By the same method in Lemma 3.1, it is valid to give the proof in smooth case on Musubscript\ud835\udc40\ud835\udc62M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT, instead of the weak sense.\nFrom (3.3) and the definition of H\ud835\udc3bHitalic_H, one obtains that Note that [\u0394\u2207u,\u2202t]\u2062u=0superscript\u0394\u2207\ud835\udc62subscript\ud835\udc61\ud835\udc620[\\Delta^{\\nabla u},\\partial_{t}]u=0[ roman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT , \u2202 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ] italic_u = 0 holds pointwise on Musubscript\ud835\udc40\ud835\udc62M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT (see [21]), and derivate (3.3) and (3.5) with respect to t\ud835\udc61titalic_t. It then follows that and Now in order to estimate \u0394\u2207u\u2062Hsuperscript\u0394\u2207\ud835\udc62\ud835\udc3b\\Delta^{\\nabla u}Hroman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT italic_H (actually in weak sense)\n, we need to utilize the Bochner\u2013Weitzenb\u00f6ck formula in Theorem 2.1. Using the assumption that RicN\u2061(\u2207f)\u2a7e\u2212K\u2062F2\u2062(\u2207f)superscriptRic\ud835\udc41\u2207\ud835\udc53\ud835\udc3esuperscript\ud835\udc392\u2207\ud835\udc53\\operatorname{Ric}^{N}(\\nabla f)\\geqslant-KF^{2}(\\nabla f)roman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ( \u2207 italic_f ) \u2a7e - italic_K italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( \u2207 italic_f ) and combining (3.9) and (3.10), we have Combining (3.11) and (3.13) it implies that \u220e Then we start to prove Theorem 1.1. Let (z,s)\ud835\udc67\ud835\udc60(z,s)( italic_z , italic_s ) be the maximal point of H\ud835\udc3bHitalic_H on M\u00d7[0,T]\ud835\udc400\ud835\udc47M\\times[0,T]italic_M \u00d7 [ 0 , italic_T ] and \u039b:=H\u2062(z,s)assign\u039b\ud835\udc3b\ud835\udc67\ud835\udc60\\Lambda:=H(z,s)roman_\u039b := italic_H ( italic_z , italic_s ) be the maximum of H\ud835\udc3bHitalic_H. Without loss of generality, we can assume \u039b>0\u039b0\\Lambda>0roman_\u039b > 0 and s>0\ud835\udc600s>0italic_s > 0, otherwise, the assertion of the theorem obviously holds. Now we shall follow the proof in [15] by S. Ohta to claim that \ud835\udca5\u2062(z,s)\u2a7d0\ud835\udca5\ud835\udc67\ud835\udc600\\mathcal{J}(z,s)\\leqslant 0caligraphic_J ( italic_z , italic_s ) \u2a7d 0. By the assumption of contrary, \ud835\udca5\u2062(z,s)>0\ud835\udca5\ud835\udc67\ud835\udc600\\mathcal{J}(z,s)>0caligraphic_J ( italic_z , italic_s ) > 0, it follows that \ud835\udca5>0\ud835\udca50\\mathcal{J}>0caligraphic_J > 0 on a neighborhood of (z,s)\ud835\udc67\ud835\udc60(z,s)( italic_z , italic_s ), say, a small parabolic cylinder Bz\u2062(\u03b4)\u00d7[s\u2212\u03b4,s]subscript\ud835\udc35\ud835\udc67\ud835\udeff\ud835\udc60\ud835\udeff\ud835\udc60B_{z}(\\delta)\\times[s-\\delta,s]italic_B start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT ( italic_\u03b4 ) \u00d7 [ italic_s - italic_\u03b4 , italic_s ], where Bz\u2062(\u03b4)subscript\ud835\udc35\ud835\udc67\ud835\udeffB_{z}(\\delta)italic_B start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT ( italic_\u03b4 ) is the forward geodesic ball with radius \u03b4\ud835\udeff\\deltaitalic_\u03b4. Thus, H\ud835\udc3bHitalic_H must be a strict subsolution to the linear parabolic operator This implies that H\u2062(z,s)\ud835\udc3b\ud835\udc67\ud835\udc60H(z,s)italic_H ( italic_z , italic_s ) would be strictly smaller than the supremum of H\ud835\udc3bHitalic_H on the boundary of the parabolic cylinder Bz\u2062(\u03b4)\u00d7[s\u2212\u03b4,s]subscript\ud835\udc35\ud835\udc67\ud835\udeff\ud835\udc60\ud835\udeff\ud835\udc60B_{z}(\\delta)\\times[s-\\delta,s]italic_B start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT ( italic_\u03b4 ) \u00d7 [ italic_s - italic_\u03b4 , italic_s ], which yields contradiction to the maximality of H\u2062(z,s)\ud835\udc3b\ud835\udc67\ud835\udc60H(z,s)italic_H ( italic_z , italic_s ). Therefore, at point (z,s)\ud835\udc67\ud835\udc60(z,s)( italic_z , italic_s ), from (3.7) and (3.8), we obtain that Denoting v:=F2\u2062(\u2207f)/Hassign\ud835\udc63superscript\ud835\udc392\u2207\ud835\udc53\ud835\udc3bv:=F^{2}(\\nabla f)/{H}italic_v := italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( \u2207 italic_f ) / italic_H and multiplying both sides of (3.15) by s\u2062\u039b\ud835\udc60\u039bs\\Lambdaitalic_s roman_\u039b, we have Case 1: Firstly we consider the case of a<0\ud835\udc4e0a<0italic_a < 0 which means a\u2062s+1\u2a7d1\ud835\udc4e\ud835\udc6011as+1\\leqslant 1italic_a italic_s + 1 \u2a7d 1, then (3.16) becomes Notice that, for the constants r,p\u2a7e0\ud835\udc5f\ud835\udc5d0r,p\\geqslant 0italic_r , italic_p \u2a7e 0 and q>0\ud835\udc5e0q>0italic_q > 0, the inequality holds for any x\u2a7e0\ud835\udc650x\\geqslant 0italic_x \u2a7e 0. Hence, Case 2: On the other hand, when a>0\ud835\udc4e0a>0italic_a > 0, then (\u03b2\u22121)\u2062a\u2062v\u2062s2\u2a7e0\ud835\udefd1\ud835\udc4e\ud835\udc63superscript\ud835\udc6020(\\beta-1)avs^{2}\\geqslant 0( italic_\u03b2 - 1 ) italic_a italic_v italic_s start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \u2a7e 0, and similarly (3.16) yields Finally, set \u03b1:=max\u2061{a/2,\u2212a/4}assign\ud835\udefc\ud835\udc4e2\ud835\udc4e4\\alpha:=\\max\\{a/2,-a/4\\}italic_\u03b1 := roman_max { italic_a / 2 , - italic_a / 4 } and combine (3.17) with (3.18). Since This completes the proof for any T>0\ud835\udc470T>0italic_T > 0.\n\u220e In this section, We will continue to discuss the case of complete but non-compact Finsler manifolds. Let us review the conditions. In forward complete n\ud835\udc5bnitalic_n-dimensional Finsler metric measure space (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ), let Bp\u2062(2\u2062R)subscript\ud835\udc35\ud835\udc5d2\ud835\udc45B_{p}(2R)italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 2 italic_R ) be the forward geodesic ball centering p\u2208M\ud835\udc5d\ud835\udc40p\\in Mitalic_p \u2208 italic_M with radius 2\u2062R2\ud835\udc452R2 italic_R, and r\u2062(x):=d\u2062(p,x)assign\ud835\udc5f\ud835\udc65\ud835\udc51\ud835\udc5d\ud835\udc65r(x):=d(p,x)italic_r ( italic_x ) := italic_d ( italic_p , italic_x ) be the distance function from p\ud835\udc5dpitalic_p. Suppose for some N\u2208(n,\u221e)\ud835\udc41\ud835\udc5bN\\in(n,\\infty)italic_N \u2208 ( italic_n , \u221e ), the mixed weighted Ricci curvature Ric\u2207rNm\u2a7e\u2212K\u2062(2\u2062R)superscriptsuperscriptsubscriptRic\u2207\ud835\udc5f\ud835\udc41\ud835\udc5a\ud835\udc3e2\ud835\udc45{}^{m}\\operatorname{Ric}_{\\nabla r}^{N}\\geqslant-K(2R)start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT roman_Ric start_POSTSUBSCRIPT \u2207 italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2a7e - italic_K ( 2 italic_R ), where K\u2062(2\u2062R)\u2a7e0\ud835\udc3e2\ud835\udc450K(2R)\\geqslant 0italic_K ( 2 italic_R ) \u2a7e 0. Additionally, we need to suppose that M\ud835\udc40Mitalic_M has finite upper bounded misalignment and non-Riemannian tensors by A\u2062(2\u2062R)\ud835\udc342\ud835\udc45A(2R)italic_A ( 2 italic_R ) and K0subscript\ud835\udc3e0K_{0}italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT respectively. It is sufficient to consider u\u2062(x,t)\ud835\udc62\ud835\udc65\ud835\udc61u(x,t)italic_u ( italic_x , italic_t ) to be a positive solution to the equation (3.1) (i.e. b=0\ud835\udc4f0b=0italic_b = 0) on Bp\u2062(2\u2062R)\u00d7[0,T]subscript\ud835\udc35\ud835\udc5d2\ud835\udc450\ud835\udc47B_{p}(2R)\\times[0,T]italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 2 italic_R ) \u00d7 [ 0 , italic_T ] where a\u22600\ud835\udc4e0a\\neq 0italic_a \u2260 0. Same as the method in section 3, we set f\u2062(x,t):=log\u2061u\u2062(x,t)assign\ud835\udc53\ud835\udc65\ud835\udc61\ud835\udc62\ud835\udc65\ud835\udc61f(x,t):=\\log u(x,t)italic_f ( italic_x , italic_t ) := roman_log italic_u ( italic_x , italic_t ) and H:= t\u2062{F2\u2062(\u2207f)+\u03b2\u2062(a\u2062f\u2212ft)}\ud835\udc61superscript\ud835\udc392\u2207\ud835\udc53\ud835\udefd\ud835\udc4e\ud835\udc53subscript\ud835\udc53\ud835\udc61t\\left\\{F^{2}(\\nabla f)+\\beta(af-f_{t})\\right\\}italic_t { italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( \u2207 italic_f ) + italic_\u03b2 ( italic_a italic_f - italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) } for any \u03b2>1\ud835\udefd1\\beta>1italic_\u03b2 > 1. The finite bounded misalignment also infers the weighted Ricci curvature RicN\u2a7e\u2212A\u2062KsuperscriptRic\ud835\udc41\ud835\udc34\ud835\udc3e\\operatorname{Ric}^{N}\\geqslant-AKroman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2a7e - italic_A italic_K.\nThen Lemma 3.1 and Lemma 3.2 still hold on Bp\u2062(2\u2062R)\u00d7[0,T]subscript\ud835\udc35\ud835\udc5d2\ud835\udc450\ud835\udc47B_{p}(2R)\\times[0,T]italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 2 italic_R ) \u00d7 [ 0 , italic_T ]. Now we start the proof with choosing a cut-off function. We define a smooth function \u03d5italic-\u03d5\\phiitalic_\u03d5 on [0,\u221e)0[0,\\infty)[ 0 , \u221e ) such that \u03d5\u2062(d)\u22611italic-\u03d5\ud835\udc511\\phi(d)\\equiv 1italic_\u03d5 ( italic_d ) \u2261 1 for d\u2a7d1\ud835\udc511d\\leqslant 1italic_d \u2a7d 1, \u03d5\u2062(d)\u22610italic-\u03d5\ud835\udc510\\phi(d)\\equiv 0italic_\u03d5 ( italic_d ) \u2261 0 for d\u2a7e2\ud835\udc512d\\geqslant 2italic_d \u2a7e 2 and 0\u2a7d\u03d5\u2a7d10italic-\u03d510\\leqslant\\phi\\leqslant 10 \u2a7d italic_\u03d5 \u2a7d 1 otherwise. Assume that for two positive constants c1subscript\ud835\udc501c_{1}italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and c2subscript\ud835\udc502c_{2}italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Then we define the cut-off function on M\ud835\udc40Mitalic_M by Clearly we notice that \u03a8\u2062(x)\u03a8\ud835\udc65\\Psi(x)roman_\u03a8 ( italic_x ) is smooth function with support in Bp\u2062(2\u2062R)subscript\ud835\udc35\ud835\udc5d2\ud835\udc45B_{p}(2R)italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 2 italic_R ) and for any reference vector field V\ud835\udc49Vitalic_V, where the inequality is from (4.1) and the bound of misalignment: Applying the Laplacian comparison theorem in Theorem 2.2 and taking V=\u2207u\ud835\udc49\u2207\ud835\udc62V=\\nabla uitalic_V = \u2207 italic_u on Musubscript\ud835\udc40\ud835\udc62M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT, we have The last inequality comes from the inequality\ncoth\u2061(x)\u2a7d1+1xhyperbolic-cotangent\ud835\udc6511\ud835\udc65\\coth(x)\\leqslant 1+\\frac{1}{x}roman_coth ( italic_x ) \u2a7d 1 + divide start_ARG 1 end_ARG start_ARG italic_x end_ARG.\n\nFor simplicity, we denote which infers that Since Cauchy inequality and (4.3), it follows that Now, we compute Using Lemma 3.2, (4.7) and (4.8) in (4.9), a straightforward calculation yields that in sense of distribution on M\u00d7(0,T)\ud835\udc400\ud835\udc47M\\times(0,T)italic_M \u00d7 ( 0 , italic_T ), where Let (z,s)\ud835\udc67\ud835\udc60(z,s)( italic_z , italic_s ) be the maximal point of \u03a8\u2062H\u03a8\ud835\udc3b\\Psi Hroman_\u03a8 italic_H on Bp\u2062(2\u2062R)\u00d7[0,T]subscript\ud835\udc35\ud835\udc5d2\ud835\udc450\ud835\udc47B_{p}(2R)\\times[0,T]italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 2 italic_R ) \u00d7 [ 0 , italic_T ] and \u039b=\u03a8\u2062(z)\u2062H\u2062(z,s)\u039b\u03a8\ud835\udc67\ud835\udc3b\ud835\udc67\ud835\udc60\\Lambda=\\Psi(z)H(z,s)roman_\u039b = roman_\u03a8 ( italic_z ) italic_H ( italic_z , italic_s ) be the maximum of \u03a8\u2062H\u03a8\ud835\udc3b\\Psi Hroman_\u03a8 italic_H. Following the same argument in section 3, we deduce that \ud835\udca6\u2062(z,s)\u2a7d0\ud835\udca6\ud835\udc67\ud835\udc600\\mathcal{K}(z,s)\\leqslant 0caligraphic_K ( italic_z , italic_s ) \u2a7d 0. Here we also set v:=F2\u2062(\u2207f)/Hassign\ud835\udc63superscript\ud835\udc392\u2207\ud835\udc53\ud835\udc3bv:=F^{2}(\\nabla f)/Hitalic_v := italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( \u2207 italic_f ) / italic_H, and it implies that at (z,s)\ud835\udc67\ud835\udc60(z,s)( italic_z , italic_s ) Note that for any fixed 0<\u03b4<10\ud835\udeff10<\\delta<10 < italic_\u03b4 < 1, and Therefore we have Then by simply modifying how we deal with different cases a>0\ud835\udc4e0a>0italic_a > 0 and a<0\ud835\udc4e0a<0italic_a < 0 in Section 3, one obtains that when a<0\ud835\udc4e0a<0italic_a < 0, And when a>0\ud835\udc4e0a>0italic_a > 0, Finally, which concludes the proof.\n\u220e As an application of gradient estimates, We now give Harnack inequalities about the solutions to the equation (1.4). Note that by taking a\u21920\u2192\ud835\udc4e0a\\to 0italic_a \u2192 0 and b=0\ud835\udc4f0b=0italic_b = 0 the equation (1.4) becomes the Finslerian heat equation and the corresponding results have already been given in [15] and [21]. Under the same conditions in Theorem 1.1, we have where for any \u03b2>1\ud835\udefd1\\beta>1italic_\u03b2 > 1, 0<t1<t2<T0subscript\ud835\udc611subscript\ud835\udc612\ud835\udc470<t_{1}<t_{2}<T0 < italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < italic_T and x1subscript\ud835\udc651x_{1}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, x2\u2208Msubscript\ud835\udc652\ud835\udc40x_{2}\\in Mitalic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2208 italic_M. For the parameter s\u2208[t1,t2]\ud835\udc60subscript\ud835\udc611subscript\ud835\udc612s\\in[t_{1},t_{2}]italic_s \u2208 [ italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] and some tangent vector v\u2208Tx2\u2062M\ud835\udc63subscript\ud835\udc47subscript\ud835\udc652\ud835\udc40v\\in T_{x_{2}}Mitalic_v \u2208 italic_T start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_M, define \u03b3\u2062(s):=exp\u2061(x2,(t2\u2212s)\u2062v)assign\ud835\udefe\ud835\udc60subscript\ud835\udc652subscript\ud835\udc612\ud835\udc60\ud835\udc63\\gamma(s):=\\exp(x_{2},(t_{2}-s)v)italic_\u03b3 ( italic_s ) := roman_exp ( italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ( italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_s ) italic_v ) as a reverse curve of the minimal geodesic from x2subscript\ud835\udc652x_{2}italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT to x1subscript\ud835\udc651x_{1}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. And that implies \u03b3\u2062(t1)=x1\ud835\udefesubscript\ud835\udc611subscript\ud835\udc651\\gamma(t_{1})=x_{1}italic_\u03b3 ( italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u03b3\u2062(t2)=x2\ud835\udefesubscript\ud835\udc612subscript\ud835\udc652\\gamma(t_{2})=x_{2}italic_\u03b3 ( italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and Putting by Theorem 1.1, Cauchy inequality and (5.2) we see that Therefore, by the monotonicity of \u03c3\ud835\udf0e\\sigmaitalic_\u03c3, which demonstrates the assertion.\n\u220e Under the assumption in Theorem 1.2, then we have where for any 0<\u03b4<10\ud835\udeff10<\\delta<10 < italic_\u03b4 < 1, \u03b2>1\ud835\udefd1\\beta>1italic_\u03b2 > 1, 0<t1<t2<T0subscript\ud835\udc611subscript\ud835\udc612\ud835\udc470<t_{1}<t_{2}<T0 < italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < italic_T and x1subscript\ud835\udc651x_{1}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, x2\u2208Bp\u2062(R)subscript\ud835\udc652subscript\ud835\udc35\ud835\udc5d\ud835\udc45x_{2}\\in B_{p}(R)italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2208 italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_R ). The proof is similar with Corollary 5.1. The only different part is to replace the function \u0398\u0398\\Thetaroman_\u0398 related to gradient estimates so we omit the proof here. In this subsection, we turn to the elliptic equation (1.11).\nApplying the aforementioned gradient estimate yields the following Liouville-type theorem: Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a forward complete n\ud835\udc5bnitalic_n-dimensional Finsler metric measure space without boundary, with misalignment and non-Riemannian tensors bounded by A\ud835\udc34Aitalic_A and K0subscript\ud835\udc3e0K_{0}italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, respectively. Let u\ud835\udc62uitalic_u be a positive solution to (1.11) on M\ud835\udc40Mitalic_M and f=log\u2061u\ud835\udc53\ud835\udc62f=\\log uitalic_f = roman_log italic_u. Suppose mixed weighted Ricci curvature RicNm\u2a7e\u2212Ksuperscriptsuperscriptnormal-Ric\ud835\udc41\ud835\udc5a\ud835\udc3e{}^{m}\\operatorname{Ric}^{N}\\geqslant-Kstart_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT roman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2a7e - italic_K for some N\ud835\udc41Nitalic_N and K\ud835\udc3eKitalic_K satisfying where \u03b1=max\u2061{a/2,\u2212a/4}\ud835\udefc\ud835\udc4e2\ud835\udc4e4\\alpha=\\max\\{a/2,-a/4\\}italic_\u03b1 = roman_max { italic_a / 2 , - italic_a / 4 }. If there exists an x0\u2208Msubscript\ud835\udc650\ud835\udc40x_{0}\\in Mitalic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2208 italic_M such that or we then have f\u2062(x)\u22610\ud835\udc53\ud835\udc650f(x)\\equiv 0italic_f ( italic_x ) \u2261 0 on M\ud835\udc40Mitalic_M. Since u\u2062(x,t)\u2261u\u2062(x)\ud835\udc62\ud835\udc65\ud835\udc61\ud835\udc62\ud835\udc65u(x,t)\\equiv u(x)italic_u ( italic_x , italic_t ) \u2261 italic_u ( italic_x ), let R\u2192+\u221e\u2192\ud835\udc45R\\to+\\inftyitalic_R \u2192 + \u221e, \u03b4\u21921\u2192\ud835\udeff1\\delta\\to 1italic_\u03b4 \u2192 1 and t\u2192\u221e\u2192\ud835\udc61t\\to\\inftyitalic_t \u2192 \u221e in (1.8), then we have The conditions in (5.7) imply that there exist Substituting either of \u03b20subscript\ud835\udefd0\\beta_{0}italic_\u03b2 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT to (5.7), we have When a<0\ud835\udc4e0a<0italic_a < 0 and f\u2062(x0)\u2a7d0\ud835\udc53subscript\ud835\udc6500f(x_{0})\\leqslant 0italic_f ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) \u2a7d 0, there exists a neighborhood U\u2062(x0)\ud835\udc48subscript\ud835\udc650U(x_{0})italic_U ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) on which f\u2062(x)\u2a7d0\ud835\udc53\ud835\udc650f(x)\\leqslant 0italic_f ( italic_x ) \u2a7d 0 (resp. f\u2062(x)\u2a7e0\ud835\udc53\ud835\udc650f(x)\\geqslant 0italic_f ( italic_x ) \u2a7e 0 when a>0\ud835\udc4e0a>0italic_a > 0). Then \u2207f\u2062(x)\u22610\u2207\ud835\udc53\ud835\udc650\\nabla f(x)\\equiv 0\u2207 italic_f ( italic_x ) \u2261 0 and f\u2062(x)\u22610\ud835\udc53\ud835\udc650f(x)\\equiv 0italic_f ( italic_x ) \u2261 0 for any x\u2208U\u2062(x0)\ud835\udc65\ud835\udc48subscript\ud835\udc650x\\in U(x_{0})italic_x \u2208 italic_U ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ).\n\u220e It should be noted that the conditions in (5.7) are sharp. Failure to fulfill these conditions would result in absence of such a feasible \u03b20>1subscript\ud835\udefd01\\beta_{0}>1italic_\u03b2 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 1. Moreover, nonnegative mixed weighted Ricci curvature (RicNm\u2a7e0superscriptsuperscriptRic\ud835\udc41\ud835\udc5a0{}^{m}\\operatorname{Ric}^{N}\\geqslant 0start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT roman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2a7e 0) or weighted Ricci curvature (RicN\u2a7e0superscriptRic\ud835\udc410\\operatorname{Ric}^{N}\\geqslant 0roman_Ric start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2a7e 0) inherently meet the second condition in (5.7). Since f=log\u2061u\ud835\udc53\ud835\udc62f=\\log uitalic_f = roman_log italic_u, one can derive directly from Theorem 5.3 that u\u2062(x)\u2a7e1\ud835\udc62\ud835\udc651u(x)\\geqslant 1italic_u ( italic_x ) \u2a7e 1 on M\ud835\udc40Mitalic_M when a<0\ud835\udc4e0a<0italic_a < 0. Namely, there is a gap for u\u2062(x)\ud835\udc62\ud835\udc65u(x)italic_u ( italic_x ) when b>\u03b1\u2062N/2=\u2212a\u2062N/8\ud835\udc4f\ud835\udefc\ud835\udc412\ud835\udc4e\ud835\udc418b>\\alpha N/2=-aN/8italic_b > italic_\u03b1 italic_N / 2 = - italic_a italic_N / 8. Bin Shen\nSchool of Mathematics, Southeast University, Nanjing 211189, P. R. China\nE-mail: shenbin@seu.edu.cn Yuhan Zhu\nSchool of Mathematics, Southeast University, Nanjing 211189, P. R. China\nE-mail: yuhanzhu@seu.edu.cn"
    },
    {
        "id": 9,
        "title": "Exact minimax entropy models of large\u2013scale neuronal activity",
        "corpus": "In the brain, fine\u2013scale correlations combine to produce macroscopic patterns of activity. However, as experiments record from larger and larger populations, we approach a fundamental bottleneck: the number of correlations one would like to include in a model grows larger than the available data. In this undersampled regime, one must focus on a sparse subset of correlations; the optimal choice contains the maximum information about patterns of activity or, equivalently, minimizes the entropy of the inferred maximum entropy model. Applying this \u201cminimax entropy\u201d principle is generally intractable, but here we present an exact and scalable solution for pairwise correlations that combine to form a tree (a network without loops). Applying our method to over one thousand neurons in the mouse hippocampus, we find that the optimal tree of correlations reduces our uncertainty about the population activity by 14% (over 50 times more than a random tree). Despite containing only 0.1% of all pairwise correlations, this minimax entropy model accurately predicts the observed large\u2013scale synchrony in neural activity and becomes even more accurate as the population grows. The inferred Ising model is almost entirely ferromagnetic (with positive interactions) and exhibits signatures of thermodynamic criticality. These results suggest that a sparse backbone of excitatory interactions may play an important role in driving collective neuronal activity. Understanding how collective behaviors emerge from webs of fine\u2013scale interactions is a central goal in statistical mechanics approaches to networks of neurons Wiener (1958); Cooper (1973); Little (1974); Hopfield (1982); Amit (1989); Hertz\u00a0et\u00a0al. (1991). At the same time, exploration of the brain has been revolutionized by experimental methods that monitor, simultaneously, the electrical activity of hundreds or even thousands of neurons Segev\u00a0et\u00a0al. (2004); Litke\u00a0et\u00a0al. (2004); Chung\u00a0et\u00a0al. (2019); Dombeck\u00a0et\u00a0al. (2010); Tian\u00a0et\u00a0al. (2012); Demas\u00a0et\u00a0al. (2021); Steinmetz\u00a0et\u00a0al. (2021). One approach to connecting these new data with statistical physics models is maximum entropy, in which we construct the maximally disordered model that is consistent with measured expectation values Jaynes (1957). In particular, is seems natural to build models that match the mean activity of individual neurons and the correlations between pairs of neurons. These pairwise maximum entropy models have been strikingly successful in describing collective behavior not only in networks of real neurons, but also in the evolution of protein families, the dynamics of genetic networks, flocks of birds, and social networks Schneidman\u00a0et\u00a0al. (2006); Nguyen\u00a0et\u00a0al. (2017); Meshulam\u00a0et\u00a0al. (2017, 2021); Tka\u010dik\u00a0et\u00a0al. (2015); Lezon\u00a0et\u00a0al. (2006); Weigt\u00a0et\u00a0al. (2009); Marks\u00a0et\u00a0al. (2011); Lapedes\u00a0et\u00a0al. (2012); Bialek\u00a0et\u00a0al. (2012); Russ\u00a0et\u00a0al. (2020); Lynn\u00a0et\u00a0al. (2019). But as experiments progress to record from larger and larger numbers of neurons, we face a combinatorial explosion. Even if we focus on pairwise correlations,\nthe number of correlations approaches the number of independent samples in modern experiments Segev\u00a0et\u00a0al. (2004); Litke\u00a0et\u00a0al. (2004); Chung\u00a0et\u00a0al. (2019); Dombeck\u00a0et\u00a0al. (2010); Tian\u00a0et\u00a0al. (2012); Demas\u00a0et\u00a0al. (2021); Steinmetz\u00a0et\u00a0al. (2021). In this undersampled regime, one is forced to select only a sparse subset of the correlations to include in any model. While constructing an accurate model with only a small number of correlations may seem hopeless, one can draw inspiration from statistical physics, where effective descriptions of macroscopic phenomena can often ignore many of the microscopic details. Here, given restrictions on the number and structure of correlations we can include in a model, we seek to identify the ones that contain the maximum information about system activity. We demonstrate that the optimal correlations are those that induce the maximum entropy model with minimum entropy Zhu\u00a0et\u00a0al. (1997). Solving this minimax entropy problem is generally infeasible. But for pairwise correlations that form a tree (a network without loops), the entropy reduction decomposes into a sum over connected pairs; the advantages of tree structure in models of neural activity have been appreciated in other contexts Prentice\u00a0et\u00a0al. (2016).\nThis decomposition reduces the minimax entropy problem to a minimum spanning tree problem, which can be solved exactly and efficiently Chow\u00a0and\u00a0Liu (1968); Nguyen\u00a0et\u00a0al. (2017). The result is a framework for uncovering the maximally informative tree of correlations in very large systems Lynn\u00a0et\u00a0al. (2023). We apply our method to investigate the collective activity of N\u223c1500similar-to\ud835\udc411500N\\sim 1500italic_N \u223c 1500 neurons in the mouse hippocampus Gauthier\u00a0and\u00a0Tank (2018). While most pairs of neurons are only weakly correlated, some rare pairs have mutual information orders of magnitude larger than average. By focusing on these exceptionally strong correlations, our minimax entropy model captures 50 times more information than a random tree and, despite containing only 0.1% of all pairwise correlations, produces realistic large\u2013scale synchrony in activity. Moreover, the model becomes even more accurate as the population grows, providing hope for statistical physics descriptions of even larger systems. The paper is organized as follows. In \u00a7II, we define the minimax entropy problem and present a solution for trees of pairwise correlations. In \u00a7III, we review a relatively recent experiment on large\u2013scale recordings of neuronal activity in the mouse hippocampus. In \u00a7IV, we demonstrate that the optimal tree of correlations produces realistic patterns of synchronized activity. In \u00a7V, we investigate the structural properties of the optimal tree and the functional properties of the induced Ising model. In \u00a7VI, we show that the minimax entropy model becomes more accurate for larger populations, and then in \u00a7VII we investigate the thermodynamic properties of the minimax entropy model, finding that the real system is poised at a special point in its phase diagram. Finally, in \u00a7VIII we provide conclusions and outlook. Consider a system of N\ud835\udc41Nitalic_N elements i=1,\u2026,N\ud835\udc561\u2026\ud835\udc41i=1,\\ldots,Nitalic_i = 1 , \u2026 , italic_N with states \ud835\udc99={xi}\ud835\udc99subscript\ud835\udc65\ud835\udc56\\bm{x}=\\{x_{i}\\}bold_italic_x = { italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT }, where xisubscript\ud835\udc65\ud835\udc56x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is the state of element i\ud835\udc56iitalic_i. From experiments, we have access to M\ud835\udc40Mitalic_M samples of the system activity \ud835\udc99(m)superscript\ud835\udc99\ud835\udc5a\\bm{x}^{(m)}bold_italic_x start_POSTSUPERSCRIPT ( italic_m ) end_POSTSUPERSCRIPT, where m=1,\u2026,M\ud835\udc5a1\u2026\ud835\udc40m=1,\\ldots,Mitalic_m = 1 , \u2026 , italic_M. Our knowledge about the system is defined by observables, which can be represented as expectation values where f\u2062(\ud835\udc99)\ud835\udc53\ud835\udc99f(\\bm{x})italic_f ( bold_italic_x ) is an arbitrary function of the state \ud835\udc99\ud835\udc99\\bm{x}bold_italic_x. For example, one could measure the average states of individual elements \u27e8xi\u27e9expsubscriptdelimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56exp\\left<x_{i}\\right>_{\\text{exp}}\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9 start_POSTSUBSCRIPT exp end_POSTSUBSCRIPT or the correlations among multiple elements \u27e8xi\u2062xj\u27e9expsubscriptdelimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57exp\\left<x_{i}x_{j}\\right>_{\\text{exp}}\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 start_POSTSUBSCRIPT exp end_POSTSUBSCRIPT, \u27e8xi\u2062xj\u2062xk\u27e9expsubscriptdelimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57subscript\ud835\udc65\ud835\udc58exp\\left<x_{i}x_{j}x_{k}\\right>_{\\text{exp}}\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \u27e9 start_POSTSUBSCRIPT exp end_POSTSUBSCRIPT, and so on. Given a set of K\ud835\udc3eKitalic_K observables \ud835\udcaa={f\u03bd\u2062(\ud835\udc99)}\ud835\udcaasubscript\ud835\udc53\ud835\udf08\ud835\udc99\\mathcal{O}=\\{f_{\\nu}(\\bm{x})\\}caligraphic_O = { italic_f start_POSTSUBSCRIPT italic_\u03bd end_POSTSUBSCRIPT ( bold_italic_x ) }, where \u03bd=1,\u2026,K\ud835\udf081\u2026\ud835\udc3e\\nu=1,\\ldots,Kitalic_\u03bd = 1 , \u2026 , italic_K, the most unbiased prediction for the distribution over states is the maximum entropy model Shannon (1948); Jaynes (1957) where Z\ud835\udc4dZitalic_Z is the normalizing partition function, and the parameters \u03bb\u03bdsubscript\ud835\udf06\ud835\udf08\\lambda_{\\nu}italic_\u03bb start_POSTSUBSCRIPT italic_\u03bd end_POSTSUBSCRIPT ensure that the model matches the experimental observations, such that To have control over errors in the K\ud835\udc3eKitalic_K expectation values, we must have K\u226aM\u2062Nmuch-less-than\ud835\udc3e\ud835\udc40\ud835\udc41K\\ll MNitalic_K \u226a italic_M italic_N. But as experiments record from larger systems, one is confronted with an explosion of possible observables. The total number of correlations grows exponentially with N\ud835\udc41Nitalic_N, and even the K\u221dN2proportional-to\ud835\udc3esuperscript\ud835\udc412K\\propto N^{2}italic_K \u221d italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT pairwise correlations violate the good sampling condition as N\ud835\udc41Nitalic_N grows large. Thus, to avoid sampling problems, one must focus on a sparse subset of correlations. Here we arrive at the central question: Among a large set of observables, which should we choose to include in a model? Suppose we want to find the set of observables \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O that yields the most accurate description of the system. We can choose \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O to maximize the log\u2013likelihood of the model P\ud835\udcaasubscript\ud835\udc43\ud835\udcaaP_{\\mathcal{O}}italic_P start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT or, equivalently, minimize the KL divergence with respect to the data DKL(Pexp||P\ud835\udcaa)D_{\\text{KL}}(P_{\\text{exp}}||P_{\\mathcal{O}})italic_D start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT ( italic_P start_POSTSUBSCRIPT exp end_POSTSUBSCRIPT | | italic_P start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT ). Due to the form of P\ud835\udcaasubscript\ud835\udc43\ud835\udcaaP_{\\mathcal{O}}italic_P start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT in Eq.\u00a0(2), the KL divergence simplifies to a difference in entropies where the final equality follows from Eq.\u00a0(3), and entropies S\ud835\udc46Sitalic_S are measured in bits. We therefore find that the optimal observables \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O are the ones that minimize the entropy of the maximum entropy model S\ud835\udcaasubscript\ud835\udc46\ud835\udcaaS_{\\mathcal{O}}italic_S start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT. This is the \u201cminimax entropy\u201d principle, which was proposed 25 years ago but has received relatively little attention Zhu\u00a0et\u00a0al. (1997). In addition to providing the best description of the data, the optimal observables \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O can also be viewed as containing the maximum information about the system. If we begin by observing each element individually, then we only have access to the marginal distributions Pi\u2062(xi)subscript\ud835\udc43\ud835\udc56subscript\ud835\udc65\ud835\udc56P_{i}(x_{i})italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ); in this case, the maximum entropy model is the independent distribution Pind\u2062(\ud835\udc99)=\u220fiPi\u2062(xi)subscript\ud835\udc43ind\ud835\udc99subscriptproduct\ud835\udc56subscript\ud835\udc43\ud835\udc56subscript\ud835\udc65\ud835\udc56P_{\\text{ind}}(\\bm{x})=\\prod_{i}P_{i}(x_{i})italic_P start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT ( bold_italic_x ) = \u220f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) with entropy Sindsubscript\ud835\udc46indS_{\\text{ind}}italic_S start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT. If, in addition to the marginals, we also observe some of the correlations between elements Schneidman\u00a0et\u00a0al. (2003), this knowledge reduces our uncertainty about the system by an amount I\ud835\udcaa=Sind\u2212S\ud835\udcaa\u22650subscript\ud835\udc3c\ud835\udcaasubscript\ud835\udc46indsubscript\ud835\udc46\ud835\udcaa0I_{\\mathcal{O}}=S_{\\text{ind}}-S_{\\mathcal{O}}\\geq 0italic_I start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT = italic_S start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT - italic_S start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT \u2265 0. Thus, by minimizing S\ud835\udcaasubscript\ud835\udc46\ud835\udcaaS_{\\mathcal{O}}italic_S start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT, the optimal observables \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O also maximize the information I\ud835\udcaasubscript\ud835\udc3c\ud835\udcaaI_{\\mathcal{O}}italic_I start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT contained in the observed correlations. In practice, applying the minimax entropy principle poses two distinct challenges. First, for each set of observables \ud835\udcaa={f\u03bd}\ud835\udcaasubscript\ud835\udc53\ud835\udf08\\mathcal{O}=\\{f_{\\nu}\\}caligraphic_O = { italic_f start_POSTSUBSCRIPT italic_\u03bd end_POSTSUBSCRIPT }, one must solve the traditional maximum entropy problem; that is, one must compute the parameters \u03bb\u03bdsubscript\ud835\udf06\ud835\udf08\\lambda_{\\nu}italic_\u03bb start_POSTSUBSCRIPT italic_\u03bd end_POSTSUBSCRIPT such that the model P\ud835\udcaasubscript\ud835\udc43\ud835\udcaaP_{\\mathcal{O}}italic_P start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT matches the expectations \u27e8f\u03bd\u2062(\ud835\udc99)\u27e9expsubscriptdelimited-\u27e8\u27e9subscript\ud835\udc53\ud835\udf08\ud835\udc99exp\\left<f_{\\nu}(\\bm{x})\\right>_{\\text{exp}}\u27e8 italic_f start_POSTSUBSCRIPT italic_\u03bd end_POSTSUBSCRIPT ( bold_italic_x ) \u27e9 start_POSTSUBSCRIPT exp end_POSTSUBSCRIPT in the data. Second, one must repeat this calculation for all sets of observables \ud835\udcaa\ud835\udcaa\\mathcal{O}caligraphic_O to find the one that minimizes the entropy S\ud835\udcaasubscript\ud835\udc46\ud835\udcaaS_{\\mathcal{O}}italic_S start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT. This search process is generally intractable. In what follows, we study a class of observables that admits an exact and efficient solution, enabling statistical physics models of very large systems. For simplicity, we focus on binary variables xi=0,1subscript\ud835\udc65\ud835\udc5601x_{i}=0,1italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0 , 1, for which the marginals Pi\u2062(xi)subscript\ud835\udc43\ud835\udc56subscript\ud835\udc65\ud835\udc56P_{i}(x_{i})italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) are defined by the averages \u27e8xi\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56\\left<x_{i}\\right>\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9. In the search for sources of order in a system, one might begin with the simplest correlations: those between pairs of elements \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\left<x_{i}x_{j}\\right>\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9. In populations of N\u223c100similar-to\ud835\udc41100N\\sim 100italic_N \u223c 100 neurons, one often has sufficient data to fit all the pairwise correlations, which can be very effective in capturing key features of the collective activity Schneidman\u00a0et\u00a0al. (2006); Meshulam\u00a0et\u00a0al. (2017, 2021). But this corresponds to K\u221dN2proportional-to\ud835\udc3esuperscript\ud835\udc412K\\propto N^{2}italic_K \u221d italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT constraints, and at large N\ud835\udc41Nitalic_N we will violate the good sampling condition K\u226aN\u2062Mmuch-less-than\ud835\udc3e\ud835\udc41\ud835\udc40K\\ll NMitalic_K \u226a italic_N italic_M. To avoid undersampling, we are forced to select a sparse subset of pairwise correlations, which can be visualized as a network \ud835\udca2\ud835\udca2\\mathcal{G}caligraphic_G with edges defining the observed correlations between variables. Each network induces a maximum entropy model where the parameters hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT enforce the constraints on \u27e8xi\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56\\left<x_{i}\\right>\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9 and \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\left<x_{i}x_{j}\\right>\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 in \ud835\udca2\ud835\udca2\\mathcal{G}caligraphic_G, respectively. The minimax entropy principle tells us that we should find the network \ud835\udca2\ud835\udca2\\mathcal{G}caligraphic_G (within some allowed set) that produces the maximum entropy model P\ud835\udca2subscript\ud835\udc43\ud835\udca2P_{\\mathcal{G}}italic_P start_POSTSUBSCRIPT caligraphic_G end_POSTSUBSCRIPT with minimum entropy S\ud835\udca2subscript\ud835\udc46\ud835\udca2S_{\\mathcal{G}}italic_S start_POSTSUBSCRIPT caligraphic_G end_POSTSUBSCRIPT. In statistical physics, calculations are difficult in part due to feedback loops. By eliminating loops, many statistical physics models become tractable, as in one\u2013dimensional systems or on Bethe lattices Sethna (2021). In the Ising model\u2014which is equivalent to Eq.\u00a0(5)\u2014if the interactions Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT lie on a tree \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T (or a network without loops), then one can efficiently compute the partition function Z\ud835\udc4dZitalic_Z and all statistics of interest (see Appendix A). Inverting this procedure, one can begin with the averages \u27e8xi\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56\\left<x_{i}\\right>\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9 and the correlations \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\left<x_{i}x_{j}\\right>\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 on a tree \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T and analytically derive the maximum entropy parameters Chow\u00a0and\u00a0Liu (1968); Nguyen\u00a0et\u00a0al. (2017): where \ud835\udca9isubscript\ud835\udca9\ud835\udc56\\mathcal{N}_{i}caligraphic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT represents the neighbors of i\ud835\udc56iitalic_i in \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T (see Appendix B). Since each tree contains N\u22121\ud835\udc411N-1italic_N - 1 correlations, the total number of observables is K=2\u2062N\u22121\ud835\udc3e2\ud835\udc411K=2N-1italic_K = 2 italic_N - 1, and so we are well sampled if the number of independent samples obeys M\u226b2much-greater-than\ud835\udc402M\\gg 2italic_M \u226b 2. Equations (6) and (7) solve the maximum entropy problem for the distribution P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT, but we still need to search over all of the NN\u22122superscript\ud835\udc41\ud835\udc412N^{N-2}italic_N start_POSTSUPERSCRIPT italic_N - 2 end_POSTSUPERSCRIPT trees to find the one that minimizes the entropy S\ud835\udcafsubscript\ud835\udc46\ud835\udcafS_{\\mathcal{T}}italic_S start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT. This search simplifies significantly by noticing that the information I\ud835\udcafsubscript\ud835\udc3c\ud835\udcafI_{\\mathcal{T}}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT decomposes into a sum over the connections (i\u2062j)\ud835\udc56\ud835\udc57(ij)( italic_i italic_j ) in \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T, where Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT is the mutual information between i\ud835\udc56iitalic_i and j\ud835\udc57jitalic_j (see Appendix C) Chow\u00a0and\u00a0Liu (1968); Nguyen\u00a0et\u00a0al. (2017). Note that for pairs (i\u2062j)\u2208\ud835\udcaf\ud835\udc56\ud835\udc57\ud835\udcaf(ij)\\in\\mathcal{T}( italic_i italic_j ) \u2208 caligraphic_T, the mutual information Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT is the same in the model and the data, so we can compute the entropy S\ud835\udcafsubscript\ud835\udc46\ud835\udcafS_{\\mathcal{T}}italic_S start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT directly from the data without constructing the model itself. Equation (8) tells us that the tree with the minimum entropy S\ud835\udcafsubscript\ud835\udc46\ud835\udcafS_{\\mathcal{T}}italic_S start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT is the one with the largest total mutual information. Identifying this optimal tree is a minimum spanning tree problem Nguyen\u00a0et\u00a0al. (2017), which can be solved efficiently using a number of different algorithms Moore\u00a0and\u00a0Mertens (2011). To begin, one computes the mutual information Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT between all elements [Fig.\u00a01(a)]. One can then grow the optimal tree by greedily connecting the element i\ud835\udc56iitalic_i in the tree to the new element j\ud835\udc57jitalic_j with the largest mutual information Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT [Fig.\u00a01(b)]; this is Prim\u2019s algorithm, which runs in O\u2062(N2)\ud835\udc42superscript\ud835\udc412O(N^{2})italic_O ( italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) time [Fig.\u00a01(c)]. Thus, by restricting to trees of pairwise correlations, we can solve the minimax entropy problem exactly, even at very large N\ud835\udc41Nitalic_N. We ultimately seek to explain the collective behaviors of very large networks.\nHowever, each tree only contains a vanishingly small fraction 2/N2\ud835\udc412/N2 / italic_N of all pairwise correlations; and even if we have access to all of the pairwise statistics, there\u2019s still no guarantee of success. Can such a sparse set of observations capture something important about the system as a whole? To answer this question, we consider patterns of electrical activity in N=1485\ud835\udc411485N=1485italic_N = 1485 neurons in the hippocampus of a mouse, recorded in a recent experiment Gauthier\u00a0and\u00a0Tank (2018). Mice are genetically engineered so that their neurons express a protein whose fluorescence is modulated by calcium concentration, which in turn follows the electrical activity of the cells. This fluorescence is recorded using a scanning two\u2013photon microscope as the mouse runs in a virtual environment. The signal from each cell consists of a quiet background punctuated by short bursts of activity Meshulam\u00a0et\u00a0al. (2017), providing a natural binarization into active (xi=1subscript\ud835\udc65\ud835\udc561x_{i}=1italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1) or silent (xi=0subscript\ud835\udc65\ud835\udc560x_{i}=0italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0) within each video frame [Fig.\u00a02(a)]. Capturing images at 30\u2062Hz30Hz30\\,\\text{Hz}30 Hz for 39\u2062min39min39\\,\\text{min}39 min yields M\u223c7\u00d7104similar-to\ud835\udc407superscript104M\\sim 7\\times 10^{4}italic_M \u223c 7 \u00d7 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT samples of the collective state \ud835\udc99={xi}\ud835\udc99subscript\ud835\udc65\ud835\udc56\\bm{x}=\\{x_{i}\\}bold_italic_x = { italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT }, but these are not all independent. Nonetheless, we can still estimate the mutual information Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT with small errors after correcting for finite data effects (see Appendix D). Among all \u223c106similar-toabsentsuperscript106\\sim 10^{6}\u223c 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT pairs of neurons, only 9%percent99\\%9 % exhibit significant mutual information with values shown in Fig.\u00a02(b). We see that a small number of pairs contain orders of magnitude more information than average (I\u00af=2.9\u00d710\u22124\u00af\ud835\udc3c2.9superscript104\\bar{I}=2.9\\times 10^{-4}over\u00af start_ARG italic_I end_ARG = 2.9 \u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT bits). This heavy\u2013tailed distribution provides hope for a tree of correlations that contains much more information than typical I\ud835\udcaf\u226b(N\u22121)\u2062I\u00afmuch-greater-thansubscript\ud835\udc3c\ud835\udcaf\ud835\udc411\u00af\ud835\udc3cI_{\\mathcal{T}}\\gg(N-1)\\bar{I}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT \u226b ( italic_N - 1 ) over\u00af start_ARG italic_I end_ARG. Additionally, while most pairs of cells are negatively correlated [Fig.\u00a02(c)], the strongest mutual information corresponds to positive correlations [Fig.\u00a02(d)]. And while most neurons are far from one another [Fig.\u00a02(e)], larger values of Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT are concentrated among pairs of cells that are close to one another, as can be seen by plotting the mean mutual information as a function of distance\n[Fig.\u00a02(f)]. Together, these observations suggest that a backbone of positively correlated and physically proximate neurons may provide a large amount of information about the collective neural activity. Constructing the minimax entropy tree (Fig.\u00a01), we find that that it captures I\ud835\udcaf=26.2subscript\ud835\udc3c\ud835\udcaf26.2I_{\\mathcal{T}}=26.2italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT = 26.2 bits of information. This reduces our uncertainty about the population activity by I\ud835\udcaf/Sind=14.4%subscript\ud835\udc3c\ud835\udcafsubscript\ud835\udc46indpercent14.4I_{\\mathcal{T}}/S_{\\text{ind}}=14.4\\%italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT / italic_S start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT = 14.4 %, which is equivalent to freezing the states of 214 randomly selected neurons. For comparison, we consider two additional networks: (i) a random tree, which represents a typical collection of correlations, and (ii) the tree of minimum physical distances, which reflects the fact that neighboring neurons are more likely to be strongly correlated [Fig.\u00a02(f)]. The optimal tree captures over twice as much information as the minimum distance tree and over 50 times more than random. While each model P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT is defined to match a sparse subset of the observed correlations \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\left<x_{i}x_{j}\\right>\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 (and thus mutual information Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT) for (i\u2062j)\u2208\ud835\udcaf\ud835\udc56\ud835\udc57\ud835\udcaf(ij)\\in\\mathcal{T}( italic_i italic_j ) \u2208 caligraphic_T, we can ask what P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT predicts for all pairs of neurons (see Appendix E). We note that the optimal tree does not simply match the largest N\u22121\ud835\udc411N-1italic_N - 1 values of Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT; in general, these will form loops. Yet we find that the minimax entropy model still predicts the distribution of Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT within experimental error for the top \u223cNsimilar-toabsent\ud835\udc41\\sim N\u223c italic_N values [Fig.\u00a03(a)]. Indeed, we find that the model captures the strong correlations in the population [Fig.\u00a03(b)]; this accuracy decreases significantly for the minimum distance and random trees (see Appendix F). As expected, the optimal tree underpredicts the strengths of weak and negative correlations [Fig.\u00a03(b)]. Although these correlations may seem unimportant individually, we note that they comprise the vast majority of neuron pairs [Fig.\u00a02(c)]. With knowledge of only 2/N\u223c0.1%similar-to2\ud835\udc41percent0.12/N\\sim 0.1\\%2 / italic_N \u223c 0.1 % of the pairwise correlations, can the optimal tree capture collective behavior in the system? In neuronal populations (and other complex systems), one key collective property is synchronized activity Schneidman\u00a0et\u00a0al. (2006); Tka\u010dik\u00a0et\u00a0al. (2015); Meshulam\u00a0et\u00a0al. (2021); Lynn\u00a0et\u00a0al. (2019), which is characterized by the probability P\u2062(K)\ud835\udc43\ud835\udc3eP(K)italic_P ( italic_K ) that K\ud835\udc3eKitalic_K out of the N\ud835\udc41Nitalic_N neurons are simultaneous active. If the neurons were independent, this distribution would be approximately Gaussian at large N\ud835\udc41Nitalic_N (Fig.\u00a04, dashed). But in real populations, the dependencies among neurons leads to a much broader distribution (Fig.\u00a04, black), with moments of extreme synchrony in both activity (large K\ud835\udc3eKitalic_K) and silence (small K\ud835\udc3eKitalic_K). If one builds a model from pairwise correlations chosen at random, then the distribution P\u2062(K)\ud835\udc43\ud835\udc3eP(K)italic_P ( italic_K ) is almost indistinguishable from that of an independent system (see Appendix F). By contrast, the optimal tree captures most of this collective behavior Lynn\u00a0et\u00a0al. (2023), correctly predicting \u2273100greater-than-or-equivalent-toabsent100\\gtrsim 100\u2273 100\u2013fold increases in the probabilities that K\u227350greater-than-or-equivalent-to\ud835\udc3e50K\\gtrsim 50italic_K \u2273 50 neurons are active in the same small time bin (Fig.\u00a04, red). Although the detailed patterns of activity in the system are shaped by competing interactions that are missing from our optimal tree, this shows that large\u2013scale synchrony can emerge from a sparse network of the strongest correlations. To understand the nature of the optimal tree, we can study the minimax entropy model P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT itself, which, as discussed above, is equivalent to an Ising model from statistical physics. This mapping is made concrete by considering a system of spins \u03c3i=2\u2062xi\u22121\u2208\u00b11subscript\ud835\udf0e\ud835\udc562subscript\ud835\udc65\ud835\udc561plus-or-minus1\\sigma_{i}=2x_{i}-1\\in\\pm 1italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 2 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - 1 \u2208 \u00b1 1 with Ising interactions Ji\u2062jI=Ji\u2062j/4subscriptsuperscript\ud835\udc3dI\ud835\udc56\ud835\udc57subscript\ud835\udc3d\ud835\udc56\ud835\udc574J^{\\text{I}}_{ij}=J_{ij}/4italic_J start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT / 4 and local fields hiI=hi/2+\u2211jJi\u2062jIsubscriptsuperscript\u210eI\ud835\udc56subscript\u210e\ud835\udc562subscript\ud835\udc57subscriptsuperscript\ud835\udc3dI\ud835\udc56\ud835\udc57h^{\\text{I}}_{i}=h_{i}/2+\\sum_{j}J^{\\text{I}}_{ij}italic_h start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / 2 + \u2211 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_J start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT, where Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT and hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are defined in Eqs. (6) and (7). If the interaction Ji\u2062jIsubscriptsuperscript\ud835\udc3dI\ud835\udc56\ud835\udc57J^{\\text{I}}_{ij}italic_J start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT is positive (negative), then activity in neuron i\ud835\udc56iitalic_i leads to activity (silence) in neuron j\ud835\udc57jitalic_j, and vice versa. For random trees, the interactions Ji\u2062jIsubscriptsuperscript\ud835\udc3dI\ud835\udc56\ud835\udc57J^{\\text{I}}_{ij}italic_J start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT are nearly evenly split between positive and negative [Fig.\u00a05(a)]; this is consistent with previous investigations of fully\u2013connected models in populations of N\u223c100similar-to\ud835\udc41100N\\sim 100italic_N \u223c 100 neurons Schneidman\u00a0et\u00a0al. (2006); Tka\u010dik\u00a0et\u00a0al. (2015); Meshulam\u00a0et\u00a0al. (2021). Meanwhile, we recall that the largest mutual information in the population belongs to positively correlated neurons [Fig.\u00a02(d)]. Accordingly, the optimal tree has interactions that are almost exclusively positive [Fig.\u00a05(a)]. We have arrived, perhaps surprisingly, at a traditional Ising ferromagnet. While the interactions Ji\u2062jIsubscriptsuperscript\ud835\udc3dI\ud835\udc56\ud835\udc57J^{\\text{I}}_{ij}italic_J start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT define effective influences between neurons, the local fields represent individual biases toward activity (hiI>0subscriptsuperscript\u210eI\ud835\udc560h^{\\text{I}}_{i}>0italic_h start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT > 0) or silence (hiI<0subscriptsuperscript\u210eI\ud835\udc560h^{\\text{I}}_{i}<0italic_h start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < 0). For random trees, all of the local fields are negative [Fig.\u00a05(b)], reflecting the fact that neurons are more likely to be silent than active. But in the optimal tree, we see that some neurons are counterintuitively biased toward activity with hiI>0subscriptsuperscript\u210eI\ud835\udc560h^{\\text{I}}_{i}>0italic_h start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT > 0 [Fig.\u00a05(b)]. These positive biases stand in competition with the positive interactions in the model, which, because neurons favor silence, tend to induce silence in the population. To understand the effects of interactions on individual cells, we note that the average activity of an independent neuron i\ud835\udc56iitalic_i is fully defined by hiIsubscriptsuperscript\u210eI\ud835\udc56h^{\\text{I}}_{i}italic_h start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT through the relation \u27e8\u03c3i\u27e9=tanh\u2061hiIdelimited-\u27e8\u27e9subscript\ud835\udf0e\ud835\udc56subscriptsuperscript\u210eI\ud835\udc56\\left<\\sigma_{i}\\right>=\\tanh h^{\\text{I}}_{i}\u27e8 italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9 = roman_tanh italic_h start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Since random trees contain only weak correlations, the neuronal activity closely tracks this independent prediction [Fig.\u00a05(c)]. As interactions become increasingly positive in the minimum distance and optimal trees, the alignment of neighboring neurons produces average activities that are significantly lower than one would expect from local fields alone [Fig.\u00a05(c)]. For each neuron i\ud835\udc56iitalic_i, the competition between internal biases and interactions is made clear by comparing the local field hiIsubscriptsuperscript\u210eI\ud835\udc56h^{\\text{I}}_{i}italic_h start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to the average influence due to interactions hiint=\u2211jJi\u2062jI\u2062\u27e8\u03c3j\u27e9subscriptsuperscript\u210eint\ud835\udc56subscript\ud835\udc57subscriptsuperscript\ud835\udc3dI\ud835\udc56\ud835\udc57delimited-\u27e8\u27e9subscript\ud835\udf0e\ud835\udc57h^{\\text{int}}_{i}=\\sum_{j}J^{\\text{I}}_{ij}\\left<\\sigma_{j}\\right>italic_h start_POSTSUPERSCRIPT int end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = \u2211 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_J start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u27e8 italic_\u03c3 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9. In random trees, only 1%percent11\\%1 % of neurons are dominated by interactions, such that hiint<hiIsubscriptsuperscript\u210eint\ud835\udc56subscriptsuperscript\u210eI\ud835\udc56h^{\\text{int}}_{i}<h^{\\text{I}}_{i}italic_h start_POSTSUPERSCRIPT int end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < italic_h start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT [Fig.\u00a05(d)]; this proportion increases to 43%percent4343\\%43 % in the minimum distance tree and 57%percent5757\\%57 % in the optimal tree [Fig.\u00a05(d)]. So despite the fact that the tree structure constrains each cell to only interact with two others in the entire population (on average), most neurons in the optimal tree are driven more strongly by interactions than internal biases. In addition to the functional properties of the model P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT, we can also study the graph structure of the optimal tree \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T. To visualize each tree, we place the cell with the most connections (or largest degree ki=|\ud835\udca9i|subscript\ud835\udc58\ud835\udc56subscript\ud835\udca9\ud835\udc56k_{i}=|\\mathcal{N}_{i}|italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = | caligraphic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT |) at the center and all of the cells with single connections (ki=1subscript\ud835\udc58\ud835\udc561k_{i}=1italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1) around the perimeter [Fig.\u00a06(a)]. For random trees, the distribution of degrees is Poisson [Fig.\u00a06(b)], preventing the emergence of high\u2013degree hub nodes. Degrees are even more sharply peaked in the minimum distance tree, such that we do not observe a single neuron with more than four connections [Fig.\u00a06(b)]. By contrast, the optimal tree has a much broader degree distribution, with a central neuron that connects to 29 other cells in the population [Fig.\u00a06(b)]. Such hub nodes are frequently observed in the brain\u2019s physical connectivity Song\u00a0et\u00a0al. (2005); Lynn\u00a0and\u00a0Bassett (2019); Lin\u00a0et\u00a0al. (2023), and are thought to play an important role in facilitating communication Albert\u00a0and\u00a0Barab\u00e1si (2002). By maximizing information about the population, one might hope that the optimal tree captures features of the true interactions between neurons. In the brain, demands on communication are constrained by energetic costs Harris\u00a0et\u00a0al. (2012). Networks have evolved to balance efficient communication (minimizing the number of steps between cells in the network, known as topological distance) with energetic efficiency (minimizing the physical lengths of connections) Laughlin\u00a0and\u00a0Sejnowski (2003); Lynn\u00a0and\u00a0Bassett (2019). These pressures are in direct competition: Networks with physically local connections form lattice\u2013like structures with long topological distances, and networks with short topological distances (known as the small\u2013world property Watts\u00a0and\u00a0Strogatz (1998)) require physically long\u2013range connections. Indeed, in the minimum distance tree, which is composed of the physically shortest connections [Fig.\u00a06(c)], communication between two neurons requires \u223c100similar-toabsent100\\sim 100\u223c 100 intermediate cells on average [Fig.\u00a06(d)]; and random trees, which are known to produce short topological distances [Fig.\u00a06(d)], are mostly composed of long\u2013range connections [Fig.\u00a06(c)]. Meanwhile, the minimax entropy model identifies connections that are much shorter than average [Fig.\u00a06(c)] while simultaneously maintaining small\u2013world structure [Fig.\u00a06(d)], just as observed in real neuronal networks Laughlin\u00a0and\u00a0Sejnowski (2003). Thus far, we have focused on a single population of N\u223c1500similar-to\ud835\udc411500N\\sim 1500italic_N \u223c 1500 neurons. But as experiments advance to record from even larger populations, how does the minimax entropy model scale with N\ud835\udc41Nitalic_N? To answer this question, in the spirit of Ref.\u00a0Meshulam\u00a0et\u00a0al. (2021) one can imagine growing a contiguous population centered at a single neuron [Fig.\u00a07(a)], and computing the optimal tree for increasing population sizes. Due to the efficiency of our model, we can repeat this process starting from each of the different neurons and average over the results. As the population grows, the independent entropy Sindsubscript\ud835\udc46indS_{\\text{ind}}italic_S start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT must increase extensively (that is, linearly with N\ud835\udc41Nitalic_N) on average [Fig.\u00a07(b)]. Since each tree contains N\u22121\ud835\udc411N-1italic_N - 1 correlations, one might also expect the information I\ud835\udcafsubscript\ud835\udc3c\ud835\udcafI_{\\mathcal{T}}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT of any tree to scale extensively. However, we find that the scaling of I\ud835\udcafsubscript\ud835\udc3c\ud835\udcafI_{\\mathcal{T}}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT with population size depends critically on which correlations we use in building the tree\n[Fig.\u00a07(b)]. If the information I\ud835\udcafsubscript\ud835\udc3c\ud835\udcafI_{\\mathcal{T}}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT grows extensively, then the model P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT explains a constant proportion of the independent entropy I\ud835\udcaf/Sindsubscript\ud835\udc3c\ud835\udcafsubscript\ud835\udc46indI_{\\mathcal{T}}/S_{\\text{ind}}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT / italic_S start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT across different population sizes. Indeed, because the properties of the closest neurons do not change as the population grows (on average), the minimum distance tree captures a nearly constant \u223c6%similar-toabsentpercent6\\sim 6\\%\u223c 6 % of the independent entropy [Fig.\u00a07(c)]. By contrast, since the mutual information Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT between neurons tends to decrease with physical distance [Fig.\u00a02(f)], the average mutual information I\u00af\u00af\ud835\udc3c\\bar{I}over\u00af start_ARG italic_I end_ARG in a spatially contiguous population decreases with N\ud835\udc41Nitalic_N. Thus, the typical information in a random tree grows subextensively with the population size [Fig.\u00a07(b)], and the fractional information I\ud835\udcaf/Sindsubscript\ud835\udc3c\ud835\udcafsubscript\ud835\udc46indI_{\\mathcal{T}}/S_{\\text{ind}}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT / italic_S start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT vanishes [Fig.\u00a07(c)]. But even though the average mutual information I\u00af\u00af\ud835\udc3c\\bar{I}over\u00af start_ARG italic_I end_ARG decreases, as the population grows we uncover more of the exceptionally large mutual information Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT in the tail of the distribution [Fig.\u00a02(b)]. By identifying these highly informative correlations, the optimal tree accumulates a superextensive amount of information I\ud835\udcafsubscript\ud835\udc3c\ud835\udcafI_{\\mathcal{T}}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT [Fig.\u00a07(b)], thus capturing a greater proportion of the independent entropy as N\ud835\udc41Nitalic_N increases [Fig.\u00a07(c)]. This increased explanatory power is underpinned by stronger interactions and weaker local fields in the Ising network [Fig.\u00a07(d)]. There is no sign that the trend in Fig.\u00a07(c) is saturating at N\u223c103similar-to\ud835\udc41superscript103N\\sim 10^{3}italic_N \u223c 10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT, suggesting that our minimax entropy framework may become even more effective for larger populations. As discussed above, each tree of observed correlations \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T generates a maximum entropy model P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT [Eq.\u00a0(5)], which in turn is equivalent to a system of Ising spins. This mapping from experimental observations to statistical physics gives us the opportunity to ask whether the model P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT occupies a special place in the space of possible models. In statistical mechanics, equilibrium systems are described by the Boltzmann distribution, where T\ud835\udc47Titalic_T is the temperature of the system and E\u2062(\ud835\udc99)\ud835\udc38\ud835\udc99E(\\bm{x})italic_E ( bold_italic_x ) is the Hamiltonian, which defines the energy of state \ud835\udc99\ud835\udc99\\bm{x}bold_italic_x. For a given tree \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T, we notice that P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT defines a Boltzmann distribution with temperature T=1\ud835\udc471T=1italic_T = 1 and energy where Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT and hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are defined in Eqs. (6) and (7). Note that we do not assume the experimental system itself is in equilibrium; this correspondence is purely mathematical. By perturbing the temperature away from T=1\ud835\udc471T=1italic_T = 1, we can probe at least one slice through the space of possible networks Tka\u010dik\u00a0et\u00a0al. (2015). For each value of T\ud835\udc47Titalic_T, we arrive at a hypothetical system P\ud835\udcaf\u2062(\ud835\udc99;T)subscript\ud835\udc43\ud835\udcaf\ud835\udc99\ud835\udc47P_{\\mathcal{T}}(\\bm{x};T)italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT ( bold_italic_x ; italic_T ) with average activities \u27e8xi\u27e9Tsubscriptdelimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56\ud835\udc47\\left<x_{i}\\right>_{T}\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT and correlations \u27e8xi\u2062xj\u27e9Tsubscriptdelimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\ud835\udc47\\left<x_{i}x_{j}\\right>_{T}\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT that are no longer constrained to match experimental observations. Consider the minimax entropy tree, which (as discussed in \u00a7V) produces a ferromagnetic Ising model with nearly all positive interactions Ji\u2062jIsubscriptsuperscript\ud835\udc3dI\ud835\udc56\ud835\udc57J^{\\text{I}}_{ij}italic_J start_POSTSUPERSCRIPT I end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT [Fig.\u00a05(a)]. At high temperatures T\u226b1much-greater-than\ud835\udc471T\\gg 1italic_T \u226b 1, fluctuations destroy the preference for silence over activity, and the system approaches the average activity 1N\u2062\u2211i\u27e8xi\u27e9T=0.51\ud835\udc41subscript\ud835\udc56subscriptdelimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56\ud835\udc470.5\\frac{1}{N}\\sum_{i}\\left<x_{i}\\right>_{T}=0.5divide start_ARG 1 end_ARG start_ARG italic_N end_ARG \u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 0.5 [Fig.\u00a08(a)]. Meanwhile, at low temperatures T\u226a1much-less-than\ud835\udc471T\\ll 1italic_T \u226a 1, activity vanishes as the network freezes into the all\u2013silent ground state \ud835\udc99=0\ud835\udc990\\bm{x}=0bold_italic_x = 0 [Fig.\u00a08(a)]. In both limits, all of the information contained in correlations is lost. As the temperature decreases, most systems experience a gradual transition from disorder to order. But for certain combinations of parameters Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT and hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, a small change in the temperature T\ud835\udc47Titalic_T can lead to a large change in the behavior of the system, and as N\ud835\udc41Nitalic_N becomes large, this transition becomes sharp Sethna (2021); Tka\u010dik\u00a0et\u00a0al. (2015); Schnabel\u00a0et\u00a0al. (2011). Such phase transitions mark a critical point in the space of possible systems, with the Ising ferromagnet as the canonical example Peierls (1936). In the optimal tree, as the temperature increases just above T=1\ud835\udc471T=1italic_T = 1, the positive interactions lead to a much steeper increase in activity than an independent system; and this transition grows even sharper for larger populations [Fig.\u00a08(a)]. We emphasize that at any finite N\ud835\udc41Nitalic_N there is no true critical point, but N\u223c1000similar-to\ud835\udc411000N\\sim 1000italic_N \u223c 1000 may be large enough that the idealization N\u2192\u221e\u2192\ud835\udc41N\\rightarrow\\inftyitalic_N \u2192 \u221e is useful. Since we are studying models defined on trees, there are also subtleties about how one would construct the thermodynamic limit, since such a large fraction of sites are on the boundary Baxter (2016). For our purposes, the interesting question is whether real networks of neurons are in any sense at special points in the space of possible networks. One way in which this could happen is if parameters are set so that simple macroscopic quantities have near\u2013extremal values. One example of a macroscopic quantity that provides a global measure of collective behavior is the total susceptibility of the mean activity to changes in the bias fields, where the rewriting in terms of connected correlations can be derived from the Boltzmann distribution [Eq.\u00a0(9)]. We recall that at conventional critical points we would see a divergence of \u03c7/N\ud835\udf12\ud835\udc41\\chi/Nitalic_\u03c7 / italic_N as N\u2192\u221e\u2192\ud835\udc41N\\rightarrow\\inftyitalic_N \u2192 \u221e. At both high and low temperatures, correlations are destroyed, and the susceptibility vanishes [Fig.\u00a08(b)]. However, at intermediate temperatures, the susceptibility exhibits a peak that becomes sharper as the system grows, even after normalizing by the population size N\ud835\udc41Nitalic_N [Fig.\u00a08(b)]. Moreover, as N\ud835\udc41Nitalic_N increases, the peak temperature decreases toward T=1\ud835\udc471T=1italic_T = 1, corresponding to the true minimax entropy model P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT. By contrast, the minimum distance and random trees undergo smooth transitions from disorder to order [Fig.\u00a08(c)], with the maximum susceptibility and peak temperatures remaining approximately constant across all population sizes N\ud835\udc41Nitalic_N [Fig.\u00a08(d)]. In addition to the susceptibility \u03c7\ud835\udf12\\chiitalic_\u03c7, we also observe a dramatic peak in the specific heat C/N\ud835\udc36\ud835\udc41C/Nitalic_C / italic_N [Fig.\u00a08(e)], where is the heat capacity (see Appendix G). Although there is no meaning to \u201cheat\u201d in this system, because the specific heat is related to the variance in energy, we can think of the peak in C\ud835\udc36Citalic_C as being a peak in the dynamic range of (log) probabilities across the states of the network. These divergences in the susceptibility and heat capacity also align with a sharp peak in the information fraction I\ud835\udcaf/Sindsubscript\ud835\udc3c\ud835\udcafsubscript\ud835\udc46indI_{\\mathcal{T}}/S_{\\text{ind}}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT / italic_S start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT [Fig.\u00a08(f)], with larger systems becoming even more strongly correlated. Together, these results indicate that the true minimax entropy model P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT is poised near a special point in the space of models P\ud835\udcaf\u2062(\ud835\udc99;T)subscript\ud835\udc43\ud835\udcaf\ud835\udc99\ud835\udc47P_{\\mathcal{T}}(\\bm{x};T)italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT ( bold_italic_x ; italic_T ), where small changes in parameter values can produce large changes in the collective behavior of the system. The maximum entropy principle provides the most unbiased mapping from experimental observations to statistical physics models. Over the past two decades, this link has proven useful in understanding the emergence of collective behaviors in populations of neurons and other complex living systems Schneidman\u00a0et\u00a0al. (2006); Nguyen\u00a0et\u00a0al. (2017); Meshulam\u00a0et\u00a0al. (2017, 2021); Tka\u010dik\u00a0et\u00a0al. (2015); Lezon\u00a0et\u00a0al. (2006); Weigt\u00a0et\u00a0al. (2009); Marks\u00a0et\u00a0al. (2011); Lapedes\u00a0et\u00a0al. (2012); Bialek\u00a0et\u00a0al. (2012); Russ\u00a0et\u00a0al. (2020); Lynn\u00a0et\u00a0al. (2019). Less widely emphasized is the fact that there is not a single maximum entropy model, but rather a landscape of possible models depending on what features of the system we choose to constrain. Quite generally, we should choose the features that are most informative\u2014the ones that minimize the entropy of the maximum entropy model\u2014leading to the minimax entropy principle Zhu\u00a0et\u00a0al. (1997). As experiments record from larger and larger populations of neurons Segev\u00a0et\u00a0al. (2004); Litke\u00a0et\u00a0al. (2004); Chung\u00a0et\u00a0al. (2019); Dombeck\u00a0et\u00a0al. (2010); Tian\u00a0et\u00a0al. (2012); Demas\u00a0et\u00a0al. (2021); Steinmetz\u00a0et\u00a0al. (2021), we enter an undersampled regime in which selecting a limited number of maximally informative features is not only conceptually appealing, but also practically necessary. While the minimax entropy problem is generally intractable, here we make progress in two steps. First, we build upon previous work by constraining mean activities and pairwise correlations, resulting in models that are equivalent to systems of Ising spins. Second, taking inspiration from the Bethe lattice, we focus only on trees of correlations, or sparse networks without loops. Under these restrictions, we solve the minimax entropy problem exactly, identifying the optimal tree in quadratic time Chow\u00a0and\u00a0Liu (1968); Nguyen\u00a0et\u00a0al. (2017). The result is a non\u2013trivial family of statistical physics models that can be constructed very efficiently for large neuronal populations. It is far from obvious that these models can capture any of the essential collective behavior in real networks. To answer this question, we study a population of N\u223c1500similar-to\ud835\udc411500N\\sim 1500italic_N \u223c 1500 neurons in the mouse hippocampus Gauthier\u00a0and\u00a0Tank (2018), identifying the maximally informative tree of pairwise correlations (Figs.\u00a05 and 6). Despite containing only one correlation per neuron, this minimax entropy model accounts for 14%percent1414\\%14 % of the independent entropy (over 50505050 times more than random trees) and predicts the distribution of large\u2013scale synchrony in activity (Fig.\u00a04). Moreover, the model becomes more effective as the population grows (Fig.\u00a07) and exhibits hints of critical behavior (Fig.\u00a08). The success of such a sparse model hinges on the fact that the distribution of mutual information between neurons is heavy\u2013tailed [Fig.\u00a02(b)], such that a few rare correlations carry much more information than average. In fact, the physical connections between neurons are now understood to be heavy\u2013tailed across a range of animals Lynn\u00a0et\u00a0al. (2022), suggesting that our approach my prove effective in other neural systems. While these minimax entropy models cannot capture all of a system\u2019s collective properties, they provide at least a starting point for simplified descriptions of the much larger systems becoming accessible in modern experiments. To establish notation, we begin by reviewing well known ideas about statistical mechanics for models without loops. We then proceed, here and in subsequent Appendices, to technical points needed for the main text. Consider a system of N\ud835\udc41Nitalic_N binary variables xi\u2208{0,1}subscript\ud835\udc65\ud835\udc5601x_{i}\\in\\{0,1\\}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2208 { 0 , 1 }, i=1,2,\u2026,N\ud835\udc5612\u2026\ud835\udc41i=1,2,\\ldots,Nitalic_i = 1 , 2 , \u2026 , italic_N, defined by fields hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and interactions Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT that lie on a tree \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T. The Boltzmann distribution [Eq.\u00a0(5)] takes the form where F=0\ud835\udc390F=0italic_F = 0 is the zero\u2013point energy, which will become useful. To begin, we seek to compute the partition function, To do so, imagine summing over one variable, and finding a new system of N\u22121\ud835\udc411N-1italic_N - 1 variables with the same partition function Z\ud835\udc4dZitalic_Z. If we can repeat this process until no variables remain, then computing Z\ud835\udc4dZitalic_Z will be trivial. We label the nodes i\ud835\udc56iitalic_i based on the order that they are removed, and we let hi(i)subscriptsuperscript\u210e\ud835\udc56\ud835\udc56h^{(i)}_{i}italic_h start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and F(i)superscript\ud835\udc39\ud835\udc56F^{(i)}italic_F start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT denote the updated parameters at step i\ud835\udc56iitalic_i, while the interactions Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT stay fixed. Consider summing over a variable i\ud835\udc56iitalic_i with only one connection in the network, say to variable j\ud835\udc57jitalic_j. We note that such a node is always guaranteed to exist in a tree. To keep the partition function fixed, the new system with i\ud835\udc56iitalic_i removed must satisfy the equations This is a system of two equations (one for each value of xjsubscript\ud835\udc65\ud835\udc57x_{j}italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT), which we can solve for the new parameters After removing i\ud835\udc56iitalic_i, the new system still forms a tree, so we can repeat the above procedure. When all nodes have been removed, we are left with a single parameter \u2131=F(N+1)\u2131superscript\ud835\udc39\ud835\udc411\\mathcal{F}=F^{(N+1)}caligraphic_F = italic_F start_POSTSUPERSCRIPT ( italic_N + 1 ) end_POSTSUPERSCRIPT, which is the free energy of the system, and the partition function is given by To compute population statistics, one simply needs to take derivatives of the partition function, where dd\u2062hi\ud835\udc51\ud835\udc51subscript\u210e\ud835\udc56\\frac{d}{dh_{i}}divide start_ARG italic_d end_ARG start_ARG italic_d italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG and dd\u2062Ji\u2062j\ud835\udc51\ud835\udc51subscript\ud835\udc3d\ud835\udc56\ud835\udc57\\frac{d}{dJ_{ij}}divide start_ARG italic_d end_ARG start_ARG italic_d italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG represent total derivatives, which account for indirect dependencies via Eqs. (16) and (17). Since d\u2062\u2131d\u2062F(i+1)=1\ud835\udc51\u2131\ud835\udc51superscript\ud835\udc39\ud835\udc5611\\frac{d\\mathcal{F}}{dF^{(i+1)}}=1divide start_ARG italic_d caligraphic_F end_ARG start_ARG italic_d italic_F start_POSTSUPERSCRIPT ( italic_i + 1 ) end_POSTSUPERSCRIPT end_ARG = 1 and d\u2062hi(i)d\u2062hi=1\ud835\udc51superscriptsubscript\u210e\ud835\udc56\ud835\udc56\ud835\udc51subscript\u210e\ud835\udc561\\frac{dh_{i}^{(i)}}{dh_{i}}=1divide start_ARG italic_d italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT end_ARG start_ARG italic_d italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG = 1, the above procedure yields Noticing that and taking derivatives of Eqs. (16) and (17), we have The correlation follows analogously, Thus, by proceeding in the opposite order from which the nodes were removed, we can compute the average activities \u27e8xi\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56\\langle x_{i}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9 and correlations \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\langle x_{i}x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 for (i\u2062j)\u2208\ud835\udcaf\ud835\udc56\ud835\udc57\ud835\udcaf(ij)\\in\\mathcal{T}( italic_i italic_j ) \u2208 caligraphic_T. For the correlations \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\langle x_{i}x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 off the tree (that is, for (i\u2062j)\u2209\ud835\udcaf\ud835\udc56\ud835\udc57\ud835\udcaf(ij)\\not\\in\\mathcal{T}( italic_i italic_j ) \u2209 caligraphic_T), see Appendix E. We now solve the inverse problem for the parameters hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT given the observations \u27e8xi\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56\\langle x_{i}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9 and \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\langle x_{i}x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 on a tree \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T. Inverting Eqs. (23) and (24) yields Combining the above equations, we can solve for the interaction Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT in Eq.\u00a0(6). To compute the local field hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, we note that we can repeat the procedure in Appendix A ending at any node; this is equivalent to choosing the root of the tree. If we choose i\ud835\udc56iitalic_i to be the final node, then we have Additionally, for each neighbor j\u2208\ud835\udca9i\ud835\udc57subscript\ud835\udca9\ud835\udc56j\\in\\mathcal{N}_{i}italic_j \u2208 caligraphic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, Eq.\u00a0(16) tells us that we receive a contribution to hi(N)superscriptsubscript\u210e\ud835\udc56\ud835\udc41h_{i}^{(N)}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_N ) end_POSTSUPERSCRIPT of the form Combining these contributions yields We have thus arrived at an analytic solution to the maximum entropy problem on a tree. Our ability to efficiently construct the optimal tree \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T depends critically on the decomposition of the information I\ud835\udcafsubscript\ud835\udc3c\ud835\udcafI_{\\mathcal{T}}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT into the sum of mutual information Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT over pairs (i\u2062j)\u2208\ud835\udcaf\ud835\udc56\ud835\udc57\ud835\udcaf(ij)\\in\\mathcal{T}( italic_i italic_j ) \u2208 caligraphic_T [Eq.\u00a0(8)]. To derive this result, we note that for each connection (i\u2062j)\u2208\ud835\udcaf\ud835\udc56\ud835\udc57\ud835\udcaf(ij)\\in\\mathcal{T}( italic_i italic_j ) \u2208 caligraphic_T, the observables \u27e8xi\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56\\langle x_{i}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9, \u27e8xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc57\\langle x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9, and \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\langle x_{i}x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 fully define the marginal distribution Pi\u2062j\u2062(xi,xj)subscript\ud835\udc43\ud835\udc56\ud835\udc57subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57P_{ij}(x_{i},x_{j})italic_P start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ). Now consider a new tree \ud835\udcaf\u2032=\ud835\udcaf/(i\u2062j)superscript\ud835\udcaf\u2032\ud835\udcaf\ud835\udc56\ud835\udc57\\mathcal{T^{\\prime}}=\\mathcal{T}/(ij)caligraphic_T start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = caligraphic_T / ( italic_i italic_j ) with the connection (i\u2062j)\ud835\udc56\ud835\udc57(ij)( italic_i italic_j ) removed, such that we do not observe \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\langle x_{i}x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9. Since \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T has no loops, after removing (i\u2062j)\ud835\udc56\ud835\udc57(ij)( italic_i italic_j ) the two elements i\ud835\udc56iitalic_i and j\ud835\udc57jitalic_j become independent. Meanwhile, the dependence of the rest of the system on i\ud835\udc56iitalic_i and j\ud835\udc57jitalic_j remains fixed. Thus, observing the correlation \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\langle x_{i}x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 leads to a drop in entropy where Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT is the observed mutual information between i\ud835\udc56iitalic_i and j\ud835\udc57jitalic_j. Repeating the above argument for every correlation in \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T, we arrive at Eq.\u00a0(8). In order to estimate the mutual information between neurons Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT, one must correct for finite\u2013data effects Strong\u00a0et\u00a0al. (1998). To do so, we subsample the data hierarchically for different data fractions {1,0.9,\u2026,0.2,0.1}10.9\u20260.20.1\\{1,0.9,\\ldots,0.2,0.1\\}{ 1 , 0.9 , \u2026 , 0.2 , 0.1 }, such that each subsample is contained within the larger subsamples. Additionally, to preserve the dependencies between consecutive data points \ud835\udc99(m)superscript\ud835\udc99\ud835\udc5a\\bm{x}^{(m)}bold_italic_x start_POSTSUPERSCRIPT ( italic_m ) end_POSTSUPERSCRIPT and \ud835\udc99(m+1)superscript\ud835\udc99\ud835\udc5a1\\bm{x}^{(m+1)}bold_italic_x start_POSTSUPERSCRIPT ( italic_m + 1 ) end_POSTSUPERSCRIPT, we sample temporally contiguous fractions of the data. To ensure that each point is sampled with equal probability, we allow subsamples that span the beginning and end of the recording. For each subsample, we estimate the mutual information between neurons i\ud835\udc56iitalic_i and j\ud835\udc57jitalic_j using the equation where The pseudo\u2013counts in Eq.\u00a0(33) ensure that the mutual information estimates do not diverge. After estimating Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT for each data fraction, following Ref.\u00a0Strong\u00a0et\u00a0al. (1998) we extrapolate to the infinite\u2013data limit using a linear fit with respect to the inverse data fraction. Repeating this process 100 times, we arrive at a distribution of infinite\u2013data estimates for Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT, from which we can compute a mean and standard deviation (Fig.\u00a09). To check the above procedure, we note that shuffling the activity of each neuron in time should destroy the mutual information Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT. Indeed, for time\u2013shuffled data, we do not observe a single significant mutual information in the population. Given a maximum entropy model with parameters hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT on a tree \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T, in Appendix A we showed how to compute the averages \u27e8xi\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56\\langle x_{i}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9 and correlations \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\langle x_{i}x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 on the tree. Specifically, we computed the partition function Z\ud835\udc4dZitalic_Z by summing over variables xisubscript\ud835\udc65\ud835\udc56x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT in the order i=1,2,\u22ef,N\ud835\udc5612\u22ef\ud835\udc41i=1,2,\\cdots,Nitalic_i = 1 , 2 , \u22ef , italic_N, and then computed statistics in the reverse order. Here, we show how to compute the correlations \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\langle x_{i}x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 not on the tree; that is, for (i\u2062j)\u2209\ud835\udcaf\ud835\udc56\ud835\udc57\ud835\udcaf(ij)\\not\\in\\mathcal{T}( italic_i italic_j ) \u2209 caligraphic_T. To begin, we assume that we have computed the correlations \u27e8xj\u2062xk\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc57subscript\ud835\udc65\ud835\udc58\\langle x_{j}x_{k}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \u27e9 for all nodes k>i>j\ud835\udc58\ud835\udc56\ud835\udc57k>i>jitalic_k > italic_i > italic_j. Then, if we compute \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\langle x_{i}x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9, the procedure will follow by induction. From the Boltzmann distribution in Eq.\u00a0(5), we have We already know how to compute the averages \u27e8xi\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56\\langle x_{i}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u27e9 and \u27e8xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc57\\langle x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9, so all that remains is to calculate the above derivative. Let p\u2062(i)\ud835\udc5d\ud835\udc56p(i)italic_p ( italic_i ) denote the parent of i\ud835\udc56iitalic_i (that is, the final neighbor when i\ud835\udc56iitalic_i is removed) and likewise for p\u2062(j)\ud835\udc5d\ud835\udc57p(j)italic_p ( italic_j ). Differentiating Eq.\u00a0(23) with respect to hjsubscript\u210e\ud835\udc57h_{j}italic_h start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, we have We note that which we have already computed by assumption, since p\u2062(i)>i\ud835\udc5d\ud835\udc56\ud835\udc56p(i)>iitalic_p ( italic_i ) > italic_i. From Eq.\u00a0(23) we have, and Finally, we note that the dependence of hi(i)superscriptsubscript\u210e\ud835\udc56\ud835\udc56h_{i}^{(i)}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT on hjsubscript\u210e\ud835\udc57h_{j}italic_h start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT runs only through hp\u2062(j)(j+1)subscriptsuperscript\u210e\ud835\udc571\ud835\udc5d\ud835\udc57h^{(j+1)}_{p(j)}italic_h start_POSTSUPERSCRIPT ( italic_j + 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_p ( italic_j ) end_POSTSUBSCRIPT, such that Since p\u2062(j)>j\ud835\udc5d\ud835\udc57\ud835\udc57p(j)>jitalic_p ( italic_j ) > italic_j, we can assume that we have already computed d\u2062hi(i)d\u2062hp\u2062(j)(j+1)\ud835\udc51superscriptsubscript\u210e\ud835\udc56\ud835\udc56\ud835\udc51subscriptsuperscript\u210e\ud835\udc571\ud835\udc5d\ud835\udc57\\frac{dh_{i}^{(i)}}{dh^{(j+1)}_{p(j)}}divide start_ARG italic_d italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT end_ARG start_ARG italic_d italic_h start_POSTSUPERSCRIPT ( italic_j + 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_p ( italic_j ) end_POSTSUBSCRIPT end_ARG. Finally, Eq.\u00a0(16) yields Plugging everything into Eq.\u00a0(36), and inducting on i>j\ud835\udc56\ud835\udc57i>jitalic_i > italic_j, one can compute the correlations \u27e8xi\u2062xj\u27e9delimited-\u27e8\u27e9subscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57\\langle x_{i}x_{j}\\rangle\u27e8 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 between all variables. In \u00a7IV, we studied the predictions of the minimax entropy model P\ud835\udcafsubscript\ud835\udc43\ud835\udcafP_{\\mathcal{T}}italic_P start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT corresponding to the optimal tree \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T. For comparison, here we consider the predictions of the minimum distance and random trees. While the optimal tree captures I\ud835\udcaf=26.2\u2062bitssubscript\ud835\udc3c\ud835\udcaf26.2bitsI_{\\mathcal{T}}=26.2\\,\\text{bits}italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT = 26.2 bits of information (I\ud835\udcaf/Sind=14.4%subscript\ud835\udc3c\ud835\udcafsubscript\ud835\udc46indpercent14.4I_{\\mathcal{T}}/S_{\\text{ind}}=14.4\\%italic_I start_POSTSUBSCRIPT caligraphic_T end_POSTSUBSCRIPT / italic_S start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT = 14.4 % of the independent entropy), the minimum distance tree only captures 11.9\u2062bits11.9bits11.9\\,\\text{bits}11.9 bits of information (6.5%percent6.56.5\\%6.5 % of the independent entropy), and a typical random tree only captures (N\u22121)\u2062I\u00af=0.4\u2062bits\ud835\udc411\u00af\ud835\udc3c0.4bits(N-1)\\bar{I}=0.4\\,\\text{bits}( italic_N - 1 ) over\u00af start_ARG italic_I end_ARG = 0.4 bits (0.2%percent0.20.2\\%0.2 % of the independent entropy). For each tree, we can predict the mutual information Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT and correlation coefficients between all pairs of neurons using the procedure in Appendix E. Since the minimum distance tree includes some of the largest mutual information in the population, it is able to match the distribution of Ii\u2062jsubscript\ud835\udc3c\ud835\udc56\ud835\udc57I_{ij}italic_I start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT (within errors) out to N\u223c100similar-to\ud835\udc41100N\\sim 100italic_N \u223c 100 neurons [Fig.\u00a010(a)]. However, the minimum distance tree fails to predict the observed correlations across most of the dynamic range of the data [Fig.\u00a010(b)]. Meanwhile, random trees typically include only weak mutual information [Fig.\u00a010(a)], such that their predictions are nearly indistinguishable from a population of independent neurons [Figs.\u00a010(b)]. For the minimax entropy model, a backbone of strong positive interactions combine to produce accurate predictions for the distribution P\u2062(K)\ud835\udc43\ud835\udc3eP(K)italic_P ( italic_K ) of population\u2013wide synchrony K\ud835\udc3eKitalic_K (Fig.\u00a04). By contrast, random trees predict a Gaussian distribution consistent with independent neurons, and the minimum distance tree only produces a slightly broader distribution (Fig.\u00a011). In both models, large\u2013scale synchrony in activity (K\u227350greater-than-or-equivalent-to\ud835\udc3e50K\\gtrsim 50italic_K \u2273 50) and silence (K\u227210less-than-or-similar-to\ud835\udc3e10K\\lesssim 10italic_K \u2272 10) occurs significantly less frequently than observed the data. Consider a system with fields hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, interactions Ji\u2062jsubscript\ud835\udc3d\ud835\udc56\ud835\udc57J_{ij}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT that lie on a tree \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T, and temperature T\ud835\udc47Titalic_T. The Boltzmann distribution P\u2062(\ud835\udc99)\ud835\udc43\ud835\udc99P(\\bm{x})italic_P ( bold_italic_x ) takes the form in Eq.\u00a0(9) with energy E\u2062(\ud835\udc99)\ud835\udc38\ud835\udc99E(\\bm{x})italic_E ( bold_italic_x ) defined in Eq.\u00a0(10). Here, we denote averages over P\u2062(\ud835\udc99)\ud835\udc43\ud835\udc99P(\\bm{x})italic_P ( bold_italic_x ) by \u27e8\u22c5\u27e9delimited-\u27e8\u27e9\u22c5\\langle\\cdot\\rangle\u27e8 \u22c5 \u27e9, while dropping the subscript T\ud835\udc47Titalic_T. The susceptibility \u03c7\ud835\udf12\\chiitalic_\u03c7 [Eq.\u00a0(11)], can be computed using the results of Appendix E. To compute the heat capacity C\ud835\udc36Citalic_C [Eq.\u00a0(12)], we begin with the average energy To calculate the free energy \u2131\u2131\\mathcal{F}caligraphic_F, we proceed as in Appendix A. After including the temperature T\ud835\udc47Titalic_T, Eqs. (16) and (17) take the form Iteratively summing over each variable, we arrive at the free energy \u2131=F(N+1)\u2131superscript\ud835\udc39\ud835\udc411\\mathcal{F}=F^{(N+1)}caligraphic_F = italic_F start_POSTSUPERSCRIPT ( italic_N + 1 ) end_POSTSUPERSCRIPT. To compute d\u2062\u2131d\u2062T\ud835\udc51\u2131\ud835\udc51\ud835\udc47\\frac{d\\mathcal{F}}{dT}divide start_ARG italic_d caligraphic_F end_ARG start_ARG italic_d italic_T end_ARG, we take derivatives of Eqs. (45) and (46), yielding Iterating the above equations, we arrive at the derivative d\u2062\u2131d\u2062T=d\u2062F(N+1)d\u2062T\ud835\udc51\u2131\ud835\udc51\ud835\udc47\ud835\udc51superscript\ud835\udc39\ud835\udc411\ud835\udc51\ud835\udc47\\frac{d\\mathcal{F}}{dT}=\\frac{dF^{(N+1)}}{dT}divide start_ARG italic_d caligraphic_F end_ARG start_ARG italic_d italic_T end_ARG = divide start_ARG italic_d italic_F start_POSTSUPERSCRIPT ( italic_N + 1 ) end_POSTSUPERSCRIPT end_ARG start_ARG italic_d italic_T end_ARG, which completes our calculation of the average energy [Eq.\u00a0(42)]. The heat capacity is given by Taking derivatives of Eqs. (45) and (46), we have Finally, after computing d2\u2062\u2131d\u2062T2=d2\u2062F(N+1)d\u2062T2superscript\ud835\udc512\u2131\ud835\udc51superscript\ud835\udc472superscript\ud835\udc512superscript\ud835\udc39\ud835\udc411\ud835\udc51superscript\ud835\udc472\\frac{d^{2}\\mathcal{F}}{dT^{2}}=\\frac{d^{2}F^{(N+1)}}{dT^{2}}divide start_ARG italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT caligraphic_F end_ARG start_ARG italic_d italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG = divide start_ARG italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_F start_POSTSUPERSCRIPT ( italic_N + 1 ) end_POSTSUPERSCRIPT end_ARG start_ARG italic_d italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG iteratively, we have arrived at the heat capacity C\ud835\udc36Citalic_C."
    },
    {
        "id": 10,
        "title": "Markovian embedding of nonlocal equations using spectral representation",
        "corpus": "Nonlocal evolutionary equations containing memory terms model a variety of non-Markovian processes. We present a Markovian embedding procedure for a class of nonlocal equations by utilising the spectral representation of the nonlinear memory kernel. This allows us to transform the nonlocal system to a local-in-time system in an abstract extended space. We demonstrate our embedding procedure and its efficacy for two different physical models, namely the (i)\ud835\udc56(i)( italic_i ) 1111D walking droplet and the (i\u2062i)\ud835\udc56\ud835\udc56(ii)( italic_i italic_i ) 1111D single-phase Stefan problem. [inst1]organization=International Centre for Theoretical Sciences, Tata Institute of Fundamental Research,\ncity=Bengaluru,\npostcode=560089,\ncountry=India\n\\affiliation[inst2]organization=School of Computer and Mathematical Sciences, University of Adelaide,\npostcode=5005,\ncountry=Australia Several evolutionary processes with memory effects are modelled by nonlocal equations. Examples include particle motion in unsteady hydrodynamic environments\u00a0(Lovalenti and Brady, 1993; Oza et\u00a0al., 2013; Peng and Schnitzer, 2023), and boundary evolution in diffusion processes in time-dependent domains\u00a0(Stefan, 1891; Fokas and Pelloni, 2012) and under nonlinear boundary forcing\u00a0(Mann and Wolf, 1951; Keller and Olmstead, 1972; Olmstead and Handelsman, 1976). In this manuscript, we are concerned with nonlocal models where the evolution equation for a state variable y\u2062(t)\ud835\udc66\ud835\udc61y(t)italic_y ( italic_t ) has the following canonical structure: where the superscript n\ud835\udc5bnitalic_n indicates the order of time derivative. The function L\u2062(\u22c5)\ud835\udc3f\u22c5L(\\cdot)italic_L ( \u22c5 ) is a local-in-time term driving the evolution, whereas the function N\u2062(\u22c5)\ud835\udc41\u22c5N(\\cdot)italic_N ( \u22c5 ) is a memory kernel of the nonlocal integral, which is also a nonlinear function of y\u2062(t)\ud835\udc66\ud835\udc61y(t)italic_y ( italic_t ). Without the nonlocal term, Eq.\u00a0(1) can be readily transformed into a system of first order ordinary differential equations (ODEs) yielding a Markovian description. However, with the nonlocal term, such a transformation is not trivial. Different Markovian embeddings in an abstract extended space are commonly realised by introducing an auxiliary variable that accounts for the memory (Dafermos, 1970). In this study, we show that a Markovian prescription can be realised for nonlocal equations of the form in Eq.\u00a0(1) by an embedding procedure that relies on the spectral representation of the nonlinear memory kernel (previously discussed for linear memory kernel in (Jaganathan et\u00a0al., 2023)). Our approach involves expressing the nonlocal integral term in Eq.\u00a0(1) as a local-in-time term. We assume that the nonlinear memory kernel has a spectral representation of the following form: where \u0393\u0393\\Gammaroman_\u0393 is a smooth contour in the complex-plane and \u03d5,\u03c8italic-\u03d5\ud835\udf13\\phi,\\psiitalic_\u03d5 , italic_\u03c8 are complex-analytic functions of the variable k\ud835\udc58kitalic_k. The spectral representation allows embedding of Eq.\u00a0(1) into an extended space. This is done by substituting the spectral representation in the memory term, followed by an interchange of order of integrals, to give: where H\u2062(k,t)\ud835\udc3b\ud835\udc58\ud835\udc61H(k,t)italic_H ( italic_k , italic_t ) is the newly-introduced complex-valued auxiliary variable. Since it encapsulates \u201cmemory\u201d, we refer to it as the history function. Owing to the particular spectral form, we can infer that the history function has a Markovian evolution given by an ODE, parameterised by the spectral variable k\ud835\udc58kitalic_k. Therefore, we have the following local-in-time reformulation of Eq.\u00a0(1) in an infinite-dimensional space: where overdot denotes time derivative. We demonstrate our embedding procedure for two physical models with nonlinear memory effects, namely the one-dimensional walking droplet and the single-phase one-dimensional Stefan problem. Both models illustrate that a Markovian embedding into an infinite-dimensional space can be constructed subject to a natural spectral representation of the nonlinear memory kernel (Eq.\u00a0(2)). These models differ in the complexity of the auxiliary history variable introduced upon embedding, highlighting the versatility of the approach. A hydrodynamic active system described by non-Markovian dynamics is that of walking (Couder et\u00a0al., 2005) and superwalking\u00a0(Valani et\u00a0al., 2019) droplets. By vertically vibrating an oil bath, a drop of the same oil can be made to bounce and walk on the liquid surface. Each bounce of the droplet locally excites a damped standing wave. The droplet interacts obliquely with these self-excited waves on subsequent bounces to propel itself horizontally, giving rise to a self-propelled, classical wave-particle entity (WPE). At large vibration amplitudes, the droplet-generated waves decay slowly in time. Hence, the motion of the droplet is affected by the history of waves along its trajectory. This gives rise to path memory in the system and makes the dynamics non-Markovian. Oza et al.\u00a0(Oza et\u00a0al., 2013) developed a theoretical stroboscopic model to describe the horizontal walking motion of such a WPE. The model averages over the fast vertical periodic bouncing of the droplet and provides a trajectory equation for the slow walking dynamics in the horizontal plane. We consider a reduction of this model to one horizontal dimension, x\u2208\u211d\ud835\udc65\u211dx\\in\\mathbb{R}italic_x \u2208 blackboard_R (see Fig.\u00a01a). Consider a droplet with position and velocity given by (xd\u2062(t),x\u02d9d\u2062(t))\u2208\u211d2subscript\ud835\udc65\ud835\udc51\ud835\udc61subscript\u02d9\ud835\udc65\ud835\udc51\ud835\udc61superscript\u211d2(x_{d}(t),\\dot{x}_{d}(t))\\in\\mathbb{R}^{2}( italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_t ) , over\u02d9 start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_t ) ) \u2208 blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, which continuously generates standing waves with prescribed spatial structure W\u2062(x)\ud835\udc4a\ud835\udc65W(x)italic_W ( italic_x ) that decay with time. The dynamics of a 1111D WPE follows the non-dimensional integro-differential equation: where C1subscript\ud835\udc361C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and C2subscript\ud835\udc362C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are non-negative constants representing dimensionless wave-amplitude and inverse memory parameter, respectively111Note that C1subscript\ud835\udc361C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and C2subscript\ud835\udc362C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are related to the dimensionless parameters \u03ba\ud835\udf05\\kappaitalic_\u03ba and \u03b2\ud835\udefd\\betaitalic_\u03b2 in Oza et al.\u00a0(Oza et\u00a0al., 2013) by C1=\u03b2\u2062\u03ba2subscript\ud835\udc361\ud835\udefdsuperscript\ud835\udf052C_{1}=\\beta\\kappa^{2}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_\u03b2 italic_\u03ba start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT and C2=\u03basubscript\ud835\udc362\ud835\udf05C_{2}=\\kappaitalic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_\u03ba.. We refer the reader to Ref.\u00a0(Oza et\u00a0al., 2013) for details and explicit expressions for these parameters. Eq.\u00a0(4) is a horizontal force balance of the WPE with the right-hand side containing an effective drag term proportional to velocity \u2212x\u02d9d\u2062(t)subscript\u02d9\ud835\udc65\ud835\udc51\ud835\udc61-\\dot{x}_{d}(t)- over\u02d9 start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_t ) and the nonlocal memory term capturing the cumulative force on the particle from the superposition of the self-generated waves along its path. The memory kernel comprises the functions W\u2032\u2062(\u22c5)superscript\ud835\udc4a\u2032\u22c5W^{\\prime}(\\cdot)italic_W start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( \u22c5 ) and K\u2062(\u22c5)\ud835\udc3e\u22c5K(\\cdot)italic_K ( \u22c5 ); the former represents the wave-gradient where the prime denotes derivative with respect to its argument, and K\u2062(\u22c5)\ud835\udc3e\u22c5K(\\cdot)italic_K ( \u22c5 ) imposes the temporal decay. In the stroboscopic model of a walking droplet, \u2212W\u2032\u2062(x)=J1\u2062(x)superscript\ud835\udc4a\u2032\ud835\udc65subscript\ud835\udc3d1\ud835\udc65-W^{\\prime}(x)=J_{1}(x)- italic_W start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_x ) = italic_J start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_x ), where J1subscript\ud835\udc3d1J_{1}italic_J start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is the Bessel-J\ud835\udc3dJitalic_J function of order one and K\u2062(t)=e\u2212C2\u2062t\ud835\udc3e\ud835\udc61superscript\ud835\udc52subscript\ud835\udc362\ud835\udc61K(t)=e^{-C_{2}t}italic_K ( italic_t ) = italic_e start_POSTSUPERSCRIPT - italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_t end_POSTSUPERSCRIPT. In the high-memory regime (C2\u226a1much-less-thansubscript\ud835\udc3621C_{2}\\ll 1italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u226a 1), WPEs exhibit hydrodynamic quantum analogs\u00a0(Bush and Oza, 2020). However, the regime may become experimentally difficult to access\u00a0(Bacot et\u00a0al., 2019) due to the increased susceptibility of the system to the Faraday instability\u00a0(Faraday, 1831). Numerical simulations provide an alternative with controllability but also entail dealing with the non-Markovian structure of Eq.\u00a0(4) and time-dependent computational costs therein. We convert Eq.(4) to a Markovian description in the following way. We recall the following integral representation of the Bessel-J1subscript\ud835\udc3d1J_{1}italic_J start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT function for some z\u2208\u211d\ud835\udc67\u211dz\\in\\mathbb{R}italic_z \u2208 blackboard_R: Substituting the above in the memory term of Eq.\u00a0(4), followed by a switch in the order of integrals, we construct the equivalent local-in-time representation for the memory integral, where the weight function w\u2062(k)=1/1\u2212k2\ud835\udc64\ud835\udc5811superscript\ud835\udc582w(k)=1/\\sqrt{1-k^{2}}italic_w ( italic_k ) = 1 / square-root start_ARG 1 - italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG and H\u2062(k,t)\ud835\udc3b\ud835\udc58\ud835\udc61H(k,t)italic_H ( italic_k , italic_t ) is a complex-valued function of time t\ud835\udc61titalic_t and a real number k\ud835\udc58kitalic_k with a finite support in [\u22121,1]11[-1,1][ - 1 , 1 ]. The induced definition of H\u2062(k,t)\ud835\udc3b\ud835\udc58\ud835\udc61H(k,t)italic_H ( italic_k , italic_t ) is The form of H\u2062(\u22c5)\ud835\udc3b\u22c5H(\\cdot)italic_H ( \u22c5 ) in (5) suggests that it has a Markovian evolution according to an ODE parameterised by the spectral variable k\ud835\udc58kitalic_k. Consequently, combined with the definition of the droplet\u2019s velocity x\u02d9d=vdsubscript\u02d9\ud835\udc65\ud835\udc51subscript\ud835\udc63\ud835\udc51\\dot{x}_{d}=v_{d}over\u02d9 start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = italic_v start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, we derive the following Markovian prescription for the WPE dynamics in the extended state space for t>0\ud835\udc610t>0italic_t > 0: subject to initial conditions (xd\u20620,vd\u20620)subscript\ud835\udc65\ud835\udc510subscript\ud835\udc63\ud835\udc510(x_{d0},v_{d0})( italic_x start_POSTSUBSCRIPT italic_d 0 end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_d 0 end_POSTSUBSCRIPT ) and H\u2062(k,0)=0\ud835\udc3b\ud835\udc5800H(k,0)=0italic_H ( italic_k , 0 ) = 0. We note in Eq.\u00a0(5) that H\u2062(\u22c5)\ud835\udc3b\u22c5H(\\cdot)italic_H ( \u22c5 ) preserves certain symmetries with respect to the spectral variable k\ud835\udc58kitalic_k at all times: Re\u2062(H)Re\ud835\udc3b\\text{Re}(H)Re ( italic_H ) has an even-symmetry whereas Im\u2062(H)Im\ud835\udc3b\\text{Im}(H)Im ( italic_H ) is odd-symmetric. Therefore, whereas the real and imaginary parts of the history function drive each other\u2019s dynamics, only the real part contributes to the memory integral in Eq.\u00a0(6a). The resultant set of local differential equations\u00a0(2.1.1) can be readily solved using any standard time-integrator; we use the second-order Runge-Kutta scheme. An additional task involves computing the history integral over k\ud835\udc58kitalic_k. The integrand, with its finite support in [\u22121,1]11[-1,1][ - 1 , 1 ] and the form of weight function w\ud835\udc64witalic_w, naturally suggests expansion of H\u2062(k,t)\ud835\udc3b\ud835\udc58\ud835\udc61H(k,t)italic_H ( italic_k , italic_t ) in the bases of Chebyshev polynomials of the first kind. Therefore, we use the spectrally-accurate Clenshaw-Curtis quadrature method to approximate the integral: where kn=cos\u2061(n\u2062\u03c0/M)subscript\ud835\udc58\ud835\udc5b\ud835\udc5b\ud835\udf0b\ud835\udc40k_{n}=\\cos(n\\pi/M)italic_k start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = roman_cos ( italic_n italic_\u03c0 / italic_M ) are the Chebyshev nodes and \u03c9nsubscript\ud835\udf14\ud835\udc5b\\omega_{n}italic_\u03c9 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT are the associated weights. We numerically solve Eq.\u00a0(2.1.1) for a few representative parameter sets (C1,C2)subscript\ud835\udc361subscript\ud835\udc362(C_{1},C_{2})( italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ). Fig.\u00a01 shows that the embedded system of equations\u00a0(2.1.1) successfully reproduces the previously known non-walking and walking regimes in the parameter space\u00a0(Durey et\u00a0al., 2020; Valani et\u00a0al., 2021). For a steady walker, an analytical expression for its steady speed\u00a0(Oza et\u00a0al., 2013) is : The numerical solution for the steady walker attains the above analytical steady walking speed (dashed line) in Fig.\u00a01c. Additionally, in Fig.\u00a02, we show the evolution of the history function in the k\u2212limit-from\ud835\udc58k-italic_k -domain over time. There have been previous works\u00a0(Mol\u00e1\u010dek, 2013; Durey et\u00a0al., 2020; Durey, 2020; Valani, 2022) that rewrite the integro-differential equation for the walker into a system of ODEs. However, these transformations work for only specific choices of the wave form W\u2062(x)\ud835\udc4a\ud835\udc65W(x)italic_W ( italic_x ). The Markovian embedding formalism is applicable for a broader class of wave forms that have a suitable spectral representation. This is particularly useful in generalised pilot-wave framework, where new hydrodynamic quantum analogues are being explored by investigating various wave forms\u00a0(Bush and Oza, 2020). \u200b\n\n\u200b \u200b\n\n\u200b\n\n\u200b We now consider the class of free boundary problems called the Stefan problem, which primarily describes phase-change processes such as the melting of a solid (Stefan, 1891; Guenther and Lee, 2012). In its simplest non-dimensional formulation, it comprises a one-dimensional domain in \u211d+superscript\u211d\\mathbb{R}^{+}blackboard_R start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, contiguously supporting a molten phase and a solid phase, separated at their interface, which is free to move as the solid melts (see Fig.\u00a03a). The solid phase is modelled as an infinite heat sink maintained at the melting temperature at all times. Therefore, the simplified problem involves finding the solution pair (\u03b8\u2062(x,t),l\u2062(t))\ud835\udf03\ud835\udc65\ud835\udc61\ud835\udc59\ud835\udc61(\\theta(x,t),l(t))( italic_\u03b8 ( italic_x , italic_t ) , italic_l ( italic_t ) ), where \u03b8\u2062(x,t)\ud835\udf03\ud835\udc65\ud835\udc61\\theta(x,t)italic_\u03b8 ( italic_x , italic_t ) describes the instantaneous temperature distribution in the molten phase and l\u2062(t)\ud835\udc59\ud835\udc61l(t)italic_l ( italic_t ) is the location of the melting front. The function \u03b8\ud835\udf03\\thetaitalic_\u03b8 satisfies the diffusion equation \u2202t\u03b8\u2212\u2202x2\u03b8=0subscript\ud835\udc61\ud835\udf03superscriptsubscript\ud835\udc652\ud835\udf030\\partial_{t}\\theta-\\partial_{x}^{2}\\theta=0\u2202 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_\u03b8 - \u2202 start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_\u03b8 = 0 in x\u2208[0,l\u2062(t)]\ud835\udc650\ud835\udc59\ud835\udc61x\\in[0,l(t)]italic_x \u2208 [ 0 , italic_l ( italic_t ) ], subject to an arbitrary initial condition \u03b80\u2062(x)subscript\ud835\udf030\ud835\udc65\\theta_{0}(x)italic_\u03b8 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_x ) in the initial domain x\u2208[0,l0]\ud835\udc650subscript\ud835\udc590x\\in[0,l_{0}]italic_x \u2208 [ 0 , italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ] at t=t0\ud835\udc61subscript\ud835\udc610t=t_{0}italic_t = italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and a temperature or heat flux condition at the fixed boundary x=0\ud835\udc650x=0italic_x = 0. The moving front, which is at the melting temperature, is governed by the Stefan condition l\u02d9=\u2212\u2202x\u03b8\u2062(l\u2062(t),t)\u02d9\ud835\udc59subscript\ud835\udc65\ud835\udf03\ud835\udc59\ud835\udc61\ud835\udc61\\dot{l}=-\\partial_{x}\\theta(l(t),t)over\u02d9 start_ARG italic_l end_ARG = - \u2202 start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_\u03b8 ( italic_l ( italic_t ) , italic_t ). We consider the case where temperature is prescribed at the fixed boundary, \u03b8\u2062(0,t)=f\u2062(t)\ud835\udf030\ud835\udc61\ud835\udc53\ud835\udc61\\theta(0,t)=f(t)italic_\u03b8 ( 0 , italic_t ) = italic_f ( italic_t ) for exposition. With primary interest in the interface\u2019s location, the bulk heat diffusion process in the molten phase may be effectively \u201cintegrated out\u201d to derive a non-Markovian equation of motion for the moving front. The resulting velocity equation for the moving front, v\u2062(t)=l\u02d9\u2062(t)\ud835\udc63\ud835\udc61\u02d9\ud835\udc59\ud835\udc61v(t)=\\dot{l}(t)italic_v ( italic_t ) = over\u02d9 start_ARG italic_l end_ARG ( italic_t ), is compactly written in the following nonlinear Volterra integral form for t>t0\ud835\udc61subscript\ud835\udc610t>t_{0}italic_t > italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT (Fokas and Pelloni, 2012; Guenther and Lee, 2012): where \u03b80\u2032,f\u02d9superscriptsubscript\ud835\udf030\u2032\u02d9\ud835\udc53\\theta_{0}^{\\prime},\\dot{f}italic_\u03b8 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , over\u02d9 start_ARG italic_f end_ARG denote the spatial derivative and temporal derivative of \u03b80,fsubscript\ud835\udf030\ud835\udc53\\theta_{0},fitalic_\u03b8 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_f respectively, and the function g\ud835\udc54gitalic_g is: The nonlinear kernel may be decomposed into contributions from forcing at the fixed boundary and the unknown velocity of the solid-liquid interface as follows: with the definitions Note that the function g\ud835\udc54gitalic_g is a local-in-time term. The second term on the right-hand side in Eq.\u00a0(8) is the memory term, which introduces non-locality and the nonlinear dependence on the moving front l\u2062(t)\ud835\udc59\ud835\udc61l(t)italic_l ( italic_t ). As before, we construct an embedding such that the present non-Markovian representation for v\u2062(t)\ud835\udc63\ud835\udc61v(t)italic_v ( italic_t ) may be turned Markovian. We claim the following spectral representation of the nonlinear kernel for a real k\ud835\udc58kitalic_k: Substituting the above spectral representations in the memory term, followed by a switch in the order of integrals, we derive the local representation with the introduction of the auxiliary history function H\u2062(k,t)\ud835\udc3b\ud835\udc58\ud835\udc61H(k,t)italic_H ( italic_k , italic_t ): The corresponding induced definition of the complex-valued history function is: Differentiating the above with respect to time, one may derive an ODE for the history function and realise the following equivalent Markovian prescription for the moving front for t>t0\ud835\udc61subscript\ud835\udc610t>t_{0}italic_t > italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT: subject to l\u2062(t0)=l0,v\u2062(t0)=g\u2062(0,l0;\u03b80\u2032,l0),H\u2062(k,t0)=0formulae-sequence\ud835\udc59subscript\ud835\udc610subscript\ud835\udc590formulae-sequence\ud835\udc63subscript\ud835\udc610\ud835\udc540subscript\ud835\udc590superscriptsubscript\ud835\udf030\u2032subscript\ud835\udc590\ud835\udc3b\ud835\udc58subscript\ud835\udc6100l(t_{0})=l_{0},v(t_{0})=g(0,l_{0};\\theta_{0}^{\\prime},l_{0}),\\;H(k,t_{0})=0italic_l ( italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_v ( italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = italic_g ( 0 , italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ; italic_\u03b8 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) , italic_H ( italic_k , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = 0. The history function in this case too preserves similar symmetries, suggesting that only its even-symmetric real part contributes to the history integral. We show equivalence of the derived embedded Markovian system to the original non-Markovian system (Eq.\u00a0(8)) by numerically solving Eq.\u00a0(2.2.1). We use the second-order Runge-Kutta exponential time-differencing method (Cox and Matthews, 2002) to solve for H\u2062(k,t)\ud835\udc3b\ud835\udc58\ud835\udc61H(k,t)italic_H ( italic_k , italic_t ) due to stiffness introduced by the \u2212k2\u2062Hsuperscript\ud835\udc582\ud835\udc3b-k^{2}H- italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_H term, and a standard integrator to solve for l\u2062(t)\ud835\udc59\ud835\udc61l(t)italic_l ( italic_t ). The latter requires evaluating the history integral whose quadrature approximation, however, demands different treatment from the walker problem on two accounts: H\u2062(k,t)\ud835\udc3b\ud835\udc58\ud835\udc61H(k,t)italic_H ( italic_k , italic_t ) has infinite support in the k\u2212limit-from\ud835\udc58k-italic_k -space. While this warrants truncation of the k\u2212limit-from\ud835\udc58k-italic_k -space, its decay behaviour at large k\ud835\udc58kitalic_k constraints the extent of truncation. H\u2062(k,t)\ud835\udc3b\ud835\udc58\ud835\udc61H(k,t)italic_H ( italic_k , italic_t ) is highly oscillatory; the frequency of oscillations increases with both k\ud835\udc58kitalic_k and t\ud835\udc61titalic_t, which is ascribed to terms such as ei\u2062k\u2062l\u2062(t)superscript\ud835\udc52\ud835\udc56\ud835\udc58\ud835\udc59\ud835\udc61e^{ikl(t)}italic_e start_POSTSUPERSCRIPT italic_i italic_k italic_l ( italic_t ) end_POSTSUPERSCRIPT in Eq.\u00a0(13b). The dependence on t\ud835\udc61titalic_t through l\u2062(t)\ud835\udc59\ud835\udc61l(t)italic_l ( italic_t ) exacerbates the oscillations in domain growth problems such as the one under discussion. Consequently, for accurate quadrature approximation, an increasingly dense set of collocation points in the truncated domain is required. The above points are cautionary observations. While one could potentially address these concerns through computationally efficient methods, such an undertaking exceeds the scope of our present work. Therefore, we adopt a heuristic approach to compute the history integral. This involves truncating the k\u2212limit-from\ud835\udc58k-italic_k -space, mapping it to the interval [\u22121,1]11[-1,1][ - 1 , 1 ], and employing Clenshaw-Curtis quadrature to compute the history integral. We consider the example corresponding to melting due to constant temperature at the fixed end, f\u2062(t)=1\ud835\udc53\ud835\udc611f(t)=1italic_f ( italic_t ) = 1, with the following analytical solution pair (Mitchell and Vynnycky, 2009): where the constant \u03b1\ud835\udefc\\alphaitalic_\u03b1 satisfies the transcendental equation: \u03c0\u2062\u03b1\u2062exp\u2061(\u03b12)\u2062erf\u2062(\u03b1)=1\ud835\udf0b\ud835\udefcsuperscript\ud835\udefc2erf\ud835\udefc1\\sqrt{\\pi}\\alpha\\exp(\\alpha^{2})\\text{erf}(\\alpha)=1square-root start_ARG italic_\u03c0 end_ARG italic_\u03b1 roman_exp ( italic_\u03b1 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) erf ( italic_\u03b1 ) = 1. To avoid the degeneracy at t=0\ud835\udc610t=0italic_t = 0 due to zero-length domain, we let the process evolve for time t0>0subscript\ud835\udc6100t_{0}>0italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0 to a non-zero domain length l0subscript\ud835\udc590l_{0}italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Prescribing (\u03b8\u2062(x,t0),l0)\ud835\udf03\ud835\udc65subscript\ud835\udc610subscript\ud835\udc590(\\theta(x,t_{0}),l_{0})( italic_\u03b8 ( italic_x , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) , italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) as the initial state, we numerically evolve Eq.\u00a0(2.2.1) from t0subscript\ud835\udc610t_{0}italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Fig.\u00a03 shows agreement between the numerical and analytical solutions (Eq.\u00a0(14)) for location of the interface, supplemented with the pointwise error. In Fig.\u00a04, we plot the pertinent history function in the truncated spectral space at different time instances. The highly oscillatory behaviour of H\u2062(k,t)\ud835\udc3b\ud835\udc58\ud835\udc61H(k,t)italic_H ( italic_k , italic_t ) in the truncated k\u2212limit-from\ud835\udc58k-italic_k -domain is evident. We have described a Markovian embedding procedure for evolutionary equations with memory effects, which critically relied on the spectral representation of the memory kernel. We have explicitly shown the embedding procedure for two physical models, namely the one-dimensional walking droplet and the single-phase Stefan problem. In both cases, the memory kernel is a nonlinear function of the underlying state variable. Physical processes inherently follow Markovian dynamics when described adequately by all the driving state variables. The non-Markovian description of the evolution of an isolated state variable, such as in Eqs.\u00a0(4), (8), is often the result of \u201cintegrating out\u201d the effects of \u201cenvironment\u201d comprising other state variables. While identifying these integrated physical variables may not always be feasible, our Markovian embedding procedure provides an alternative mathematical reconstruction of the Markovian dynamics. From a computational standpoint, a Markovian representation ensures that the numerical evolution of the corresponding time-discretized system incurs a time-independent cost. This is in contrast with the standard approaches for memory-dependent systems, where the computational cost grows with time. It is important to recognise that our Markovian embedding procedure comes at the cost of solving an additional local-in-time equation for the history function, which is an infinite-dimensional object. An accurate finite-dimensional approximation of the function depends on the behaviour of H\u2062(k,t)\ud835\udc3b\ud835\udc58\ud835\udc61H(k,t)italic_H ( italic_k , italic_t ) in the spectral space. In this regard, the two model problems discussed here demonstrate the extreme scenarios: the Stefan problem required a higher-dimensional approximation of the history function, comprising thousands of spectral variables, while the walker problem allowed a lower-dimensional approximation, with only a few tens of spectral variables for an accurate representation of the history function. DJ acknowledges support of the Department of Atomic Energy, Government of India, under project no. RTI4001. RV was supported by Australian Research Council (ARC) Discovery Project DP200100834 during the course of the work. We thank Vishal Vasan for introducing the Stefan problem to us and for the various discussions pertaining to this work. We also thank Rama Govindarajan for her feedback on the draft."
    },
    {
        "id": 11,
        "title": "Metabolic scaling in small life forms",
        "corpus": "Metabolic scaling is one of the most important patterns in biology. Theory explaining the 3/4-power size-scaling of biological metabolic rate does not predict the non-linear scaling observed for smaller life forms. Here we present a new model for cells <10\u22128absentsuperscript108<10^{-8}< 10 start_POSTSUPERSCRIPT - 8 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT that maximizes power from the reaction-displacement dynamics of enzyme-catalyzed reactions. Maximum metabolic rate is achieved through an allocation of cell volume to optimize a ratio of reaction velocity to molecular movement. Small cells <10\u221217absentsuperscript1017<10^{-17}< 10 start_POSTSUPERSCRIPT - 17 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT generate power under diffusion by diluting enzyme concentration as cell volume increases. Larger cells require bulk flow of cytoplasm generated by molecular motors. These outcomes predict curves with literature-reported parameters that match the observed scaling of metabolic rates for unicells, and predicts the volume at which Prokaryotes transition to Eukaryotes. We thus reveal multiple size-dependent physical constraints for microbes in a model that extends prior work to provide a parsimonious hypothesis for how metabolism scales across small life. Understanding how and why organisms differ in their demand for and use of resources is a key objective of biologists [1, 2, 3] and critical to understanding the response of biodiversity and ecosystem function to global changes [4, 5]. A fundamental and often-debated pattern is how metabolic rate, B\ud835\udc35Bitalic_B, scales with body mass, M\ud835\udc40Mitalic_M [1, 6, 7], followng the form Data for vertebrates and vascular plants [8, 9, 10, 11, 12]show an average interspecific scaling exponent of 3/4. This relationship has inspired diverse theories [10, 11, 13, 14, 15], including the network model, which derives 3/4 from the need for organisms to supply the entire body volume with resources from vascular resource distribution networks that minimize energy dissipation. More recent analyses [16, 1, 17, 18, 19, 20] that include organisms from the smallest 11 orders of magnitude in size that largely lack vascular distribution networks, show a variable metabolic scaling exponent that changes across size ranges from scaling exponents as high as 2 \u2013 super-linear scaling \u2013 for the smallest range and near 3/4 for the largest organisms. Understanding the basis for this variation is important, as many different organism features can be derived from this metabolic scaling, including how maximum growth rates and ribosomal abundances scale with cell size along with key tradeoffs between features [21, 22]. However, there is no general, parsimonious theory derived from physical and chemical principles that addresses this size-dependent scaling for these smallest organisms [16]. Here we propose a combined thermodynamic and reaction description of metabolic rate for a cell. We assume that natural selection will favor organisms that can perform more work per time (power) for material synthesis, replication, repair, locomotion, and other cellular functions [23]. While often co-limited by materials in the environment, optimizing this power faces cellular trade-offs concerning both environmental and intra-cellular physical constraints. Consequently, we optimize cellular features to maximize the free energy produced by the conversion of chemical substrates to products, where heat and products may inhibit metabolism if not moved away from reaction sites. This thermodynamic approach provides a framework for considering the two processes, conversion and displacement, simultaneously. We assume that work is proportional to the volume of reactive surface, where macromolecular catalytic enzymes are freely dispersed in the cytoplasm or attached to the membranes, cytoskeleton, and/or other organelles within the entity [24]. However, a portion of cell volume is needed to allow substrates from the environment to reach reaction surfaces and to allow displacement of reaction products away from reaction structures. This sets up a conflict between the volume devoted to metabolic processes and that devoted to transport. Here we derive a physical and chemical principles-based theory for metabolic scaling for metabolic rate across the roughly 11 orders of magnitude in volume of organisms that lack branching vascular systems. We describe metabolism from a reaction-displacement thermodynamic system centered on or near reaction surfaces and its generation of free energy within a spherical space otherwise obstructed by surfaces at which reactions occur. Our framework applies to unicellular Prokaryotes, Archaea, and Eukaryotes along with eukaryotic organelles. Our basic model, which we expand on in stages, is to consider metabolism in a sphere described by the following reaction-diffusion model where the product, P\u2062(r)\ud835\udc43\ud835\udc5fP\\left(r\\right)italic_P ( italic_r ), substrate, A\u2062(r)\ud835\udc34\ud835\udc5fA\\left(r\\right)italic_A ( italic_r ), and enzyme, Z\u2062(r)\ud835\udc4d\ud835\udc5fZ\\left(r\\right)italic_Z ( italic_r ), concentrations (mol m\u221233{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT) are all a function of radius, r\ud835\udc5fritalic_r, inside a sphere, and where the dynamics are one dimensional in spherical coordinates with spherical symmetry. Additionally, k=kc\u2062a\u2062t/KM\ud835\udc58subscript\ud835\udc58\ud835\udc50\ud835\udc4e\ud835\udc61subscript\ud835\udc3e\ud835\udc40k=k_{cat}/K_{M}italic_k = italic_k start_POSTSUBSCRIPT italic_c italic_a italic_t end_POSTSUBSCRIPT / italic_K start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT is the reaction constant ((m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT mol \u221211{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT s\u221211{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT)) and D\ud835\udc37Ditalic_D is a displacement coefficient (e.g. molecular diffusivity in some cases) and has units of (m22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT s\u221211{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT) so that each rate is a change in concentration (mol m\u221233{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT s\u221211{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT). We consider the steady-state dynamics, representing a persistent entity and its metabolism in a fixed environment over time, allowing us to solve for closed-form solutions of P\u2062(r)\ud835\udc43\ud835\udc5fP(r)italic_P ( italic_r ) and A\u2062(r)\ud835\udc34\ud835\udc5fA(r)italic_A ( italic_r ) under a given concentration of Z\ud835\udc4dZitalic_Z (see SI). The steady-state free energy production at any location in the cell is given by where Ke\u2062qsubscript\ud835\udc3e\ud835\udc52\ud835\udc5eK_{eq}italic_K start_POSTSUBSCRIPT italic_e italic_q end_POSTSUBSCRIPT is the equilibrium constant of the energy producing reaction (which can be interrelated with \u0394\u2062G0\u0394subscript\ud835\udc3a0\\Delta G_{0}roman_\u0394 italic_G start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT), T\ud835\udc47Titalic_T is temperature, and R\ud835\udc45Ritalic_R is the ideal gas constant. The entire metabolism (given as a power in watts) of the entire cell is then described by where rcsubscript\ud835\udc5f\ud835\udc50r_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT is the radius of the cell and Vesubscript\ud835\udc49\ud835\udc52V_{e}italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT is the essential volume required for other for other cellular materials, such as DNA, and is unavailable for energy generation. In this system, we can maximize power (free energy/time), B\ud835\udc35Bitalic_B (Watts), as a function of Z\ud835\udc4dZitalic_Z. If there were no tradeoffs, then B\ud835\udc35Bitalic_B would be maximized by the largest feasible Z\ud835\udc4dZitalic_Z at a given size (a cell full of enzymes). However, the need to move substrate into different regions of the cell and to displace products away from reaction sites introduces a trade-off between the effective diffusion coefficient, D\ud835\udc37Ditalic_D, and enzyme concentration, Z\ud835\udc4dZitalic_Z. An increase in Z\ud835\udc4dZitalic_Z corresponds to a decrease in diffusivity [25, 26], and this leads to an optimal enzyme concentration corresponding to a maximal metabolic rate (see SI). Maximizing power over the whole cell, at a given cell size rcsubscript\ud835\udc5f\ud835\udc50r_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT subject to variation in the concentration of enzymes, Z\ud835\udc4dZitalic_Z, we find that the optimal enzyme concentration Z*superscript\ud835\udc4dZ^{*}italic_Z start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT follows where \u03b3\ud835\udefe\\gammaitalic_\u03b3 is the scaling between diffusivity and enzyme concentration at high enzyme concentrations, and D0subscript\ud835\udc370D_{0}italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is the normalization constant for that scaling relationship (see SI). Remarkably, this relationship shows that the optimal enzyme concentration in cells can be predicted from a few fundamental thermodynamic, Ke\u2062qsubscript\ud835\udc3e\ud835\udc52\ud835\udc5eK_{eq}italic_K start_POSTSUBSCRIPT italic_e italic_q end_POSTSUBSCRIPT, and kinetic, k\ud835\udc58kitalic_k, constants (Figure 1). Note that Z*superscript\ud835\udc4dZ^{*}italic_Z start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT depends on a ratio of reaction rate, k\ud835\udc58kitalic_k, to a diffusivity normalization for small molecules in the cytoplasm, D0subscript\ud835\udc370D_{0}italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Using the known relationship for diffusivity with enzyme concentration, where \u03b3\u2248\u22123/2\ud835\udefe32\\gamma\\approx-3/2italic_\u03b3 \u2248 - 3 / 2 for sufficiently high concentrations [26], we obtain Previous studies have shown that total protein count scales with cell size following a power law with an exponent <1absent1<1< 1 [22], but these relationships have no fundamental explanation. Our optimization predicts that protein concentration should become more dilute as cells become larger following an exponent of \u22124/15\u2248\u22120.274150.27-4/15\\approx-0.27- 4 / 15 \u2248 - 0.27, which is indistinguishable from the best fit exponent to data of \u22120.30\u00b10.06plus-or-minus0.300.06-0.30\\pm 0.06- 0.30 \u00b1 0.06 (Figure 1). The prediction for Z\ud835\udc4dZitalic_Z was determined by optimizing metabolic rate and so we also predict the relationship for maximum metabolic rate: Here B0subscript\ud835\udc350B_{0}italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is a constant that is a complicated function of diffusivity, kinetic and thermodynamic parameters (see SI), and Vesubscript\ud835\udc49\ud835\udc52V_{e}italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT is the volume of other essential macromolecules which follows Ve=v0\u2062Vc\u03b1subscript\ud835\udc49\ud835\udc52subscript\ud835\udc630superscriptsubscript\ud835\udc49\ud835\udc50\ud835\udefcV_{e}=v_{0}V_{c}^{\\alpha}italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = italic_v start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT with \u03b1=0.83\ud835\udefc0.83\\alpha=0.83italic_\u03b1 = 0.83 [22]. Equation 7 provides excellent agreement with observed metabolic rates for prokaryotes (Fig. 2). Metabolic rate has strong, non-power law curvature for small cell sizes driven by the volume V\u2062e\ud835\udc49\ud835\udc52V{e}italic_V italic_e required for macromolecules not involved in reactions, such as DNA, and this is what leads to the apparent super-linear (\u03b2>1\ud835\udefd1\\beta>1italic_\u03b2 > 1) scaling previously observed for prokaryotes [16]. This curvature quickly relaxes for larger cells due to the sublinear (\u03b2<1\ud835\udefd1\\beta<1italic_\u03b2 < 1) scaling of Vesubscript\ud835\udc49\ud835\udc52V_{e}italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT. For cell sizes up to about the volume of E. coli (\u224810\u221218absentsuperscript1018\\approx 10^{-18}\u2248 10 start_POSTSUPERSCRIPT - 18 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT) the power law approximation is superlinear (SI Figure 4) with an approximate exponent of 1.681.681.681.68 which agrees well with the previous estimates of 1.751.751.751.75 [16]. For larger bacteria, the scaling of B\ud835\udc35Bitalic_B converges on the sublinear scaling of 11/15=0.7311150.7311/15=0.7311 / 15 = 0.73. For intermediate prokaryote cell sizes, binning the data to remove oversampling of certain cell volumes and scatter, shows exceptionally good agreement between our model and the data (SI Figure 5). These results are not in conflict with the overall superlinear fit to all of the prokaryotic data [16], but show that this is a consequence of a complicated set of scale transitions and shifting constraints. Thus, downstream models that derive results from the scaling exponent of metabolic rate (e.g. [21, 22]) will gain accuracy and predictive power by starting from our more complex model. For example, models of growth which assume a power law for metabolism [21] should incorporate the curvature described in Equation 7. The trade-off between decreasing enzyme concentration and increased diffusivity applies only for high concentrations of the enzyme. Eventually, for large enough cells, sufficiently low enzyme concentrations are reached such that D=Dm\u2062a\u2062x\ud835\udc37subscript\ud835\udc37\ud835\udc5a\ud835\udc4e\ud835\udc65D=D_{max}italic_D = italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT, the maximum diffusivity of small molecules in water (see SI). Once diffusivity saturates, the optimal concentration follows Z\u221dVc\u22122/3proportional-to\ud835\udc4dsuperscriptsubscript\ud835\udc49\ud835\udc5023Z\\propto V_{c}^{-2/3}italic_Z \u221d italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 2 / 3 end_POSTSUPERSCRIPT (see SI) yielding B\u221dVc1/3proportional-to\ud835\udc35superscriptsubscript\ud835\udc49\ud835\udc5013B\\propto V_{c}^{1/3}italic_B \u221d italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 / 3 end_POSTSUPERSCRIPT (Fig. 2, dashed red curve) and a metabolic rate controlled by diffusion across the cell membrane. Such scaling also avoids thermodynamic shutdown (power = 0) that can occur in the center of larger cells. Shutdown can occur when Dm\u2062a\u2062xsubscript\ud835\udc37\ud835\udc5a\ud835\udc4e\ud835\udc65D_{max}italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT is not fast enough to sufficiently displace reaction products and avoid reaction reversal. These changes may result in body designs, such as large central vacuoles, filamented rods, membrane bound organelles, and extreme polyploidy [28, 29, 22, 30] that minimize the potential for interior thermodynamic shutdown, but yield a relatively slow metabolic rate for prokaryotes larger than 10\u221217superscript101710^{-17}10 start_POSTSUPERSCRIPT - 17 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT [22]. With further increases in cell volume, metabolic rate can only be increased by increasing the rate of molecular displacement, as Z\ud835\udc4dZitalic_Z is well below the concentration that influences diffusivity. A variety of means for increasing transport in cells exist (e.g. [31, 32, 33, 34, 35, 36, 37, 38, 39, 40]) with most attributable to the addition of structures, such as molecular motors or transport proteins, that each generate active transport of molecules or viscous bulk flow of cytoplasm over at least some local region within the cell. We model this as an enhanced effective diffusivity of Dt\u2062r\u2062a\u2062n\u2062ssubscript\ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc60D_{trans}italic_D start_POSTSUBSCRIPT italic_t italic_r italic_a italic_n italic_s end_POSTSUBSCRIPT. For example, the movement of molecules along a cytoskeletal network and randomly arranged regions of bulk flow with a random flow direction can each be thought of as random walks with long single steps, and so displacement in the simplest summary model for all of these processes can be described as an enhanced diffusion (e.g. [31, 41, 42, 35, 36, 34, 39, 40]). A new trade-off is introduced between the space occupied by dedicated transport structures versus the space devoted to catalyzing reactions (enzymes and supporting structures). This effective diffusivity and volume tradeoffs are captured by and where Dt\u2062r\u2062a\u2062n\u2062ssubscript\ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc60D_{trans}italic_D start_POSTSUBSCRIPT italic_t italic_r italic_a italic_n italic_s end_POSTSUBSCRIPT is the enhanced diffusivity in the region affected by the active transport or bulk flow, \u03c1\ud835\udf0c\\rhoitalic_\u03c1 is the fraction of the average cellular volume that is associated with active transport or bulk flow, and \u03f5italic-\u03f5\\epsilonitalic_\u03f5 is the ratio of the effective volume of active transport to the volume of the structures generating that transport (e.g. the ratio of the volume of a region of enhanced transport to a molecular motor or transport protein\u2019s volume). We optimize total metabolic rate (see SI) at a given cell volume as a function of \u03c1\ud835\udf0c\\rhoitalic_\u03c1 and find that \u03c1\ud835\udf0c\\rhoitalic_\u03c1 grows with cell size following a complicated function (see SI) that scales like \u2248Vc0.10absentsuperscriptsubscript\ud835\udc49\ud835\udc500.10\\approx V_{c}^{0.10}\u2248 italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0.10 end_POSTSUPERSCRIPT for small cell sizes and \u2248Vc2/3absentsuperscriptsubscript\ud835\udc49\ud835\udc5023\\approx V_{c}^{2/3}\u2248 italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 / 3 end_POSTSUPERSCRIPT in the limit of large cell sizes. This density scaling implies that the volume dedicated to transport structures scales super-linearly with overall cell size (\u2248Vc1.1absentsuperscriptsubscript\ud835\udc49\ud835\udc501.1\\approx V_{c}^{1.1}\u2248 italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1.1 end_POSTSUPERSCRIPT to \u2248Vc5/3absentsuperscriptsubscript\ud835\udc49\ud835\udc5053\\approx V_{c}^{5/3}\u2248 italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 5 / 3 end_POSTSUPERSCRIPT).Thus, for cell sizes larger than 10\u221217superscript101710^{-17}10 start_POSTSUPERSCRIPT - 17 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT, the effective diffusivity parameter can increase with cell volume but at the expense of an ever-increasing proportion of cell volume devoted to transport. This yields a size-dependent curve for maximum metabolic power in logarithmic space (blue curve in Fig. 3) that fits the available data for metabolic rate of Eukaryotes (again with average transport and reaction kinetic parameters). Over the middle size range of the single cell Eukaryotes, metabolic rate should approximate a power law with an exponent of 0.900.900.900.90 which agrees very well with the power law fit to data of 0.90\u00b10.17plus-or-minus0.900.170.90\\pm 0.170.90 \u00b1 0.17 [16, 21]. However, the super-linear scaling of the required volume of transport molecules means that motors and transport proteins begin to substantially reduce the volume for reaction structures. This transport volume requirement ultimately may limit metabolic rate, and impose a theoretical upper limit to Eukaryote size of 10\u22129superscript10910^{-9}10 start_POSTSUPERSCRIPT - 9 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT which compares well to the size of the largest unicellular organisms in the metabolic database (Fig. 2). These analyses produce a series of metabolic scaling curves (Fig. 2) across a succession of cell (or organism) volume ranges. Each curve is associated with a particular mode of reaction volume and molecular displacement mechanisms, with molecular diffusion at the smallest sizes then with an enhanced diffusion within devoted transport regions at the largest sizes (Fig. 3). Across the size spectrum, optimal metabolic rate is set by the tradeoff between volume for transport and volume for metabolic reactions. For prokaryotes, the smallest cells require space for other macromolecules such as DNA, which limit the space available for catalytic reaction enzymes. The largest unstructured prokaryotes face the slow scaling of metabolism set by the maximum diffusivity of small molecules in water. For unicellular eukaryotes, transport molecules provide the needed increase in molecular movement and metabolism scales almost linearly with cell volume. At the largest sizes, unicellular eukaryotes reach a sharp decrease dictated by the required overpacking of transport structures to assure the necessary effective diffusivity throughout the cell. Collectively, these curves merge to form an overall nonlinear relationship between metabolic rate and size that fit observed data very strongly (Fig. 2) and predict the scaling of protein and other material concentrations and the size at which major transitions in body plans occur. These curves clearly depart from the prediction of a single scaling exponent of 3/4343/43 / 4 predicted by the theory for the optimal organization of vascular networks, and support the general hypothesis that the smallest forms of life face different physical constraints, with different accompanying solutions, for maximizing metabolic power. However, the derived mechanisms here tend, as a first approximation, to a sublinear scaling not far from 3/4343/43 / 4. For example, the mid range bacteria are predicted to scale like 11/15=0.7311150.7311/15=0.7311 / 15 = 0.73, and the largest eukaryotes scale like \u2248.80absent.80\\approx.80\u2248 .80 as curvature sets in. These scalings for both small life and for organisms with vascular systems occur for very different mechanistic reasons, but are linked by the fundamental need for life to allocate and organize space to achieve sufficiently high rates of molecular displacement. Our results thus support more general arguments for why metabolic scaling should not be either surface area to volume scaling (\u03b2=2/3\ud835\udefd23\\beta=2/3italic_\u03b2 = 2 / 3) or strictly proportional to volume (isometric, \u03b2=1\ud835\udefd1\\beta=1italic_\u03b2 = 1). Our work suggests that previous analyses of prokaryote metabolic scaling with all of the data [16], which found super-linear scaling, requires size-dependent shifts in physical constraints that accompany shifts in scaling to approximate a super-linear power law. Our results demonstrate that the overall super-linear pattern is driven by strong curvature away from a power law at the smallest cell sizes. Downstream extension of the fits using all data have been used to derive other features such as the increase in growth rate with cell size and the total abundance of ribosomes [21, 22]. Such models may gain accuracy and improved resolution in size ranges by incorporating the more complicated metabolic scaling derived here. In addition, other cellular constraint perspectives have been proposed for explaining scaling in bacteria such as biosynthetic costs of the membrane [44], ribosome and protein abundances and costs [45, 22], the spatial location and number of organelles and genomes [16, 29], the increasing number of genes and their cost [16, 29, 45, 46], and transporter optimizations associated with the environment (e.g. [23] for a review). In addition, the deployment of phase separation as another means for enhancing reaction rates [47, 48] and the spatial architecture of macromolecules [49, 50] may also be important for cellular scaling. These are all important biophysical, physiological, and evolutionary considerations, and it will be important to integrate these additional constraints with cellular scaling in a more complicated optimization approach [23] that combines these costs with the diffusive tradeoffs employed here. Large prokaryotes also deploy active molecular transport and so the two models presented here represent bounding cases where large prokaryotes (E. coli and bigger) and small unicellular eukaryotes. Multicellular organisms overcome the limit faced by the largest single cells by evolving mechanisms of bulk flow among cells. At its extreme, optimizing such bulk flow through tubular vascular systems to minimize energy dissipation (friction) produces the well-known B\u221dM3/4proportional-to\ud835\udc35superscript\ud835\udc4034B\\propto M^{3/4}italic_B \u221d italic_M start_POSTSUPERSCRIPT 3 / 4 end_POSTSUPERSCRIPT [10, 11, 51, 13, 52, 53]. Taken together, our results and vascular network models show that, organisms across the tree of life may face universal tradeoffs between biochemical reactions and the space devoted to transport, where larger organisms must employ increasingly energy-requiring methods to increase molecular transport velocities. Our results also predict the scaling of materials within the cell. For small entities relying on diffusion, we predict the total mass of enzymes (protein) to scale as Vc11/15superscriptsubscript\ud835\udc49\ud835\udc501115V_{c}^{11/15}italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 11 / 15 end_POSTSUPERSCRIPT, which closely agrees with observed scaling proportional to Vc0.70superscriptsubscript\ud835\udc49\ud835\udc500.70V_{c}^{0.70}italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0.70 end_POSTSUPERSCRIPT [22]. We also predict the minimum size and volume scaling at which cells should produce molecular motors, microtubules and other cytoskeletal material and other mechanisms to enhance diffusivity (Fig. 2). These scaling predictions cannot yet be tested, as they predate the measurement of such volumes or masses for diverse species and cell sizes, with just recently-developed microscopy techniques. However, the largest prokaryotes are known for unusual storage capacity [28, 22], many copies of the genome [29], and surprising amount of cytoskeleton [54]. All of these characteristics may give hints to the eukaryotic transition, and indeed Asgard archaea, which are suggested to be the eukaryotic ancestor, have several atypical cellular morphological characteristics [54, 55, 56]. Our results suggest that active transport in and/or bulk flow of the cytoplasm is likely required to generate free energy even in single cell organisms such as larger Prokaryotes and single-cell Eukaryotes. Extrapolation of the required molecular movement in our models further suggests that smaller multicellular organisms may require mechanisms such as contraction of tissues and/or locomotion to generate bulk transport of intercellular fluids without an organized single source vascular system. Extending further, branching pressurized circulatory networks may be required to sustain metabolism for organisms >1absent1>1> 1 g, a hypothesis supported by evidence that smallest mechanical pumping circulatory systems are limited by damping of pulsatile flow [10]. Our results now provide a physical and chemical explanation for the unique metabolic scaling exhibited by the smallest 11111111 orders of magnitude in organism size. We demonstrate that these life forms face significant design constraints, set by limited space for macromolecules and diffusive molecular movement, and the continuing need for faster molecular displacement mechanisms for the largest unicellulars. The predicted scaling relationships as organisms shift across the different transport limitation domains suggest that natural selection has addressed this sequence of problems during the evolution of larger cell body sizes. Such evolution has led to cells with clustered reaction surfaces, channels of cytoplasm for transporting molecules, molecular motors and cytoskeletal structures to enhance diffusion and then finally by mechanical pumping mechanisms that preview the evolution of powered branched circulatory systems. Our work now extends prior theory to provide a parsimonious hypothesis for how metabolism and the materials that support such activity scale across all life. The coupled diffusion equations to be solved for steady state are with the boundary conditions The solution to these equations is Following a similar derivation, the corresponding equation for P\ud835\udc43Pitalic_P is Returning to the integral which represents the full metabolic rate of the cell, can can use these solutions for A\ud835\udc34Aitalic_A and P\ud835\udc43Pitalic_P set constraints on Z\ud835\udc4dZitalic_Z. To avoid thermodynamic shutdown we need Ke\u2062q\u2062A\u2062(r)P\u2062(r)>1subscript\ud835\udc3e\ud835\udc52\ud835\udc5e\ud835\udc34\ud835\udc5f\ud835\udc43\ud835\udc5f1\\frac{K_{eq}A(r)}{P(r)}>1divide start_ARG italic_K start_POSTSUBSCRIPT italic_e italic_q end_POSTSUBSCRIPT italic_A ( italic_r ) end_ARG start_ARG italic_P ( italic_r ) end_ARG > 1 which, given the solutions above, leads to the condition Thermodynamic shutdown is a problem for the interior of the cell and so we are interested in checking this condition for r=0\ud835\udc5f0r=0italic_r = 0. Evaluating the above inequality at r=0\ud835\udc5f0r=0italic_r = 0 and expanding in small rcsubscript\ud835\udc5f\ud835\udc50r_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT leads to This equation isn\u2019t fully solved because the diffusivity, D\ud835\udc37Ditalic_D, depends on Z\ud835\udc4dZitalic_Z. Previous work has shown that for large enough Z\ud835\udc4dZitalic_Z changes in diffusivity will approximately follow a power law [26], and so we can consider D\u2062(Z)=D0\u2062Z\u03b3\ud835\udc37\ud835\udc4dsubscript\ud835\udc370superscript\ud835\udc4d\ud835\udefeD\\left(Z\\right)=D_{0}Z^{\\gamma}italic_D ( italic_Z ) = italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_Z start_POSTSUPERSCRIPT italic_\u03b3 end_POSTSUPERSCRIPT which yields which for P\u22480\ud835\udc430P\\approx 0italic_P \u2248 0 is This equation states how the concentration of enzyme should either concentrate or dilute with cell size to avoid thermodynamic limitations. Given that \u03b3\u2248\u22123/2\ud835\udefe32\\gamma\\approx-3/2italic_\u03b3 \u2248 - 3 / 2 [26] we have that Z\u221drc\u22124/5proportional-to\ud835\udc4dsuperscriptsubscript\ud835\udc5f\ud835\udc5045Z\\propto r_{c}^{-4/5}italic_Z \u221d italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 4 / 5 end_POSTSUPERSCRIPT or It should be noted that given Equation 20, Z\ud835\udc4dZitalic_Z is bounded by a concentration that is diluting out as cells increase in size. This should set a hard upper bound where the cellular concentrations start to reach discrete numbers of enzymes. Thus, under a fixed tradeoff for diffusivity an upper bound on cell volume is predicted by the dilution of enzyme concentrations required to avoid thermodynamic shutdown. It should be noted that once Z\ud835\udc4dZitalic_Z reaches sufficiently low concentrations diffusivity saturates to a maximum value set by molecular motion in the fluid [26]. At this point D\u2062(Z)=Dm\u2062a\u2062x\ud835\udc37\ud835\udc4dsubscript\ud835\udc37\ud835\udc5a\ud835\udc4e\ud835\udc65D\\left(Z\\right)=D_{max}italic_D ( italic_Z ) = italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT and we have In this limit Z\ud835\udc4dZitalic_Z will scale like Vc\u22122/3superscriptsubscript\ud835\udc49\ud835\udc5023V_{c}^{-2/3}italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 2 / 3 end_POSTSUPERSCRIPT to avoid thermodynamic shutdown. More generally, we are interested in the concentrations of enzymes that would optimize cellular metabolic rate. The above arguments give us a bounding expectation for the scaling of enzyme concentration, but we can replace these with the complete optimization of cellular metabolic rate, B\ud835\udc35Bitalic_B. Specifically, we are interested in where the total metabolism integrated over a cell is Considering cases where the environmental concentration of the product is low, P0\u22480subscript\ud835\udc4300P_{0}\\approx 0italic_P start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2248 0, the integrand is given by We approximate this integral considering small rcsubscript\ud835\udc5f\ud835\udc50r_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT and with, D\u2062(Z)=D0\u2062Z\u03b3\ud835\udc37\ud835\udc4dsubscript\ud835\udc370superscript\ud835\udc4d\ud835\udefeD\\left(Z\\right)=D_{0}Z^{\\gamma}italic_D ( italic_Z ) = italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_Z start_POSTSUPERSCRIPT italic_\u03b3 end_POSTSUPERSCRIPT, the dependence of diffusivity on Z\ud835\udc4dZitalic_Z . Given these assumptions integrand is well approximated by leading to the solution of the integral as In the small radius limit the derivative, \u2202B/\u2202Z\ud835\udc35\ud835\udc4d\\partial B/\\partial Z\u2202 italic_B / \u2202 italic_Z, is then well approximated by Setting this to zero leads to This optimal solution of Zo\u2062p\u2062tsubscript\ud835\udc4d\ud835\udc5c\ud835\udc5d\ud835\udc61Z_{opt}italic_Z start_POSTSUBSCRIPT italic_o italic_p italic_t end_POSTSUBSCRIPT can be substituted back into the approximate solution for total metabolic rate, B\ud835\udc35Bitalic_B, which we find does a good job of approximating the full numerical integral. If we take \u03b3=\u22123/2\ud835\udefe32\\gamma=-3/2italic_\u03b3 = - 3 / 2 this gives This solution shows that the optimal Z\ud835\udc4dZitalic_Z scales like in agreement with our considerations above for thermodynamic shutdown. The corresponding solution for metabolic rate is given by which scales like predicting that metabolic rate will scale slightly sublinearly for sufficiently large size. It should be note that this is the approximate scaling of B\ud835\udc35Bitalic_B over a range of larger cell sizes, but the full form of B\ud835\udc35Bitalic_B is more complicated a small cells sizes, especially considering the factor of (1\u2212Ve\u2062(rc)/Vc)1subscript\ud835\udc49\ud835\udc52subscript\ud835\udc5f\ud835\udc50subscript\ud835\udc49\ud835\udc50(1-V_{e}\\left(r_{c}\\right)/V_{c})( 1 - italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) / italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) multiplying the entire scaling where Ve=v0\u2062Vc\u03b1subscript\ud835\udc49\ud835\udc52subscript\ud835\udc630superscriptsubscript\ud835\udc49\ud835\udc50\ud835\udefcV_{e}=v_{0}V_{c}^{\\alpha}italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = italic_v start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT with \u03b1=0.83\ud835\udefc0.83\\alpha=0.83italic_\u03b1 = 0.83 [22]. Figure 4 shows the full solution of B\ud835\udc35Bitalic_B with more strongly superlinear scaling because of the small-size curvature. It should be noted that at very low Z\ud835\udc4dZitalic_Z the diffusivity saturates to a constant maximum behavior and stops following a power law. In this case diffusivity reaches the maximum molecular diffusivity, D=Dm\u2062a\u2062x\ud835\udc37subscript\ud835\udc37\ud835\udc5a\ud835\udc4e\ud835\udc65D=D_{max}italic_D = italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT, and the above equations lead a optimal enzyme concentration of and corresponding metabolic rate of Here enzyme concentration will scale like Z\u221dVc\u22122/3proportional-to\ud835\udc4dsuperscriptsubscript\ud835\udc49\ud835\udc5023Z\\propto V_{c}^{-2/3}italic_Z \u221d italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 2 / 3 end_POSTSUPERSCRIPT and B\u221dVc1/3proportional-to\ud835\udc35superscriptsubscript\ud835\udc49\ud835\udc5013B\\propto V_{c}^{1/3}italic_B \u221d italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 / 3 end_POSTSUPERSCRIPT. However, these scalings are unlikely to be observed because of the shift to employing active transport, and these results are only shown to illustrate the extreme limitation faced by large cells if they only used molecular diffusion. Our model for active transport treats diffusion in the cell as with a modified effective diffusivity, D\u2032superscript\ud835\udc37\u2032D^{\\prime}italic_D start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, that follows where \u03c1\ud835\udf0c\\rhoitalic_\u03c1 is the fraction of cell volume occupied by transport structures. Here we define an effective volume (region with enhanced transport) of a transport structure, and \u03c1\ud835\udf0c\\rhoitalic_\u03c1 is the ratio of the total of these effective volumes to the total cell volume. The optimization of metabolism now depends on tradeoffs between the adjusted diffusivity and the space occupied by the transport structures, where total metabolism follows where \u03f5italic-\u03f5\\epsilonitalic_\u03f5 is the ratio of the volume of a transport structure to the effective volume of enhanced transport that structure creates. The solutions for A\u2062(r)\ud835\udc34\ud835\udc5fA\\left(r\\right)italic_A ( italic_r ) and P\u2062(r)\ud835\udc43\ud835\udc5fP\\left(r\\right)italic_P ( italic_r ) are the same as in Equations 15 and 16. We are again interested in optimizing cellular metabolic rate, B\ud835\udc35Bitalic_B, where now we are looking for solutions to The integration of B\ud835\udc35Bitalic_B is well approximated by for small values of rcsubscript\ud835\udc5f\ud835\udc50r_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. Again we are considering the regime where transport, now represented by the adjusted diffusivity D\u2032superscript\ud835\udc37\u2032D^{\\prime}italic_D start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, is large relative to the scale of the cell. Taking the derivative of this this solution and again approximating it for small rcsubscript\ud835\udc5f\ud835\udc50r_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT and also for small Dm\u2062a\u2062xsubscript\ud835\udc37\ud835\udc5a\ud835\udc4e\ud835\udc65D_{max}italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT (the maximum molecular diffusivity) we have which gives the optimal fraction of transport structures as where W\ud835\udc4aWitalic_W is the Lambert W\ud835\udc4aWitalic_W function (the product logarithm). For small rcsubscript\ud835\udc5f\ud835\udc50r_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT this is well approximated by Similar to our solutions above for the enzyme concentration tradeoffs in bacteria, this function again highlights that optimal metabolic values depend on D\u2062Ke\u2062qk\u2062rc2\ud835\udc37subscript\ud835\udc3e\ud835\udc52\ud835\udc5e\ud835\udc58superscriptsubscript\ud835\udc5f\ud835\udc502\\frac{DK_{eq}}{kr_{c}^{2}}divide start_ARG italic_D italic_K start_POSTSUBSCRIPT italic_e italic_q end_POSTSUBSCRIPT end_ARG start_ARG italic_k italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG. Taking all of this together we have that the optimal metabolic rate follows This scales like B\u221drc3\u221dVcproportional-to\ud835\udc35superscriptsubscript\ud835\udc5f\ud835\udc503proportional-tosubscript\ud835\udc49\ud835\udc50B\\propto r_{c}^{3}\\propto V_{c}italic_B \u221d italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT \u221d italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT with a logarithmic correction term. This explains why the scaling of metabolism in Eukaryotes is close to linear with cell volume but actually sublinear due to the logarithmic terms. Figure 6 gives the approximate local exponent of B\ud835\udc35Bitalic_B with cell size. The full range of Eukaryotes is well approximated by \u03b2=0.90\ud835\udefd0.90\\beta=0.90italic_\u03b2 = 0.90 which agrees with data as discussed in the maintext. This function also comes with an asymptotic limit that occurs because transportors begin to overpack the cell. This limit occurs when which corresponds to an maximum single cell eukaryote of This solution mirrors the molecular diffusion limit but with an altered diffusivity."
    },
    {
        "id": 12,
        "title": "Gradient Estimate for Fisher-KPP Equation on Finsler metric measure spaces",
        "corpus": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on. Authors: achieve the best HTML results from your LaTeX submissions by following these best practices. In this manuscript, we study the positive solutions of the Finslerian Fisher-KPP equation The Fisher-KPP equation is widely applied and connected to many mathematical branches. We establish the global gradient estimates on compact Finsler metric measure manifold with the traditional C\u2062D\u2062(K,N)\ud835\udc36\ud835\udc37\ud835\udc3e\ud835\udc41CD(K,N)italic_C italic_D ( italic_K , italic_N ) condition, which is developed by S. Ohta and K.-T. Sturm in Finsler geometry. Furthermore, With the assistance of a new comparison theorem developed by the first author, we also give the gradient estimate on forward complete noncompact locally finite misalignment Finsler metric measure spaces with the mixed weighted curvature bounded below and some non-Riemannian curvatures norm-bounded. MSC Classification]35K55, 53C60, 58J35 . The Fisher-KPP equation on a complete Riemannian manifold M\ud835\udc40Mitalic_M is given by where u\ud835\udc62uitalic_u is a real-valued function on M\u00d7[0,\u221e)\ud835\udc400M\\times[0,\\infty)italic_M \u00d7 [ 0 , \u221e ) and c\ud835\udc50citalic_c is a positive constant. The equation was proposed by R. A. Fisher in 1937 to describe the propagation of an evolutionarily advantageous gene in a population, and was also independently described in a seminal paper by A. N. Kolmogorov, I. G. Petrovskii, and N. S. Piskunov in the same year; for this reason, it is often referred to in the literature as the name of Fisher\u2013KPP equation. Since the two papers in 1937, there have been extensive investigations on traveling wave solutions and asymptotic behavior in terms of spreading speeds for various evolution systems. Traveling waves were adopted to study the nonlinear PDEs, such as the nonlinear reaction-diffusion equations modeling physical and biological phenomena (cf. [22][23]), the integral and integrodifferential population models (cf. [2][7][15][16][30]), the lattice differential systems (cf. [6][11][12][14][21][40]), and the time-delayed reaction-diffusion equations (cf. [29][38]). In 2017, Cao et al. [10] derived differential Harnack estimates for positive solutions to (1.1) on Riemannian manifolds with nonnegative Ricci curvature. The idea comes from [8][9], in which a systematic method was developed to find a Harnack inequality for geometric evolution equations. Actually, they obtained the following theorem.\nTheorem A. [10]\nLet (M,g)\ud835\udc40\ud835\udc54(M,g)( italic_M , italic_g ) be an n\ud835\udc5bnitalic_n-dimensional complete noncompact Riemannian manifold with nonnegative Ricci curvature, and let u\u2062(x,t):M\u00d7[0,\u221e)\u2192Rnormal-:\ud835\udc62\ud835\udc65\ud835\udc61normal-\u2192\ud835\udc400\ud835\udc45u(x,t):M\\times\\left[0,\\infty\\right)\\to Ritalic_u ( italic_x , italic_t ) : italic_M \u00d7 [ 0 , \u221e ) \u2192 italic_R be a positive solution to (1.1), where u\ud835\udc62uitalic_u is C2superscript\ud835\udc362C^{2}italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT in x\ud835\udc65xitalic_x and C1superscript\ud835\udc361C^{1}italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT in t\ud835\udc61titalic_t.\nlet f=l\u2062o\u2062g\u2062u\ud835\udc53\ud835\udc59\ud835\udc5c\ud835\udc54\ud835\udc62f=loguitalic_f = italic_l italic_o italic_g italic_u, then we have for all x\ud835\udc65xitalic_x and t\ud835\udc61titalic_t, provided that 0<\u03b1<10\ud835\udefc10<\\alpha<10 < italic_\u03b1 < 1 as well as \u2212c\u2062n\u2062(2+2)4\u2062(1\u2212\u03b1)<\u03b2<min\u2061{\u2212c\u2062n\u2062(1+\u03b1)4\u2062\u03b12\u22124\u2062\u03b1+2\u2062n,\u2212c\u2062n\u2062(2\u22122)4\u2062(1\u2212\u03b1)}<0\ud835\udc50\ud835\udc5b2241\ud835\udefc\ud835\udefd\ud835\udc50\ud835\udc5b1\ud835\udefc4superscript\ud835\udefc24\ud835\udefc2\ud835\udc5b\ud835\udc50\ud835\udc5b2241\ud835\udefc0\\frac{-cn(2+\\sqrt{2})}{4(1-\\alpha)}<\\beta<\\min\\{\\frac{-cn(1+\\alpha)}{4\\alpha^{%\n2}-4\\alpha+2n},\\frac{-cn(2-\\sqrt{2})}{4(1-\\alpha)}\\}<0divide start_ARG - italic_c italic_n ( 2 + square-root start_ARG 2 end_ARG ) end_ARG start_ARG 4 ( 1 - italic_\u03b1 ) end_ARG < italic_\u03b2 < roman_min { divide start_ARG - italic_c italic_n ( 1 + italic_\u03b1 ) end_ARG start_ARG 4 italic_\u03b1 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 4 italic_\u03b1 + 2 italic_n end_ARG , divide start_ARG - italic_c italic_n ( 2 - square-root start_ARG 2 end_ARG ) end_ARG start_ARG 4 ( 1 - italic_\u03b1 ) end_ARG } < 0, where \u03d5\u2062(t)=u\u2062(e2\u2062\u03bc\u2062w\u2062tv\u2212w\u22121\u03bc+w)1\u2212e2\u2062\u03bc\u2062w\u2062t,italic-\u03d5\ud835\udc61\ud835\udc62superscript\ud835\udc522\ud835\udf07\ud835\udc64\ud835\udc61\ud835\udc63\ud835\udc641\ud835\udf07\ud835\udc641superscript\ud835\udc522\ud835\udf07\ud835\udc64\ud835\udc61\\phi(t)=\\frac{u(\\frac{e^{2\\mu wt}}{v-w}-\\frac{1}{\\mu+w})}{1-e^{2\\mu wt}},italic_\u03d5 ( italic_t ) = divide start_ARG italic_u ( divide start_ARG italic_e start_POSTSUPERSCRIPT 2 italic_\u03bc italic_w italic_t end_POSTSUPERSCRIPT end_ARG start_ARG italic_v - italic_w end_ARG - divide start_ARG 1 end_ARG start_ARG italic_\u03bc + italic_w end_ARG ) end_ARG start_ARG 1 - italic_e start_POSTSUPERSCRIPT 2 italic_\u03bc italic_w italic_t end_POSTSUPERSCRIPT end_ARG , with\n\u03bc=\u03b2\u2062c\u20622\u2062(1\u2212\u03b1)c\u2062(\u2212c\u2062n\u22128\u2062\u03b2\u2062(1\u2212\u03b1)),\ud835\udf07\ud835\udefd\ud835\udc5021\ud835\udefc\ud835\udc50\ud835\udc50\ud835\udc5b8\ud835\udefd1\ud835\udefc\\mu=\\beta c\\sqrt{\\frac{2(1-\\alpha)}{c(-cn-8\\beta(1-\\alpha))}},italic_\u03bc = italic_\u03b2 italic_c square-root start_ARG divide start_ARG 2 ( 1 - italic_\u03b1 ) end_ARG start_ARG italic_c ( - italic_c italic_n - 8 italic_\u03b2 ( 1 - italic_\u03b1 ) ) end_ARG end_ARG , v=(4\u2062\u03b2\u2062(1\u2212\u03b1)n+c)\u22c52\u2062(1\u2212\u03b1)c\u2062(\u2212c\u2062n\u22128\u2062\u03b2\u2062(1\u2212\u03b1))\ud835\udc63normal-\u22c54\ud835\udefd1\ud835\udefc\ud835\udc5b\ud835\udc5021\ud835\udefc\ud835\udc50\ud835\udc50\ud835\udc5b8\ud835\udefd1\ud835\udefcv=\\Big{(}\\frac{4\\beta(1-\\alpha)}{n}+c\\Big{)}\\cdot\\sqrt{\\frac{2(1-\\alpha)}{c(-%\ncn-8\\beta(1-\\alpha))}}italic_v = ( divide start_ARG 4 italic_\u03b2 ( 1 - italic_\u03b1 ) end_ARG start_ARG italic_n end_ARG + italic_c ) \u22c5 square-root start_ARG divide start_ARG 2 ( 1 - italic_\u03b1 ) end_ARG start_ARG italic_c ( - italic_c italic_n - 8 italic_\u03b2 ( 1 - italic_\u03b1 ) ) end_ARG end_ARG and\nw=2\u2062(1\u2212\u03b1)n.\ud835\udc6421\ud835\udefc\ud835\udc5bw=\\sqrt{\\frac{2(1-\\alpha)}{n}}.italic_w = square-root start_ARG divide start_ARG 2 ( 1 - italic_\u03b1 ) end_ARG start_ARG italic_n end_ARG end_ARG . Utilizing Theorem A, one can integrate along space-time curves to get a Harnack inequality. However, it is different from the classical Li\u2013Yau Harnack inequality [20] in form.\nGradient estimates play an important role in studying elliptic and parabolic operators. The method originated first in [44] and [13], and was further developed by Li and Yau [20], Li [19], Negrin [24], P. Souplet and Q. Zhang [37], Y. Yang [43], etc.. Recent gradient estimates under the geometric flow include [4] and [3]. For more results on the nonlinear PDEs, one may refer to [1][18]. In 2018, following the line in [19], X. Geng and S. Hou [17] proved the positive solutions to the Fisher\u2013KPP equation on complete Riemannian manifolds. They derived a gradient estimate, and got the classic Harnack inequality by using it, which extended the recent result of Cao, Liu, Pendleton and Ward [10]. In 2009, upon the foundational investigations of gradient estimation on Riemannian manifolds, S. Ohta initially put forward a sophisticated framework for gradient estimation applicable to the heat equation on compact Finsler manifolds [25]. Subsequently, in the year 2014, C. Xia [41] undertook a comprehensive analysis of harmonic functions within the context of both compact and non-compact (specifically, forward complete) Finsler structures by utilizing an advanced form of Moser\u2019s iterative technique. Progressing further, Q. Xia [42] delivered intricate gradient estimates for positive solutions to the heat equation on forward complete Finsler spaces, employing methodologies analogous to those documented in [41]. The first author [32] proposed a method for global and local gradient estimates on Finsler metric measure spaces, which was also used to solve the Finslerian Schr\u00f6dinger equation. Later, the first author [31] gives the gradient estimates of bounded solutions to the Finslerian Allen-Cahn equation. In this paper, we study the Fisher-KPP equation (1.1)\non a Finsler metric measure manifold (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ), where c\ud835\udc50citalic_c is a positive constant, the solution of (1.1) is a function u\u2062(x)\ud835\udc62\ud835\udc65u(x)italic_u ( italic_x ) on M\u00d7[0,\u221e)\ud835\udc400M\\times[0,\\infty)italic_M \u00d7 [ 0 , \u221e ). Our main theorems in this paper are as follows Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a compact Finsler metric measure space with dimensional n\u22652\ud835\udc5b2n\\geq 2italic_n \u2265 2, whose weighted Ricci curvature satisfies R\u2062i\u2062cN\u2265\u2212K\ud835\udc45\ud835\udc56superscript\ud835\udc50\ud835\udc41\ud835\udc3eRic^{N}\\geq-Kitalic_R italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2265 - italic_K, for some positive constant K\ud835\udc3eKitalic_K. Assume the reversibility of M\ud835\udc40Mitalic_M has upper bound \u03c10subscript\ud835\udf0c0\\rho_{0}italic_\u03c1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Suppose u\ud835\udc62uitalic_u is a bounded positive smooth solution of the Fisher-KPP parabolic equation (1.1) on M\u00d7[0,\u221e)\ud835\udc400M\\times[0,\\infty)italic_M \u00d7 [ 0 , \u221e ), then we have where, M1=supu\u2062(x,t)subscript\ud835\udc401supremum\ud835\udc62\ud835\udc65\ud835\udc61M_{1}=\\sup u(x,t)italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = roman_sup italic_u ( italic_x , italic_t ). Similarily, on a noncompact forward complete Finsler manifold, the following local gradient estimates is obtained. Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a complete noncompact Finsler metric measure space. Denote by B\u2062(p,2\u2062R)\ud835\udc35\ud835\udc5d2\ud835\udc45B(p,2R)italic_B ( italic_p , 2 italic_R ) the forward geodesic ball centered at p\ud835\udc5dpitalic_p with forward radius 2R\ud835\udc45Ritalic_R. Suppose the mixed weighted Ricci curvature Rm\u2062i\u2062cN\u2265\u2212K\u2062(2\u2062R)superscript\ud835\udc45\ud835\udc5a\ud835\udc56superscript\ud835\udc50\ud835\udc41\ud835\udc3e2\ud835\udc45{}^{m}Ric^{N}\\geq-K(2R)start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2265 - italic_K ( 2 italic_R ) in B\u2062(p,2\u2062R)\ud835\udc35\ud835\udc5d2\ud835\udc45B(p,2R)italic_B ( italic_p , 2 italic_R ) with K\u2062(2\u2062R)\u22650\ud835\udc3e2\ud835\udc450K(2R)\\geq 0italic_K ( 2 italic_R ) \u2265 0, and the misalignment \u03b1\ud835\udefc\\alphaitalic_\u03b1 satisfies \u03b1\u2264A\u2062(2\u2062R)\ud835\udefc\ud835\udc342\ud835\udc45\\alpha\\leq A(2R)italic_\u03b1 \u2264 italic_A ( 2 italic_R ) in B\u2062(p,2\u2062R)\ud835\udc35\ud835\udc5d2\ud835\udc45B(p,2R)italic_B ( italic_p , 2 italic_R ). Moreover, the non-Riemannian tensors satisfy F\u2062(U)+F*\u2062(\ud835\udcaf)+F\u2062(d\u2062i\u2062v\u2062C\u2062(V))\u2264K0\ud835\udc39\ud835\udc48superscript\ud835\udc39\ud835\udcaf\ud835\udc39\ud835\udc51\ud835\udc56\ud835\udc63\ud835\udc36\ud835\udc49subscript\ud835\udc3e0F(U)+F^{*}(\\mathcal{T})+F(divC(V))\\leq K_{0}italic_F ( italic_U ) + italic_F start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( caligraphic_T ) + italic_F ( italic_d italic_i italic_v italic_C ( italic_V ) ) \u2264 italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Assume u\u2062(x,t)\ud835\udc62\ud835\udc65\ud835\udc61u(x,t)italic_u ( italic_x , italic_t ) is a bounded positive smooth solution of the Fisher-KPP parabolic equation (1.1) on M\u00d7[0,\u221e)\ud835\udc400M\\times[0,\\infty)italic_M \u00d7 [ 0 , \u221e ), then we have on B\u2062(p,R)\ud835\udc35\ud835\udc5d\ud835\udc45B(p,R)italic_B ( italic_p , italic_R ) for 0<\u03b5<10\ud835\udf0010<\\varepsilon<10 < italic_\u03b5 < 1 , s>1\ud835\udc601s>1italic_s > 1 , q>0\ud835\udc5e0q>0italic_q > 0, such that 2\u2062(1\u2212\u03b5)N\u2212\u03b5\u2062(N\u2212n)\u2062s\u22121s\u2062q\u22651\u03b5\u22121+(2\u2062s\u22121)2821\ud835\udf00\ud835\udc41\ud835\udf00\ud835\udc41\ud835\udc5b\ud835\udc601\ud835\udc60\ud835\udc5e1\ud835\udf001superscript2\ud835\udc60128\\frac{2(1-\\varepsilon)}{N-\\varepsilon(N-n)}\\frac{s-1}{sq}\\geq\\frac{1}{%\n\\varepsilon}-1+\\frac{(2s-1)^{2}}{8}divide start_ARG 2 ( 1 - italic_\u03b5 ) end_ARG start_ARG italic_N - italic_\u03b5 ( italic_N - italic_n ) end_ARG divide start_ARG italic_s - 1 end_ARG start_ARG italic_s italic_q end_ARG \u2265 divide start_ARG 1 end_ARG start_ARG italic_\u03b5 end_ARG - 1 + divide start_ARG ( 2 italic_s - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 8 end_ARG, where C1subscript\ud835\udc361C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, C2subscript\ud835\udc362C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are positive constants. . In this section, we introduce the fundamental principles governing Finsler metric measure spaces (refer to [32] for more details). A Finsler metric space is a triple (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ), which indicates that a differential manifold is equipped with a Finsler metric F\ud835\udc39Fitalic_F and a measure \u03bc\ud835\udf07\\muitalic_\u03bc. Suppose the local coordinate of the tangent bundle is (x,y)\ud835\udc65\ud835\udc66(x,y)( italic_x , italic_y ), where x\ud835\udc65xitalic_x is the point on M\ud835\udc40Mitalic_M and y\ud835\udc66yitalic_y is the direction on Tx\u2062Msubscript\ud835\udc47\ud835\udc65\ud835\udc40T_{x}Mitalic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M. A Finsler metric F\ud835\udc39Fitalic_F is a nonnegative function F:T\u2062M\u2192[0,+\u221e):\ud835\udc39\u2192\ud835\udc47\ud835\udc400F:TM\\to\\left[0,+\\infty\\right)italic_F : italic_T italic_M \u2192 [ 0 , + \u221e ) satisfies that (i) F\ud835\udc39Fitalic_F is smooth and positive on T\u2062M\u2216{0}\ud835\udc47\ud835\udc400TM\\setminus\\left\\{0\\right\\}italic_T italic_M \u2216 { 0 }; (ii) F\ud835\udc39Fitalic_F is a positive homogenous norm, i.e., F\u2062(x,k\u2062y)=k\u2062F\u2062(x,y)\ud835\udc39\ud835\udc65\ud835\udc58\ud835\udc66\ud835\udc58\ud835\udc39\ud835\udc65\ud835\udc66F(x,ky)=kF(x,y)italic_F ( italic_x , italic_k italic_y ) = italic_k italic_F ( italic_x , italic_y ) for any (x,y)\u2208T\u2062M\ud835\udc65\ud835\udc66\ud835\udc47\ud835\udc40\\left(x,y\\right)\\in TM( italic_x , italic_y ) \u2208 italic_T italic_M and for any k>0\ud835\udc580k>0italic_k > 0; (iii) F\ud835\udc39Fitalic_F is strongly pseudo-convex, namely, for any (x,y)\u2208T\u2062M\u2216{0}\ud835\udc65\ud835\udc66\ud835\udc47\ud835\udc400\\left(x,y\\right)\\in TM\\setminus\\left\\{0\\right\\}( italic_x , italic_y ) \u2208 italic_T italic_M \u2216 { 0 }, the fundamental tensor is a positive definite matrix defined by Unlike the Riemann metric, the Finsler metric is defined locally as the norm on the tangent space at each point, and globally as a metric on the pull-back bundle, so there are a large number of non-Riemannian geometric quantities on a Finsler metric measure space. The Cartan tensor is defined by for any local vector fields X\ud835\udc4bXitalic_X, Y\ud835\udc4cYitalic_Y, Z\ud835\udc4dZitalic_Z. There is a unique almost g-compatible and torsion-free connection on the pull-back tangent bundle \u03c0*\u2062T\u2062Msuperscript\ud835\udf0b\ud835\udc47\ud835\udc40\\pi^{*}TMitalic_\u03c0 start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_T italic_M of the Finsler manifold (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ) called the Chern connection. It is determined by for any X,Y,Z\u2208T\u2062M\u2216{0}\ud835\udc4b\ud835\udc4c\ud835\udc4d\ud835\udc47\ud835\udc400X,Y,Z\\in TM\\setminus\\left\\{0\\right\\}italic_X , italic_Y , italic_Z \u2208 italic_T italic_M \u2216 { 0 }, where Cysubscript\ud835\udc36\ud835\udc66C_{y}italic_C start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT is the Cartan tensor. The Chern connection coefficients are locally denoted by \u0393j\u2062ki\u2062(x,y)subscriptsuperscript\u0393\ud835\udc56\ud835\udc57\ud835\udc58\ud835\udc65\ud835\udc66\\Gamma^{i}_{jk}(x,y)roman_\u0393 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT ( italic_x , italic_y ) in a natural coordinate system, which could induce the spray coefficients as Gi=12\u2062\u0393j\u2062ki\u2062yj\u2062yksuperscript\ud835\udc3a\ud835\udc5612subscriptsuperscript\u0393\ud835\udc56\ud835\udc57\ud835\udc58superscript\ud835\udc66\ud835\udc57superscript\ud835\udc66\ud835\udc58G^{i}=\\frac{1}{2}\\Gamma^{i}_{jk}y^{j}y^{k}italic_G start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = divide start_ARG 1 end_ARG start_ARG 2 end_ARG roman_\u0393 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT italic_y start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT italic_y start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT. The spray is given by in which \u03b4\u03b4\u2062xi=\u2202\u03b4\u2062xi\u2212Nij\u2062\u2202\u2202yj\ud835\udeff\ud835\udeffsuperscript\ud835\udc65\ud835\udc56\ud835\udeffsuperscript\ud835\udc65\ud835\udc56subscriptsuperscript\ud835\udc41\ud835\udc57\ud835\udc56superscript\ud835\udc66\ud835\udc57\\frac{\\delta}{\\delta x^{i}}=\\frac{\\partial}{\\delta x^{i}}-N^{j}_{i}\\frac{%\n\\partial}{\\partial y^{j}}divide start_ARG italic_\u03b4 end_ARG start_ARG italic_\u03b4 italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG = divide start_ARG \u2202 end_ARG start_ARG italic_\u03b4 italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG - italic_N start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT divide start_ARG \u2202 end_ARG start_ARG \u2202 italic_y start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG and the nonlinear connection coefficients are locally induced from the spray coefficients by Nji=\u2202Gi\u2202yjsubscriptsuperscript\ud835\udc41\ud835\udc56\ud835\udc57superscript\ud835\udc3a\ud835\udc56superscript\ud835\udc66\ud835\udc57N^{i}_{j}=\\frac{\\partial G^{i}}{\\partial y^{j}}italic_N start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = divide start_ARG \u2202 italic_G start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG start_ARG \u2202 italic_y start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG. The Chern connection can define the Chern Riemannian curvature R\ud835\udc45Ritalic_R and Chern non-Riemannian connection P\ud835\udc43Pitalic_P. Denote by \u03a9\u03a9\\Omegaroman_\u03a9 the curvature form of the Chern connection, so that for any X,Y,Z\u2208T\u2062M\u2216{0}\ud835\udc4b\ud835\udc4c\ud835\udc4d\ud835\udc47\ud835\udc400X,Y,Z\\in TM\\setminus\\left\\{0\\right\\}italic_X , italic_Y , italic_Z \u2208 italic_T italic_M \u2216 { 0 }, where locally Customarily, we denote the horizontal Chern derivative by \"\u2223\"conditional\"\"\"\\mid\"\" \u2223 \" and the vertical Chern derivative by \";\"\"\"\";\"\" ; \". For example, for any 1-form v=vi\u2062d\u2062xi\ud835\udc63subscript\ud835\udc63\ud835\udc56\ud835\udc51superscript\ud835\udc65\ud835\udc56v=v_{i}dx^{i}italic_v = italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_d italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT on the pull-back bundle. The angular metric form hysubscript\u210e\ud835\udc66h_{y}italic_h start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT is defined by for any y,u,v\u2208Tx\u2062M\ud835\udc66\ud835\udc62\ud835\udc63subscript\ud835\udc47\ud835\udc65\ud835\udc40y,u,v\\in T_{x}Mitalic_y , italic_u , italic_v \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M with y\u22600\ud835\udc660y\\neq 0italic_y \u2260 0 Thus, for any two linearly independent vectors y,v\u2208Tx\u2062M\u2216{0}\ud835\udc66\ud835\udc63subscript\ud835\udc47\ud835\udc65\ud835\udc400y,v\\in T_{x}M\\setminus\\left\\{0\\right\\}italic_y , italic_v \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M \u2216 { 0 }, which span a tangent plane \u03a0y=s\u2062p\u2062a\u2062n\u2062{y,v}subscript\u03a0\ud835\udc66\ud835\udc60\ud835\udc5d\ud835\udc4e\ud835\udc5b\ud835\udc66\ud835\udc63\\Pi_{y}=span\\{y,v\\}roman_\u03a0 start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT = italic_s italic_p italic_a italic_n { italic_y , italic_v }, the flag curvature with pole y\ud835\udc66yitalic_y is defined by which is locally expressed by The Ricci curvature is defined by where e1,\u2026,en\u22121,vF\u2062(v)subscript\ud835\udc521\u2026subscript\ud835\udc52\ud835\udc5b1\ud835\udc63\ud835\udc39\ud835\udc63e_{1},\\dots,e_{n-1},\\frac{v}{F(v)}italic_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_e start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT , divide start_ARG italic_v end_ARG start_ARG italic_F ( italic_v ) end_ARG form an orthonormal basis of Tx\u2062Msubscript\ud835\udc47\ud835\udc65\ud835\udc40T_{x}Mitalic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M with respect to gysubscript\ud835\udc54\ud835\udc66g_{y}italic_g start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT. The Landsberg curvature of (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ) is given by By the zero homogeneity, according to the Euler lemma, it easy to see that H.B. Rademacher introduced the concepts of reversibility and reversible manifolds [28], which are also closely related to the analytical assumptions on Finsler manifolds. A Finsler metric is defined to be reversible if F\u2062(x,V)=F\u00af\u2062(x,V)\ud835\udc39\ud835\udc65\ud835\udc49\u00af\ud835\udc39\ud835\udc65\ud835\udc49F(x,V)=\\bar{F}(x,V)italic_F ( italic_x , italic_V ) = over\u00af start_ARG italic_F end_ARG ( italic_x , italic_V ) for any point x\ud835\udc65xitalic_x and any vector field V\ud835\udc49Vitalic_V, where F\u00af\u2062(x,V):=F\u2062(x,\u2212V)assign\u00af\ud835\udc39\ud835\udc65\ud835\udc49\ud835\udc39\ud835\udc65\ud835\udc49\\bar{F}(x,V):=F(x,-V)over\u00af start_ARG italic_F end_ARG ( italic_x , italic_V ) := italic_F ( italic_x , - italic_V ) is called the reversed Finsler metric of F\ud835\udc39Fitalic_F. Obviously, F\ud835\udc39Fitalic_F is reversible if and only if \u03c1\u22611\ud835\udf0c1\\rho\\equiv 1italic_\u03c1 \u2261 1. A Finsler manifold (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ) is said to have finite reversibility if \u03c1<+\u221e\ud835\udf0c\\rho<+\\inftyitalic_\u03c1 < + \u221e. Later, K. Ball, E. Carlen, and E. Lieb introduced the concepts of uniform smoothness and uniform convexity in Banach space theory [5], whose geometric interpretation in Finsler geometry was provided by S. Ohta [26]. We say F\ud835\udc39Fitalic_F satisfies uniform convexity and uniform smoothness if there exist uniform positive constants \u03ba*superscript\ud835\udf05\\kappa^{*}italic_\u03ba start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT and \u03ba\ud835\udf05\\kappaitalic_\u03ba, called the uniform convexity constant and the uniform smoothness constant, respectively, such that for any x\u2208M\ud835\udc65\ud835\udc40x\\in Mitalic_x \u2208 italic_M, V\u2208Tx\u2062M\u2216{0}\ud835\udc49subscript\ud835\udc47\ud835\udc65\ud835\udc400V\\in T_{x}M\\setminus\\{0\\}italic_V \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M \u2216 { 0 }, and W\u2208Tx\u2062M\ud835\udc4asubscript\ud835\udc47\ud835\udc65\ud835\udc40W\\in T_{x}Mitalic_W \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M, we have where gV=(gi\u2062j\u2062(x,V))subscript\ud835\udc54\ud835\udc49subscript\ud835\udc54\ud835\udc56\ud835\udc57\ud835\udc65\ud835\udc49g_{V}=(g_{ij}(x,V))italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT = ( italic_g start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_x , italic_V ) ) is the Riemannian metric on M\ud835\udc40Mitalic_M induced from F\ud835\udc39Fitalic_F with respect to the reference vector V\ud835\udc49Vitalic_V . In this situation, the reversibility \u03c1\ud835\udf0c\\rhoitalic_\u03c1 could be controlled by \u03ba\ud835\udf05\\kappaitalic_\u03ba and \u03ba*superscript\ud835\udf05\\kappa^{*}italic_\u03ba start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT as F\ud835\udc39Fitalic_F is Riemannian if and only if \u03ba=1\ud835\udf051\\kappa=1italic_\u03ba = 1 if and only if \u03ba*=1superscript\ud835\udf051\\kappa^{*}=1italic_\u03ba start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT = 1 [26]. The Riemannian structure is inconsistent when the reference vectors are different. For example, given three different local non-vanishing vector fields around x\ud835\udc65xitalic_x, namely, V\ud835\udc49Vitalic_V, W\ud835\udc4aWitalic_W, Y\ud835\udc4cYitalic_Y , the norm of Y\ud835\udc4cYitalic_Y about gVsubscript\ud835\udc54\ud835\udc49g_{V}italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT and gWsubscript\ud835\udc54\ud835\udc4ag_{W}italic_g start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT maybe not the same in general case. The ratio gV\u2062(Y,Y)=gW\u2062(Y,Y)subscript\ud835\udc54\ud835\udc49\ud835\udc4c\ud835\udc4csubscript\ud835\udc54\ud835\udc4a\ud835\udc4c\ud835\udc4cg_{V}(Y,Y)=g_{W}(Y,Y)italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_Y , italic_Y ) = italic_g start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT ( italic_Y , italic_Y ) is a function about V\ud835\udc49Vitalic_V, W\ud835\udc4aWitalic_W, Y\ud835\udc4cYitalic_Y . Based on this fact, [32] defined an important constant on a Finsler manifold, called the misalignment. ([32]). For a Finsler manifold (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ), the misalignment of a Finsler metric at point x\ud835\udc65xitalic_x is defined by Moreover, the global misalignment of the Finsler metric is defined by it also provided in [32] some characterizations of the misalignment. Especially, a Finsler manifold (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ) is a Riemannian manifold if and only if \u03b1M=1subscript\ud835\udefc\ud835\udc401\\alpha_{M}=1italic_\u03b1 start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT = 1. Moreover, a Finsler manifold (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ) is uniform convexity and uniform smoothness if and only if it satisfies finite misalignment. Since that, we have gaven an important class of Finsler manifold as the following. We call a Finsler manifold (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ) has finite misalignment if there is a positive constant A\ud835\udc34Aitalic_A such that \u03b1\u2264A\ud835\udefc\ud835\udc34\\alpha\\leq Aitalic_\u03b1 \u2264 italic_A, and has locally finite misalignment if for any compact subset \u03a9\u2282Mnormal-\u03a9\ud835\udc40\\Omega\\subset Mroman_\u03a9 \u2282 italic_M, there is a constant A\u2062(\u03a9)\ud835\udc34normal-\u03a9A(\\Omega)italic_A ( roman_\u03a9 ) depending on \u03a9normal-\u03a9\\Omegaroman_\u03a9 such that \u03b1\u2062(x)\u2264A\u2062(\u03c9)\ud835\udefc\ud835\udc65\ud835\udc34\ud835\udf14\\alpha(x)\\leq A(\\omega)italic_\u03b1 ( italic_x ) \u2264 italic_A ( italic_\u03c9 ) for any x\u2208\u03a9\ud835\udc65normal-\u03a9x\\in\\Omegaitalic_x \u2208 roman_\u03a9. So far, we have briefly introduced some Riemannian or non-Riemannian local quantities and tensors in Finsler geometry corresponding to Riemannian geometric quantities. Next, we will introduce more tensors related to the measure d\u2062\u03bc\ud835\udc51\ud835\udf07d\\muitalic_d italic_\u03bc. For any smooth function f:M\u2192R:\ud835\udc53\u2192\ud835\udc40\ud835\udc45f:M\\to Ritalic_f : italic_M \u2192 italic_R, df denotes its differential 1-form and its gradient \u2207f\u2207\ud835\udc53\\nabla f\u2207 italic_f is defined as the dual of the 1-form via the Legendre transformation, namely, \u2207f\u2062(x):=l\u22121\u2062(d\u2062f\u2062(x))\u2208Tx\u2062Massign\u2207\ud835\udc53\ud835\udc65superscript\ud835\udc591\ud835\udc51\ud835\udc53\ud835\udc65subscript\ud835\udc47\ud835\udc65\ud835\udc40\\nabla f(x):=l^{-1}(df(x))\\in T_{x}M\u2207 italic_f ( italic_x ) := italic_l start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_d italic_f ( italic_x ) ) \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M. Locally it can be written as on Mf:=d\u2062f\u22600assignsubscript\ud835\udc40\ud835\udc53\ud835\udc51\ud835\udc530M_{f}:={df\\neq 0}italic_M start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT := italic_d italic_f \u2260 0. The Hessian of f\ud835\udc53fitalic_f is defined via the Chern connection by It can be shown that \u22072f\u2062(X,Y)superscript\u22072\ud835\udc53\ud835\udc4b\ud835\udc4c\\nabla^{2}f(X,Y)\u2207 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_f ( italic_X , italic_Y ) is symmetric [27]. For any two points p\ud835\udc5dpitalic_p, q\ud835\udc5eqitalic_q on M\ud835\udc40Mitalic_M, the distance function is defined by where the infimum is taken over all the C1superscript\ud835\udc361C^{1}italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT curves \u03b3:[0,1]\u2192M:\ud835\udefe\u219201\ud835\udc40\\gamma:[0,1]\\to Mitalic_\u03b3 : [ 0 , 1 ] \u2192 italic_M such that \u03b3\u2062(0)=p\ud835\udefe0\ud835\udc5d\\gamma(0)=pitalic_\u03b3 ( 0 ) = italic_p and \u03b3\u2062(1)=q\ud835\udefe1\ud835\udc5e\\gamma(1)=qitalic_\u03b3 ( 1 ) = italic_q. Fixed a base point p\ud835\udc5dpitalic_p on M\ud835\udc40Mitalic_M, we denote the forward distance function by r\ud835\udc5fritalic_r. That is, r\u2062(x)=d\u2062(p,x)\ud835\udc5f\ud835\udc65\ud835\udc51\ud835\udc5d\ud835\udc65r(x)=d(p,x)italic_r ( italic_x ) = italic_d ( italic_p , italic_x ), with d denotes the forward distance. The forward distance function r\ud835\udc5fritalic_r is a function defined on the Finsler manifold M\ud835\udc40Mitalic_M. d\u2062r\ud835\udc51\ud835\udc5fdritalic_d italic_r is a 1-form on M\ud835\udc40Mitalic_M, whose dual is a gradient vector field, noted by \u2207r\u2207\ud835\udc5f\\nabla r\u2207 italic_r. Precisely, \u2207r=gi\u2062j\u2062(x,\u2207r)\u2062\u2202r\u2202xi\u2062\u2202\u2202xj\u2207\ud835\udc5fsuperscript\ud835\udc54\ud835\udc56\ud835\udc57\ud835\udc65\u2207\ud835\udc5f\ud835\udc5fsuperscript\ud835\udc65\ud835\udc56superscript\ud835\udc65\ud835\udc57\\nabla r=g^{ij}(x,\\nabla r)\\frac{\\partial r}{\\partial x^{i}}\\frac{\\partial}{%\n\\partial x^{j}}\u2207 italic_r = italic_g start_POSTSUPERSCRIPT italic_i italic_j end_POSTSUPERSCRIPT ( italic_x , \u2207 italic_r ) divide start_ARG \u2202 italic_r end_ARG start_ARG \u2202 italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG divide start_ARG \u2202 end_ARG start_ARG \u2202 italic_x start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG Taking the Chern horizontal derivative of \u2207r\u2207\ud835\udc5f\\nabla r\u2207 italic_r yields the Hessian of distance function \u22072rsuperscript\u22072\ud835\udc5f\\nabla^{2}r\u2207 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r. Locally, in a natural coordinate system In (2.23), the derivative is taken in the direction \u2207r\u2207\ud835\udc5f\\nabla r\u2207 italic_r naturally. Generally, we can take the derivative in any direction. Suppose V\ud835\udc49Vitalic_V is a local vector field around x\ud835\udc65xitalic_x on M\ud835\udc40Mitalic_M. Note that the distance function may not be symmetric about p\ud835\udc5dpitalic_p and q\ud835\udc5eqitalic_q unless F\ud835\udc39Fitalic_F is reversible. A\u2062C2\ud835\udc34superscript\ud835\udc362AC^{2}italic_A italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT curve \u03b3\ud835\udefe\\gammaitalic_\u03b3 is called a geodesic if locally where Gi\u2062(x,y)superscript\ud835\udc3a\ud835\udc56\ud835\udc65\ud835\udc66G^{i}(x,y)italic_G start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ( italic_x , italic_y ) are the spray coefficients. A forward geodesic ball centered at p\ud835\udc5dpitalic_p with radius R\ud835\udc45Ritalic_R can be represented by Adopting the exponential map, a Finsler manifold (M,F)\ud835\udc40\ud835\udc39(M,F)( italic_M , italic_F ) is said to be forward complete or forward geodesically complete if the exponential map is defined on the entire T\u2062M\ud835\udc47\ud835\udc40TMitalic_T italic_M. Thus, any two points in a forward complete manifold M\ud835\udc40Mitalic_M can be connected by a minimal forward geodesic. Moreover, the forward closed balls BR+\u2062(p)\u00af\u00afsubscriptsuperscript\ud835\udc35\ud835\udc45\ud835\udc5d\\overline{B^{+}_{R}(p)}over\u00af start_ARG italic_B start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT ( italic_p ) end_ARG are compact. A Finsler metric measure space (M,F,d\u2062\u03bc)\ud835\udc40\ud835\udc39\ud835\udc51\ud835\udf07(M,F,d\\mu)( italic_M , italic_F , italic_d italic_\u03bc ) is a Finsler manifold equipped with a given measure \u03bc\ud835\udf07\\muitalic_\u03bc. In local coordinates {xi}i=1nsuperscriptsubscriptsuperscript\ud835\udc65\ud835\udc56\ud835\udc561\ud835\udc5b\\{x^{i}\\}_{i=1}^{n}{ italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, we can express the volume form as d\u2062\u03bc=\u03c3\u2062(x)\u2062d\u2062x1\u2062\u2026\u2062d\u2062xn\ud835\udc51\ud835\udf07\ud835\udf0e\ud835\udc65\ud835\udc51superscript\ud835\udc651\u2026\ud835\udc51superscript\ud835\udc65\ud835\udc5bd\\mu=\\sigma(x)dx^{1}\\dots dx^{n}italic_d italic_\u03bc = italic_\u03c3 ( italic_x ) italic_d italic_x start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT \u2026 italic_d italic_x start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. For any y\u2208Tx\u2062M\u2216{0}\ud835\udc66subscript\ud835\udc47\ud835\udc65\ud835\udc400y\\in T_{x}M\\setminus\\left\\{0\\right\\}italic_y \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M \u2216 { 0 }, define which is called the distortion of (M,F,d\u2062\u03bc)\ud835\udc40\ud835\udc39\ud835\udc51\ud835\udf07(M,F,d\\mu)( italic_M , italic_F , italic_d italic_\u03bc ). The definition of the S-curvature is given in the following. ([35][34]). Suppose (M,F,d\u2062\u03bc)\ud835\udc40\ud835\udc39\ud835\udc51\ud835\udf07(M,F,d\\mu)( italic_M , italic_F , italic_d italic_\u03bc ) is a Finsler metric measure space. For any point x\u2208M\ud835\udc65\ud835\udc40x\\in Mitalic_x \u2208 italic_M, let \u03b3=\u03b3\u2062(t)\ud835\udefe\ud835\udefe\ud835\udc61\\gamma=\\gamma(t)italic_\u03b3 = italic_\u03b3 ( italic_t ) be a forward geodesic from x with the initial tangent vector \u03b3\u02d9\u2062(0)=ynormal-\u02d9\ud835\udefe0\ud835\udc66\\dot{\\gamma}(0)=yover\u02d9 start_ARG italic_\u03b3 end_ARG ( 0 ) = italic_y. The S-curvature of (M,F,d\u2062\u03bc)\ud835\udc40\ud835\udc39\ud835\udc51\ud835\udf07(M,F,d\\mu)( italic_M , italic_F , italic_d italic_\u03bc ) is Definition 2.3 means that the S-curvature is the changing of distortion along the geodesic in direction y. Modeled on the definition of \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T curvature in [36], [32] defined the difference of \u2207\u03c4normal-\u2207\ud835\udf0f\\nabla\\tau\u2207 italic_\u03c4 on the tangent sphere, denoted by \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T, ([32]). The difference of \u2207\u03c4normal-\u2207\ud835\udf0f\\nabla\\tau\u2207 italic_\u03c4 on the tangent bundle is a tensor denoted by \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T, which is given by for vector fields V\ud835\udc49Vitalic_V,W\ud835\udc4aWitalic_W on M\ud835\udc40Mitalic_M. Locally, it is \ud835\udcaf\u2062(V,W)=\ud835\udcafi\u2062(V,w)\u2062d\u2062xi\ud835\udcaf\ud835\udc49\ud835\udc4asubscript\ud835\udcaf\ud835\udc56\ud835\udc49\ud835\udc64\ud835\udc51superscript\ud835\udc65\ud835\udc56\\mathcal{T}(V,W)=\\mathcal{T}_{i}(V,w)dx^{i}caligraphic_T ( italic_V , italic_W ) = caligraphic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_V , italic_w ) italic_d italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT, with Obviously, \ud835\udcaf\u2062(V,W)\ud835\udcaf\ud835\udc49\ud835\udc4a\\mathcal{T}(V,W)caligraphic_T ( italic_V , italic_W ) is anti-symmetric about V\ud835\udc49Vitalic_V and W\ud835\udc4aWitalic_W, that is, \ud835\udcaf\u2062(V,W)=\u2212\ud835\udcaf\u2062(W,V)\ud835\udcaf\ud835\udc49\ud835\udc4a\ud835\udcaf\ud835\udc4a\ud835\udc49\\mathcal{T}(V,W)=-\\mathcal{T}(W,V)caligraphic_T ( italic_V , italic_W ) = - caligraphic_T ( italic_W , italic_V ) for any nonvanishing V\ud835\udc49Vitalic_V and W\ud835\udc4aWitalic_W. If in local coordinates {xi}i=1nsubscriptsuperscriptsuperscript\ud835\udc65\ud835\udc56\ud835\udc5b\ud835\udc561\\{x^{i}\\}^{n}_{i=1}{ italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT, expressing d\u2062\u03bc=e\u03d5\u2062d\u2062x1\u2062\u2026\u2062d\u2062xn\ud835\udc51\ud835\udf07superscript\ud835\udc52italic-\u03d5\ud835\udc51superscript\ud835\udc651\u2026\ud835\udc51superscript\ud835\udc65\ud835\udc5bd\\mu=e^{\\phi}dx^{1}\\dots dx^{n}italic_d italic_\u03bc = italic_e start_POSTSUPERSCRIPT italic_\u03d5 end_POSTSUPERSCRIPT italic_d italic_x start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT \u2026 italic_d italic_x start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, the divergence of a smooth vector field V\ud835\udc49Vitalic_V can be written as The Finsler Laplacian of a function f\ud835\udc53fitalic_f on M\ud835\udc40Mitalic_M could now be given by \u0394d\u2062\u03bc\u2062f:=d\u2062i\u2062vd\u2062\u03bc\u2062(\u2207f)assignsubscript\u0394\ud835\udc51\ud835\udf07\ud835\udc53\ud835\udc51\ud835\udc56subscript\ud835\udc63\ud835\udc51\ud835\udf07\u2207\ud835\udc53\\Delta_{d\\mu}f:=div_{d\\mu}(\\nabla f)roman_\u0394 start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT italic_f := italic_d italic_i italic_v start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT ( \u2207 italic_f ), noticing that \u0394d\u2062\u03bc=\u0394\u2207f\u2062fsubscript\u0394\ud835\udc51\ud835\udf07superscript\u0394\u2207\ud835\udc53\ud835\udc53\\Delta_{d\\mu}=\\Delta^{\\nabla f}froman_\u0394 start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT = roman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT italic_f, where\n\u0394d\u2062\u03bc\u2207f\u2062f:=d\u2062i\u2062vd\u2062\u03bc\u2062(\u2207\u2207ff)assignsubscriptsuperscript\u0394\u2207\ud835\udc53\ud835\udc51\ud835\udf07\ud835\udc53\ud835\udc51\ud835\udc56subscript\ud835\udc63\ud835\udc51\ud835\udf07superscript\u2207\u2207\ud835\udc53\ud835\udc53\\Delta^{\\nabla f}_{d\\mu}f:=div_{d\\mu}(\\nabla^{\\nabla f}f)roman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT italic_f := italic_d italic_i italic_v start_POSTSUBSCRIPT italic_d italic_\u03bc end_POSTSUBSCRIPT ( \u2207 start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT italic_f ) is in the view of weighted Laplacian with A Finsler Laplacian is better to be viewed in a weak sense due to the lack of regularity. Concretely, assuming f\u2208W1,p\u2062(M)\ud835\udc53superscript\ud835\udc4a1\ud835\udc5d\ud835\udc40f\\in W^{1,p}(M)italic_f \u2208 italic_W start_POSTSUPERSCRIPT 1 , italic_p end_POSTSUPERSCRIPT ( italic_M ), for any test function \u03d5\u2208C0\u221e\u2062(M)italic-\u03d5superscriptsubscript\ud835\udc360\ud835\udc40\\phi\\in C_{0}^{\\infty}(M)italic_\u03d5 \u2208 italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT ( italic_M ). On the other hand, the Laplacian of a function f\ud835\udc53fitalic_f on a Riemannian manifold is the trace of the Hessian of f\ud835\udc53fitalic_f with respect to the Riemannian metric g\ud835\udc54gitalic_g. On a Finsler metric measure space (M,F,d\u2062\u03bc)\ud835\udc40\ud835\udc39\ud835\udc51\ud835\udf07(M,F,d\\mu)( italic_M , italic_F , italic_d italic_\u03bc ), the weighted Hessian H~\u2062(f)~\ud835\udc3b\ud835\udc53\\tilde{H}(f)over~ start_ARG italic_H end_ARG ( italic_f ) of a function f\ud835\udc53fitalic_f on Mf={x\u2208M:\u2207f|x\u22600}subscript\ud835\udc40\ud835\udc53conditional-set\ud835\udc65\ud835\udc40evaluated-at\u2207\ud835\udc53\ud835\udc650M_{f}=\\{x\\in M:\\nabla f|_{x}\\neq 0\\}italic_M start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT = { italic_x \u2208 italic_M : \u2207 italic_f | start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT \u2260 0 }is defined in [39] by where h\u2207fsubscript\u210e\u2207\ud835\udc53h_{\\nabla f}italic_h start_POSTSUBSCRIPT \u2207 italic_f end_POSTSUBSCRIPT is the angular metric form in the direction \u2207f\u2207\ud835\udc53\\nabla f\u2207 italic_f, given in (2.9) It is clear that H~\u2062(f)~\ud835\udc3b\ud835\udc53\\tilde{H}(f)over~ start_ARG italic_H end_ARG ( italic_f ) is still a symmetric bilinear form with Inspired by this, [32] defined the mixed weighted Hessian where hV,\u2207fsubscript\u210e\ud835\udc49\u2207\ud835\udc53h_{V,\\nabla f}italic_h start_POSTSUBSCRIPT italic_V , \u2207 italic_f end_POSTSUBSCRIPT is the mixed angular metric form in the directions V\ud835\udc49Vitalic_V and \u2207f\u2207\ud835\udc53\\nabla f\u2207 italic_f, which is defined by for any vector X\ud835\udc4bXitalic_X, Y\ud835\udc4cYitalic_Y. It is necessary to remark that h\u2207f,\u2207f=h\u2207fsubscript\u210e\u2207\ud835\udc53\u2207\ud835\udc53subscript\u210e\u2207\ud835\udc53h_{\\nabla f,\\nabla f}=h_{\\nabla f}italic_h start_POSTSUBSCRIPT \u2207 italic_f , \u2207 italic_f end_POSTSUBSCRIPT = italic_h start_POSTSUBSCRIPT \u2207 italic_f end_POSTSUBSCRIPT, so that H~\u2207f\u2062(f)=H~\u2062(f)superscript~\ud835\udc3b\u2207\ud835\udc53\ud835\udc53~\ud835\udc3b\ud835\udc53\\tilde{H}^{\\nabla f}(f)=\\tilde{H}(f)over~ start_ARG italic_H end_ARG start_POSTSUPERSCRIPT \u2207 italic_f end_POSTSUPERSCRIPT ( italic_f ) = over~ start_ARG italic_H end_ARG ( italic_f ) for any function f\ud835\udc53fitalic_f on M\ud835\udc40Mitalic_M. With the assistance of the S-curvature, one can present the definition of the weighted Ricci curvature as the following. ([27][34]). Given a unit vector V\u2208Tx\u2062M\ud835\udc49subscript\ud835\udc47\ud835\udc65\ud835\udc40V\\in T_{x}Mitalic_V \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M and an positive integral number k\ud835\udc58kitalic_k, the weighted Ricci curvature is defined by where the derivative is taken along the geodesic started from x\ud835\udc65xitalic_x in the direction of V\ud835\udc49Vitalic_V. According to the definition of weighted Ricci curvature, B. Wu defined the weighted flag curvature when k=N\u2208(1,n)\u222a(n,\u221e)\ud835\udc58\ud835\udc411\ud835\udc5b\ud835\udc5bk=N\\in(1,n)\\cup(n,\\infty)italic_k = italic_N \u2208 ( 1 , italic_n ) \u222a ( italic_n , \u221e ) in [39]. We have completely introduced this concept for any k\ud835\udc58kitalic_k in [32]. ([32]). Let (M,F,d\u2062\u03bc)\ud835\udc40\ud835\udc39\ud835\udc51\ud835\udf07(M,F,d\\mu)( italic_M , italic_F , italic_d italic_\u03bc ) be a Finsler metric measure space, and V,W\u2208Tx\u2062M\ud835\udc49\ud835\udc4asubscript\ud835\udc47\ud835\udc65\ud835\udc40V,W\\in T_{x}Mitalic_V , italic_W \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M be linearly independent vectors. The weighted flag curvature Kk\u2062(V,W)superscript\ud835\udc3e\ud835\udc58\ud835\udc49\ud835\udc4aK^{k}(V,W)italic_K start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_V , italic_W ) is defined by where the derivative is taken along the geodesic started from x\ud835\udc65xitalic_x in the direction of V\ud835\udc49Vitalic_V. Moreover, it has also been defined the mixed weighted Ricci curvature in [32], denoted by Rm\u2062i\u2062cksuperscript\ud835\udc45\ud835\udc5a\ud835\udc56superscript\ud835\udc50\ud835\udc58{}^{m}Ric^{k}start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT. ([32])Given two unit vectors V,W\u2208Tx\u2062M\ud835\udc49\ud835\udc4asubscript\ud835\udc47\ud835\udc65\ud835\udc40V,W\\in T_{x}Mitalic_V , italic_W \u2208 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M and an positive integral number k\ud835\udc58kitalic_k, the mixed weighted Ricci curvature Rm\u2062i\u2062ck\u2062(V,W)=mR\u2062i\u2062cWk\u2062(V)superscript\ud835\udc5asuperscript\ud835\udc45\ud835\udc5a\ud835\udc56superscript\ud835\udc50\ud835\udc58\ud835\udc49\ud835\udc4a\ud835\udc45\ud835\udc56subscriptsuperscript\ud835\udc50\ud835\udc58\ud835\udc4a\ud835\udc49{}^{m}Ric^{k}(V,W)=^{m}Ric^{k}_{W}(V)start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_V , italic_W ) = start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT ( italic_V )is defined by where the derivative is taken along the geodesic started from x\ud835\udc65xitalic_x in the direction of V\ud835\udc49Vitalic_V, and t\u2062rW\u2062RV\u2062(V)=gi\u2062j\u2062(W)\u2062gV\u2062(RV\u2062(ei,V)\u2062V,ej)\ud835\udc61subscript\ud835\udc5f\ud835\udc4asubscript\ud835\udc45\ud835\udc49\ud835\udc49superscript\ud835\udc54\ud835\udc56\ud835\udc57\ud835\udc4asubscript\ud835\udc54\ud835\udc49subscript\ud835\udc45\ud835\udc49subscript\ud835\udc52\ud835\udc56\ud835\udc49\ud835\udc49subscript\ud835\udc52\ud835\udc57tr_{W}R_{V}(V)=g^{ij}(W)g_{V}(R_{V}(e_{i},V)V,e_{j})italic_t italic_r start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT italic_R start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_V ) = italic_g start_POSTSUPERSCRIPT italic_i italic_j end_POSTSUPERSCRIPT ( italic_W ) italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_R start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_V ) italic_V , italic_e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) means taking trace of the flag curvature with respect to g\u2062(x,W)\ud835\udc54\ud835\udc65\ud835\udc4ag(x,W)italic_g ( italic_x , italic_W ). The weighted Ricci curvature is a special case of the mixed weighted Ricci curvature, i.e., R\u2062i\u2062ck\u2062(V)=mR\u2062i\u2062cVk\u2062(V)superscript\ud835\udc5a\ud835\udc45\ud835\udc56superscript\ud835\udc50\ud835\udc58\ud835\udc49\ud835\udc45\ud835\udc56subscriptsuperscript\ud835\udc50\ud835\udc58\ud835\udc49\ud835\udc49Ric^{k}(V)=^{m}Ric^{k}_{V}(V)italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_V ) = start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_V ).\nDefining the function c\u2062tc\u2062(r)\ud835\udc50subscript\ud835\udc61\ud835\udc50\ud835\udc5fct_{c}(r)italic_c italic_t start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_r ) as the following weighted Hessian comparison theorem is cited from Theorem 3.3 in [39]. ([32]). Let (M,F,d\u2062\u03bc)\ud835\udc40\ud835\udc39\ud835\udc51\ud835\udf07(M,F,d\\mu)( italic_M , italic_F , italic_d italic_\u03bc ) be a forward complete n-dimensional Finsler metric measure space with finite misalignment \u03b1\ud835\udefc\\alphaitalic_\u03b1. Denote the forward distance function by r\ud835\udc5fritalic_r and by V\ud835\udc49Vitalic_V a fixed vector field on M\ud835\udc40Mitalic_M. Suppose the mixed weighted Ricci curvature R\u2062i\u2062cN\u2062(V,\u2207r)\ud835\udc45\ud835\udc56superscript\ud835\udc50\ud835\udc41\ud835\udc49normal-\u2207\ud835\udc5fRic^{N}(V,\\nabla r)italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ( italic_V , \u2207 italic_r ) of M\ud835\udc40Mitalic_M is bounded from below by \u2212K\ud835\udc3e-K- italic_K with K>0\ud835\udc3e0K>0italic_K > 0, for some N>n\ud835\udc41\ud835\udc5bN>nitalic_N > italic_n, as well as the non-Riemannian curvatures U\ud835\udc48Uitalic_U, \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T and d\u2062i\u2062v\u2062C\u2062(V)=Ck|ii\u2062j\u2062(V)\u2062Vk\u2062\u03b4\u03b4\u2062xj\ud835\udc51\ud835\udc56\ud835\udc63\ud835\udc36\ud835\udc49subscriptsuperscript\ud835\udc36\ud835\udc56\ud835\udc57conditional\ud835\udc58\ud835\udc56\ud835\udc49superscript\ud835\udc49\ud835\udc58\ud835\udeff\ud835\udeffsuperscript\ud835\udc65\ud835\udc57divC(V)=C^{ij}_{k|i}(V)V^{k}\\frac{\\delta}{\\delta x^{j}}italic_d italic_i italic_v italic_C ( italic_V ) = italic_C start_POSTSUPERSCRIPT italic_i italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k | italic_i end_POSTSUBSCRIPT ( italic_V ) italic_V start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG italic_\u03b4 end_ARG start_ARG italic_\u03b4 italic_x start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG satisfy the norm bounds by F\u2062(U)+F\u2062(\ud835\udcaf)+F*\u2062(d\u2062i\u2062v\u2062C\u2062(V))\u2264K0\ud835\udc39\ud835\udc48\ud835\udc39\ud835\udcafsuperscript\ud835\udc39\ud835\udc51\ud835\udc56\ud835\udc63\ud835\udc36\ud835\udc49subscript\ud835\udc3e0F(U)+F(\\mathcal{T})+F^{*}(divC(V))\\leq K_{0}italic_F ( italic_U ) + italic_F ( caligraphic_T ) + italic_F start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_d italic_i italic_v italic_C ( italic_V ) ) \u2264 italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Then, by setting l=K/C\u2062(N,\u03b1)\ud835\udc59\ud835\udc3e\ud835\udc36\ud835\udc41\ud835\udefcl=K/C(N,\\alpha)italic_l = italic_K / italic_C ( italic_N , italic_\u03b1 ) with C\u2062(N,\u03b1)=N+(\u03b1\u22121)\u2062n\u2212\u03b1\ud835\udc36\ud835\udc41\ud835\udefc\ud835\udc41\ud835\udefc1\ud835\udc5b\ud835\udefcC(N,\\alpha)=N+(\\alpha-1)n-\\alphaitalic_C ( italic_N , italic_\u03b1 ) = italic_N + ( italic_\u03b1 - 1 ) italic_n - italic_\u03b1, wherever r\ud835\udc5fritalic_r is C2superscript\ud835\udc362C^{2}italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, the nonlinear Laplacian of r\ud835\udc5fritalic_r with reference vector V\ud835\udc49Vitalic_V satisfies . In this section, we will focus on the global gradient estimates of positive solutions to the Fisher-KPP equation (1.1) on compact Finsler manifolds, with the weighted Ricci curvature bounded from below. This condition of curvature is extensively employed within the realm of Finsler geometric analysis. Suppose that u\ud835\udc62uitalic_u is a positive solution on M\u00d7[0,\u221e)\ud835\udc400M\\times[0,\\infty)italic_M \u00d7 [ 0 , \u221e ) to the Fisher-KPP equation(1.1) . We define the function W\u2062(x,t)=u\u2212q\ud835\udc4a\ud835\udc65\ud835\udc61superscript\ud835\udc62\ud835\udc5eW(x,t)=u^{-q}italic_W ( italic_x , italic_t ) = italic_u start_POSTSUPERSCRIPT - italic_q end_POSTSUPERSCRIPT, where q\ud835\udc5eqitalic_q is a positive constant to be fixed later. We now have the following lemma. Let u\ud835\udc62uitalic_u be a positive solution on M\u00d7[0,\u221e)\ud835\udc400M\\times[0,\\infty)italic_M \u00d7 [ 0 , \u221e ) to the Fisher-KPP equation (1.1) and W\u2062(x,t)=u\u2212q\ud835\udc4a\ud835\udc65\ud835\udc61superscript\ud835\udc62\ud835\udc5eW(x,t)=u^{-q}italic_W ( italic_x , italic_t ) = italic_u start_POSTSUPERSCRIPT - italic_q end_POSTSUPERSCRIPT, then W\ud835\udc4aWitalic_W satisfies that The gradient of W\ud835\udc4aWitalic_W with respect to \u2207u\u2207\ud835\udc62\\nabla u\u2207 italic_u is the dual of dW\ud835\udc4aWitalic_W by the pull-back metric g\u2207usubscript\ud835\udc54\u2207\ud835\udc62g_{\\nabla u}italic_g start_POSTSUBSCRIPT \u2207 italic_u end_POSTSUBSCRIPT. Precisely, \u2207W=\u2212q\u2062u\u2212q\u22121\u2062\u2207u\u2207\ud835\udc4a\ud835\udc5esuperscript\ud835\udc62\ud835\udc5e1\u2207\ud835\udc62\\nabla W=-qu^{-q-1}\\nabla u\u2207 italic_W = - italic_q italic_u start_POSTSUPERSCRIPT - italic_q - 1 end_POSTSUPERSCRIPT \u2207 italic_u on M\ud835\udc40Mitalic_M and Wt=\u2212q\u2062u\u2212q\u22121\u2062utsubscript\ud835\udc4a\ud835\udc61\ud835\udc5esuperscript\ud835\udc62\ud835\udc5e1subscript\ud835\udc62\ud835\udc61W_{t}=-qu^{-q-1}u_{t}italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = - italic_q italic_u start_POSTSUPERSCRIPT - italic_q - 1 end_POSTSUPERSCRIPT italic_u start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, so we have Then we deduce that in the distributional sense on Musubscript\ud835\udc40\ud835\udc62M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT, wherever \u2207u\u22600\u2207\ud835\udc620\\nabla u\\neq 0\u2207 italic_u \u2260 0 Combine with (1.1) and (3.2), we have After the transformation, we obtain the Lemma 3.1.\n\u220e Now, we follow the line in [19]. Define three functions as the follow. where a\ud835\udc4eaitalic_a, \u03b2\ud835\udefd\\betaitalic_\u03b2 are two positive constants to be determined later. Direct calculations provide that and on Musubscript\ud835\udc40\ud835\udc62M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT, where we have employed the Ricci-type identity in [33]. On the other hand, it satisfies that and Plugging (3.10) and (3.11) into (3.9) yields wherever \u2207u\u22600\u2207\ud835\udc620\\nabla u\\neq 0\u2207 italic_u \u2260 0.\nBy a basic computation of Finsler geometry, we could get where we have already employed the fact that C\u2062(\u2207u,\u22c5,\u22c5)=0\ud835\udc36\u2207\ud835\udc62\u22c5\u22c50C(\\nabla u,\\cdot,\\cdot)=0italic_C ( \u2207 italic_u , \u22c5 , \u22c5 ) = 0 and C\u22072u\u2207u\u2062(\u2207\u2207uH0)=u|ik\u2062Cki\u2062j\u2062(\u2207u)\u2062HjC_{\\nabla^{2}u}^{\\nabla u}(\\nabla^{\\nabla u}H_{0})=u_{|i}^{k}C_{k}^{ij}(\\nabla\nu%\n)H_{j}italic_C start_POSTSUBSCRIPT \u2207 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT ( \u2207 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = italic_u start_POSTSUBSCRIPT | italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i italic_j end_POSTSUPERSCRIPT ( \u2207 italic_u ) italic_H start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. The notation \u201c||||\u201d denotes the horizontal derivative with respect to the Chern connection in the direction \u2207u\u2207\ud835\udc62\\nabla u\u2207 italic_u. It follows from that (3.13) is equal to Combining it with (3.12), we could find that by noticing that Therefore, H0\u2062(x,t)subscript\ud835\udc3b0\ud835\udc65\ud835\udc61H_{0}(x,t)italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_x , italic_t ) satisfies that Because of\n\u2207Wt=(\u2207W)t\u2207subscript\ud835\udc4a\ud835\udc61subscript\u2207\ud835\udc4a\ud835\udc61\\nabla W_{t}=(\\nabla W)_{t}\u2207 italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( \u2207 italic_W ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT,\nit follows for \u2207\u2207uH1superscript\u2207\u2207\ud835\udc62subscript\ud835\udc3b1\\nabla^{\\nabla u}H_{1}\u2207 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT italic_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT that It asserts by direct caiculation that arccording to [32]. Thus,\nfor H1subscript\ud835\udc3b1H_{1}italic_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, one may find that so that Moreover, one could calculate that as well as Plugging (3.22)-(3.24) into (3.16) and (3.17) yields It asserts from the h\u00f6lder inequality that Thus, when 0<\u03b5<10\ud835\udf0010<\\varepsilon<10 < italic_\u03b5 < 1, it satisfies that According to the equality (a+b)2n=a2N\u2212b2N\u2212n+N\u2062(N\u2212n)n\u2062(aN+bN\u2212b)2superscript\ud835\udc4e\ud835\udc4f2\ud835\udc5bsuperscript\ud835\udc4e2\ud835\udc41superscript\ud835\udc4f2\ud835\udc41\ud835\udc5b\ud835\udc41\ud835\udc41\ud835\udc5b\ud835\udc5bsuperscript\ud835\udc4e\ud835\udc41\ud835\udc4f\ud835\udc41\ud835\udc4f2\\frac{(a+b)^{2}}{n}=\\frac{a^{2}}{N}-\\frac{b^{2}}{N-n}+\\frac{N(N-n)}{n}(\\frac{a%\n}{N}+\\frac{b}{N-b})^{2}divide start_ARG ( italic_a + italic_b ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_n end_ARG = divide start_ARG italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_N end_ARG - divide start_ARG italic_b start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_N - italic_n end_ARG + divide start_ARG italic_N ( italic_N - italic_n ) end_ARG start_ARG italic_n end_ARG ( divide start_ARG italic_a end_ARG start_ARG italic_N end_ARG + divide start_ARG italic_b end_ARG start_ARG italic_N - italic_b end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, for any N>n\ud835\udc41\ud835\udc5bN>nitalic_N > italic_n, the following inequality holds by substituting a\ud835\udc4eaitalic_a, b\ud835\udc4fbitalic_b and N\ud835\udc41Nitalic_N by \u0394\u2207u\u2062Wsuperscript\u0394\u2207\ud835\udc62\ud835\udc4a\\Delta^{\\nabla u}Wroman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT italic_W, S\u02d9\u2062(\u2207\u2207uW)\u02d9\ud835\udc46superscript\u2207\u2207\ud835\udc62\ud835\udc4a\\dot{S}(\\nabla^{\\nabla u}W)over\u02d9 start_ARG italic_S end_ARG ( \u2207 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT italic_W ) and N\u2212\u03b5\u2062(N\u2212n)\ud835\udc41\ud835\udf00\ud835\udc41\ud835\udc5bN-\\varepsilon(N-n)italic_N - italic_\u03b5 ( italic_N - italic_n ), respectively. Namely, so that Moreover, it\u2019s easy to infer that It is deduced from (3.25) by combining (3.27)-(3.30) and employing the definition of weighted Ricci curvature that on Musubscript\ud835\udc40\ud835\udc62M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT. Let \u03b2=aq\ud835\udefd\ud835\udc4e\ud835\udc5e\\beta=\\frac{a}{q}italic_\u03b2 = divide start_ARG italic_a end_ARG start_ARG italic_q end_ARG, combining with (3.21), we have Noticing \u0394\u2207u\u2062WW=qa\u2062H+(q+1q\u2212qa)\u2062F\u2207u2\u2062(\u2207\u2207uW)W2superscript\u0394\u2207\ud835\udc62\ud835\udc4a\ud835\udc4a\ud835\udc5e\ud835\udc4e\ud835\udc3b\ud835\udc5e1\ud835\udc5e\ud835\udc5e\ud835\udc4esubscriptsuperscript\ud835\udc392\u2207\ud835\udc62superscript\u2207\u2207\ud835\udc62\ud835\udc4asuperscript\ud835\udc4a2\\frac{\\Delta^{\\nabla u}W}{W}=\\frac{q}{a}H+({\\frac{q+1}{q}}-\\frac{q}{a})\\frac{F%\n^{2}_{\\nabla u}(\\nabla^{\\nabla u}W)}{W^{2}}divide start_ARG roman_\u0394 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT italic_W end_ARG start_ARG italic_W end_ARG = divide start_ARG italic_q end_ARG start_ARG italic_a end_ARG italic_H + ( divide start_ARG italic_q + 1 end_ARG start_ARG italic_q end_ARG - divide start_ARG italic_q end_ARG start_ARG italic_a end_ARG ) divide start_ARG italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u2207 italic_u end_POSTSUBSCRIPT ( \u2207 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT italic_W ) end_ARG start_ARG italic_W start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG, and setting a=s\u2062q2\ud835\udc4e\ud835\udc60superscript\ud835\udc5e2a=sq^{2}italic_a = italic_s italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, we get that Plugging it into (3.32), we arrive at the following lemma. Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a forward complete Finsler metric measure space, and denote Mu={x\u2208M\u2223\u2207u\u2062(x)\u22600}subscript\ud835\udc40\ud835\udc62conditional-set\ud835\udc65\ud835\udc40normal-\u2207\ud835\udc62\ud835\udc650M_{u}=\\{x\\in M\\mid\\nabla u(x)\\neq 0\\}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT = { italic_x \u2208 italic_M \u2223 \u2207 italic_u ( italic_x ) \u2260 0 }. For H=F\u2207u2\u2062(\u2207\u2207uW)W2+a\u2062c\u2062(1\u2212W\u22121q)+\u03b2\u2062WtW\ud835\udc3bsubscriptsuperscript\ud835\udc392normal-\u2207\ud835\udc62superscriptnormal-\u2207normal-\u2207\ud835\udc62\ud835\udc4asuperscript\ud835\udc4a2\ud835\udc4e\ud835\udc501superscript\ud835\udc4a1\ud835\udc5e\ud835\udefdsubscript\ud835\udc4a\ud835\udc61\ud835\udc4aH=\\frac{F^{2}_{\\nabla u}(\\nabla^{\\nabla u}W)}{W^{2}}+ac(1-W^{-\\frac{1}{q}})+%\n\\beta\\frac{W_{t}}{W}italic_H = divide start_ARG italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u2207 italic_u end_POSTSUBSCRIPT ( \u2207 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT italic_W ) end_ARG start_ARG italic_W start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG + italic_a italic_c ( 1 - italic_W start_POSTSUPERSCRIPT - divide start_ARG 1 end_ARG start_ARG italic_q end_ARG end_POSTSUPERSCRIPT ) + italic_\u03b2 divide start_ARG italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG italic_W end_ARG with a=s\u2062q2\ud835\udc4e\ud835\udc60superscript\ud835\udc5e2a=sq^{2}italic_a = italic_s italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, \u03b2=aq\ud835\udefd\ud835\udc4e\ud835\udc5e\\beta=\\frac{a}{q}italic_\u03b2 = divide start_ARG italic_a end_ARG start_ARG italic_q end_ARG, it satisfies on Musubscript\ud835\udc40\ud835\udc62M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT that Employing Lemma 3.2, the following global gradient estimate theorem could be obtained by utilizing the maximum principle argument, which was first adopted in [27] and was applied also in [32][31]. Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a compact Finsler metric measure manifold whose weighted Ricci curvature satisfies R\u2062i\u2062cN\u2265\u2212K\ud835\udc45\ud835\udc56superscript\ud835\udc50\ud835\udc41\ud835\udc3eRic^{N}\\geq-Kitalic_R italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2265 - italic_K, for some positive constant K\ud835\udc3eKitalic_K. Assume the bound of the reversibility on M\ud835\udc40Mitalic_M is \u03c10subscript\ud835\udf0c0\\rho_{0}italic_\u03c1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Suppose u\u2062(x,t)\ud835\udc62\ud835\udc65\ud835\udc61u(x,t)italic_u ( italic_x , italic_t ) is a bounded positive smooth solution of the Fisher-KPP parabolic equation (1.1) on M\u00d7[0,\u221e)\ud835\udc400M\\times[0,\\infty)italic_M \u00d7 [ 0 , \u221e ), then we have where, 0<\u03b5<10\ud835\udf0010<\\varepsilon<10 < italic_\u03b5 < 1, s>1\ud835\udc601s>1italic_s > 1, q>0\ud835\udc5e0q>0italic_q > 0, such that 2\u2062(1\u2212\u03b5)N\u2212\u03b5\u2062(N\u2212n)\u2062s\u22121s\u2062q\u22651\u03b5\u22121+(2\u2062s\u22121)2821\ud835\udf00\ud835\udc41\ud835\udf00\ud835\udc41\ud835\udc5b\ud835\udc601\ud835\udc60\ud835\udc5e1\ud835\udf001superscript2\ud835\udc60128\\frac{2(1-\\varepsilon)}{N-\\varepsilon(N-n)}\\frac{s-1}{sq}\\geq\\frac{1}{%\n\\varepsilon}-1+\\frac{(2s-1)^{2}}{8}divide start_ARG 2 ( 1 - italic_\u03b5 ) end_ARG start_ARG italic_N - italic_\u03b5 ( italic_N - italic_n ) end_ARG divide start_ARG italic_s - 1 end_ARG start_ARG italic_s italic_q end_ARG \u2265 divide start_ARG 1 end_ARG start_ARG italic_\u03b5 end_ARG - 1 + divide start_ARG ( 2 italic_s - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 8 end_ARG, and M1=supu\u2062(x,t)subscript\ud835\udc401supremum\ud835\udc62\ud835\udc65\ud835\udc61M_{1}=\\sup u(x,t)italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = roman_sup italic_u ( italic_x , italic_t ). Lemma 3.34 implies that (3.34) holds in the distributional sense on M\ud835\udc40Mitalic_M. For any nonnegative test function \u03c6\ud835\udf11\\varphiitalic_\u03c6, we have where \u03b2\ud835\udefd\\betaitalic_\u03b2 denotes the RHS of (3.34). Assume y0=(x0,t0)\u2208B\u2062(p,2\u2062R)\u00d7[0,\u221e)subscript\ud835\udc660subscript\ud835\udc650subscript\ud835\udc610\ud835\udc35\ud835\udc5d2\ud835\udc450y_{0}=(x_{0},t_{0})\\in B(p,2R)\\times[0,\\infty)italic_y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) \u2208 italic_B ( italic_p , 2 italic_R ) \u00d7 [ 0 , \u221e ) be the point where H\ud835\udc3bHitalic_H achieves its maximum. Without loss of generality, we could assume H\u2062(x0,t0)\u22650\ud835\udc3bsubscript\ud835\udc650subscript\ud835\udc6100H(x_{0},t_{0})\\geq 0italic_H ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) \u2265 0, otherwise the result will be satisfied trivially. We claim that \u03b2\u2062(x0,t0)\u22640\ud835\udefdsubscript\ud835\udc650subscript\ud835\udc6100\\beta(x_{0},t_{0})\\leq 0italic_\u03b2 ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) \u2264 0. Otherwise, \u03b2\ud835\udefd\\betaitalic_\u03b2 is strictly positive at (x0,t0)subscript\ud835\udc650subscript\ud835\udc610(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ), so that \u03b2\u2062(x0,t0)\ud835\udefdsubscript\ud835\udc650subscript\ud835\udc610\\beta(x_{0},t_{0})italic_\u03b2 ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) is positive in a small neighborhood of (x0,t0)subscript\ud835\udc650subscript\ud835\udc610(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) on M\ud835\udc40Mitalic_M, which may be denoted by U\ud835\udc48Uitalic_U. Chosen a test function \u03c6\ud835\udf11\\varphiitalic_\u03c6 whose compact support V\ud835\udc49Vitalic_V is contained in U\ud835\udc48Uitalic_U, we know from (3.36) that H\ud835\udc3bHitalic_H is a weak, local subharmonic function in a neighborhood V\u2282U\ud835\udc49\ud835\udc48V\\subset Uitalic_V \u2282 italic_U. It is a contradiction because (x0,t0)subscript\ud835\udc650subscript\ud835\udc610(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) is a inner point of V\ud835\udc49Vitalic_V. Because of \u03b2\u2062(x0,t0)\u22640\ud835\udefdsubscript\ud835\udc650subscript\ud835\udc6100\\beta(x_{0},t_{0})\\leq 0italic_\u03b2 ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) \u2264 0 and \u2207\u2207uH\u2062(y0)=0superscript\u2207\u2207\ud835\udc62\ud835\udc3bsubscript\ud835\udc6600\\nabla^{\\nabla u}H(y_{0})=0\u2207 start_POSTSUPERSCRIPT \u2207 italic_u end_POSTSUPERSCRIPT italic_H ( italic_y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = 0, we arrive at It follows from the h\u00f6lder inequality that and where M1=supu\u2062(x)subscript\ud835\udc401supremum\ud835\udc62\ud835\udc65M_{1}=\\sup u(x)italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = roman_sup italic_u ( italic_x ). Now, let q>0\ud835\udc5e0q>0italic_q > 0 such that 2\u2062(1\u2212\u03b5)N\u2212\u03b5\u2062(N\u2212n)\u2062s\u22121s\u2062q\u22651\u03b5\u22121+(2\u2062s\u22121)2821\ud835\udf00\ud835\udc41\ud835\udf00\ud835\udc41\ud835\udc5b\ud835\udc601\ud835\udc60\ud835\udc5e1\ud835\udf001superscript2\ud835\udc60128\\frac{2(1-\\varepsilon)}{N-\\varepsilon(N-n)}\\frac{s-1}{sq}\\geq\\frac{1}{%\n\\varepsilon}-1+\\frac{(2s-1)^{2}}{8}divide start_ARG 2 ( 1 - italic_\u03b5 ) end_ARG start_ARG italic_N - italic_\u03b5 ( italic_N - italic_n ) end_ARG divide start_ARG italic_s - 1 end_ARG start_ARG italic_s italic_q end_ARG \u2265 divide start_ARG 1 end_ARG start_ARG italic_\u03b5 end_ARG - 1 + divide start_ARG ( 2 italic_s - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 8 end_ARG. Combining with (3.37), we get Hence we achieve the global gradient estimates on compact Finsler manifolds.\n\u220e Theorem 1.1 follows by taking \u03b5=12\ud835\udf0012\\varepsilon=\\frac{1}{2}italic_\u03b5 = divide start_ARG 1 end_ARG start_ARG 2 end_ARG , s=2\ud835\udc602s=2italic_s = 2, q=227\u2062(N+n)\ud835\udc5e227\ud835\udc41\ud835\udc5bq=\\frac{2}{27(N+n)}italic_q = divide start_ARG 2 end_ARG start_ARG 27 ( italic_N + italic_n ) end_ARG in Theorem 3.1 . In this section, we prove the local gradient estimates on forward complete Finsler metric measure spaces with the assistance of Lemma 3.34 and the Comparison theorem (cf. Theorem 2.1). Let (M,F,\u03bc)\ud835\udc40\ud835\udc39\ud835\udf07(M,F,\\mu)( italic_M , italic_F , italic_\u03bc ) be a complete noncompact Finsler metric measure space. Denote by B\u2062(p,2\u2062R)\ud835\udc35\ud835\udc5d2\ud835\udc45B(p,2R)italic_B ( italic_p , 2 italic_R ) the forward geodesic ball centered at p\ud835\udc5dpitalic_p with forward radius 2\u2062R2\ud835\udc452R2 italic_R. Suppose the mixed weighted Ricci curvature Rm\u2062i\u2062cN\u2265\u2212K\u2062(2\u2062R)superscript\ud835\udc45\ud835\udc5a\ud835\udc56superscript\ud835\udc50\ud835\udc41\ud835\udc3e2\ud835\udc45{}^{m}Ric^{N}\\geq-K(2R)start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2265 - italic_K ( 2 italic_R ) in B\u2062(p,2\u2062R)\ud835\udc35\ud835\udc5d2\ud835\udc45B(p,2R)italic_B ( italic_p , 2 italic_R ) with K\u2062(2\u2062R)\u22650\ud835\udc3e2\ud835\udc450K(2R)\\geq 0italic_K ( 2 italic_R ) \u2265 0, and the misalignment \u03b1\ud835\udefc\\alphaitalic_\u03b1 satisfies \u03b1\u2264A\u2062(2\u2062R)\ud835\udefc\ud835\udc342\ud835\udc45\\alpha\\leq A(2R)italic_\u03b1 \u2264 italic_A ( 2 italic_R ) in B\u2062(p,2\u2062R)\ud835\udc35\ud835\udc5d2\ud835\udc45B(p,2R)italic_B ( italic_p , 2 italic_R ). Moreover, the non-Riemannian tensors satisfy F\u2062(U)+F*\u2062(\ud835\udcaf)+F\u2062(d\u2062i\u2062v\u2062C\u2062(V))\u2264K0\ud835\udc39\ud835\udc48superscript\ud835\udc39\ud835\udcaf\ud835\udc39\ud835\udc51\ud835\udc56\ud835\udc63\ud835\udc36\ud835\udc49subscript\ud835\udc3e0F(U)+F^{*}(\\mathcal{T})+F(divC(V))\\leq K_{0}italic_F ( italic_U ) + italic_F start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( caligraphic_T ) + italic_F ( italic_d italic_i italic_v italic_C ( italic_V ) ) \u2264 italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Assume u\u2062(x,t)\ud835\udc62\ud835\udc65\ud835\udc61u(x,t)italic_u ( italic_x , italic_t ) is a bounded positive smooth solution of the Fisher-KPP parabolic equation (1.1) on M\u00d7[0,\u221e)\ud835\udc400M\\times[0,\\infty)italic_M \u00d7 [ 0 , \u221e ), then we have on B\u2062(p,R)\ud835\udc35\ud835\udc5d\ud835\udc45B(p,R)italic_B ( italic_p , italic_R ) for 0<\u03b5<10\ud835\udf0010<\\varepsilon<10 < italic_\u03b5 < 1, s>1\ud835\udc601s>1italic_s > 1, q>0\ud835\udc5e0q>0italic_q > 0, such that 2\u2062(1\u2212\u03b5)N\u2212\u03b5\u2062(N\u2212n)\u2062s\u22121s\u2062q\u22651\u03b5\u22121+(2\u2062s\u22121)2821\ud835\udf00\ud835\udc41\ud835\udf00\ud835\udc41\ud835\udc5b\ud835\udc601\ud835\udc60\ud835\udc5e1\ud835\udf001superscript2\ud835\udc60128\\frac{2(1-\\varepsilon)}{N-\\varepsilon(N-n)}\\frac{s-1}{sq}\\geq\\frac{1}{%\n\\varepsilon}-1+\\frac{(2s-1)^{2}}{8}divide start_ARG 2 ( 1 - italic_\u03b5 ) end_ARG start_ARG italic_N - italic_\u03b5 ( italic_N - italic_n ) end_ARG divide start_ARG italic_s - 1 end_ARG start_ARG italic_s italic_q end_ARG \u2265 divide start_ARG 1 end_ARG start_ARG italic_\u03b5 end_ARG - 1 + divide start_ARG ( 2 italic_s - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 8 end_ARG, where C1subscript\ud835\udc361C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, C2subscript\ud835\udc362C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are positive constants. In noncompact situation, we choose the cut-off function \u03c6~\u2208C2\u2062[0,+\u221e)~\ud835\udf11superscript\ud835\udc3620\\tilde{\\varphi}\\in C^{2}[0,+\\infty)over~ start_ARG italic_\u03c6 end_ARG \u2208 italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT [ 0 , + \u221e ), such that So \u03c6~\u2062(r)\u2208[0,1]~\ud835\udf11\ud835\udc5f01\\tilde{\\varphi}(r)\\in[0,1]over~ start_ARG italic_\u03c6 end_ARG ( italic_r ) \u2208 [ 0 , 1 ].\nIn addition, we supposed that where C1,C2subscript\ud835\udc361subscript\ud835\udc362C_{1},C_{2}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are positive constants. For a fixed point p\ud835\udc5dpitalic_p, denote by r\u2062(x)\ud835\udc5f\ud835\udc65r(x)italic_r ( italic_x ) the forward distance function from p\ud835\udc5dpitalic_p to any point x\ud835\udc65xitalic_x. We define the cut-off function by \u03c6\u2062(x)=\u03c6~\u2062(r\u2062(x)R)\ud835\udf11\ud835\udc65~\ud835\udf11\ud835\udc5f\ud835\udc65\ud835\udc45\\varphi(x)=\\tilde{\\varphi}(\\frac{r(x)}{R})italic_\u03c6 ( italic_x ) = over~ start_ARG italic_\u03c6 end_ARG ( divide start_ARG italic_r ( italic_x ) end_ARG start_ARG italic_R end_ARG ).\nSo that According to the curvature conditions and the Laplacian comparison theorem on forward complete Finsler manifolds, it satisfies the Laplacian estimation [32] that where C3=C3\u2062(N,A,K0)subscript\ud835\udc363subscript\ud835\udc363\ud835\udc41\ud835\udc34subscript\ud835\udc3e0C_{3}=C_{3}(N,A,K_{0})italic_C start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = italic_C start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_N , italic_A , italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) is a constant depending on K0subscript\ud835\udc3e0K_{0}italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, N\ud835\udc41Nitalic_N and A\ud835\udc34Aitalic_A. Defining Z=t\u2062H\u2062(x,t)\ud835\udc4d\ud835\udc61\ud835\udc3b\ud835\udc65\ud835\udc61Z=tH(x,t)italic_Z = italic_t italic_H ( italic_x , italic_t ), we suppose that the support of function \u03c6\u2062(x)\u2062Z\u2062(x,t)\ud835\udf11\ud835\udc65\ud835\udc4d\ud835\udc65\ud835\udc61\\varphi(x)Z(x,t)italic_\u03c6 ( italic_x ) italic_Z ( italic_x , italic_t ) is contained in Bp\u2062(2\u2062R)subscript\ud835\udc35\ud835\udc5d2\ud835\udc45B_{p}(2R)italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 2 italic_R ). For any fixed T>0\ud835\udc470T>0italic_T > 0, let (x0,t0)subscript\ud835\udc650subscript\ud835\udc610(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) be the point where \u03c6\u2062(x)\u2062Z\u2062(x,t)\ud835\udf11\ud835\udc65\ud835\udc4d\ud835\udc65\ud835\udc61\\varphi(x)Z(x,t)italic_\u03c6 ( italic_x ) italic_Z ( italic_x , italic_t ) achieves its positive maximum, at which it satisfies that (4.6) implies that and at the maximum point (x0,t0)subscript\ud835\udc650subscript\ud835\udc610(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ).\nLet \u03b2=aq\ud835\udefd\ud835\udc4e\ud835\udc5e\\beta=\\frac{a}{q}italic_\u03b2 = divide start_ARG italic_a end_ARG start_ARG italic_q end_ARG, a=s\u2062q2\ud835\udc4e\ud835\udc60superscript\ud835\udc5e2a=sq^{2}italic_a = italic_s italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, employing Lemma 3.34, we have It follows from the h\u00f6lder inequality that and Substituting (4.10) and (4.11) into (4.9), and choosing s>1\ud835\udc601s>1italic_s > 1, q>0\ud835\udc5e0q>0italic_q > 0, such that 2\u2062(1\u2212\u03b5)n\u2062s\u22121s\u2062q\u22651\u03b5\u22121+(2\u2062s\u22121)2821\ud835\udf00\ud835\udc5b\ud835\udc601\ud835\udc60\ud835\udc5e1\ud835\udf001superscript2\ud835\udc60128\\frac{2(1-\\varepsilon)}{n}\\frac{s-1}{sq}\\geq\\frac{1}{\\varepsilon}-1+\\frac{(2s-%\n1)^{2}}{8}divide start_ARG 2 ( 1 - italic_\u03b5 ) end_ARG start_ARG italic_n end_ARG divide start_ARG italic_s - 1 end_ARG start_ARG italic_s italic_q end_ARG \u2265 divide start_ARG 1 end_ARG start_ARG italic_\u03b5 end_ARG - 1 + divide start_ARG ( 2 italic_s - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 8 end_ARG, one may find that Substituting (4.12) into (4.8) and noticing (4.7), we have It\u2019s easy to know that Multiplying through by t\u2062\u03c6\ud835\udc61\ud835\udf11t\\varphiitalic_t italic_\u03c6 at (4.13) and utilizing (4.14), we get that which implies that is satisfied at (x0,t0)subscript\ud835\udc650subscript\ud835\udc610(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ). Clearly, corresponding to the assumption of (x0,t0)subscript\ud835\udc650subscript\ud835\udc610(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ), one can deduce that Recall a result that, if a1,a2,a3\u22650subscript\ud835\udc4e1subscript\ud835\udc4e2subscript\ud835\udc4e30a_{1},a_{2},a_{3}\\geq 0italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2265 0 then a1\u2062a2+a3\u2264a1\u2062a2+a1\u2062a3subscript\ud835\udc4e1subscript\ud835\udc4e2subscript\ud835\udc4e3subscript\ud835\udc4e1subscript\ud835\udc4e2subscript\ud835\udc4e1subscript\ud835\udc4e3\\sqrt{a_{1}}\\sqrt{a_{2}+a_{3}}\\leq\\sqrt{a_{1}a_{2}}+\\sqrt{a_{1}a_{3}}square-root start_ARG italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG square-root start_ARG italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG \u2264 square-root start_ARG italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG + square-root start_ARG italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG. Thus, on B\u2062(p,2\u2062R)\ud835\udc35\ud835\udc5d2\ud835\udc45B(p,2R)italic_B ( italic_p , 2 italic_R ), which is the desired inequality.\n\u220e Theorem 1.2 follows from Theorem 4.1 directly."
    },
    {
        "id": 13,
        "title": "Radical Pair Mechanism and the Role of Chirality-Induced Spin Selectivity during Planaria Regeneration: Effect of Weak Magnetic Field on ROS levels",
        "corpus": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on. Authors: achieve the best HTML results from your LaTeX submissions by following these best practices. Planarian is an intriguing model system wherein the effect of electric and magnetic fields can be studied on various biochemical pathways during cell morphogenesis. Recent experimental observations have demonstrated the non-trivial modulation of reactive oxygen species (ROS) levels by weak magnetic field during planaria regeneration. However, the underlying biophysical mechanism behind this remains elusive.\nIn this paper, we study the radical pair mechanism to explain the effect of weak magnetic fields on ROS modulation during planaria regeneration to explain the experimental results. We also investigate the effect of chirality-induced spin selectivity (CISS) on ROS levels by including it in the framework of the radical pair mechanism. We conclude that the inclusion of CISS not only explains the experimental results better but also allows for the radical pair model to have more parametric space to satisfy the experimental constraints. This study explains the crucial process of ROS modulation by the weak magnetic field with and without CISS thereby paving the way to unravel the vast domain of ROS modulation for desired outcomes. Several research studies emphasize the significant impact of electromagnetic fields on diverse biological processes and systems [1, 2, 3]. Morphogenesis, a biological process, is affected by electromagnetic fields, with planarians serving as a notable model for comprehending morphogenesis and cell communication. Planarians, recognized for their exceptional regenerative abilities, are often studied in this context \u00a0[4, 5, 6, 7, 8, 9].\nPlanaria\u2019s impressive regenerative ability is due to the presence of a set of robust adult stem cells known as neoblasts. Once injured, these cells migrate to the injured site and form a specialized structure known as a blastema. The blastema subsequently undergoes multiplication and transformation, regenerating the lost body parts like the head, trunk, or tail [10, 11, 12, 13, 14]. The formation of the blastema is influenced by specific signaling molecules known as reactive oxygen species (ROS). Blocking and activation of these molecules contribute to the change in the formation of blastema. Consequently, this impacts the growth of new tissues and affects the process of planarian regeneration [15, 16, 17].\nRecent insights into how living organisms interact with electromagnetic radiation indicate the possibility of discovering novel techniques for controlling ROS within the body using weak magnetic fields (WMFs)\u00a0[17]. However, the exact biophysical mechanism behind the effect of weak magnetic fields on ROS levels is not fully known. Radical pair mechanism has been proposed to elucidate the impact of weak magnetic fields on modulation of ROS levels\u00a0[18, 19, 20, 21, 22, 23, 24, 25].\nMore generally, the radical pair mechanism (RPM) has emerged as a prominent theory explaining the effect of magnetic field on various biological and chemical systems\u00a0[23, 26, 27, 28, 29] In particular, it has been studied in detail for the cryptochrome protein present in bird\u2019s retina and is considered a potential explanation for the avian magnetoreception [30, 31, 32, 33, 34].\nMoreover, it has recently been reported that CISS might play a role in conjunction with radical pairs in birds for the navigational compass [35, 36, 37]. The radical pair mechanism involves electron transport steps during the formation and recombination\u00a0[32, 38, 39]. This involves the movement of electrons through protein molecules. Owing to the chirality of protein molecules, the chiral-induced spin selectivity (CISS) effect could play an essential role in the electron transport part of the reaction. Although the exact role of CISS in the avian magnetoreception has been debated, there are strong evidence in support of its presence in various biochemical reactions involving electron transfer or rearrangement in chiral molecules\u00a0[40, 41, 42, 43, 44]. The origin of CISS is attributed to the spin-orbit interaction and the electrostatic potential provided by the chiral molecules\u00a0[45, 46, 47, 48, 49, 50, 51, 52]. \nIn this work, we examine the radical pair mechanism in light of recent experimental work pertaining to ROS level modulation by the weak magnetic field\u00a0[53]. Furthermore, we also investigate the effect of chirality-induced spin selectivity (CISS) in the modulation of Reactive Oxygen Species (ROS) in the planarian system. To achieve this, we establish a theoretical model of the CISS-assisted radical pair mechanism, aligning our simulated results with experimental data [17]. Our investigation of the CISS-assisted radical pair mechanism is structured around three key considerations: 1) the absolute yield of the reaction, 2) the ratio of yield values at the experimental point of interest, and 3) the number of nuclei configurations that adhere to the experimental trend. Additionally, we explore two scenarios: 1) CISS presence exclusively during the formation of radicals and 2) CISS presence during both the formation and recombination of radical pairs.\nThe manuscript has been organized as follows: Section\u00a0II discusses the simulation methodology followed for analysis. Section \u00a0III discusses the results, where subsection\u00a0III.1 discusses the RP model with no CISS subsection\u00a0III.2 discusses the RP model with CISS, subsection\u00a0III.3 explores the impact of singlet and triplet recombination rate on planaria regeneration and \u00a0III.4 discuss a system with higher number of nuclei. Finally, we discuss the shortcomings and conclusions of the study. In the radical pair model of the planaria regeneration, an electron is excited in the acceptor molecule, creating a vacancy in the ground state. Another electron from a neighboring donor molecule travels in the chiral medium to fill this vacancy. It results in the formation of a radical pair. The spin operator of the electron on the donor molecule is S^D\u2062zsubscript^\ud835\udc46\ud835\udc37\ud835\udc67\\hat{S}_{Dz}over^ start_ARG italic_S end_ARG start_POSTSUBSCRIPT italic_D italic_z end_POSTSUBSCRIPT and on the acceptor molecule is S^A\u2062zsubscript^\ud835\udc46\ud835\udc34\ud835\udc67\\hat{S}_{Az}over^ start_ARG italic_S end_ARG start_POSTSUBSCRIPT italic_A italic_z end_POSTSUBSCRIPT. Therefore, the spin state of the above-formed radical pair is governed by the following Hamiltonian\u00a0[54, 31, 37] where \u03c9=g\u2062\u03bcB\u00af\u2062B\u00af\ud835\udf14\ud835\udc54\u00afsubscript\ud835\udf07\ud835\udc35\u00af\ud835\udc35\\omega=g\\bar{\\mu_{B}}\\bar{B}italic_\u03c9 = italic_g over\u00af start_ARG italic_\u03bc start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT end_ARG over\u00af start_ARG italic_B end_ARG, B\u00af=B0\u2062z\u00af\u00af\ud835\udc35subscript\ud835\udc350\u00af\ud835\udc67\\bar{B}=B_{0}\\bar{z}over\u00af start_ARG italic_B end_ARG = italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT over\u00af start_ARG italic_z end_ARG where B0subscript\ud835\udc350B_{0}italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT corresponds to the applied magnetic field. J\ud835\udc3dJitalic_J and D\ud835\udc37Ditalic_D are the exchange and dipolar interactions. A\ud835\udc34Aitalic_A is the hyperfine tensor depicting interactions between electrons and neighboring nuclear spins. The spin state of the radical pair evolves under the zeeman and hyperfine interactions. Along with this evolution, the radical pair also recombines back to the singlet yield and triplet yield shown in Fig.\u00a01. The singlet yield corresponds to the ground state while the triplet state corresponds to reactive oxygen species(ROS) concentrationFig.\u00a01).\nThe radical pair formation begins with the donor molecule (D) and the acceptor molecule (A) in their ground states. The reaction initiates with the excitation of\nthe acceptor molecule, causing an electron to transition to a higher energy state and leaving a vacancy in the ground state of the acceptor molecule. Electron transfer occurs from the ground state of the donor molecule to fill the vacancy in the ground state of the acceptor molecule. This leads to the formation of the radical pair on donor ion D.+D^{.+}italic_D start_POSTSUPERSCRIPT . + end_POSTSUPERSCRIPT and acceptor ion A.\u2212A^{.-}italic_A start_POSTSUPERSCRIPT . - end_POSTSUPERSCRIPT. Fig,2 illustrates the formation of the radical pair in a chiral medium where the spin state of the electron |\u2193\u27e9ket\u2193\\ket{\\downarrow}| start_ARG \u2193 end_ARG \u27e9 is allowed in the forward propagation of the electron. In a non-chiral case, both |\u2193\u27e9ket\u2193\\ket{\\downarrow}| start_ARG \u2193 end_ARG \u27e9 and |\u2191\u27e9ket\u2191\\ket{\\uparrow}| start_ARG \u2191 end_ARG \u27e9 will be allowed in the formation of the radical pair. \nThe recombination of the radical pair involves the transition from the donor ion D.+D^{.+}italic_D start_POSTSUPERSCRIPT . + end_POSTSUPERSCRIPT and acceptor ion A.\u2212A^{.-}italic_A start_POSTSUPERSCRIPT . - end_POSTSUPERSCRIPT to their respective ground states, as well as the generation of regenerative oxygen species. This process occurs in three stages. Stage 1 is the initial stage where the radical pair is formed. The chirality of the medium allows only the |\u2193\u27e9ket\u2193\\ket{\\downarrow}| start_ARG \u2193 end_ARG \u27e9 state to move from the donor ion D.+D^{.+}italic_D start_POSTSUPERSCRIPT . + end_POSTSUPERSCRIPT to the acceptor ion A.\u2212A^{.-}italic_A start_POSTSUPERSCRIPT . - end_POSTSUPERSCRIPT as illustrated in Fig.2. In Stage 2, the system exists in a superposition of singlet and triplet states. The spins of the isolated electrons on D.+D^{.+}italic_D start_POSTSUPERSCRIPT . + end_POSTSUPERSCRIPT and A.\u2212A^{.-}italic_A start_POSTSUPERSCRIPT . - end_POSTSUPERSCRIPT change due to their interaction with the nuclei (hyperfine interaction). This stage is affected by the system Hamiltonian (Eq.1). In stage 3, because the forward movement allowed the |\u2193\u27e9ket\u2193\\ket{\\downarrow}| start_ARG \u2193 end_ARG \u27e9 state, the |\u2191\u27e9ket\u2191\\ket{\\uparrow}| start_ARG \u2191 end_ARG \u27e9 state will move in the opposite (backward) direction for recombination. This recombination yield leads to the formation of the respective singlet and triplet yield. The triplet yield would contribute towards the ROS signaling, whereas the singlet yield would contribute towards the ground state of the donor and acceptor molecule.\nIn Fig.3, we have illustrated it for a fully chiral medium and how chirality affects the formation of the yield. Due to chirality, since only |\u2191\u27e9ket\u2191\\ket{\\uparrow}| start_ARG \u2191 end_ARG \u27e9 is allowed, we observe that yield formation of the yield of triplet state |\u2193\u2193\u27e9ket\u2193absent\u2193\\ket{\\downarrow\\downarrow}| start_ARG \u2193 \u2193 end_ARG \u27e9\nis inhibited. The CISS effect plays a role in forming (Fig.2) and recombining (Fig.3) the radical pair as it involves electron transport through the chiral protein molecule. Therefore, the action of CISS is captured by the initial state PIsubscript\ud835\udc43\ud835\udc3cP_{I}italic_P start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT and recombination state PSsubscript\ud835\udc43\ud835\udc46P_{S}italic_P start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT and PTsubscript\ud835\udc43\ud835\udc47P_{T}italic_P start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT, shown with red arrows in Fig.\u00a01. Then the initial state density matrix is given as: PI\u2062n\u2062i\u2062t\u2062i\u2062a\u2062l=PI\u2062n\u2297IZsubscript\ud835\udc43\ud835\udc3c\ud835\udc5b\ud835\udc56\ud835\udc61\ud835\udc56\ud835\udc4e\ud835\udc59tensor-productsubscript\ud835\udc43\ud835\udc3c\ud835\udc5b\ud835\udc3c\ud835\udc4dP_{Initial}=P_{In}\\otimes\\frac{I}{Z}italic_P start_POSTSUBSCRIPT italic_I italic_n italic_i italic_t italic_i italic_a italic_l end_POSTSUBSCRIPT = italic_P start_POSTSUBSCRIPT italic_I italic_n end_POSTSUBSCRIPT \u2297 divide start_ARG italic_I end_ARG start_ARG italic_Z end_ARG, where IZ\ud835\udc3c\ud835\udc4d\\frac{I}{Z}divide start_ARG italic_I end_ARG start_ARG italic_Z end_ARG corresponds to the mixed state of nuclei, and Z\ud835\udc4dZitalic_Z is the size of the nuclear Hilbert space. The singlet recombination operator PS=|\u03c8S\u27e9\u2062\u27e8\u03c8S|subscript\ud835\udc43\ud835\udc46ketsubscript\ud835\udf13\ud835\udc46brasubscript\ud835\udf13\ud835\udc46P_{S}={\\ket{\\psi_{S}}\\bra{\\psi_{S}}}italic_P start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = | start_ARG italic_\u03c8 start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT end_ARG \u27e9 \u27e8 start_ARG italic_\u03c8 start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT end_ARG | accounts for recombination to the ground state where: The triplet recombination operator PT=PT++PT\u2212+PT\u20620subscript\ud835\udc43\ud835\udc47subscript\ud835\udc43limit-from\ud835\udc47subscript\ud835\udc43limit-from\ud835\udc47subscript\ud835\udc43\ud835\udc470P_{T}=P_{T+}+P_{T-}+P_{T0}italic_P start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = italic_P start_POSTSUBSCRIPT italic_T + end_POSTSUBSCRIPT + italic_P start_POSTSUBSCRIPT italic_T - end_POSTSUBSCRIPT + italic_P start_POSTSUBSCRIPT italic_T 0 end_POSTSUBSCRIPT accounts for recombination to the reactive oxygen species concentration. PT+subscript\ud835\udc43limit-from\ud835\udc47P_{T+}italic_P start_POSTSUBSCRIPT italic_T + end_POSTSUBSCRIPT correspond to triplet state when net magnetic moment mS=1subscript\ud835\udc5a\ud835\udc461m_{S}=1italic_m start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 1. PT\u2212subscript\ud835\udc43limit-from\ud835\udc47P_{T-}italic_P start_POSTSUBSCRIPT italic_T - end_POSTSUBSCRIPT correspond to triplet state when net magnetic moment mS=\u22121subscript\ud835\udc5a\ud835\udc461m_{S}=-1italic_m start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = - 1 and PT\u20620subscript\ud835\udc43\ud835\udc470P_{T0}italic_P start_POSTSUBSCRIPT italic_T 0 end_POSTSUBSCRIPT correspond to triplet state when net magnetic moment mS=0subscript\ud835\udc5a\ud835\udc460m_{S}=0italic_m start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 0 The CISS parameter \u03c7\u2208[0,\u03c02]\ud835\udf120\ud835\udf0b2\\chi\\in[0,\\frac{\\pi}{2}]italic_\u03c7 \u2208 [ 0 , divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG ] depends on the spin selectivity of the protein medium; \u03c7=0\ud835\udf120\\chi=0italic_\u03c7 = 0 corresponding to no CISS and \u03c7=\u03c0/2\ud835\udf12\ud835\udf0b2\\chi=\\pi/2italic_\u03c7 = italic_\u03c0 / 2 corresponding to the full CISS. The master equation governing the state evolution of the system is given as: Where kSsubscript\ud835\udc58\ud835\udc46k_{S}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT is the singlet recombination rate, and kTsubscript\ud835\udc58\ud835\udc47k_{T}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT is the triplet recombination rate. [A,B]=A\u2062B\u2212B\u2062A\ud835\udc34\ud835\udc35\ud835\udc34\ud835\udc35\ud835\udc35\ud835\udc34[A,B]=AB-BA[ italic_A , italic_B ] = italic_A italic_B - italic_B italic_A correspond to the commutator whereas, {A,B}=A\u2062B+B\u2062A\ud835\udc34\ud835\udc35\ud835\udc34\ud835\udc35\ud835\udc35\ud835\udc34\\{A,B\\}=AB+BA{ italic_A , italic_B } = italic_A italic_B + italic_B italic_A is the anti-commutator. As the literature states, the triplet yield is directly related to reactive oxygen species (ROS) concentration [17, 53]. Consequently, it is crucial to determine how the distribution of triplet yield varies concerning the external magnetic field. Defining the yield product of the triplet state (\u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT) is imperative; therefore, it is defined according to Eq.10. \u03c1\u2062(t)^^\ud835\udf0c\ud835\udc61\\hat{\\rho(t)}over^ start_ARG italic_\u03c1 ( italic_t ) end_ARG is the solution of the master equation Eq.\u00a09, T\u2062r\ud835\udc47\ud835\udc5fTritalic_T italic_r is the trace over the state density matrix \u03c1\ud835\udf0c\\rhoitalic_\u03c1. As reported in [17, 53], the ROS yield follows the following distribution Hence, if RPM dictates the generation of reactive oxygen species (ROS), a plot of triplet yield (\u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT) against the external magnetic field (B0subscript\ud835\udc350B_{0}italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT) should exhibit a strong correlation with the aforementioned experimental findings. In [17, 53], it is documented that the two nuclei involved may be an oxide (O2\u2212\u02d9superscriptsubscript\ud835\udc422\u02d9O_{2}^{\\dot{-}}italic_O start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT over\u02d9 start_ARG - end_ARG end_POSTSUPERSCRIPT) and tryptophan (T\u2062r\u2062p+\u02d9\ud835\udc47\ud835\udc5fsuperscript\ud835\udc5d\u02d9Trp^{\\dot{+}}italic_T italic_r italic_p start_POSTSUPERSCRIPT over\u02d9 start_ARG + end_ARG end_POSTSUPERSCRIPT). The oxygen nucleus in O2\u2212\u02d9superscriptsubscript\ud835\udc422\u02d9O_{2}^{\\dot{-}}italic_O start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT over\u02d9 start_ARG - end_ARG end_POSTSUPERSCRIPT is nonmagnetic and, thus, does not contribute to the hyperfine interaction. Conversely, tryptophan contains multiple magnetic nuclei of nitrogen and hydrogen.\nConsidering the biological context where distances between nuclei and electrons are variable, a parametric approach has been adopted, specifically addressing the hyperfine interaction of tryptophan with an electron. In our initial investigation into the feasibility of the radical pair mechanism, we have defined three quantities that will assist us in our investigation. Based on the experimental results reported in [17, 53], we expect parameters L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT to have values at least greater than 1. We initially perform analysis considering there is no CISS (\u03c7=0\ud835\udf120\\chi=0italic_\u03c7 = 0) in the system and try to ascertain the planaria response to the external magnetic field. In Figure 4, the triplet yield (\u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT) is plotted against the external magnetic field (B0subscript\ud835\udc350B_{0}italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT) for \u03c7=0\ud835\udf120\\chi=0italic_\u03c7 = 0 (no CISS) at kS=108subscript\ud835\udc58\ud835\udc46superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\ud835\udc58\ud835\udc47superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT, with D=0\ud835\udc370D=0italic_D = 0 and J=0\ud835\udc3d0J=0italic_J = 0, under the hyperfine configuration [ax\u2062x,ay\u2062y,az\u2062z]=[0.54,0.06,0.24]\u2062m\u2062Tsubscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc670.540.060.24\ud835\udc5a\ud835\udc47[a_{xx},a_{yy},a_{zz}]=[0.54,0.06,0.24]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0.54 , 0.06 , 0.24 ] italic_m italic_T. The figure highlights points of interest corresponding to experimental conditions in planaria: A\ud835\udc34Aitalic_A for \u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT at 45\u2062\u03bc\u2062T45\ud835\udf07\ud835\udc4745\\mu T45 italic_\u03bc italic_T, B\ud835\udc35Bitalic_B for \u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT at 200\u2062\u03bc\u2062T200\ud835\udf07\ud835\udc47200\\mu T200 italic_\u03bc italic_T, and C\ud835\udc36Citalic_C for \u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT at 500\u2062\u03bc\u2062T500\ud835\udf07\ud835\udc47500\\mu T500 italic_\u03bc italic_T. The experimental plot from references [17, 53] is displayed at the bottom of Figure 4, demonstrating the concentration of reactive oxygen species (ROC) in the experimental outcome.\nA parametric analysis was conducted for all values of [ax\u2062x,ay\u2062y,az\u2062z]subscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc67[a_{xx},a_{yy},a_{zz}][ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ], with each component ranging from 0 to 3 m\u2062T\ud835\udc5a\ud835\udc47mTitalic_m italic_T (step size 0.06 m\u2062T\ud835\udc5a\ud835\udc47mTitalic_m italic_T), ensuring that all three parameters (L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT) yield values greater than unity. Out of 132,651 possible hyperfine tensors, approximately 39 values met the desired condition. From Figure 4, the observed values were L1=1.132,L2=1.131,L3=1.001formulae-sequencesubscript\ud835\udc3f11.132formulae-sequencesubscript\ud835\udc3f21.131subscript\ud835\udc3f31.001L_{1}=1.132,L_{2}=1.131,L_{3}=1.001italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.132 , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1.131 , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1.001. Although ideally, a higher value of these ratios is preferred, the range of these ratios for all 39 possible hyperfine tensors was between 1-1.25. The maximum values of hyperfine tensor [ax\u2062x,ay\u2062y,az\u2062z]subscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc67[a_{xx},a_{yy},a_{zz}][ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ], where L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are greater than unity, were found to be [0.54,0.06,0.24]\u2062m\u2062T0.540.060.24\ud835\udc5a\ud835\udc47[0.54,0.06,0.24]mT[ 0.54 , 0.06 , 0.24 ] italic_m italic_T . Consequently, the desired trend was only observed for low hyperfine values. Additionally, it was noted that the absolute value of \u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT was relatively low.\nIn the next section, chirality will be introduced to investigate whether spin selectivity provides a more accurate model that closely aligns with the experimental outcome. This section introduces spin selectivity arising from chirality, taking into account the nonzero value of \u03c7\ud835\udf12\\chiitalic_\u03c7. Initially, we focus on spin selectivity during the formation of the radical pair from the acceptor and donor molecules. Consequently, the initial density matrix, denoted as P^I\u2062nsubscript^\ud835\udc43\ud835\udc3c\ud835\udc5b\\hat{P}_{In}over^ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_I italic_n end_POSTSUBSCRIPT, is influenced by variations in the CISS parameter \u03c7\ud835\udf12\\chiitalic_\u03c7. However, the recombination operators are observed under the no CISS case (\u03c7=0\ud835\udf120\\chi=0italic_\u03c7 = 0), representing the standard singlet and triplet projection operators. In the subsequent part, we explore the role of CISS in both the formation and recombination of the radical. Thus, \u03c7\ud835\udf12\\chiitalic_\u03c7 will impact not only the initial density matrix P^I\u2062nsubscript^\ud835\udc43\ud835\udc3c\ud835\udc5b\\hat{P}_{In}over^ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_I italic_n end_POSTSUBSCRIPT but also recombination operators P^Ssubscript^\ud835\udc43\ud835\udc46\\hat{P}_{S}over^ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT and P^Tsubscript^\ud835\udc43\ud835\udc47\\hat{P}_{T}over^ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT. This work calculates the result for the fixed orientation of the CISS axis to the hyperfine z-axis [37]. In Figure 5, the triplet yield (\u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT) is graphed against the external magnetic field for five different values of \u03c7=0,\u03c06,\u03c04,\u03c03,\u03c02\ud835\udf120\ud835\udf0b6\ud835\udf0b4\ud835\udf0b3\ud835\udf0b2\\chi=0,\\frac{\\pi}{6},\\frac{\\pi}{4},\\frac{\\pi}{3},\\frac{\\pi}{2}italic_\u03c7 = 0 , divide start_ARG italic_\u03c0 end_ARG start_ARG 6 end_ARG , divide start_ARG italic_\u03c0 end_ARG start_ARG 4 end_ARG , divide start_ARG italic_\u03c0 end_ARG start_ARG 3 end_ARG , divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG. This analysis is conducted at kS=108subscript\ud835\udc58\ud835\udc46superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\ud835\udc58\ud835\udc47superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT, with D=0\ud835\udc370D=0italic_D = 0 and J=0\ud835\udc3d0J=0italic_J = 0, and under the hyperfine configuration [ax\u2062x,ay\u2062y,az\u2062z]=[0,0.78,0.84]\u2062m\u2062Tsubscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc6700.780.84\ud835\udc5a\ud835\udc47[a_{xx},a_{yy},a_{zz}]=[0,0.78,0.84]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0 , 0.78 , 0.84 ] italic_m italic_T. Notably, CISS is present only during the formation of the radical in this scenario. We list the values of L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT in Tab.1 for Fig 5. It is noteworthy that when CISS exclusively influences the formation of the radical, the observed trend aligns with the experimental findings. A distinctive peak is evident at 500\u2062\u03bc\u2062T500\ud835\udf07\ud835\udc47500\\mu T500 italic_\u03bc italic_T when CISS is considered. Specifically, when \u03c7=\u03c02\ud835\udf12\ud835\udf0b2\\chi=\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG, there is a notable increase in the ratio L1subscript\ud835\udc3f1L_{1}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT by at least four times. Tab. 2 provides the count of hyperfine tensors corresponding to the five \u03c7\ud835\udf12\\chiitalic_\u03c7 values that meet the criteria 11 at kS=108subscript\ud835\udc58\ud835\udc46superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\ud835\udc58\ud835\udc47superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT, considering CISS solely in the formation of the radical pair. In Fig.6, we plotted triplet yield \u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT with respect to external magnetic field for five values of \u03c7=0,\u03c06,\u03c04,\u03c03,\u03c02\ud835\udf120\ud835\udf0b6\ud835\udf0b4\ud835\udf0b3\ud835\udf0b2\\chi=0,\\frac{\\pi}{6},\\frac{\\pi}{4},\\frac{\\pi}{3},\\frac{\\pi}{2}italic_\u03c7 = 0 , divide start_ARG italic_\u03c0 end_ARG start_ARG 6 end_ARG , divide start_ARG italic_\u03c0 end_ARG start_ARG 4 end_ARG , divide start_ARG italic_\u03c0 end_ARG start_ARG 3 end_ARG , divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG at kS=108subscript\ud835\udc58\ud835\udc46superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\ud835\udc58\ud835\udc47superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT with D=0\ud835\udc370D=0italic_D = 0 and J=0\ud835\udc3d0J=0italic_J = 0 at two different hyperfine configuration. (a) [ax\u2062x,ay\u2062y,az\u2062z]=[0.12,0.12,0]\u2062m\u2062Tsubscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc670.120.120\ud835\udc5a\ud835\udc47[a_{xx},a_{yy},a_{zz}]=[0.12,0.12,0]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0.12 , 0.12 , 0 ] italic_m italic_T and (b) [ax\u2062x,ay\u2062y,az\u2062z]=[0,0.72,0.9]\u2062m\u2062Tsubscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc6700.720.9\ud835\udc5a\ud835\udc47[a_{xx},a_{yy},a_{zz}]=[0,0.72,0.9]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0 , 0.72 , 0.9 ] italic_m italic_T. We list the values of L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT in Tab.3 and Tab.4 for all five values of \u03c7\ud835\udf12\\chiitalic_\u03c7. Our parametric analysis found no single combination of hyperfine values for which L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are greater than one for all five values of \u03c7\ud835\udf12\\chiitalic_\u03c7 at kS=108subscript\ud835\udc58\ud835\udc46superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\ud835\udc58\ud835\udc47superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT. The closest result observed was when [ax\u2062x,ay\u2062y,az\u2062z]=[0.12,0.12,0]\u2062m\u2062Tsubscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc670.120.120\ud835\udc5a\ud835\udc47[a_{xx},a_{yy},a_{zz}]=[0.12,0.12,0]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0.12 , 0.12 , 0 ] italic_m italic_T when \u03c7=\u03c06,\u03c04,\u03c03,\u03c02\ud835\udf12\ud835\udf0b6\ud835\udf0b4\ud835\udf0b3\ud835\udf0b2\\chi=\\frac{\\pi}{6},\\frac{\\pi}{4},\\frac{\\pi}{3},\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 6 end_ARG , divide start_ARG italic_\u03c0 end_ARG start_ARG 4 end_ARG , divide start_ARG italic_\u03c0 end_ARG start_ARG 3 end_ARG , divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG all reported a value of L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT greater than 1 however this was not observed for \u03c7=0\ud835\udf120\\chi=0italic_\u03c7 = 0.\nIt was observed that the values of \u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT at \u03c7=\u03c02\ud835\udf12\ud835\udf0b2\\chi=\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG are at least ten times larger than that for the case when \u03c7=0\ud835\udf120\\chi=0italic_\u03c7 = 0. However, the values of the ratio L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT remain almost the same. Moreover, the number of hyperfine tensors corresponding to five values of \u03c7\ud835\udf12\\chiitalic_\u03c7 which satisfy criteria 11 at kS=108subscript\ud835\udc58\ud835\udc46superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\ud835\udc58\ud835\udc47superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT is given in 5 when CISS acts both in formation and recombination of radical pair. Hence, we summarize the difference in the cases when CISS is only present at the formation of the radical (Case A) and when CISS is present both in the formation and recombination of radicals (Case B). Case A has a lower value of triplet yield at 45,200,500\u2062\u03bc\u2062T45200500\ud835\udf07\ud835\udc4745,200,500\\mu T45 , 200 , 500 italic_\u03bc italic_T compared to Case B; hence, case B seems more favorable. Case A shows an improved increase in the ratio of L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT due to CISS compared to Case B at around the same hyperfine tensor; hence, case A seems more favorable. Case A has more number of hyperfine tensor for \u03c7\u22600\ud835\udf120\\chi\\neq 0italic_\u03c7 \u2260 0 compared to case B. Since this reaction occurs in a biological system, this property gives the system more degree of freedom and reaction and is not bounded by strict values of hyperfine tensors. Therefore, case A is more promising if we consider this property. In this section, our aim was to investigate the impact of singlet and triplet recombination rates on the yield of the triplet product, \u03d5Tsubscriptitalic-\u03d5\ud835\udc47\\phi_{T}italic_\u03d5 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT. The goal is to discern a trend that aligns with experimental findings, as articulated in Eq.11, across the maximum number of hyperfine tensors. Recognizing that the planaria reaction transpires in a biological medium, we have exercised the discretion to consider hyperfine tensors. Tabulated in Tab6 are the counts of hyperfine configurations, out of the 132,651 possible configurations, that adhere to the observed experimental trend when \u03c7=0\ud835\udf120\\chi=0italic_\u03c7 = 0. Our observation indicates that when \u03c7=0\ud835\udf120\\chi=0italic_\u03c7 = 0, rate combinations with kS=108subscript\ud835\udc58\ud835\udc46superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=105subscript\ud835\udc58\ud835\udc47superscript105k_{T}=10^{5}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT exhibit the maximum number of hyperfine configurations satisfying the experimental conditions. However, the absolute value of triplet yield is low due to the diminished triplet recombination rate. Consequently, a higher triplet rate leads to an increased triplet yield value; nevertheless, the rapid recombination rate renders the yield less sensitive to the external magnetic field. This results in a limited number of hyperfine tensor values that meet the specified criteria. Additionally, it was observed that no rate combination resulted in L1,L2,L3\u22652subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f32L_{1},L_{2},L_{3}\\geq 2italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2265 2 (table not shown). When \u03c7=\u03c02\ud835\udf12\ud835\udf0b2\\chi=\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG, we have calculated the number of combinations of hyperfine tensors for which L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is greater than unity. This has been done for case A (Tab.7) and case B (Tab.8) at \u03c7=\u03c02\ud835\udf12\ud835\udf0b2\\chi=\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG. We generally observe an increase in the number of hyperfine tensors for either case when compared to when \u03c7=0\ud835\udf120\\chi=0italic_\u03c7 = 0. However, in case A, the number\nof hyperfine tensors for which L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is greater than unity is much greater compared to case B for most values of kSsubscript\ud835\udc58\ud835\udc46k_{S}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT and kTsubscript\ud835\udc58\ud835\udc47k_{T}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT. We have also computed the maximum values of L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT when each component of the hyperfine tensor [ax\u2062x,ay\u2062y,az\u2062z]subscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc67[a_{xx},a_{yy},a_{zz}][ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] varies from 0 to 3 mT, covering a total of 132,651 tensor values at \u03c7=\u03c02\ud835\udf12\ud835\udf0b2\\chi=\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG for case A (Tab.13) and case B (Tab.14).\nNotably, significant values of L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are observed when kTsubscript\ud835\udc58\ud835\udc47k_{T}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT is in the range of 104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT and 105superscript10510^{5}10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT, with the singlet recombination rate being at least a hundred times (107superscript10710^{7}10 start_POSTSUPERSCRIPT 7 end_POSTSUPERSCRIPT and 108superscript10810^{8}10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT) for both the cases.We also observe that L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT values are higher for case A compared to case B. We have also calculated the maximum absolute value of triplet yield (ROS level) at 45\u2062\u03bc\u2062T,200\u2062\u03bc\u2062T,500\u2062\u03bc\u2062T45\ud835\udf07\ud835\udc47200\ud835\udf07\ud835\udc47500\ud835\udf07\ud835\udc4745\\mu T,~{}200\\mu T,~{}500\\mu T45 italic_\u03bc italic_T , 200 italic_\u03bc italic_T , 500 italic_\u03bc italic_T for case A (Tab.16) and case B (Tab.15)\nIt is essential to acknowledge that the rate combination resulting in the maximum value of L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT tends to yield lower values of triplet yield compared to yields observed at other rates. This implies that at \u03c7=\u03c02\ud835\udf12\ud835\udf0b2\\chi=\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG, one can either achieve the maximum value of the ratio L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT or attain the absolute yield value by adjusting the recombination rates. This section examines whether the intended experimental outcomes are observed for higher nuclei or if the trend diverges. Given in \u00a0[17, 53], indicating that the second nucleus might be tryptophan, we assume the second nucleus to be spin-half, akin to hydrogen. We vary it similarly to a single-nuclei system, but with two nuclei, the number of parameters increases to six. We sampled 51 points from 0 to 3 mT for each component of the hyperfine tensor for a single nuclei system, resulting in 132,651 combinations. This number is 516superscript51651^{6}51 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT tensors for two nuclei systems a very large value. Consequently, we selected values for the hyperfine tensor of the first nucleus that satisfy the conditions outlined in the criteria 11 as given in the preceding section of one nucleus study and varied the hyperfine tensor for the second nucleus. We observe in Fig.7 that for a two nuclei system, we observe the desired trend for \u03c7=\u03c02\ud835\udf12\ud835\udf0b2\\chi=\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG. The L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are listed in Tab.9 for five values of \u03c7\ud835\udf12\\chiitalic_\u03c7. We observe that compared to single nucleus case with hyperfine tensor [ax\u2062x,ay\u2062y,az\u2062z]=[0.12,0.12,0]\u2062m\u2062Tsubscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc670.120.120\ud835\udc5a\ud835\udc47[a_{xx},a_{yy},a_{zz}]=[0.12,0.12,0]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0.12 , 0.12 , 0 ] italic_m italic_T Fig.(6.a), we observe that L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is greater for \u03c7=\u03c02\ud835\udf12\ud835\udf0b2\\chi=\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG for two nuclei case. Hence, we also observe an experimental trend for two nuclei cases. However, due to scaling issues, it might not be possible to give maximum values of L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. Keeping the value of hyperfine tensor fixed [ax\u2062x,ay\u2062y,az\u2062z]=[0.12,0.12,0]\u2062m\u2062Tsubscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc670.120.120\ud835\udc5a\ud835\udc47[a_{xx},a_{yy},a_{zz}]=[0.12,0.12,0]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0.12 , 0.12 , 0 ] italic_m italic_T, we have done a parametric analysis for the second nucleus and found a number of hyperfine tensors satisfying the criteria for various value of \u03c7\ud835\udf12\\chiitalic_\u03c7 (Tab.10). A similar analysis for hyperfine tensor is[ax\u2062x,ay\u2062y,az\u2062z]=[0,0.72,0.9]\u2062m\u2062Tsubscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc6700.720.9\ud835\udc5a\ud835\udc47[a_{xx},a_{yy},a_{zz}]=[0,0.72,0.9]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0 , 0.72 , 0.9 ] italic_m italic_T of spin 1 nucleus give us very different results in Tab.11. Here, we obtain no hyperfine tensor for second nuclei, which might satisfy the criteria for \u03c7=\u03c02\ud835\udf12\ud835\udf0b2\\chi=\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG. Hence, we cannot reach any conclusive result by this brute-force method.\nWe also simulated the case when CISS is only present in the formation of the radical pair when the spin one nucleus has hyperfine tensor [ax\u2062x,ay\u2062y,az\u2062z]=[0,0.78,0.84]\u2062m\u2062Tsubscript\ud835\udc4e\ud835\udc65\ud835\udc65subscript\ud835\udc4e\ud835\udc66\ud835\udc66subscript\ud835\udc4e\ud835\udc67\ud835\udc6700.780.84\ud835\udc5a\ud835\udc47[a_{xx},a_{yy},a_{zz}]=[0,0.78,0.84]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0 , 0.78 , 0.84 ] italic_m italic_T. We found, in general, that more hyperfine tensors satisfied the criteria (Tab.12). This hints more towards the involvement of CISS only in forming the radical pair. However, a more rigorous approach is required to achieve a more conclusive outcome. The process of blastema formation, crucial for planarian regeneration, seems to be correlated with the level of Reactive Oxygen Species (ROS). Interestingly, the experiments suggest that exposure to Weak Magnetic Fields (WMF) should be continued until the blastema is fully formed.\nIt\u2019s worth noting that the radical pair mechanism, which involves the spin dynamics of electrons and is influenced by magnetic fields, typically has a very short lifetime, on the order of microseconds. This short lifetime raises questions about whether the radical pair mechanism directly participates in the planarian regeneration process or if there\u2019s another mechanism at play.\nThe observed correlation between WMF exposure duration and blastema formation could imply a more complex interplay between magnetic field effects and biological processes. It\u2019s possible that the radical pair mechanism, despite its short-lived nature, triggers or influences other biochemical pathways or mechanisms that lead to blastema formation over a longer timescale. Further research is needed to unravel the specifics of these interactions and mechanisms in planarian regeneration.\nThe issue of radical pair formation in the context of planarian regeneration, especially in the absence of an external excitation source, raises intriguing questions. In avian magnetoreception, radical pairs are typically formed through the photoexcitation of neutral acceptor molecules.\nIn the experiments conducted on planaria regeneration, where Weak Magnetic Fields (WMF) are applied [17, 53], there is no apparent external excitation source. The absence of a known external stimulus for radical pair formation prompts the question of what initiates this reaction in the absence of an external excitation source.\nOne plausible explanation could be related to the cut or segment of the planaria body. The external cut might release some reactive chemical or signaling molecule, which could act as an internal stimulus, leading to the generation of excitation and the subsequent formation of radical pairs in the system. However, the specific identity and nature of this chemical or excitation remain unclear and would require further investigation.\nUnderstanding the underlying biochemical processes triggered by the external cut in planaria regeneration, especially in the context of magnetic field effects, could provide valuable insights into the role of radical pair mechanisms and other potential signaling pathways in this intriguing biological phenomenoa. In summary, our analysis suggests that the Radical Pair Mechanism (RPM) provides an explanation for the influence of a weak magnetic field on planaria regeneration. However, our findings indicate that the effect is more robustly explained when considering the Chirality-Induced Spin Selectivity (CISS) in conjunction with the radical pair mechanism. Specifically, when chirality is involved solely in the formation of the radical pair, it yields even more consistent and fitting results based on the experimental findings. This underscores the potential significance of CISS in understanding the magnetic field effects on planaria regeneration with radical pair mechanism. In this section, we have listed the L1,L2,L3subscript\ud835\udc3f1subscript\ud835\udc3f2subscript\ud835\udc3f3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT at all possible recombination rates of kS,kTsubscript\ud835\udc58\ud835\udc46subscript\ud835\udc58\ud835\udc47k_{S},k_{T}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT when CISS is involved in the formation and recombination of radical pair as well as when it is involved only in the formation of the radical. We have also listed the absolute values of the yield at 45\u2062\u03bc\u2062T,200\u2062\u03bc\u2062T,500\u2062\u03bc\u2062T45\ud835\udf07\ud835\udc47200\ud835\udf07\ud835\udc47500\ud835\udf07\ud835\udc4745\\mu T,200\\mu T,500\\mu T45 italic_\u03bc italic_T , 200 italic_\u03bc italic_T , 500 italic_\u03bc italic_T for both of the mentioned cases. All the results are for the case when \u03c7=\u03c02\ud835\udf12\ud835\udf0b2\\chi=\\frac{\\pi}{2}italic_\u03c7 = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG."
    },
    {
        "id": 14,
        "title": "Local sensitivity analysis of heating degree day and cooling degree day temperature derivatives prices",
        "corpus": "We study the local sensitivity of heating degree day (HDD) and cooling degree day (CDD) temperature futures and option prices with respect to\nperturbations in the deseasonalized temperature or in one of its derivatives up to a certain order determined by\nthe continuous-time autoregressive process modelling the deseasonalized temperature in the HDD and CDD indexes.\nWe also consider an empirical case where a CAR process of autoregressive order 3 is fitted to New York temperatures\nand we perform a study of the local sensitivity of these financial contracts and a posterior analysis of the results. Weather related risks can be hedged by trading in weather derivatives.\nThe Chicago Mercantile Exchange (CME) organizes trade in futures contracts written\nin weather indexes in several cities around the world.\nWe focus on the temperature indexes HDD (heating-degree day) and CDD\n(cooling-degree day) which measure the aggregation\nof temperature below and above a threshold of 65\u2218superscript6565^{\\circ}65 start_POSTSUPERSCRIPT \u2218 end_POSTSUPERSCRIPTF over a time period, respectively.\nThe daily modelling of temperature\nis an approach that can be used to get the non-arbitrage price of temperature derivatives.\nA continuous-time function which consists of a deterministic\nterm modelling the seasonal cycle\nof temperatures and a noise term modelling uncertainty is fitted\nto historical time series of daily average temperatures (DATs).\nSeveral empirical studies of temperature\ndata, see H\u00e4rdle and L\u00f3pez Cabrera [6], Benth and \u0160altyt\u0117 Benth [3] and the references therein, have shown that continuous time autoregressive (CAR) models explain very well the statistical properties of the deseasonalized temperature dynamics.\nAlthough this approach requires a model for the instantaneous temperature, it has the advantage that\nthe model can be used for all available contracts on the market on the same location.\nIn Benth and Solanilla Blanco [2], HDD and CDD futures prices based on CAR temperature dynamics\nand option on these futures are derived theoretically. An approximative model for the HDD and CDD futures is suggested in order\nto derive a closed formula for the call option price. The (approximative) formulas for HDD and CDD futures and option prices\ndepend on the deseasonalized temperature and its derivatives up to p\u22121\ud835\udc5d1p-1italic_p - 1, where p\u2208\u2115\u2212{0}\ud835\udc5d\u21150p\\in\\mathbb{N}-\\{0\\}italic_p \u2208 blackboard_N - { 0 }\nrefers to the autoregressive order of the CAR process which models the deseasonalized temperature dynamics of these indexes. The objective of this paper is to study the local sensitivity of the (approximative) HDD and CDD futures\nand option prices derived in Benth and Solanilla Blanco [2]\nwith respect to perturbations in the deseasonalized temperature or in one of its\nderivatives up to order p\u22121\ud835\udc5d1p-1italic_p - 1.\nTo do so, we consider the partial derivatives of such financial contracts with respect to\nthese variables evaluated at a fixed point.\nLocal sensitivity measures parameter importance by considering infinitesimal variations\nin a specific variable. Sensitivity analysis is widely used in mathematical modelling to determine the influence of parameter values\non response variables. The local sensitivity analysis with partial\nderivatives is a first step to study the response of a model\nto changes in their inputs variables. In mathematical finance there is extensive literature\nof Greeks, which are quantities representing the sensitivity of derivatives prices to a change\nin underlying parameters. The sensitivity analysis focused on\nHDD and CDD futures and option prices where the temperature dynamics follows a CAR process has\nnot been considered yet. Our contribution is a first analysis of the local sensitivities of such financial contracts\nwith respect to a perturbation in the deseasonalized temperature or in one of its p\u22121\ud835\udc5d1p-1italic_p - 1 derivatives. The paper is structured as follows: in the next section we review results concerning the\narbitrage-free pricing of temperature HDD and CDD futures with measurement over a period and call options written on these.\nWe also derive some results to study the sensitivity of these financial contracts to perturbations in the deseasonalized temperature\nor in one of its derivatives up to order p\u22121\ud835\udc5d1p-1italic_p - 1,\nwith p\ud835\udc5dpitalic_p being the order of the CAR process used to model the deseasonalized temperature in these indexes.\nIn Section 3 we adapt all the results in Section 2 for the case where the measurement time is a day instead.\nIn Section 4 we consider a previous empirical study of New York temperatures where the deseasonalized temperature dynamics follows a CAR(3)-process and\nwe study local sensitivity of HDD and CDD futures and option prices with a measurement day.\nIn Section 5 we include an empirical analysis of the sensitivity of the HDD and CDD futures prices with measurement over a period.\nFinally, in Section 6 we present a conclusion of the results. In this Section we review results concerning\npricing futures written on the temperature indexes CDD and HDD defined over a\nmeasurement period and call options on these temperature futures.\nThese results are the baseline to develop a study of the sensitivity of these financial contracts\nwith respect to changes in the components of the vector function \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) involved in\nthe definition of the indexes. Let (\u03a9,\u2131,{\u2131t}t\u22650,P)\u03a9\u2131subscriptsubscript\u2131\ud835\udc61\ud835\udc610\ud835\udc43(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t\\geq 0},P)( roman_\u03a9 , caligraphic_F , { caligraphic_F start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t \u2265 0 end_POSTSUBSCRIPT , italic_P ) be a complete probability space,\nthe CDD and HDD indexes over a time period [\u03c41,\u03c42],\u03c41<\u03c42subscript\ud835\udf0f1subscript\ud835\udf0f2subscript\ud835\udf0f1subscript\ud835\udf0f2[\\tau_{1},\\tau_{2}],\\tau_{1}<\\tau_{2}[ italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] , italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT,\nare defined respectively as and where T\u2062(t)\ud835\udc47\ud835\udc61T(t)italic_T ( italic_t ) is the daily average temperature in the location\nat time t\ud835\udc61titalic_t and the threshold c\ud835\udc50citalic_c is 65\u2218superscript6565^{\\circ}65 start_POSTSUPERSCRIPT \u2218 end_POSTSUPERSCRIPTF (or 18\u2218superscript1818^{\\circ}18 start_POSTSUPERSCRIPT \u2218 end_POSTSUPERSCRIPTC). The temperature is modelled\nas T\u2062(t)=\u039b\u2062(t)+Y\u2062(t)\ud835\udc47\ud835\udc61\u039b\ud835\udc61\ud835\udc4c\ud835\udc61T(t)=\\Lambda(t)+Y(t)italic_T ( italic_t ) = roman_\u039b ( italic_t ) + italic_Y ( italic_t ) by means of a seasonal function \u039b\u039b\\Lambdaroman_\u039b\nand a CAR(p\ud835\udc5dpitalic_p)-process Y\u2062(t)=\ud835\udc1e1\u2032\u2062\ud835\udc17\u2062(t)\ud835\udc4c\ud835\udc61superscriptsubscript\ud835\udc1e1\u2032\ud835\udc17\ud835\udc61Y(t)=\\mathbf{e}_{1}^{\\prime}\\mathbf{X}(t)italic_Y ( italic_t ) = bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT bold_X ( italic_t ) defined as the first component of a multivariate Orstein-Uhlenbeck\nprocess \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) with dynamics We use the notation \ud835\udc33\u2032superscript\ud835\udc33\u2032\\mathbf{z}^{\\prime}bold_z start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT to denote the transpose\nof a vector (or matrix) \ud835\udc33\ud835\udc33\\mathbf{z}bold_z. The matrix A\ud835\udc34Aitalic_A, which has a particular representation,\ncontains the different speeds of mean reversion. We assume the condition of having different eigenvalues with strictly\nnegative real part in order to have a stationary model. The function \u03c3\u2062(t)\ud835\udf0e\ud835\udc61\\sigma(t)italic_\u03c3 ( italic_t ) is the time-dependent volatility of the process.\nThe arbitrage-free futures price written on a CDD index at time t\u2264\u03c42\ud835\udc61subscript\ud835\udf0f2t\\leq\\tau_{2}italic_t \u2264 italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT with measurement\nperiod [\u03c41,\u03c42]subscript\ud835\udf0f1subscript\ud835\udf0f2[\\tau_{1},\\tau_{2}][ italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] is defined as where the conditional expectation is taken under\nsome probability Q\u223cPsimilar-to\ud835\udc44\ud835\udc43Q\\sim Pitalic_Q \u223c italic_P. Analogously it can be considered for HDD indexes.\nWe choose to work with the probability measure Q\ud835\udc44Qitalic_Q considered in Benth and Solanilla Blanco [2] given\nby a Girsanov transform which involves the parameter function \u03b8\ud835\udf03\\thetaitalic_\u03b8 referred as the market price of risk and the\nthe stochastic process \u03c3\ud835\udf0e\\sigmaitalic_\u03c3 modeling the volatility.\nFor a better understanding of this setting we refer Benth and Solanilla Blanco [2],\nwhere it is possible to find also all the results that we present next about futures and call options prices.\nWe recall the CDD and HDD futures prices formulas provided\nin Proposition.\u00a02.1 and Proposition.\u00a02.3 respectively. For our convenience in this setting we restrict t\u2264\u03c41\ud835\udc61subscript\ud835\udf0f1t\\leq\\tau_{1}italic_t \u2264 italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, so that and Note that \u03a8\u2062(x)=x\u2062\u03a6\u2062(x)+\u03a6\u2032\u2062(x)\u03a8\ud835\udc65\ud835\udc65\u03a6\ud835\udc65superscript\u03a6\u2032\ud835\udc65\\Psi(x)=x\\Phi(x)+\\Phi^{\\prime}(x)roman_\u03a8 ( italic_x ) = italic_x roman_\u03a6 ( italic_x ) + roman_\u03a6 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_x ), with \u03a6\u03a6\\Phiroman_\u03a6 being the cumulative standard normal\ndistribution function and for \ud835\udc31\u2208\u211dp\ud835\udc31superscript\u211d\ud835\udc5d\\mathbf{x}\\in\\mathbb{R}^{p}bold_x \u2208 blackboard_R start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT If we consider the initial condition \ud835\udc17\u2062(0)=\ud835\udc31\u2208\u211dp\ud835\udc170\ud835\udc31superscript\u211d\ud835\udc5d\\mathbf{X}(0)=\\mathbf{x}\\in\\mathbb{R}^{p}bold_X ( 0 ) = bold_x \u2208 blackboard_R start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT, then\nFCDD\u2062(t,\u03c41,\u03c42)subscript\ud835\udc39CDD\ud835\udc61subscript\ud835\udf0f1subscript\ud835\udf0f2F_{\\text{CDD}}(t,\\tau_{1},\\tau_{2})italic_F start_POSTSUBSCRIPT CDD end_POSTSUBSCRIPT ( italic_t , italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) as defined in (2.2) is a random variable for t>0\ud835\udc610t>0italic_t > 0\nwith all the stochasticity contained in the term \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ). In our setting\nwe loose this condition when for t\u22650\ud835\udc610t\\geq 0italic_t \u2265 0 we fix \ud835\udc17\u2062(t)=\ud835\udc31\u2208\u211dp\ud835\udc17\ud835\udc61\ud835\udc31superscript\u211d\ud835\udc5d\\mathbf{X}(t)=\\mathbf{x}\\in\\mathbb{R}^{p}bold_X ( italic_t ) = bold_x \u2208 blackboard_R start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT with \ud835\udc31\u2032=(\ud835\udea11,\u2026,\ud835\udea1p)superscript\ud835\udc31\u2032subscript\ud835\udea11\u2026subscript\ud835\udea1\ud835\udc5d\\mathbf{x}^{\\prime}=(\\texttt{x}_{1},\\ldots,\\texttt{x}_{p})bold_x start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = ( x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , x start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ).\nIn such a case the CDD futures price can be explained as a deterministic function.\nDenote by Xi\u2062(t)=\ud835\udc1ei\u2032\u2062\ud835\udc17\u2062(t)subscript\ud835\udc4b\ud835\udc56\ud835\udc61superscriptsubscript\ud835\udc1e\ud835\udc56\u2032\ud835\udc17\ud835\udc61X_{i}(t)=\\mathbf{e}_{i}^{\\prime}\\mathbf{X}(t)italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) = bold_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT bold_X ( italic_t ), for i=1,\u2026,p\ud835\udc561\u2026\ud835\udc5di=1,\\ldots,pitalic_i = 1 , \u2026 , italic_p the i\ud835\udc56iitalic_ith component of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ).\nNote that Y\u2062(t)=\ud835\udc1e1\u2032\u2062\ud835\udc17\u2062(t)=X1\u2062(t)\ud835\udc4c\ud835\udc61superscriptsubscript\ud835\udc1e1\u2032\ud835\udc17\ud835\udc61subscript\ud835\udc4b1\ud835\udc61Y(t)=\\mathbf{e}_{1}^{\\prime}\\mathbf{X}(t)=X_{1}(t)italic_Y ( italic_t ) = bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT bold_X ( italic_t ) = italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ). We find that the term \ud835\udc1e1\u2032\u2062eA\u2062(s\u2212t)\u2062\ud835\udc17\u2062(t)superscriptsubscript\ud835\udc1e1\u2032superscript\ud835\udc52\ud835\udc34\ud835\udc60\ud835\udc61\ud835\udc17\ud835\udc61\\mathbf{e}_{1}^{\\prime}e^{A(s-t)}\\mathbf{X}(t)bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT italic_A ( italic_s - italic_t ) end_POSTSUPERSCRIPT bold_X ( italic_t ) in the CDD and HDD future prices can be rewritten as follows where for i=1,\u2026,p\ud835\udc561\u2026\ud835\udc5di=1,\\ldots,pitalic_i = 1 , \u2026 , italic_p that is as a linear combination of the components of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ).\nFrom now on, we focus on CDD futures prices and call options\nwritten on these. Similar results can be obtained considering the HDD index.\nThe new notation in (2.5) let us to rewrite the CDD future price formula in (2.3) as follows: To answer the question to what extent an infinitesimal change in a component of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) is affecting the behavior of the CDD futures price, we need to consider partial derivatives of this with respect to the components of \ud835\udc17\u2062(t),\ud835\udc17\ud835\udc61\\mathbf{X}(t),bold_X ( italic_t ) ,\nsay \ud835\udea1i,i=1,\u2026,pformulae-sequencesubscript\ud835\udea1\ud835\udc56\ud835\udc561\u2026\ud835\udc5d\\texttt{x}_{i},i=1,\\ldots,px start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_i = 1 , \u2026 , italic_p to avoid misunderstandings in the notation.\nIn the next proposition we consider the partial derivatives of the CDD futures price with respect to the components of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x. Let t\u2264\u03c41\ud835\udc61subscript\ud835\udf0f1t\\leq\\tau_{1}italic_t \u2264 italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, then for i=1,\u2026,p\ud835\udc561normal-\u2026\ud835\udc5di=1,\\ldots,pitalic_i = 1 , \u2026 , italic_p it holds that The proof follows by first exchanging the derivative and the integral and afterwards\napplying the chain-rule on the integrand. In this last step consider that \u03a8\u2032\u2062(x)=\u03a6\u2062(x)superscript\u03a8\u2032\ud835\udc65\u03a6\ud835\udc65\\Psi^{\\prime}(x)=\\Phi(x)roman_\u03a8 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_x ) = roman_\u03a6 ( italic_x )\nand take into account that m\u03b8subscript\ud835\udc5a\ud835\udf03m_{\\theta}italic_m start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT can be rewritten as a linear combination of the components of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x so that \u25a1\u25a1\\Box\u25a1 CDD futures prices depend nonlinearly on the vector \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t )\nwhich is included in the function \u03a8\u03a8\\Psiroman_\u03a8. This fact makes difficult to\nderive analytic formulas for plain vanilla options (call options) which\nare traded at the CME. To this aim, we recall some useful linearized formulas that allow to\napproximate the CDD futures prices.\nLet t\u2264\u03c41\ud835\udc61subscript\ud835\udf0f1t\\leq\\tau_{1}italic_t \u2264 italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, setting \u03a8\u2062(x)\u2248x\u03a8\ud835\udc65\ud835\udc65\\Psi(x)\\approx xroman_\u03a8 ( italic_x ) \u2248 italic_x in\u00a0(2.6) reduces to where We can consider the first order Taylor approximation \u03a8\u2062(x)\u224812\u2062\u03c0+12\u2062x\u03a8\ud835\udc6512\ud835\udf0b12\ud835\udc65\\Psi(x)\\approx\\frac{1}{\\sqrt{2\\pi}}+\\frac{1}{2}xroman_\u03a8 ( italic_x ) \u2248 divide start_ARG 1 end_ARG start_ARG square-root start_ARG 2 italic_\u03c0 end_ARG end_ARG + divide start_ARG 1 end_ARG start_ARG 2 end_ARG italic_x instead, then (2.6) reduces to where We introduce a new notation that encompasses both approximated formulas for the CDD futures price.\nTo this end let t\u2264\u03c41\ud835\udc61subscript\ud835\udf0f1t\\leq\\tau_{1}italic_t \u2264 italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, then where \u0398\u0398\\Thetaroman_\u0398 and \ud835\udc1a\ud835\udc1a\\mathbf{a}bold_a are generic notations for\n\u0398xsubscript\u0398\ud835\udc65\\Theta_{x}roman_\u0398 start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT and \ud835\udc1axsubscript\ud835\udc1a\ud835\udc65\\mathbf{a}_{x}bold_a start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT or \u0398Taylorsubscript\u0398Taylor\\Theta_{\\text{Taylor}}roman_\u0398 start_POSTSUBSCRIPT Taylor end_POSTSUBSCRIPT and \ud835\udc1aTaylorsubscript\ud835\udc1aTaylor\\mathbf{a}_{\\text{Taylor}}bold_a start_POSTSUBSCRIPT Taylor end_POSTSUBSCRIPT.\nThe next proposition provides the partial derivatives of the approximate CDD futures prices with respect to the components of \ud835\udc31.\ud835\udc31\\mathbf{x}.bold_x . Let t\u2264\u03c41\ud835\udc61subscript\ud835\udf0f1t\\leq\\tau_{1}italic_t \u2264 italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, then it holds that for i=1,\u2026,p\ud835\udc561normal-\u2026\ud835\udc5di=1,\\ldots,pitalic_i = 1 , \u2026 , italic_p where \ud835\udc1a\ud835\udc1a\\mathbf{a}bold_a is the generic notation for \ud835\udc1a\ud835\udc65subscript\ud835\udc1a\ud835\udc65\\mathbf{a}_{\\text{x}}bold_a start_POSTSUBSCRIPT x end_POSTSUBSCRIPT and \ud835\udc1a\ud835\udc47\u2062a\u2062y\u2062l\u2062o\u2062rsubscript\ud835\udc1a\ud835\udc47\ud835\udc4e\ud835\udc66\ud835\udc59\ud835\udc5c\ud835\udc5f\\mathbf{a}_{\\text{T}aylor}bold_a start_POSTSUBSCRIPT T italic_a italic_y italic_l italic_o italic_r end_POSTSUBSCRIPT\u2009. Rewrite (2.9) in terms of the components of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x as and differentiate with respect to the components \ud835\udea1isubscript\ud835\udea1\ud835\udc56\\texttt{x}_{i}x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for i=1,\u2026,p\ud835\udc561\u2026\ud835\udc5di=1,\\ldots,pitalic_i = 1 , \u2026 , italic_p.\n\u00a0 \u25a1\u25a1\\Box\u25a1 Observe that (2.10) does not depend on \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ). We consider now CDD and HDD futures prices as the underlying to price call options. The arbitrage-free price for\na call option with strike K\ud835\udc3eKitalic_K at exercise time \u03c4\ud835\udf0f\\tauitalic_\u03c4,\nwritten on a CDD futures with measurement period [\u03c41,\u03c42]subscript\ud835\udf0f1subscript\ud835\udf0f2\\left[\\tau_{1},\\tau_{2}\\right][ italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ],\nwith \u03c4\u2264\u03c41\ud835\udf0fsubscript\ud835\udf0f1\\tau\\leq\\tau_{1}italic_\u03c4 \u2264 italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and for times t\u2264\u03c41\ud835\udc61subscript\ud835\udf0f1t\\leq\\tau_{1}italic_t \u2264 italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is defined as where r>0\ud835\udc5f0r>0italic_r > 0 is the risk-free interest rate. All the stochasticity in the call option price is in\nthe term \ud835\udc1e1\u2032\u2062eA\u2062(s\u2212\u03c4)\u2062\ud835\udc17\u2062(\u03c4)superscriptsubscript\ud835\udc1e1\u2032superscripte\ud835\udc34\ud835\udc60\ud835\udf0f\ud835\udc17\ud835\udf0f\\mathbf{e}_{1}^{\\prime}{\\mathrm{e}}^{A(s-\\tau)}\\mathbf{X}(\\tau)bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT roman_e start_POSTSUPERSCRIPT italic_A ( italic_s - italic_\u03c4 ) end_POSTSUPERSCRIPT bold_X ( italic_\u03c4 ) which is contained in the CDD futures price at exercise time\nand more specifically in m\u03b8subscript\ud835\udc5a\ud835\udf03m_{\\theta}italic_m start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT. For \u03c4\u2265t\ud835\udf0f\ud835\udc61\\tau\\geq titalic_\u03c4 \u2265 italic_t, is a solution of the stochastic differential equation in (2.1). Therefore \ud835\udc1e1\u2032\u2062eA\u2062(s\u2212\u03c4)\u2062\ud835\udc17\u2062(\u03c4)superscriptsubscript\ud835\udc1e1\u2032superscripte\ud835\udc34\ud835\udc60\ud835\udf0f\ud835\udc17\ud835\udf0f\\mathbf{e}_{1}^{\\prime}{\\mathrm{e}}^{A(s-\\tau)}\\mathbf{X}(\\tau)bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT roman_e start_POSTSUPERSCRIPT italic_A ( italic_s - italic_\u03c4 ) end_POSTSUPERSCRIPT bold_X ( italic_\u03c4 ) reduces to where the dependence on \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) is explicited in \ud835\udc1e1\u2032\u2062eA\u2062(s\u2212t)\u2062\ud835\udc17\u2062(t)superscriptsubscript\ud835\udc1e1\u2032superscripte\ud835\udc34\ud835\udc60\ud835\udc61\ud835\udc17\ud835\udc61\\mathbf{e}_{1}^{\\prime}{\\mathrm{e}}^{A(s-t)}\\mathbf{X}(t)bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT roman_e start_POSTSUPERSCRIPT italic_A ( italic_s - italic_t ) end_POSTSUPERSCRIPT bold_X ( italic_t ). We can use the same argument\nas for the CDD futures price to rewritte the call option price as follows To study the sensitivity of the call option price with respcect to infinitesimal changes in the components of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) we have to consider also partial derivatives which is not an easy task, if possible.\nTo avoid differentiating the payoff max\u2061(FCDD\u2062(\u03c4,\u03c41,\u03c42,\ud835\udea11,\u2026,\ud835\udea1p)\u2212K,0)subscript\ud835\udc39CDD\ud835\udf0fsubscript\ud835\udf0f1subscript\ud835\udf0f2subscript\ud835\udea11\u2026subscript\ud835\udea1\ud835\udc5d\ud835\udc3e0\\max(F_{\\text{CDD}}(\\tau,\\tau_{1},\\tau_{2},\\texttt{x}_{1},\\ldots,\\texttt{x}_{p%\n})-K,0)roman_max ( italic_F start_POSTSUBSCRIPT CDD end_POSTSUBSCRIPT ( italic_\u03c4 , italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , x start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) - italic_K , 0 ),\nit is known the density approach which moves the dependency of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) from the payoff to the required density function to compute the\nconditional expectation, see Broadie and Glasserman [4]. Next, we see that this method fails here because the payoff function is path-dependent\non \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) from \u03c41subscript\ud835\udf0f1\\tau_{1}italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT to \u03c42subscript\ud835\udf0f2\\tau_{2}italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Indeed, the payoff function contains the term \ud835\udc1e1\u2032\u2062eA\u2062(s\u2212\u03c4)\u2062\ud835\udc17\u2062(\u03c4)superscriptsubscript\ud835\udc1e1\u2032superscripte\ud835\udc34\ud835\udc60\ud835\udf0f\ud835\udc17\ud835\udf0f\\mathbf{e}_{1}^{\\prime}{\\mathrm{e}}^{A(s-\\tau)}\\mathbf{X}(\\tau)bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT roman_e start_POSTSUPERSCRIPT italic_A ( italic_s - italic_\u03c4 ) end_POSTSUPERSCRIPT bold_X ( italic_\u03c4 ) in m\u03b8subscript\ud835\udc5a\ud835\udf03m_{\\theta}italic_m start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT which\ndepends on \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) as we have seen in (2.13). This fact makes not possible to perform the study of the sensitivity in call options written on CDD futures prices over a measurement period with respect to infinitesimal changes in \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ).\nThe linearized CDD futures price as defined in (2.9) makes possible to get\nan approximate call option price formula which is analytically treatable in the sense that\napproximation methods like Monte Carlo are not required.\nThis problem is thoroughly tackled by setting in (2.14)\nthe linearized CDD futures prices defined in (2.9), see Benth and Solanilla Blanco [2] for a detailed explanation.\nThe approximate formula for the call option price then reduces to with and Observe that the approximate call option becomes explicitly dependent on the approximate futures price.\nThe next proposition provides the partial derivatives of the approximate call option price with respect to the components of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x. Let t\u2264\u03c41\ud835\udc61subscript\ud835\udf0f1t\\leq\\tau_{1}italic_t \u2264 italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, then it holds that for i=1,\u2026,p.\ud835\udc561normal-\u2026\ud835\udc5di=1,\\ldots,p.italic_i = 1 , \u2026 , italic_p . The proof follows by taking partial derivatives in (2.15). Take into account that \u03a8\u2032\u2062(x)=\u03a6\u2062(x)superscript\u03a8\u2032\ud835\udc65\u03a6\ud835\udc65\\Psi^{\\prime}(x)=\\Phi(x)roman_\u03a8 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_x ) = roman_\u03a6 ( italic_x )\nand that the only component in the function d\ud835\udc51ditalic_d dependent on the components of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) is the approximate\nfutures price whose partial derivatives are provided in Proposition.\u00a02.2.\n\u00a0 \u25a1\u25a1\\Box\u25a1 In the next section we simplify our setting to perform the study of sensitivity and consider futures prices with a measurement day and call options written on these. In this Section we perform a complete study of the sensitivity of CDD and HDD futures prices with a measurement day and call options written on these to infinitesimal changes on the components of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ). The Fubini-Tonelli theorem, see e.g. Folland [5] connects futures prices\nsetting over a time period and futures prices with a delivery day running over a time period\nas follows for t\u2264s\ud835\udc61\ud835\udc60t\\leq sitalic_t \u2264 italic_s. We see that FCDD\u2062(t,\u03c41,\u03c42)subscript\ud835\udc39CDD\ud835\udc61subscript\ud835\udf0f1subscript\ud835\udf0f2F_{\\text{CDD}}(t,\\tau_{1},\\tau_{2})italic_F start_POSTSUBSCRIPT CDD end_POSTSUBSCRIPT ( italic_t , italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) is expressed as the CDD futures price at time t\ud835\udc61titalic_t with a measurement day s\ud835\udc60sitalic_s, denoted FCDD\u2062(t,s)subscript\ud835\udc39CDD\ud835\udc61\ud835\udc60F_{\\text{CDD}}(t,s)italic_F start_POSTSUBSCRIPT CDD end_POSTSUBSCRIPT ( italic_t , italic_s ), running over the time period [\u03c41,\u03c42].subscript\ud835\udf0f1subscript\ud835\udf0f2[\\tau_{1},\\tau_{2}].[ italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] . Consequently, we deduce from (2.3) and (2.4) respectively that and where, for \ud835\udc31\u2208\u211dp\ud835\udc31superscript\u211d\ud835\udc5d\\mathbf{x}\\in\\mathbb{R}^{p}bold_x \u2208 blackboard_R start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT Recall that \u03a8\u2062(x)=x\u2062\u03a6\u2062(x)+\u03a6\u2032\u2062(x)\u03a8\ud835\udc65\ud835\udc65\u03a6\ud835\udc65superscript\u03a6\u2032\ud835\udc65\\Psi(x)=x\\Phi(x)+\\Phi^{\\prime}(x)roman_\u03a8 ( italic_x ) = italic_x roman_\u03a6 ( italic_x ) + roman_\u03a6 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_x ), with \u03a6\u03a6\\Phiroman_\u03a6 being the cumulative standard normal\ndistribution function. The same notation introduced in (2.6) can be used in this context, then The term \ud835\udc1e1\u2032\u2062exp\u2061(A\u2062(s\u2212t))\u2062\ud835\udc17\u2062(t)superscriptsubscript\ud835\udc1e1\u2032\ud835\udc34\ud835\udc60\ud835\udc61\ud835\udc17\ud835\udc61\\mathbf{e}_{1}^{\\prime}\\exp(A(s-t))\\mathbf{X}(t)bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT roman_exp ( italic_A ( italic_s - italic_t ) ) bold_X ( italic_t ) included in m\u03b8subscript\ud835\udc5a\ud835\udf03m_{\\theta}italic_m start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT\nand rewritten as in (2.5) contains all the stochasticity\nof the futures prices and provides information about its evolution.\nNote that when the time to measurement x=s\u2212t\u2192\u221e\ud835\udc65\ud835\udc60\ud835\udc61\u2192x=s-t\\rightarrow\\inftyitalic_x = italic_s - italic_t \u2192 \u221e,\nthe function fi\u2062(s\u2212t)subscript\ud835\udc53\ud835\udc56\ud835\udc60\ud835\udc61f_{i}(s-t)italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_s - italic_t ) tends to zero for i=1,\u22ef,p\ud835\udc561\u22ef\ud835\udc5di=1,\\cdots,pitalic_i = 1 , \u22ef , italic_p since the real parts of\nthe eigenvalues of the matrix A\ud835\udc34Aitalic_A are all strictly negative for having a stationary model.\nHence, at the long end we can say that\nthe behavior of the future prices is not affected by this term.\nBut, if x\ud835\udc65xitalic_x is approaching to zero, the term \ud835\udc1e1\u2032\u2062exp\u2061(A\u2062(s\u2212t))\u2062\ud835\udc17\u2062(t)superscriptsubscript\ud835\udc1e1\u2032\ud835\udc34\ud835\udc60\ud835\udc61\ud835\udc17\ud835\udc61\\mathbf{e}_{1}^{\\prime}\\exp(A(s-t))\\mathbf{X}(t)bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT roman_exp ( italic_A ( italic_s - italic_t ) ) bold_X ( italic_t )\nis influenced for all the components of the \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ). Finally, for x=0\ud835\udc650x=0italic_x = 0, only the first component of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t )\ntakes part on the evolution of the futures prices. These arguments determine\nthe evolution of futures prices at time t>0\ud835\udc610t>0italic_t > 0 when time to delivery is a day s\ud835\udc60sitalic_s,\u2009s\u2265t\ud835\udc60\ud835\udc61s\\geq titalic_s \u2265 italic_t.\nIn the case of futures prices with measurement period as presented in Section 2,\nwe have to take into account that s\ud835\udc60sitalic_s is running over a measurement period.\nIn the next proposition we consider the partial derivatives of the CDD futures price with respect to the components of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x. Let t\u2264s\ud835\udc61\ud835\udc60t\\leq sitalic_t \u2264 italic_s, it holds that for i=1,\u2026,p\ud835\udc561normal-\u2026\ud835\udc5di=1,\\ldots,pitalic_i = 1 , \u2026 , italic_p. The proof follows by applying the chain-rule. Consider that \u03a8\u2032\u2062(x)=\u03a6\u2062(x)superscript\u03a8\u2032\ud835\udc65\u03a6\ud835\udc65\\Psi^{\\prime}(x)=\\Phi(x)roman_\u03a8 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_x ) = roman_\u03a6 ( italic_x )\nand also take into account that m\u03b8subscript\ud835\udc5a\ud835\udf03m_{\\theta}italic_m start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT can be written as a linear combination of the components of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x as follows so that \u25a1\u25a1\\Box\u25a1 Next, we also adapt the linearized formulas for CDD futures\nprices presented before to our setting. To this end let t\u2264s\ud835\udc61\ud835\udc60t\\leq sitalic_t \u2264 italic_s,\nformulas (2.7) and (2.8) reduce respectively to where and where We provide also the new notation that encompasses\nboth approximate CDD futures prices formulas. To this end let t\u2264s\ud835\udc61\ud835\udc60t\\leq sitalic_t \u2264 italic_s, then where \u0398\u0398\\Thetaroman_\u0398 and \ud835\udc1a\ud835\udc1a\\mathbf{a}bold_a are generic notations for\n\u0398xsubscript\u0398\ud835\udc65\\Theta_{x}roman_\u0398 start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT and \ud835\udc1axsubscript\ud835\udc1a\ud835\udc65\\mathbf{a}_{x}bold_a start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT or \u0398Taylorsubscript\u0398Taylor\\Theta_{\\text{Taylor}}roman_\u0398 start_POSTSUBSCRIPT Taylor end_POSTSUBSCRIPT and \ud835\udc1aTaylorsubscript\ud835\udc1aTaylor\\mathbf{a}_{\\text{Taylor}}bold_a start_POSTSUBSCRIPT Taylor end_POSTSUBSCRIPT.\nThe next proposition provides the partial derivatives of the approximate CDD futures prices with respect to the components of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x. Let t\u2264s\ud835\udc61\ud835\udc60t\\leq sitalic_t \u2264 italic_s, then it holds that for i=1,\u2026,p\ud835\udc561normal-\u2026\ud835\udc5di=1,\\ldots,pitalic_i = 1 , \u2026 , italic_p, where \ud835\udc1a\ud835\udc1a\\mathbf{a}bold_a is the generic notation for \ud835\udc1a\ud835\udc65subscript\ud835\udc1a\ud835\udc65\\mathbf{a}_{\\text{x}}bold_a start_POSTSUBSCRIPT x end_POSTSUBSCRIPT and \ud835\udc1a\ud835\udc47\u2062a\u2062y\u2062l\u2062o\u2062rsubscript\ud835\udc1a\ud835\udc47\ud835\udc4e\ud835\udc66\ud835\udc59\ud835\udc5c\ud835\udc5f\\mathbf{a}_{\\text{T}aylor}bold_a start_POSTSUBSCRIPT T italic_a italic_y italic_l italic_o italic_r end_POSTSUBSCRIPT. Rewrite (3.4) in terms of the components of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x as and differentiate with respect to the components \ud835\udea1isubscript\ud835\udea1\ud835\udc56\\texttt{x}_{i}x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for i=1,\u2026,p\ud835\udc561\u2026\ud835\udc5di=1,\\ldots,pitalic_i = 1 , \u2026 , italic_p.\n\u00a0 \u25a1\u25a1\\Box\u25a1 Observe that unlike the result in Proposition.\u00a03.1, here we loose the dependency on \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ). The arbitrage-free price for a call option with strike K\ud835\udc3eKitalic_K at exercise time \u03c4\ud835\udf0f\\tauitalic_\u03c4,\nwritten on a CDD futures with measurement day s\ud835\udc60sitalic_s, for a time t\ud835\udc61titalic_t\nwith t\u2264\u03c4\u2264s\ud835\udc61\ud835\udf0f\ud835\udc60t\\leq\\tau\\leq sitalic_t \u2264 italic_\u03c4 \u2264 italic_s is defined as where r>0\ud835\udc5f0r>0italic_r > 0 is the risk-free interest rate. For our purposes and making use of the same argument as in Section 2 we can rewritte (3.6) as Next, we see that the density approach here works well as the payoff function of the call option price is\nnot path-dependent on \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) over a time period. In the next Proposition we present then the partial derivatives of the call option price\nwith respect to the components of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x. Let t\u2264s\ud835\udc61\ud835\udc60t\\leq sitalic_t \u2264 italic_s, then it holds that for i=1,\u2026,p\ud835\udc561normal-\u2026\ud835\udc5di=1,\\ldots,pitalic_i = 1 , \u2026 , italic_p, where for \ud835\udc31\u2208\u211dp\ud835\udc31superscript\u211d\ud835\udc5d\\mathbf{x}\\in\\mathbb{R}^{p}bold_x \u2208 blackboard_R start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT Z=\ud835\udc1e1\u2032\u2062exp\u2061(A\u2062(s\u2212\u03c4))\u2062\ud835\udc17\u2062(\u03c4)\ud835\udc4dsuperscriptsubscript\ud835\udc1e1\u2032\ud835\udc34\ud835\udc60\ud835\udf0f\ud835\udc17\ud835\udf0fZ=\\mathbf{e}_{1}^{\\prime}\\exp(A(s-\\tau))\\mathbf{X}(\\tau)italic_Z = bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT roman_exp ( italic_A ( italic_s - italic_\u03c4 ) ) bold_X ( italic_\u03c4 ) is a normally distributed random variable and are the mean and the variance of Z\ud835\udc4dZitalic_Z conditioned on \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ), respectively. The random variable \ud835\udc1e1\u2032\u2062exp\u2061(A\u2062(s\u2212\u03c4))\u2062\ud835\udc17\u2062(\u03c4)=Zsuperscriptsubscript\ud835\udc1e1\u2032\ud835\udc34\ud835\udc60\ud835\udf0f\ud835\udc17\ud835\udf0f\ud835\udc4d\\mathbf{e}_{1}^{\\prime}\\exp(A(s-\\tau))\\mathbf{X}(\\tau)=Zbold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT roman_exp ( italic_A ( italic_s - italic_\u03c4 ) ) bold_X ( italic_\u03c4 ) = italic_Z included in m\u03b8subscript\ud835\udc5a\ud835\udf03m_{\\theta}italic_m start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT\nis normally distributed and and are the mean and the variance of Z\ud835\udc4dZitalic_Z, respectively, conditioned on\n\ud835\udc17\u2062(t).\ud835\udc17\ud835\udc61\\mathbf{X}(t).bold_X ( italic_t ) . The probability density function of Z\ud835\udc4dZitalic_Z is then We see that we have moved the dependency of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) contained in\nZ\ud835\udc4dZitalic_Z from the payoff function to the required density function to compute the\nthe conditional expectation as follows \u25a1\u25a1\\Box\u25a1 Next, we adapt to our setting the approximate call option price formula in (2.15)\nwhich reduces to with and We end up this Section with a result for the partial derivatives of the approximate call option price\nwith respect to the components of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x. Let t\u2264s\ud835\udc61\ud835\udc60t\\leq sitalic_t \u2264 italic_s, then it holds that for i=1,\u2026,p.\ud835\udc561normal-\u2026\ud835\udc5di=1,\\ldots,p.italic_i = 1 , \u2026 , italic_p . The proof follows by taking partial derivatives in (3.8). Take into account that \u03a8\u2032\u2062(x)=\u03a6\u2062(x)superscript\u03a8\u2032\ud835\udc65\u03a6\ud835\udc65\\Psi^{\\prime}(x)=\\Phi(x)roman_\u03a8 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_x ) = roman_\u03a6 ( italic_x )\nand that the only component in function d\ud835\udc51ditalic_d dependent on the components of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) is the approximate\nfutures price whose partial derivatives are provided in Proposition.\u00a03.2.\n\u00a0 \u25a1\u25a1\\Box\u25a1 Consider the stationary CAR(3333)-process obtained to model the\ntemperature data from New York in Benth and Solanilla Blanco [2]\nwhich is defined with the following mean reverting matrix A\ud835\udc34Aitalic_A, and a constant volatility, \u03c3=5.25\ud835\udf0e5.25\\sigma=5.25italic_\u03c3 = 5.25. The function \u03a32superscript\u03a32\\Sigma^{2}roman_\u03a3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT which defines\nthe CDD and HDD futures price now reduces to Furthermore we choose to work with \u03b8=0\ud835\udf030\\theta=0italic_\u03b8 = 0 and fix the measurement day as August 1st, 2011.\nWe focus our empirical study on CDD futures prices with a measurement day being August 1st, 2011\nand call options written on these.\nWe include also a final section with some empirics on CDD futures prices with a delivery period being\nAugust 2011. We choose to work with delivery in August 2011, whether it is a particular day\nor all the month, as it was proved in Benth and Solanilla Blanco [2] that\nthe approximative formula for the CDD futures price worked well in this time period. To analyze the sensitivity of CDD futures prices with measurement as August 1st 2011 we consider\nProposition. 3.1 and Proposition. 3.2 in Section 3.\nIn this context, the random variable \u03a6(m\u03b8(t,s,\ud835\udc17(t))\u2212c)/\u03a3(s\u2212t))\\Phi(m_{\\theta}(t,s,\\mathbf{X}(t))-c)/\\Sigma(s-t))roman_\u03a6 ( italic_m start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_t , italic_s , bold_X ( italic_t ) ) - italic_c ) / roman_\u03a3 ( italic_s - italic_t ) )\nwhich makes the difference between the result provided in Proposition\u00a03.1\nand Proposition\u00a03.2 can be rewritten as \u03a6\u2062(Z\u2062(t,s))\u03a6\ud835\udc4d\ud835\udc61\ud835\udc60\\Phi(Z(t,s))roman_\u03a6 ( italic_Z ( italic_t , italic_s ) ) where and s\u2212t\ud835\udc60\ud835\udc61s-titalic_s - italic_t is the time to maturity. In Benth and Solanilla Blanco [2],\na more general study with \u03b8\ud835\udf03\\thetaitalic_\u03b8 being a time dependent function concludes that\nwhen s\u2212t\u21930\u2193\ud835\udc60\ud835\udc610s-t\\downarrow 0italic_s - italic_t \u2193 0 the expected value of Z\u2062(t,s)\ud835\udc4d\ud835\udc61\ud835\udc60Z(t,s)italic_Z ( italic_t , italic_s ) tends to \u00b1\u221eplus-or-minus\\pm\\infty\u00b1 \u221e and the\nvariance \u221e\\infty\u221e. Such a case indicates too much dispersion.\nOn the other hand, when s\u2212t\u2192\u221e\u2192\ud835\udc60\ud835\udc61s-t\\rightarrow\\inftyitalic_s - italic_t \u2192 \u221e, the variance of Z\u2062(t,s)\ud835\udc4d\ud835\udc61\ud835\udc60Z(t,s)italic_Z ( italic_t , italic_s ) tends to zero, then\nZ\u2062(t,s)\u2248\ud835\udd3cQ\u2062(Z\u2062(t,s))\ud835\udc4d\ud835\udc61\ud835\udc60subscript\ud835\udd3c\ud835\udc44\ud835\udc4d\ud835\udc61\ud835\udc60Z(t,s)\\approx\\mathbb{E}_{Q}(Z(t,s))italic_Z ( italic_t , italic_s ) \u2248 blackboard_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_Z ( italic_t , italic_s ) ). Figure. 1 shows the tendency Z\u2062(t,s)\ud835\udc4d\ud835\udc61\ud835\udc60Z(t,s)italic_Z ( italic_t , italic_s )\nwhen the measurement day s\ud835\udc60sitalic_s is August 1st, 2011. Figure.\u00a02 is the result of applying the function \u03a6\u03a6\\Phiroman_\u03a6 to the plot in Figure.\u00a01. We see that\n\u03a6\u2062(Z\u2062(t,s))=1\u03a6\ud835\udc4d\ud835\udc61\ud835\udc601\\Phi(Z(t,s))=1roman_\u03a6 ( italic_Z ( italic_t , italic_s ) ) = 1 for s\u2212t=1,2\ud835\udc60\ud835\udc6112s-t=1,2italic_s - italic_t = 1 , 2. From s\u2212t=3\ud835\udc60\ud835\udc613s-t=3italic_s - italic_t = 3 to s\u2212t=11\ud835\udc60\ud835\udc6111s-t=11italic_s - italic_t = 11 there is a small decay and finally \u03a6\u2062(Z\u2062(t,s))\u03a6\ud835\udc4d\ud835\udc61\ud835\udc60\\Phi(Z(t,s))roman_\u03a6 ( italic_Z ( italic_t , italic_s ) ) stabilizes at 0.9924 for s\u2212t\u226512\ud835\udc60\ud835\udc6112s-t\\geq 12italic_s - italic_t \u2265 12.\nThe values between the dashed lines are more probable than the ones in between the dotted lines.\nWe deduce that for i=1,\u2026,3\ud835\udc561\u20263i=1,\\ldots,3italic_i = 1 , \u2026 , 3\u2009, i.e., the approximate CDD futures prices are more sensitive to changes in the components of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) than the CDD futures prices. Recall from Benth and Solanilla Blanco [1] that \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t )\ncontains the deseasonalized temperature Y\u2062(t)\ud835\udc4c\ud835\udc61Y(t)italic_Y ( italic_t ) and its derivatives\nup to order p\u22121\ud835\udc5d1p-1italic_p - 1. In our setting then, \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) reduces to where Y\u2032\u2062(t)superscript\ud835\udc4c\u2032\ud835\udc61Y^{\\prime}(t)italic_Y start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_t ) and Y\u2032\u2032\u2062(t)superscript\ud835\udc4c\u2032\u2032\ud835\udc61Y^{\\prime\\prime}(t)italic_Y start_POSTSUPERSCRIPT \u2032 \u2032 end_POSTSUPERSCRIPT ( italic_t ) are respectively the slope and the curvature of Y\u2062(t)\ud835\udc4c\ud835\udc61Y(t)italic_Y ( italic_t ), respectively. Figure.\u00a03 shows the partial derivatives of the approximate CDD futures price with respect the coordinates of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x as presented in Proposition. 3.2.\nThe x-axis considers the time to maturity, s\u2212t\ud835\udc60\ud835\udc61s-titalic_s - italic_t, where the measurement day s\ud835\udc60sitalic_s is August 1st, 2011. The y-axis shows the different partial derivatives.\nFirstly, we observe that the partial derivatives of the approximate CDD futures price are positive.\nWe see that at time to maturity s\u2212t=1\ud835\udc60\ud835\udc611s-t=1italic_s - italic_t = 1 any perturbation in the component \ud835\udea11subscript\ud835\udea11\\texttt{x}_{1}x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT affects the tendency\nof the approximate CDD futures price more than in the components \ud835\udea12subscript\ud835\udea12\\texttt{x}_{2}x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and \ud835\udea13subscript\ud835\udea13\\texttt{x}_{3}x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT.\nHowever, when time to maturity increases the contribution of \ud835\udea11subscript\ud835\udea11\\texttt{x}_{1}x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT decreases gradually.\nFrom s\u2212t=1\ud835\udc60\ud835\udc611s-t=1italic_s - italic_t = 1 to s\u2212t=2\ud835\udc60\ud835\udc612s-t=2italic_s - italic_t = 2 the contribution of \ud835\udea12subscript\ud835\udea12\\texttt{x}_{2}x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT increases\nto the extent that at time to maturity s\u2212t=2\ud835\udc60\ud835\udc612s-t=2italic_s - italic_t = 2 perturbations in x2subscript\ud835\udc652x_{2}italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT dominate the evolution of the approximate CDD futures price.\nFrom s\u2212t>2\ud835\udc60\ud835\udc612s-t>2italic_s - italic_t > 2 the contribution of \ud835\udea12subscript\ud835\udea12\\texttt{x}_{2}x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT decreases gradually but it remains always above \ud835\udea11subscript\ud835\udea11\\texttt{x}_{1}x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.\nThe contribution of \ud835\udea13subscript\ud835\udea13\\texttt{x}_{3}x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT increases from s\u2212t=1\ud835\udc60\ud835\udc611s-t=1italic_s - italic_t = 1 to s\u2212t=3\ud835\udc60\ud835\udc613s-t=3italic_s - italic_t = 3. For bigger times to maturity it decreases gradually.\nWe point out that variations in \ud835\udea13subscript\ud835\udea13\\texttt{x}_{3}x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT always contribute less than variations in \ud835\udea11subscript\ud835\udea11\\texttt{x}_{1}x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT or \ud835\udea12subscript\ud835\udea12\\texttt{x}_{2}x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT.\nAt the long end, small variations in any component hardly affect the tendency of the approximate CDD futures price.\nThis fact makes sense as the term \ud835\udc1e1\u2062eA\u2062(s\u2212t)\u2062\ud835\udc31subscript\ud835\udc1e1superscript\ud835\udc52\ud835\udc34\ud835\udc60\ud835\udc61\ud835\udc31\\mathbf{e}_{1}e^{A(s-t)}\\mathbf{x}bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_e start_POSTSUPERSCRIPT italic_A ( italic_s - italic_t ) end_POSTSUPERSCRIPT bold_x, which is dependent on\nthe coordinates of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x, tends to zero at the long end.\nThe partial derivatives of the CDD futures price with respect the coordinates of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x, as presented in Proposition. 3.1, depend on \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ).\nThe first component Y\u2062(t)=T\u2062(t)\u2212\u039b\u2062(t)\ud835\udc4c\ud835\udc61\ud835\udc47\ud835\udc61\u039b\ud835\udc61Y(t)=T(t)-\\Lambda(t)italic_Y ( italic_t ) = italic_T ( italic_t ) - roman_\u039b ( italic_t ) corresponds to the deseasonalized temperature.\nWe approximate the derivatives of Y\u2062(t)\ud835\udc4c\ud835\udc61Y(t)italic_Y ( italic_t ) with backward finite differences.\nHence Y\u2032\u2062(t)\u2248Y\u2062(t)\u2212Y\u2062(t\u22121)superscript\ud835\udc4c\u2032\ud835\udc61\ud835\udc4c\ud835\udc61\ud835\udc4c\ud835\udc611Y^{\\prime}(t)\\approx Y(t)-Y(t-1)italic_Y start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_t ) \u2248 italic_Y ( italic_t ) - italic_Y ( italic_t - 1 ) is approximated by\nthe difference between the deseasonalized temperature at times t\ud835\udc61titalic_t and t\u22121\ud835\udc611t-1italic_t - 1.\nY\u2032\u2032\u2062(t)\u2248Y\u2062(t)\u22122\u2062Y\u2062(t\u22121)+Y\u2062(t\u22122)superscript\ud835\udc4c\u2032\u2032\ud835\udc61\ud835\udc4c\ud835\udc612\ud835\udc4c\ud835\udc611\ud835\udc4c\ud835\udc612Y^{\\prime\\prime}(t)\\approx Y(t)-2Y(t-1)+Y(t-2)italic_Y start_POSTSUPERSCRIPT \u2032 \u2032 end_POSTSUPERSCRIPT ( italic_t ) \u2248 italic_Y ( italic_t ) - 2 italic_Y ( italic_t - 1 ) + italic_Y ( italic_t - 2 ) is approximated by a linear combination of the\ndeseasonalized temperatures at times t\ud835\udc61titalic_t and the two prior times t\u22121\ud835\udc611t-1italic_t - 1 and t\u22122\ud835\udc612t-2italic_t - 2.\nFinally, we get the following relation between the temperature and the seasonal\nfunction: Observe that given a fixed \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) with 0\u2264t\u2264s0\ud835\udc61\ud835\udc600\\leq t\\leq s0 \u2264 italic_t \u2264 italic_s, the temperature at time t\ud835\udc61titalic_t\nis approximately \ud835\udea11subscript\ud835\udea11\\texttt{x}_{1}x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT degrees above the seasonal mean function and one and tho days prior to t\ud835\udc61titalic_t, it is\napproximately \ud835\udea11\u2212\ud835\udea12subscript\ud835\udea11subscript\ud835\udea12\\texttt{x}_{1}-\\texttt{x}_{2}x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and\n\ud835\udea13\u22122\u2062\ud835\udea12+\ud835\udea11subscript\ud835\udea132subscript\ud835\udea12subscript\ud835\udea11\\texttt{x}_{3}-2\\texttt{x}_{2}+\\texttt{x}_{1}x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - 2 x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT degrees above the seasonal mean function, respectively. Consider \ud835\udc17\u2062(t)=\ud835\udfce\ud835\udc17\ud835\udc610\\mathbf{X}(t)=\\mathbf{0}bold_X ( italic_t ) = bold_0 where \ud835\udfce0\\mathbf{0}bold_0 is the null vector in \u211d3superscript\u211d3\\mathbb{R}^{3}blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. The partial derivatives of the CDD futures price are completely deterministic.\nBy the relation between the temperature and the seasonal function established in (4.8), for this particular case the temperature for the time t\ud835\udc61titalic_t and the two prior times t\u22121\ud835\udc611t-1italic_t - 1 and t\u22122\ud835\udc612t-2italic_t - 2 is approximately\nthe seasonal mean function. Figure.\u00a04 shows the partial derivatives of the CDD futures price with respect the coordinates of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x derived in Proposition 3.1.\nThe x-axis considers the time to maturity, s\u2212t\ud835\udc60\ud835\udc61s-titalic_s - italic_t, where the measurement day s\ud835\udc60sitalic_s is August 1st, 2011. The y-axis shows the\ndifferent partial derivatives. Observe that at first sight Figure.\u00a03 and Figure.\u00a04 seem to coincide.\nIndeed, Figure. 5 below shows that the relative error between them is less than 1%percent\\%% entirely. Consider also the case where \ud835\udc17\u2062(t)=\ud835\udc1ek\ud835\udc17\ud835\udc61subscript\ud835\udc1e\ud835\udc58\\mathbf{X}(t)=\\mathbf{e}_{k}bold_X ( italic_t ) = bold_e start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT is the k\ud835\udc58kitalic_kth canonical basis vector in \u211d3superscript\u211d3\\mathbb{R}^{3}blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT for k=1,\u2026,3\ud835\udc581\u20263k=1,\\ldots,3italic_k = 1 , \u2026 , 3.\nFor \ud835\udc17\u2062(t)=\ud835\udc1e1\ud835\udc17\ud835\udc61subscript\ud835\udc1e1\\mathbf{X}(t)=\\mathbf{e}_{1}bold_X ( italic_t ) = bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT\nthe temperature at the present time t\ud835\udc61titalic_t and at the two consecutive prior times to t\ud835\udc61titalic_t, say t\u22121\ud835\udc611t-1italic_t - 1 and t\u22122\ud835\udc612t-2italic_t - 2, is approximately one degree above the seasonal mean function.\nFor \ud835\udc17\u2062(t)=\ud835\udc1e2\ud835\udc17\ud835\udc61subscript\ud835\udc1e2\\mathbf{X}(t)=\\mathbf{e}_{2}bold_X ( italic_t ) = bold_e start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, the temperature is close to the seasonal mean at present time t\ud835\udc61titalic_t and\nit is approximately one and two degrees below the seasonal mean at times t\u22121\ud835\udc611t-1italic_t - 1 and t\u22122\ud835\udc612t-2italic_t - 2, respectively.\nFinally for \ud835\udc17\u2062(t)=\ud835\udc1e3\ud835\udc17\ud835\udc61subscript\ud835\udc1e3\\mathbf{X}(t)=\\mathbf{e}_{3}bold_X ( italic_t ) = bold_e start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT the temperature is close to the seasonal mean at present time t\ud835\udc61titalic_t\nand one prior time, but two days prior to t\ud835\udc61titalic_t it is nearly one degree above its seasonal mean. The partial derivatives\nof the CDD futures price evaluated at the canonical basis vectors in \u211d3superscript\u211d3\\mathbb{R}^{3}blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT also behave in a similar way to the partial\nderivatives on the approximate CDD futures price. Figure.\u00a06 below shows that, for the case \ud835\udc17\u2062(t)=\ud835\udc1e1\ud835\udc17\ud835\udc61subscript\ud835\udc1e1\\mathbf{X}(t)=\\mathbf{e}_{1}bold_X ( italic_t ) = bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT,\nthe relative error between the partial derivatives of the approximate CDD futures price and the CDD futures price\nis also less than 1% entirely. We proceed now with the analysis of call option prices written on CDD futures prices and call option prices\nwritten on the approximate CDD futures prices. To do so, we consider the results in\nPropositons\u00a03.3 and 3.4. Observe that in both results there is dependency on\n\ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ). We focus on an at-the-money call option prices. In view of Figure.\u00a07\nwe fix the strike price K\ud835\udc3eKitalic_K being K=13\ud835\udc3e13K=13italic_K = 13. For the study of the sensitivity of call option prices, we restrict our attention to the cases \ud835\udc17\u2062(t)=\ud835\udfce\ud835\udc17\ud835\udc610\\mathbf{X}(t)=\\mathbf{0}bold_X ( italic_t ) = bold_0 and \ud835\udc17\u2062(t)=\ud835\udc1e1\ud835\udc17\ud835\udc61subscript\ud835\udc1e1\\mathbf{X}(t)=\\mathbf{e}_{1}bold_X ( italic_t ) = bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.\nNext, we show the plots with the partial derivatives of the (approximate) call option prices\nwith respect to the coordinates of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x derived in Proposition. 3.3 and Proposition. 3.4. The x-axis considers the time to maturity, s\u2212t\ud835\udc60\ud835\udc61s-titalic_s - italic_t, where s\ud835\udc60sitalic_s is August 2nd, 2011. We have fixed the exercise time \u03c4\ud835\udf0f\\tauitalic_\u03c4 being August 1st, 2011.\nThe y-axis shows the different partial derivatives of the call option price when \ud835\udc17\u2062(t)=\ud835\udfce\ud835\udc17\ud835\udc610\\mathbf{X}(t)=\\mathbf{0}bold_X ( italic_t ) = bold_0.\nFirstly, we observe that all the partial derivatives of the call option are positive.\nWe see that for all times to maturity the call option price is more\nsensitive to any infinitesimal change in the component \ud835\udea12subscript\ud835\udea12\\texttt{x}_{2}x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, followed by \ud835\udea11subscript\ud835\udea11\\texttt{x}_{1}x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \ud835\udea13subscript\ud835\udea13\\texttt{x}_{3}x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT.\nThis tendency follows as time to maturity increases.\nAt the long end, small variations in any component hardly affect the tendency of the call option prices. Figure.\u00a09 shows the partial derivatives of the approximate call option prices\nwith respect to the coordinates of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x derived in Proposition. 3.4 when \ud835\udc17\u2062(t)=\ud835\udfce\ud835\udc17\ud835\udc610\\mathbf{X}(t)=\\mathbf{0}bold_X ( italic_t ) = bold_0.\nWe observe that the partial derivatives in Figure.\u00a08 and Figure.\u00a09 show a close habavior.\nWe also see that for small times to maturity the partial derivatives of the approximate call option price are bigger than\nthe partial derivatives of the call option price. We end our analysis with the results for the case \ud835\udc17\u2062(t)=\ud835\udc1e1\ud835\udc17\ud835\udc61subscript\ud835\udc1e1\\mathbf{X}(t)=\\mathbf{e}_{1}bold_X ( italic_t ) = bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Figure. 10 and Figure.11 show the partial derivatives for the (approximate) call option prices, respectively.\nWe see also here that both prices are more sensitive to changes in the second component of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x in all the domain. Furthermore,\nthe sensitivity to this component decreases as time to maturity increases. The sensitivity analysis of CDD future prices with measurement over a period [\u03c41,\u03c42]subscript\ud835\udf0f1subscript\ud835\udf0f2[\\tau_{1},\\tau_{2}][ italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] with respect to infinitesimal changes in the components of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t )\ncan be performed by means of the partial derivatives provided in Proposition.2.1 and Proposition. 2.2.\nWe proceed analogously as in the previous section for CDD futures prices with a measurement day. The random variable \u03a6\u2062(Z\u2062(t,s))\u03a6\ud835\udc4d\ud835\udc61\ud835\udc60\\Phi(Z(t,s))roman_\u03a6 ( italic_Z ( italic_t , italic_s ) ) with Z\u2062(t,s)\ud835\udc4d\ud835\udc61\ud835\udc60Z(t,s)italic_Z ( italic_t , italic_s ) in (4.1) makes here also the difference between the results provided in both Propositions. The same reasoning followed for CDD future prices with a measurement day is valid to conclude that Hence, the approximate CDD futures price becomes more sensitive to any infinitesimal change in the coordinates of \ud835\udc17\u2062(t)\ud835\udc17\ud835\udc61\\mathbf{X}(t)bold_X ( italic_t ) than the CDD futures price. Figure.12 shows the partial derivatives of the approximate CDD futures price with respect the coordinates of \ud835\udc31\ud835\udc31\\mathbf{x}bold_x derived in\nProposition.\u00a02.2. The x-axis considers the time to maturity, \u03c41\u2212tsubscript\ud835\udf0f1\ud835\udc61\\tau_{1}-titalic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_t, where \u03c41subscript\ud835\udf0f1\\tau_{1}italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is August 1st, 2011\nand the measurement period [\u03c41,\u03c42]subscript\ud835\udf0f1subscript\ud835\udf0f2[\\tau_{1},\\tau_{2}][ italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] is August 2011.\nThe y-axis shows the different partial derivatives of the approximate CDD futures price.\nFirstly, we observe that the values here of the partial derivatives\nare greater than those corresponding to the partial derivatives of the approximate CDD futures price with a measurement day,\nwith more emphasis on times t\ud835\udc61titalic_t which are close to \u03c41subscript\ud835\udf0f1\\tau_{1}italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.\nIndeed, the partial derivatives of the approximate CDD futures prices can be understood\nas the partial derivatives of the approximate CDD futures prices with measurement day s\ud835\udc60sitalic_s which runs over [\u03c41,\u03c42]subscript\ud835\udf0f1subscript\ud835\udf0f2[\\tau_{1},\\tau_{2}][ italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] as shown as follows Recall that Figure.\u00a03 shows that the derivatives of the approximate CDD futures price with a measurement day are\npositive and when time to maturity increases tend to zero. This fact together with the\nrelation in (5.1) let us to justify why the derivatives of the approximate CDD futures prices with measurement over a period behave in this way.\nWe also observe that any infinitesimal change in \ud835\udea12subscript\ud835\udea12\\texttt{x}_{2}x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT dominates more the behaviour of the\napproximate CDD futures price, followed by any change in \ud835\udea11subscript\ud835\udea11\\texttt{x}_{1}x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \ud835\udea13subscript\ud835\udea13\\texttt{x}_{3}x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT.\nThis was exactly the same tendency followed by the partial derivatives of the approximate CDD futures price with\na measurement day, see Figure.\u00a03, for times to maturity greater than 2. For the study of the sensitivity of the partial derivatives of the CDD futures price with measurement over a period\nderived in Proposition. 2.1 we consider the cases \ud835\udc17\u2062(t)=\ud835\udfce\ud835\udc17\ud835\udc610\\mathbf{X}(t)=\\mathbf{0}bold_X ( italic_t ) = bold_0 and \ud835\udc17\u2062(t)=\ud835\udc1e1\ud835\udc17\ud835\udc61subscript\ud835\udc1e1\\mathbf{X}(t)=\\mathbf{e}_{1}bold_X ( italic_t ) = bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Figure. 13 and Figure. 14 show also that perturbations in \ud835\udea12subscript\ud835\udea12\\texttt{x}_{2}x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT\naffect also more in these cases the CDD futures price. In this paper we have studied the local sensitivity of the (approximate) CDD and HDD futures and options prices\nwith respect to a perturbation in the deseasonalized temperature or in one of its derivatives up to a certain order,\ndetermined by the CAR process modelling the deseasonalized temperature. We have considered the partial derivatives\nof these financial contracts with respect to these variables (deseasonalized temperature and its derivatives).\nThe HDD and CDD futures and call option prices and their approximate formulas were derived in Benth and Solanilla Blanco [2].\nWe have considered and empirical analysis where we have taken\nthe same CAR(3)-process fitted to the time series of New York temperatures in Benth and Solanilla Blanco [2].\nThe sensitivity study of these financial contracts with a fixed measurement day shows first that the approximate futures prices\nare more sensitive to any perturbation in one of these variables than the theoretical futures prices. Nevertheless, the relative error\nbetween both partial derivatives is rather small.\nWe also observe that one time prior to the considered measurement day the behaviour of the (approximate) futures prices is more affected by\na perturbation in the deseasonalized temperature. As time to maturity increases then a perturbation in the slope of the deseasonalized temperature\ndominates the behaviour of both futures prices. At the long end any perturbation of these variables hardly affect\ntheir behaviour. For the call option prices we also observe that the approximate model is more sensitive to any pertubation in one of the previous variables than the theoretical model. We emphasize that unlike futures prices,\nany perturbation in the slope of the deseasonalized temperature, dominates the behaviour of the call option prices.\nWe have also extended the analysis of sensitivity to futures prices with measurement over a fixed month. We have seen that in this case\nthe slope of the deseasonalized temperature dominates the bahaviour in all the domain."
    },
    {
        "id": 15,
        "title": "Marginal Fermi liquid behavior at the onset of \ud835\udfd0\u2062\ud835\udc8c\ud835\udc6d2subscript\ud835\udc8c\ud835\udc6d\\boldsymbol{2k_{F}}bold_2 bold_italic_k start_POSTSUBSCRIPT bold_italic_F end_POSTSUBSCRIPT density wave order \nin two-dimensional metals with flat hot spots",
        "corpus": "We analyze quantum fluctuation effects at the onset of incommensurate 2\u2062kF2subscript\ud835\udc58\ud835\udc392k_{F}2 italic_k start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT charge- or spin-density wave order in two-dimensional metals, for a model where the ordering wave vector \ud835\udc10\ud835\udc10{\\bf Q}bold_Q connects a single pair of hot spots on the Fermi surface with a vanishing Fermi surface curvature. The tangential momentum dependence of the bare dispersion near the hot spots is proportional to |kt|\u03b1superscriptsubscript\ud835\udc58\ud835\udc61\ud835\udefc|k_{t}|^{\\alpha}| italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT with \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2. We first compute the order parameter susceptibility and the fermion self-energy in random phase approximation (RPA). Logarithmic divergences are subsequently treated by a renormalization group analysis. The coupling between the order parameter fluctuations and the fermions vanishes logarithmically in the low-energy limit. As a consequence, the logarithmic divergences found in RPA do not sum up to anomalous power laws. Instead, only logarithmic corrections to Fermi liquid behavior are obtained. In particular, the quasiparticle weight and the Fermi velocity vanish logarithmically at the hot spots. Quantum fluctuations at and near quantum critical points in metallic electron systems can trigger non-Fermi liquid behavior with unconventional temperature, momentum, and frequency dependencies of thermodynamic, spectroscopic, and transport properties [1]. In view of non-Fermi liquid or \u201cstrange metal\u201d behavior observed in several layered compounds such as the high-Tcsubscript\ud835\udc47\ud835\udc50T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT cuprates, quantum criticality in two-dimensional systems has attracted particular interest. Metals at the onset of charge or spin-density wave order can be grouped in several distinct universality classes of quantum critical non-Fermi liquids. The most thoroughly studied case of N\u00e9el order is just one example [2, 3, 4, 5].\nA particularly intriguing situation arises when the wave vector \ud835\udc10\ud835\udc10{\\bf Q}bold_Q of the density wave is a nesting vector (also known as \u201c2\u2062kF2subscript\ud835\udc58\ud835\udc392k_{F}2 italic_k start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT\u201d vector [6]) of the Fermi surface, that is, when it connects Fermi points with collinear Fermi velocities [7]. Charge and spin susceptibilities exhibit a singularity at such wave vectors due to an enhanced phase space for low-energy particle-hole excitations.\nThe wave vector of a N\u00e9el state is a nesting vector only for special electron densities [8, 9].\nWhile fluctuations are naturally stronger in two dimensions, quantum fluctuation effects at the onset of 2\u2062kF2subscript\ud835\udc58\ud835\udc392k_{F}2 italic_k start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT density wave order are interesting also in three dimensions [10]. Non-Fermi liquid behavior at the onset of charge- or spin-density wave order with incommensurate [11] nesting wave vectors \ud835\udc10\ud835\udc10{\\bf Q}bold_Q in two-dimensional metals has already been analyzed, too.\nIn a perturbative one-loop calculation of the fermion self-energy, a breakdown of Fermi liquid behavior was found at the hot spots on the Fermi surface connected by the ordering wave vector [12]. If the ordering wave vector \ud835\udc10\ud835\udc10{\\bf Q}bold_Q connects only a single pair of hot spots, in axial or diagonal direction, the frequency dependence of the one-loop self-energy at the hot spots obeys a power-law with exponent\u00a02323\\frac{2}{3}divide start_ARG 2 end_ARG start_ARG 3 end_ARG. If \ud835\udc10\ud835\udc10{\\bf Q}bold_Q connects two pairs of hot spots, the imaginary part of the real frequency one-loop self-energy exhibits a linear frequency dependence.\nIn none of these two cases the perturbative solution is self-consistent, and the feedback of the non-Fermi liquid self-energy seems to shift the ordering wave vector away from the nesting point [13, 14]. For the case of a single hot spot pair, it was argued already long ago that quantum fluctuations replace the QCP by a first order transition [6].\nHowever, a fluctuation induced flattening of the Fermi surface at the hot spots might save the QCP [13], and this scenario was supported by a systematic \u03f5italic-\u03f5\\epsilonitalic_\u03f5-expansion around the critical dimension dc=52subscript\ud835\udc51\ud835\udc5052d_{c}=\\frac{5}{2}italic_d start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = divide start_ARG 5 end_ARG start_ARG 2 end_ARG [15].\nFor the two hot-spot pair case, a self-consistent solution with a stable QCP was found numerically [14]. Recently, we have analyzed non-Fermi liquid behavior at the onset of density wave order for a case where the nesting vector connects a single pair of flat hot spots, where the Fermi surface curvature vanishes already in the non-interacting reference system, that is, before fluctuations are taken into account [16]. Such a situation can arise at special electron filling factors, for example, in a tight-binding model with nearest and next-nearest neighbor hopping on a square lattice. Expanded in terms of relative momentum coordinates krsubscript\ud835\udc58\ud835\udc5fk_{r}italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and ktsubscript\ud835\udc58\ud835\udc61k_{t}italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT in normal and tangential directions with respect to the Fermi surface at a hot spot (see Fig.\u00a01), the dispersion relation assumed in Ref.\u00a0[16] has the form \u03be\ud835\udc24=\u03f5\ud835\udc24\u2212\u03bc=v\u2062kr+b\u2062kt4subscript\ud835\udf09\ud835\udc24subscriptitalic-\u03f5\ud835\udc24\ud835\udf07\ud835\udc63subscript\ud835\udc58\ud835\udc5f\ud835\udc4fsuperscriptsubscript\ud835\udc58\ud835\udc614\\xi_{\\bf k}=\\epsilon_{\\bf k}-\\mu=vk_{r}+bk_{t}^{4}italic_\u03be start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT = italic_\u03f5 start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT - italic_\u03bc = italic_v italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT + italic_b italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT, where v\ud835\udc63vitalic_v is the Fermi velocity at the hot spot, and b\ud835\udc4fbitalic_b is a real constant.\nUnlike the conventional case of hot spots with finite curvature, the order parameter susceptibility of our model with flat hot spots has a robust peak at the nesting vector. The imaginary part of the perturbative one-loop self-energy was found to depend linearly on (real) frequency, while the momentum and frequency dependences of its real part exhibit logarithmic divergences indicating non-Fermi liquid behavior with a vanishing quasiparticle weight and a vanishing Fermi velocity. The logarithmic divergences were tentatively interpreted as perturbative signatures of power-laws with anomalous exponents [16]. In this paper we extend our previous analysis of non-Fermi liquid behavior at 2\u2062kF2subscript\ud835\udc58\ud835\udc392k_{F}2 italic_k start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT density wave quantum criticality with flat hot spots in two directions. First, we treat the logarithmic divergences obtained in perturbation theory in a controlled and systematic way by using a field theoretic renormalization group. Second, we generalize the tangential momentum dependence of the bare dispersion from quartic to arbitrary powers, that is, with an arbitrary exponent \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2. Our motivation for this generalization is to disentangle general features of models with flat hot spots from features specific for the case \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4. Moreover, we would like to explore whether one can shed light on the most important but also most tricky case \u03b1=2\ud835\udefc2\\alpha=2italic_\u03b1 = 2 by considering the limit \u03b1\u21922\u2192\ud835\udefc2\\alpha\\to 2italic_\u03b1 \u2192 2. The renormalization group analysis reveals that the logarithms found in perturbation theory do not sum up to anomalous power-laws, but rather yield only a logarithmic breakdown of Fermi liquid theory. Hence, the flat hot spot model turns out to be a marginal Fermi liquid [18].\nFor \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2 the renormalization group analysis is controlled by the inverse number of fermion flavors N\ud835\udc41Nitalic_N. However, in the limit \u03b1\u21922\u2192\ud835\udefc2\\alpha\\to 2italic_\u03b1 \u2192 2, the fluctuation corrections exhibit divergences which cannot be tamed by the renormalization group, indicating a qualitatively different behavior for \u03b1=2\ud835\udefc2\\alpha=2italic_\u03b1 = 2. Recently, Song [17] et al.\u00a0have computed the quasiparticle decay rate near Fermi points with a dispersion of the form Eq.\u00a0(1) in a stable two-dimensional Fermi liquid (away from instabilities), and found an energy dependence of the form \u03f5\u03b1\u03b1\u22121superscriptitalic-\u03f5\ud835\udefc\ud835\udefc1\\epsilon^{\\frac{\\alpha}{\\alpha-1}}italic_\u03f5 start_POSTSUPERSCRIPT divide start_ARG italic_\u03b1 end_ARG start_ARG italic_\u03b1 - 1 end_ARG end_POSTSUPERSCRIPT for \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2. While this decay rate is enhanced compared to the conventional quadratic behavior, it is still parametrically smaller than the quasiparticle energy in the low energy limit, for any finite \u03b1\ud835\udefc\\alphaitalic_\u03b1, so that the quasiparticles remain asymptotically stable. The remainder of the paper is structured as follows. In Sec.\u00a0II we compute the order parameter susceptibility and the effective interaction at the QCP in one-loop approximation. A perturbative one-loop calculation of the momentum and frequency dependence of the fermion self-energy is performed in Sec.\u00a0III, and the corresponding renormalization group analysis in Sec.\u00a0IV. In Sec.\u00a0V we close the presentation with a summary and discussion of the main results. We consider a one-band system of interacting fermions with a bare single-particle energy-momentum relation \u03f5\ud835\udc24subscriptitalic-\u03f5\ud835\udc24\\epsilon_{\\bf k}italic_\u03f5 start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT. We are dealing exclusively with ground state properties (temperature T=0\ud835\udc470T=0italic_T = 0). The bare fermion propagator has the form where k0subscript\ud835\udc580k_{0}italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT denotes the imaginary frequency, and \u03be\ud835\udc24=\u03f5\ud835\udc24\u2212\u03bcsubscript\ud835\udf09\ud835\udc24subscriptitalic-\u03f5\ud835\udc24\ud835\udf07\\xi_{\\bf k}=\\epsilon_{\\bf k}-\\muitalic_\u03be start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT = italic_\u03f5 start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT - italic_\u03bc.\nWe assume that, in mean-field theory, the system undergoes a charge or spin-density wave transition with an incommensurate and nested wave vector \ud835\udc10\ud835\udc10{\\bf Q}bold_Q, which connects a pair of hot spots on the Fermi surface, where the dispersion relation in the vicinity of the hot spots has a momentum dependence of the from Eq.\u00a0(1). In random phase approximation (RPA) the order parameter susceptibility has the form where g<0\ud835\udc540g<0italic_g < 0 is the coupling constant parametrizing the interaction in the instability channel. The bare charge or spin susceptibility \u03c70subscript\ud835\udf120\\chi_{0}italic_\u03c7 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is related to the particle-hole bubble \u03a00subscript\u03a00\\Pi_{0}roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT by \u03c70\u2062(\ud835\udc2a,i\u2062q0)=\u2212N\u2062\u03a00\u2062(\ud835\udc2a,i\u2062q0)subscript\ud835\udf120\ud835\udc2a\ud835\udc56subscript\ud835\udc5e0\ud835\udc41subscript\u03a00\ud835\udc2a\ud835\udc56subscript\ud835\udc5e0\\chi_{0}({\\bf q},iq_{0})=-N\\Pi_{0}({\\bf q},iq_{0})italic_\u03c7 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_q , italic_i italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = - italic_N roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_q , italic_i italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ), where N\ud835\udc41Nitalic_N is the spin multiplicity, and [19] \u222b\ud835\udc24subscript\ud835\udc24\\int_{\\bf k}\u222b start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT is a shorthand notation for \u222bd2\u2062\ud835\udc24(2\u2062\u03c0)2superscript\ud835\udc512\ud835\udc24superscript2\ud835\udf0b2\\int\\frac{d^{2}{\\bf k}}{(2\\pi)^{2}}\u222b divide start_ARG italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT bold_k end_ARG start_ARG ( 2 italic_\u03c0 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG, and \u222bk0subscriptsubscript\ud835\udc580\\int_{k_{0}}\u222b start_POSTSUBSCRIPT italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT for \u222bd\u2062k02\u2062\u03c0\ud835\udc51subscript\ud835\udc5802\ud835\udf0b\\int\\frac{dk_{0}}{2\\pi}\u222b divide start_ARG italic_d italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG start_ARG 2 italic_\u03c0 end_ARG.\nWhile keeping N\ud835\udc41Nitalic_N as a general parameter in our equations, we choose N=2\ud835\udc412N=2italic_N = 2, corresponding to spin-1212\\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG fermions, in all numerical results.\nContinuing \u03a00\u2062(\ud835\udc2a,i\u2062q0)subscript\u03a00\ud835\udc2a\ud835\udc56subscript\ud835\udc5e0\\Pi_{0}({\\bf q},iq_{0})roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_q , italic_i italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) analytically to the real frequency axis from the upper complex frequency half-plane yields the retarded polarization function \u03a00\u2062(\ud835\udc2a,\u03c9)subscript\u03a00\ud835\udc2a\ud835\udf14\\Pi_{0}({\\bf q},\\omega)roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_q , italic_\u03c9 ). The RPA susceptibility diverges when g\u2062\u03c70\u2062(\ud835\udc10,0)=\u22121\ud835\udc54subscript\ud835\udf120\ud835\udc1001g\\chi_{0}({\\bf Q},0)=-1italic_g italic_\u03c7 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_Q , 0 ) = - 1, signalling an instability at the critical coupling gc=\u22121/\u03c70\u2062(\ud835\udc10,0)subscript\ud835\udc54\ud835\udc501subscript\ud835\udf120\ud835\udc100g_{c}=-1/\\chi_{0}({\\bf Q},0)italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = - 1 / italic_\u03c7 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_Q , 0 ) toward charge or spin density wave order with one of the nesting wave vectors \ud835\udc10\ud835\udc10{\\bf Q}bold_Q at which \u03c70\u2062(\ud835\udc2a,0)subscript\ud835\udf120\ud835\udc2a0\\chi_{0}({\\bf q},0)italic_\u03c7 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_q , 0 ) has a (finite) peak. To analyze the behavior of the susceptibility near the singularity, we expand for \ud835\udc2a\ud835\udc2a{\\bf q}bold_q near \ud835\udc10\ud835\udc10{\\bf Q}bold_Q and small \u03c9\ud835\udf14\\omegaitalic_\u03c9. Momenta near \ud835\udc10\ud835\udc10{\\bf Q}bold_Q are parametrized by relative momentum coordinates qrsubscript\ud835\udc5e\ud835\udc5fq_{r}italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and qtsubscript\ud835\udc5e\ud835\udc61q_{t}italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, parallel and perpendicular to \ud835\udc10\ud835\udc10{\\bf Q}bold_Q, respectively.\nThe leading contributions to \u03b4\u2062\u03a00\u2062(\ud835\udc2a,\u03c9)\ud835\udeffsubscript\u03a00\ud835\udc2a\ud835\udf14\\delta\\Pi_{0}({\\bf q},\\omega)italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_q , italic_\u03c9 ) come from fermionic momenta near the hot spots connected by \ud835\udc10\ud835\udc10{\\bf Q}bold_Q, where the dispersion relations in Eq.\u00a0(4) can be expanded as in Eq.\u00a0(1), that is, \u03be\ud835\udc24=v\u2062kr+b\u2062|kt|\u03b1subscript\ud835\udf09\ud835\udc24\ud835\udc63subscript\ud835\udc58\ud835\udc5f\ud835\udc4fsuperscriptsubscript\ud835\udc58\ud835\udc61\ud835\udefc\\xi_{\\bf k}=vk_{r}+b|k_{t}|^{\\alpha}italic_\u03be start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT = italic_v italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT + italic_b | italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT and\n\u03be\ud835\udc24\u2212\ud835\udc2a=\u2212v\u2062(kr\u2212qr)+b\u2062|kt\u2212qt|\u03b1subscript\ud835\udf09\ud835\udc24\ud835\udc2a\ud835\udc63subscript\ud835\udc58\ud835\udc5fsubscript\ud835\udc5e\ud835\udc5f\ud835\udc4fsuperscriptsubscript\ud835\udc58\ud835\udc61subscript\ud835\udc5e\ud835\udc61\ud835\udefc\\xi_{{\\bf k}-{\\bf q}}=-v(k_{r}-q_{r})+b|k_{t}-q_{t}|^{\\alpha}italic_\u03be start_POSTSUBSCRIPT bold_k - bold_q end_POSTSUBSCRIPT = - italic_v ( italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT - italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) + italic_b | italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT.\nIn the following we assume that b\ud835\udc4fbitalic_b is positive. Our derivations and results can be easily adapted to negative b\ud835\udc4fbitalic_b. For qt=0subscript\ud835\udc5e\ud835\udc610q_{t}=0italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0 all integrations are elementary, and we obtain\n\u03b4\u2062\u03a00\u2062(qr,0,\u03c9)=\u03b4\u2062\u03a00+\u2062(qr,0,\u03c9)+\u03b4\u2062\u03a00\u2212\u2062(qr,0,\u03c9)\ud835\udeffsubscript\u03a00subscript\ud835\udc5e\ud835\udc5f0\ud835\udf14\ud835\udeffsuperscriptsubscript\u03a00subscript\ud835\udc5e\ud835\udc5f0\ud835\udf14\ud835\udeffsuperscriptsubscript\u03a00subscript\ud835\udc5e\ud835\udc5f0\ud835\udf14\\delta\\Pi_{0}(q_{r},0,\\omega)=\\delta\\Pi_{0}^{+}(q_{r},0,\\omega)+\\delta\\Pi_{0}^%\n{-}(q_{r},0,\\omega)italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , 0 , italic_\u03c9 ) = italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ( italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , 0 , italic_\u03c9 ) + italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ( italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , 0 , italic_\u03c9 ),\nwhere and \u03b4\u2062\u03a00\u2212\u2062(qr,0,\u03c9)=[\u03b4\u2062\u03a00+\u2062(qr,0,\u2212\u03c9)]*\ud835\udeffsuperscriptsubscript\u03a00subscript\ud835\udc5e\ud835\udc5f0\ud835\udf14superscriptdelimited-[]\ud835\udeffsuperscriptsubscript\u03a00subscript\ud835\udc5e\ud835\udc5f0\ud835\udf14\\delta\\Pi_{0}^{-}(q_{r},0,\\omega)=[\\delta\\Pi_{0}^{+}(q_{r},0,-\\omega)]^{*}italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ( italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , 0 , italic_\u03c9 ) = [ italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ( italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , 0 , - italic_\u03c9 ) ] start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT.\nIn the static limit \u03c9\u21920\u2192\ud835\udf140\\omega\\to 0italic_\u03c9 \u2192 0, this yields \u03b4\u2062\u03a00\u2062(qr,0,0)\ud835\udeffsubscript\u03a00subscript\ud835\udc5e\ud835\udc5f00\\delta\\Pi_{0}(q_{r},0,0)italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , 0 , 0 ) has a cusp with diverging slope for qr\u21920\u2192subscript\ud835\udc5e\ud835\udc5f0q_{r}\\to 0italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \u2192 0 for any \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2. In the special case \u03b1=2\ud835\udefc2\\alpha=2italic_\u03b1 = 2, the slope vanishes for qr<0subscript\ud835\udc5e\ud835\udc5f0q_{r}<0italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT < 0. For qt\u22600subscript\ud835\udc5e\ud835\udc610q_{t}\\neq 0italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2260 0, the particle-hole bubble can be expressed in a scaling form as (see Appendix\u00a0A) with the dimensionless scaling function In Fig.\u00a02 we show I\u03b1\u2062(x)subscript\ud835\udc3c\ud835\udefc\ud835\udc65I_{\\alpha}(x)italic_I start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT ( italic_x ) for various choices of \u03b1\ud835\udefc\\alphaitalic_\u03b1. The integrand in Eq.\u00a0(9) is real for\nx<|k~t+12|\u03b1+|k~t\u221212|\u03b1\ud835\udc65superscriptsubscript~\ud835\udc58\ud835\udc6112\ud835\udefcsuperscriptsubscript~\ud835\udc58\ud835\udc6112\ud835\udefcx<|\\tilde{k}_{t}+\\frac{1}{2}|^{\\alpha}+|\\tilde{k}_{t}-\\frac{1}{2}|^{\\alpha}italic_x < | over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + divide start_ARG 1 end_ARG start_ARG 2 end_ARG | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT + | over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - divide start_ARG 1 end_ARG start_ARG 2 end_ARG | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT.\nFor x>|k~t+12|\u03b1+|k~t\u221212|\u03b1\u226521\u2212\u03b1\ud835\udc65superscriptsubscript~\ud835\udc58\ud835\udc6112\ud835\udefcsuperscriptsubscript~\ud835\udc58\ud835\udc6112\ud835\udefcsuperscript21\ud835\udefcx>|\\tilde{k}_{t}+\\frac{1}{2}|^{\\alpha}+|\\tilde{k}_{t}-\\frac{1}{2}|^{\\alpha}%\n\\geq 2^{1-\\alpha}italic_x > | over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + divide start_ARG 1 end_ARG start_ARG 2 end_ARG | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT + | over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - divide start_ARG 1 end_ARG start_ARG 2 end_ARG | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT \u2265 2 start_POSTSUPERSCRIPT 1 - italic_\u03b1 end_POSTSUPERSCRIPT,\nthe logarithm has a constant imaginary part \u2212\u03c0\ud835\udf0b-\\pi- italic_\u03c0.\nHence, the imaginary part of I\u03b1\u2062(x)subscript\ud835\udc3c\ud835\udefc\ud835\udc65I_{\\alpha}(x)italic_I start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT ( italic_x ) vanishes for x<21\u2212\u03b1\ud835\udc65superscript21\ud835\udefcx<2^{1-\\alpha}italic_x < 2 start_POSTSUPERSCRIPT 1 - italic_\u03b1 end_POSTSUPERSCRIPT, while where k~t0\u2062(x)superscriptsubscript~\ud835\udc58\ud835\udc610\ud835\udc65\\tilde{k}_{t}^{0}(x)over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ( italic_x ) is the unique positive solution of the equation\n|k~t+12|\u03b1+|k~t\u221212|\u03b1=xsuperscriptsubscript~\ud835\udc58\ud835\udc6112\ud835\udefcsuperscriptsubscript~\ud835\udc58\ud835\udc6112\ud835\udefc\ud835\udc65|\\tilde{k}_{t}+\\frac{1}{2}|^{\\alpha}+|\\tilde{k}_{t}-\\frac{1}{2}|^{\\alpha}=x| over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + divide start_ARG 1 end_ARG start_ARG 2 end_ARG | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT + | over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - divide start_ARG 1 end_ARG start_ARG 2 end_ARG | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT = italic_x.\nFor x=1\ud835\udc651x=1italic_x = 1, one has k~t0=12superscriptsubscript~\ud835\udc58\ud835\udc61012\\tilde{k}_{t}^{0}=\\frac{1}{2}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = divide start_ARG 1 end_ARG start_ARG 2 end_ARG for any \u03b1\ud835\udefc\\alphaitalic_\u03b1. This is why all the curves in the right panel of Fig.\u00a02 go through the same crossing point at x=1\ud835\udc651x=1italic_x = 1. For large |x|\ud835\udc65|x|| italic_x |, the scaling function behaves asymptotically as The next-to-leading correction for large |x|\ud835\udc65|x|| italic_x | is of order |x|\u22121\u03b1superscript\ud835\udc651\ud835\udefc|x|^{-\\frac{1}{\\alpha}}| italic_x | start_POSTSUPERSCRIPT - divide start_ARG 1 end_ARG start_ARG italic_\u03b1 end_ARG end_POSTSUPERSCRIPT. For \u03b1=2\ud835\udefc2\\alpha=2italic_\u03b1 = 2 and \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4, the scaling functions I\u03b1\u2062(x)subscript\ud835\udc3c\ud835\udefc\ud835\udc65I_{\\alpha}(x)italic_I start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT ( italic_x ) can be expressed in terms of square roots, Inserting I2\u2062(x)subscript\ud835\udc3c2\ud835\udc65I_{2}(x)italic_I start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_x ) into Eq.\u00a0(8) one recovers the well-known expression for the particle-hole bubble for a quadratic dispersion relation. I4\u2062(x)subscript\ud835\udc3c4\ud835\udc65I_{4}(x)italic_I start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( italic_x ) has been computed numerically in Ref.\u00a0[16], but analytic results were found there only for x=0\ud835\udc650x=0italic_x = 0 and x=18\ud835\udc6518x=\\frac{1}{8}italic_x = divide start_ARG 1 end_ARG start_ARG 8 end_ARG. We derive Eq.\u00a0(13) in Appendix\u00a0A. The RPA effective interaction is given by on the imaginary frequency axis, and by the same expression with i\u2062q0\u2192\u03c9\u2192\ud835\udc56subscript\ud835\udc5e0\ud835\udf14iq_{0}\\to\\omegaitalic_i italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2192 italic_\u03c9 on the real frequency axis. At the QCP, g\u2062\u03c70\u2062(\ud835\udc10,0)\ud835\udc54subscript\ud835\udf120\ud835\udc100g\\chi_{0}({\\bf Q},0)italic_g italic_\u03c7 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_Q , 0 ) is equal to minus one, so that To leading order in the effective interaction D\ud835\udc37Ditalic_D, the fermion self-energy is given by the one-loop integral with M=1\ud835\udc401M=1italic_M = 1 for a charge-density and M=3\ud835\udc403M=3italic_M = 3 for a spin-density wave instability [13]. This approximation for the self-energy is also known as random-phase approximation (RPA).\nAnalytic continuation of Eq.\u00a0(16) to the real frequency axis yields [20] where b\u2062(\u03bd)=[e\u03b2\u2062\u03bd\u22121]\u22121\ud835\udc4f\ud835\udf08superscriptdelimited-[]superscript\ud835\udc52\ud835\udefd\ud835\udf0811b(\\nu)=[e^{\\beta\\nu}-1]^{-1}italic_b ( italic_\u03bd ) = [ italic_e start_POSTSUPERSCRIPT italic_\u03b2 italic_\u03bd end_POSTSUPERSCRIPT - 1 ] start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT and f\u2062(\u03bd)=[e\u03b2\u2062\u03bd+1]\u22121\ud835\udc53\ud835\udf08superscriptdelimited-[]superscript\ud835\udc52\ud835\udefd\ud835\udf0811f(\\nu)=[e^{\\beta\\nu}+1]^{-1}italic_f ( italic_\u03bd ) = [ italic_e start_POSTSUPERSCRIPT italic_\u03b2 italic_\u03bd end_POSTSUPERSCRIPT + 1 ] start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT are the Bose and Fermi functions, respectively. At zero temperature (\u03b2=\u221e\ud835\udefd\\beta=\\inftyitalic_\u03b2 = \u221e) these functions become step functions b\u2062(\u03bd)=\u2212\u0398\u2062(\u2212\u03bd)\ud835\udc4f\ud835\udf08\u0398\ud835\udf08b(\\nu)=-\\Theta(-\\nu)italic_b ( italic_\u03bd ) = - roman_\u0398 ( - italic_\u03bd ) and f\u2062(\u03bd)=\u0398\u2062(\u2212\u03bd)\ud835\udc53\ud835\udf08\u0398\ud835\udf08f(\\nu)=\\Theta(-\\nu)italic_f ( italic_\u03bd ) = roman_\u0398 ( - italic_\u03bd ).\nIn the following we denote \u03a3\u2062(\ud835\udc24,\u03c9+i\u20620+)\u03a3\ud835\udc24\ud835\udf14\ud835\udc56superscript0\\Sigma({\\bf k},\\omega+i0^{+})roman_\u03a3 ( bold_k , italic_\u03c9 + italic_i 0 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ), G\u2062(\ud835\udc24,\u03c9+i\u20620+)\ud835\udc3a\ud835\udc24\ud835\udf14\ud835\udc56superscript0G({\\bf k},\\omega+i0^{+})italic_G ( bold_k , italic_\u03c9 + italic_i 0 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ), and D\u2062(\ud835\udc2a,\u03bd+i\u20620+)\ud835\udc37\ud835\udc2a\ud835\udf08\ud835\udc56superscript0D({\\bf q},\\nu+i0^{+})italic_D ( bold_q , italic_\u03bd + italic_i 0 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) by \u03a3\u2062(\ud835\udc24,\u03c9)\u03a3\ud835\udc24\ud835\udf14\\Sigma({\\bf k},\\omega)roman_\u03a3 ( bold_k , italic_\u03c9 ), G\u2062(\ud835\udc24,\u03c9)\ud835\udc3a\ud835\udc24\ud835\udf14G({\\bf k},\\omega)italic_G ( bold_k , italic_\u03c9 ), and D\u2062(\ud835\udc2a,\u03bd)\ud835\udc37\ud835\udc2a\ud835\udf08D({\\bf q},\\nu)italic_D ( bold_q , italic_\u03bd ), respectively. We analyze \u03a3\u2062(\ud835\udc24,\u03c9)\u03a3\ud835\udc24\ud835\udf14\\Sigma({\\bf k},\\omega)roman_\u03a3 ( bold_k , italic_\u03c9 ) at the QCP for low frequencies \u03c9\ud835\udf14\\omegaitalic_\u03c9 and momenta \ud835\udc24\ud835\udc24{\\bf k}bold_k near one of the hot spots on the Fermi surface, which we denote as \ud835\udc24Hsubscript\ud835\udc24\ud835\udc3b{\\bf k}_{H}bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT. The effective interaction D\u2062(\ud835\udc2a,\u03c9)\ud835\udc37\ud835\udc2a\ud835\udf14D({\\bf q},\\omega)italic_D ( bold_q , italic_\u03c9 ) at the QCP is given by Eq.\u00a0(15) with \u03b4\u2062\u03a00\u2062(\ud835\udc2a,\u03c9)\ud835\udeffsubscript\u03a00\ud835\udc2a\ud835\udf14\\delta\\Pi_{0}({\\bf q},\\omega)italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_q , italic_\u03c9 ) from Eq.\u00a0(8).\nThe dominant contributions come from momentum transfers \ud835\udc2a\ud835\udc2a{\\bf q}bold_q near \ud835\udc10\ud835\udc10{\\bf Q}bold_Q, so that \ud835\udc24\u2212\ud835\udc2a\ud835\udc24\ud835\udc2a{\\bf k}-{\\bf q}bold_k - bold_q is situated near the antipodal hot spot \u2212\ud835\udc24Hsubscript\ud835\udc24\ud835\udc3b-{\\bf k}_{H}- bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT. Using relative momentum variables as above, the dispersion relation in the fermion propagator can be expanded as \u03be\ud835\udc24\u2212\ud835\udc2a=\u2212v\u2062(kr\u2212qr)+b\u2062|kt\u2212qt|\u03b1subscript\ud835\udf09\ud835\udc24\ud835\udc2a\ud835\udc63subscript\ud835\udc58\ud835\udc5fsubscript\ud835\udc5e\ud835\udc5f\ud835\udc4fsuperscriptsubscript\ud835\udc58\ud835\udc61subscript\ud835\udc5e\ud835\udc61\ud835\udefc\\xi_{{\\bf k}-{\\bf q}}=-v(k_{r}-q_{r})+b|k_{t}-q_{t}|^{\\alpha}italic_\u03be start_POSTSUBSCRIPT bold_k - bold_q end_POSTSUBSCRIPT = - italic_v ( italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT - italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) + italic_b | italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT. To evaluate the self-energy, it is convenient to first consider its imaginary part, and then compute the real part from a Kramers-Kronig relation. The imaginary part of Eq.\u00a0(III) reads Note that Im\u2062D\u2062(\ud835\udc2a,\u03bd\u2212i\u20620+)=\u2212Im\u2062D\u2062(\ud835\udc2a,\u03bd+i\u20620+)Im\ud835\udc37\ud835\udc2a\ud835\udf08\ud835\udc56superscript0Im\ud835\udc37\ud835\udc2a\ud835\udf08\ud835\udc56superscript0{\\rm Im}D({\\bf q},\\nu-i0^{+})=-{\\rm Im}D({\\bf q},\\nu+i0^{+})roman_Im italic_D ( bold_q , italic_\u03bd - italic_i 0 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) = - roman_Im italic_D ( bold_q , italic_\u03bd + italic_i 0 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ).\nUsing the Dirac identity Im\u2062G0\u2062(\ud835\udc24,\u03c9)=\u2212\u03c0\u2062\u03b4\u2062(\u03c9\u2212\u03be\ud835\udc24)Imsubscript\ud835\udc3a0\ud835\udc24\ud835\udf14\ud835\udf0b\ud835\udeff\ud835\udf14subscript\ud835\udf09\ud835\udc24{\\rm Im}G_{0}({\\bf k},\\omega)=-\\pi\\delta(\\omega-\\xi_{{\\bf k}})roman_Im italic_G start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_k , italic_\u03c9 ) = - italic_\u03c0 italic_\u03b4 ( italic_\u03c9 - italic_\u03be start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT ), the frequency integral in Eq.\u00a0(18) can be easily carried out, yielding At zero temperature, the sum of Bose and Fermi functions in Eq.\u00a0(19) is given by restricting thus the contributing momentum region.\nThe integral in Eq.\u00a0(19) is convergent even if the momentum integration over qrsubscript\ud835\udc5e\ud835\udc5fq_{r}italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and qtsubscript\ud835\udc5e\ud835\udc61q_{t}italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is extended to infinity. The real part of the self-energy can be obtained from the Kramers-Kronig-type relation The last term in this relation is a real constant, which can be absorbed by a shift of the chemical potential. The real part of the self-energy is dominated by contributions from large frequencies in Eq.\u00a0(21), where the low-frequency expansion of Im\u2062\u03a3Im\u03a3{\\rm Im}\\Sigmaroman_Im roman_\u03a3 is not valid. Since we are not interested in a constant offset but rather in the frequency and momentum dependence of the self-energy near the hot spots, we will analyze the difference\n\u03b4\u2062\u03a3\u2062(\ud835\udc24,\u03c9)=\u03a3\u2062(\ud835\udc24,\u03c9)\u2212\u03a3\u2062(\ud835\udc24H,0)\ud835\udeff\u03a3\ud835\udc24\ud835\udf14\u03a3\ud835\udc24\ud835\udf14\u03a3subscript\ud835\udc24\ud835\udc3b0\\delta\\Sigma({\\bf k},\\omega)=\\Sigma({\\bf k},\\omega)-\\Sigma({\\bf k}_{H},0)italic_\u03b4 roman_\u03a3 ( bold_k , italic_\u03c9 ) = roman_\u03a3 ( bold_k , italic_\u03c9 ) - roman_\u03a3 ( bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , 0 ), where the leading ultraviolet contributions cancel each other. The frequency dependence at the hot spot (for \ud835\udc24=\ud835\udc24H\ud835\udc24subscript\ud835\udc24\ud835\udc3b{\\bf k}={\\bf k}_{H}bold_k = bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT) can be derived by a simple rescaling of the integration variables in Eq.\u00a0(19). Substituting qr=|\u03c9/v|\u2062q~rsubscript\ud835\udc5e\ud835\udc5f\ud835\udf14\ud835\udc63subscript~\ud835\udc5e\ud835\udc5fq_{r}=|\\omega/v|\\tilde{q}_{r}italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = | italic_\u03c9 / italic_v | over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and qt=|\u03c9/b|1/\u03b1\u2062q~tsubscript\ud835\udc5e\ud835\udc61superscript\ud835\udf14\ud835\udc4f1\ud835\udefcsubscript~\ud835\udc5e\ud835\udc61q_{t}=|\\omega/b|^{1/\\alpha}\\tilde{q}_{t}italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = | italic_\u03c9 / italic_b | start_POSTSUPERSCRIPT 1 / italic_\u03b1 end_POSTSUPERSCRIPT over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, one obtains where A+subscript\ud835\udc34A_{+}italic_A start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and A\u2212subscript\ud835\udc34A_{-}italic_A start_POSTSUBSCRIPT - end_POSTSUBSCRIPT are two positive dimensionless numbers depending on \u03b1\ud835\udefc\\alphaitalic_\u03b1 and on the sign of \u03c9\ud835\udf14\\omegaitalic_\u03c9. These numbers are determined by the integral where s=s\u2062(\u03c9)=\u00b11\ud835\udc60\ud835\udc60\ud835\udf14plus-or-minus1s=s(\\omega)=\\pm 1italic_s = italic_s ( italic_\u03c9 ) = \u00b1 1, and the prime at the integral sign indicates a restriction of the integration region to 0<q~r+|q~t|\u03b1<10subscript~\ud835\udc5e\ud835\udc5fsuperscriptsubscript~\ud835\udc5e\ud835\udc61\ud835\udefc10<\\tilde{q}_{r}+|\\tilde{q}_{t}|^{\\alpha}<10 < over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT + | over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT < 1 for \u03c9>0\ud835\udf140\\omega>0italic_\u03c9 > 0, and to \u22121<q~r+|q~t|\u03b1<01subscript~\ud835\udc5e\ud835\udc5fsuperscriptsubscript~\ud835\udc5e\ud835\udc61\ud835\udefc0-1<\\tilde{q}_{r}+|\\tilde{q}_{t}|^{\\alpha}<0- 1 < over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT + | over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT < 0 for \u03c9<0\ud835\udf140\\omega<0italic_\u03c9 < 0.\nNote that the frequency dependence of the self-energy at the hot spot depends neither on v\ud835\udc63vitalic_v nor on b\ud835\udc4fbitalic_b.\nIn Appendix B we show a plot of the coefficients A\u00b1subscript\ud835\udc34plus-or-minusA_{\\pm}italic_A start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT as a function of \u03b1\ud835\udefc\\alphaitalic_\u03b1.\nThey are positive and finite for all \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2 and diverge for \u03b1\u21922\u2192\ud835\udefc2\\alpha\\to 2italic_\u03b1 \u2192 2. The divergence for a quadratic dispersion is due to the vanishing slope of \u03b4\u2062\u03a00\u2062(qr,0,0)\ud835\udeffsubscript\u03a00subscript\ud835\udc5e\ud835\udc5f00\\delta\\Pi_{0}(q_{r},0,0)italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , 0 , 0 ) for qr<0subscript\ud835\udc5e\ud835\udc5f0q_{r}<0italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT < 0, see Eq.\u00a0(7). The real part of the self-energy can be obtained from the Kramers-Kronig relation Eq.\u00a0(21). With Im\u2062\u03a3\u2062(\ud835\udc24H,\u03c9)Im\u03a3subscript\ud835\udc24\ud835\udc3b\ud835\udf14{\\rm Im}\\Sigma({\\bf k}_{H},\\omega)roman_Im roman_\u03a3 ( bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_\u03c9 ) as in Eq.\u00a0(22), the integral in Eq.\u00a0(21) is logarithmically divergent at large frequencies \u03c9\u2032superscript\ud835\udf14\u2032\\omega^{\\prime}italic_\u03c9 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. This is due to the fact that the linear frequency dependence has been obtained from an expansion that captures only the asymptotic low frequency behavior, which cannot be extended to all frequencies. The imaginary part of the exact self-energy of any physical system has to vanish in the high-frequency limit. To compute the low-frequency behavior of Re\u2062\u03a3Re\u03a3{\\rm Re}\\Sigmaroman_Re roman_\u03a3, we mimic the high-frequency decay of Im\u2062\u03a3Im\u03a3{\\rm Im}\\Sigmaroman_Im roman_\u03a3 by imposing an ultraviolet (UV) frequency cutoff \u039b\u039b\\Lambdaroman_\u039b, so that the frequency integration in Eq.\u00a0(21) is restricted to |\u03c9\u2032|<\u039bsuperscript\ud835\udf14\u2032\u039b|\\omega^{\\prime}|<\\Lambda| italic_\u03c9 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT | < roman_\u039b. Defining \u03b4\u2062\u03a3\u2062(\ud835\udc24,\u03c9)=\u03a3\u2062(\ud835\udc24,\u03c9)\u2212\u03a3\u2062(\ud835\udc24H,0)\ud835\udeff\u03a3\ud835\udc24\ud835\udf14\u03a3\ud835\udc24\ud835\udf14\u03a3subscript\ud835\udc24\ud835\udc3b0\\delta\\Sigma({\\bf k},\\omega)=\\Sigma({\\bf k},\\omega)-\\Sigma({\\bf k}_{H},0)italic_\u03b4 roman_\u03a3 ( bold_k , italic_\u03c9 ) = roman_\u03a3 ( bold_k , italic_\u03c9 ) - roman_\u03a3 ( bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , 0 ), we then obtain for |\u03c9|\u226a\u039bmuch-less-than\ud835\udf14\u039b|\\omega|\\ll\\Lambda| italic_\u03c9 | \u226a roman_\u039b. The imaginary frequency self-energy \u03b4\u2062\u03a3\u2062(\ud835\udc24H,i\u2062k0)\ud835\udeff\u03a3subscript\ud835\udc24\ud835\udc3b\ud835\udc56subscript\ud835\udc580\\delta\\Sigma({\\bf k}_{H},ik_{0})italic_\u03b4 roman_\u03a3 ( bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_i italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) is given by the same expression with \u03c9\u21a6i\u2062k0maps-to\ud835\udf14\ud835\udc56subscript\ud835\udc580\\omega\\mapsto ik_{0}italic_\u03c9 \u21a6 italic_i italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. The logarithm in Eq.\u00a0(24) implies a logarithmic divergence of the inverse quasiparticle weight [19],\n1\u2212\u2202\u03a3\u2062(\ud835\udc24H,\u03c9)/\u2202\u03c9\u223cln\u2061(\u039b/|\u03c9|)similar-to1\u03a3subscript\ud835\udc24\ud835\udc3b\ud835\udf14\ud835\udf14\u039b\ud835\udf141-\\partial\\Sigma({\\bf k}_{H},\\omega)/\\partial\\omega\\sim\\ln(\\Lambda/|\\omega|)1 - \u2202 roman_\u03a3 ( bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_\u03c9 ) / \u2202 italic_\u03c9 \u223c roman_ln ( roman_\u039b / | italic_\u03c9 | ).\nHence, Landau quasiparticles do not exist at the hot spots, and Fermi liquid theory breaks down. Logarithmic divergences are frequently a perturbative manifestation of power-law behavior, especially in (quantum) critical systems. Assuming that the one-loop result in Eq.\u00a0(24) reflects the leading order of an expansion of a power-law, one obtains at low frequencies, with the anomalous dimension Hence, the quasiparticle weight vanishes as |\u03c9|\u03b7superscript\ud835\udf14\ud835\udf02|\\omega|^{\\eta}| italic_\u03c9 | start_POSTSUPERSCRIPT italic_\u03b7 end_POSTSUPERSCRIPT in the low-energy limit.\nA plot of \u03b7\ud835\udf02\\etaitalic_\u03b7 as a function of \u03b1\ud835\udefc\\alphaitalic_\u03b1 is shown in Fig.\u00a03. The power-law in Eq.\u00a0(25) is only an educated guess.\nIn Sec.\u00a0IV we will see that \u03b7\ud835\udf02\\etaitalic_\u03b7 is actually scale dependent, so that the quasiparticle weight ultimately vanishes only logarithmically. We now analyze the momentum and frequency dependence of the self-energy in the vicinity of a hot spot. We consider radial and tangential momentum dependencies separately. For kt=0subscript\ud835\udc58\ud835\udc610k_{t}=0italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0, we can express Im\u2062\u03a3\u2062(\ud835\udc24,\u03c9)Im\u03a3\ud835\udc24\ud835\udf14{\\rm Im}\\Sigma({\\bf k},\\omega)roman_Im roman_\u03a3 ( bold_k , italic_\u03c9 ) from Eq.\u00a0(19) in the scaling form with the dimensionless scaling functions where the integration region is restricted to 0<\u2212k~r+q~r+|q~t|\u03b1<10subscript~\ud835\udc58\ud835\udc5fsubscript~\ud835\udc5e\ud835\udc5fsuperscriptsubscript~\ud835\udc5e\ud835\udc61\ud835\udefc10<-\\tilde{k}_{r}+\\tilde{q}_{r}+|\\tilde{q}_{t}|^{\\alpha}<10 < - over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT + over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT + | over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT < 1 for \u03c9>0\ud835\udf140\\omega>0italic_\u03c9 > 0, and to \u22121<\u2212k~r+q~r+|q~t|\u03b1<01subscript~\ud835\udc58\ud835\udc5fsubscript~\ud835\udc5e\ud835\udc5fsuperscriptsubscript~\ud835\udc5e\ud835\udc61\ud835\udefc0-1<-\\tilde{k}_{r}+\\tilde{q}_{r}+|\\tilde{q}_{t}|^{\\alpha}<0- 1 < - over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT + over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT + | over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT < 0 for \u03c9<0\ud835\udf140\\omega<0italic_\u03c9 < 0.\nThe rescaled variables are defined by qr=|\u03c9/v|\u2062q~rsubscript\ud835\udc5e\ud835\udc5f\ud835\udf14\ud835\udc63subscript~\ud835\udc5e\ud835\udc5fq_{r}=|\\omega/v|\\tilde{q}_{r}italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = | italic_\u03c9 / italic_v | over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, qt=|\u03c9/b|1/\u03b1\u2062q~tsubscript\ud835\udc5e\ud835\udc61superscript\ud835\udf14\ud835\udc4f1\ud835\udefcsubscript~\ud835\udc5e\ud835\udc61q_{t}=|\\omega/b|^{1/\\alpha}\\tilde{q}_{t}italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = | italic_\u03c9 / italic_b | start_POSTSUPERSCRIPT 1 / italic_\u03b1 end_POSTSUPERSCRIPT over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, and kr=|\u03c9/v|\u2062k~rsubscript\ud835\udc58\ud835\udc5f\ud835\udf14\ud835\udc63subscript~\ud835\udc58\ud835\udc5fk_{r}=|\\omega/v|\\tilde{k}_{r}italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = | italic_\u03c9 / italic_v | over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT.\nThe scaling functions A\u00b1(r)superscriptsubscript\ud835\udc34plus-or-minus\ud835\udc5fA_{\\pm}^{(r)}italic_A start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_r ) end_POSTSUPERSCRIPT are shown graphically for various choices of \u03b1\ud835\udefc\\alphaitalic_\u03b1 in Fig.\u00a04. For k~r=0subscript~\ud835\udc58\ud835\udc5f0\\tilde{k}_{r}=0over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = 0 we recover Eq.\u00a0(22), since A\u00b1(r)\u2062(0)=A\u00b1subscriptsuperscript\ud835\udc34\ud835\udc5fplus-or-minus0subscript\ud835\udc34plus-or-minusA^{(r)}_{\\pm}(0)=A_{\\pm}italic_A start_POSTSUPERSCRIPT ( italic_r ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT ( 0 ) = italic_A start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT from Eq.\u00a0(23). For small finite k~rsubscript~\ud835\udc58\ud835\udc5f\\tilde{k}_{r}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, the leading k~rsubscript~\ud835\udc58\ud835\udc5f\\tilde{k}_{r}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT dependence of As(r)\u2062(k~r)subscriptsuperscript\ud835\udc34\ud835\udc5f\ud835\udc60subscript~\ud835\udc58\ud835\udc5fA^{(r)}_{s}(\\tilde{k}_{r})italic_A start_POSTSUPERSCRIPT ( italic_r ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) is linear, The coefficients B\u00b1subscript\ud835\udc35plus-or-minusB_{\\pm}italic_B start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT are shown as functions of \u03b1\ud835\udefc\\alphaitalic_\u03b1 in Appendix B.\nWhile B+subscript\ud835\udc35B_{+}italic_B start_POSTSUBSCRIPT + end_POSTSUBSCRIPT is always negative, B\u2212subscript\ud835\udc35B_{-}italic_B start_POSTSUBSCRIPT - end_POSTSUBSCRIPT has a sign change for \u03b1\u22482.3\ud835\udefc2.3\\alpha\\approx 2.3italic_\u03b1 \u2248 2.3. Both B+subscript\ud835\udc35B_{+}italic_B start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and B\u2212subscript\ud835\udc35B_{-}italic_B start_POSTSUBSCRIPT - end_POSTSUBSCRIPT diverge for \u03b1\u21922\u2192\ud835\udefc2\\alpha\\to 2italic_\u03b1 \u2192 2.\nFor large |k~r|subscript~\ud835\udc58\ud835\udc5f|\\tilde{k}_{r}|| over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT |, As(r)\u2062(k~r)subscriptsuperscript\ud835\udc34\ud835\udc5f\ud835\udc60subscript~\ud835\udc58\ud835\udc5fA^{(r)}_{s}(\\tilde{k}_{r})italic_A start_POSTSUPERSCRIPT ( italic_r ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) decays as |k~r|\u22121superscriptsubscript~\ud835\udc58\ud835\udc5f1|\\tilde{k}_{r}|^{-1}| over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT. For kr\u22600subscript\ud835\udc58\ud835\udc5f0k_{r}\\neq 0italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \u2260 0 and small |\u03c9|\ud835\udf14|\\omega|| italic_\u03c9 |, the leading frequency dependence of Im\u2062\u03a3\u2062(\ud835\udc24,\u03c9)Im\u03a3\ud835\udc24\ud835\udf14{\\rm Im}\\Sigma({\\bf k},\\omega)roman_Im roman_\u03a3 ( bold_k , italic_\u03c9 ) is quadratic. For |\u03c9|\u226bv\u2062|kr|much-greater-than\ud835\udf14\ud835\udc63subscript\ud835\udc58\ud835\udc5f|\\omega|\\gg v|k_{r}|| italic_\u03c9 | \u226b italic_v | italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT |, Im\u2062\u03a3\u2062(\ud835\udc24,\u03c9)Im\u03a3\ud835\udc24\ud835\udf14{\\rm Im}\\Sigma({\\bf k},\\omega)roman_Im roman_\u03a3 ( bold_k , italic_\u03c9 ) approaches the asymptotic behavior which follows from Eq.\u00a0(30).\nInserting this asymptotic dependence into the Kramers-Kronig relation Eq.\u00a0(21) with an ultraviolet frequency cutoff \u039b\u039b\\Lambdaroman_\u039b, one obtains the leading krsubscript\ud835\udc58\ud835\udc5fk_{r}italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT dependence of the real part of the self-energy at zero frequency as The same result is obtained by inserting Eq.\u00a0(27) with the full (not expanded) scaling function As(r)\u2062(k~r)subscriptsuperscript\ud835\udc34\ud835\udc5f\ud835\udc60subscript~\ud835\udc58\ud835\udc5fA^{(r)}_{s}(\\tilde{k}_{r})italic_A start_POSTSUPERSCRIPT ( italic_r ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) into the Kramers-Kronig integral.\nThe difference B\u2212\u2212B+subscript\ud835\udc35subscript\ud835\udc35B_{-}-B_{+}italic_B start_POSTSUBSCRIPT - end_POSTSUBSCRIPT - italic_B start_POSTSUBSCRIPT + end_POSTSUBSCRIPT in Eq.\u00a0(32) is always positive (for all \u03b1\ud835\udefc\\alphaitalic_\u03b1), and diverges for \u03b1\u21922\u2192\ud835\udefc2\\alpha\\to 2italic_\u03b1 \u2192 2.\nAssuming, as before, that the logarithm reflects the leading contribution from a power-law, we might expect a momentum dependence of the form for small krsubscript\ud835\udc58\ud835\udc5fk_{r}italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, with the anomalous dimension We show \u03b7rsubscript\ud835\udf02\ud835\udc5f\\eta_{r}italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT for M=1\ud835\udc401M=1italic_M = 1 and N=2\ud835\udc412N=2italic_N = 2 as a function of \u03b1\ud835\udefc\\alphaitalic_\u03b1 in Fig.\u00a05. The effective Fermi velocity [19] given by\nv\u2062(kr)=(1\u2212\u2202\u03a3/\u2202\u03c9)\u22121\u2062(1+\u2202\u03a3/\u2202kr)\u2062v\ud835\udc63subscript\ud835\udc58\ud835\udc5fsuperscript1\u03a3\ud835\udf1411\u03a3subscript\ud835\udc58\ud835\udc5f\ud835\udc63v(k_{r})=\\left(1-\\partial\\Sigma/\\partial\\omega\\right)^{-1}\\left(1+\\partial%\n\\Sigma/\\partial k_{r}\\right)vitalic_v ( italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) = ( 1 - \u2202 roman_\u03a3 / \u2202 italic_\u03c9 ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( 1 + \u2202 roman_\u03a3 / \u2202 italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) italic_v is proportional to\n|\u03c9|\u03b7\u2062|kr|\u2212\u03b7rsuperscript\ud835\udf14\ud835\udf02superscriptsubscript\ud835\udc58\ud835\udc5fsubscript\ud835\udf02\ud835\udc5f|\\omega|^{\\eta}|k_{r}|^{-\\eta_{r}}| italic_\u03c9 | start_POSTSUPERSCRIPT italic_\u03b7 end_POSTSUPERSCRIPT | italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT - italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUPERSCRIPT with \u03c9=v\u2062kr\ud835\udf14\ud835\udc63subscript\ud835\udc58\ud835\udc5f\\omega=vk_{r}italic_\u03c9 = italic_v italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, and thus\nv\u00af\u2062(kr)\u221d|kr|\u03b7\u2212\u03b7rproportional-to\u00af\ud835\udc63subscript\ud835\udc58\ud835\udc5fsuperscriptsubscript\ud835\udc58\ud835\udc5f\ud835\udf02subscript\ud835\udf02\ud835\udc5f\\bar{v}(k_{r})\\propto|k_{r}|^{\\eta-\\eta_{r}}over\u00af start_ARG italic_v end_ARG ( italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) \u221d | italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b7 - italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUPERSCRIPT.\nThis quantity vanishes for kr\u21920\u2192subscript\ud835\udc58\ud835\udc5f0k_{r}\\to 0italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \u2192 0, since \u03b7>\u03b7r\ud835\udf02subscript\ud835\udf02\ud835\udc5f\\eta>\\eta_{r}italic_\u03b7 > italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT for all \u03b1\ud835\udefc\\alphaitalic_\u03b1.\nHowever, the renormalization group analysis in Sec.\u00a0IV shows that v\u2062(kr)\ud835\udc63subscript\ud835\udc58\ud835\udc5fv(k_{r})italic_v ( italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) actually vanishes only logarithmically. We now discuss the tangential momentum dependence of the self-energy.\nFor kr=0subscript\ud835\udc58\ud835\udc5f0k_{r}=0italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = 0, we can express Im\u2062\u03a3\u2062(\ud835\udc24,\u03c9)Im\u03a3\ud835\udc24\ud835\udf14{\\rm Im}\\Sigma({\\bf k},\\omega)roman_Im roman_\u03a3 ( bold_k , italic_\u03c9 ) in the scaling form with the dimensionless scaling functions where the integration region is restricted to 0<q~r+|k~t\u2212q~t|\u03b1<10subscript~\ud835\udc5e\ud835\udc5fsuperscriptsubscript~\ud835\udc58\ud835\udc61subscript~\ud835\udc5e\ud835\udc61\ud835\udefc10<\\tilde{q}_{r}+|\\tilde{k}_{t}-\\tilde{q}_{t}|^{\\alpha}<10 < over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT + | over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT < 1 for \u03c9>0\ud835\udf140\\omega>0italic_\u03c9 > 0, and to \u22121<q~r+|k~t\u2212q~t|\u03b1<01subscript~\ud835\udc5e\ud835\udc5fsuperscriptsubscript~\ud835\udc58\ud835\udc61subscript~\ud835\udc5e\ud835\udc61\ud835\udefc0-1<\\tilde{q}_{r}+|\\tilde{k}_{t}-\\tilde{q}_{t}|^{\\alpha}<0- 1 < over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT + | over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT < 0 for \u03c9<0\ud835\udf140\\omega<0italic_\u03c9 < 0.\nThe rescaled variables are defined by qr=|\u03c9/v|\u2062q~rsubscript\ud835\udc5e\ud835\udc5f\ud835\udf14\ud835\udc63subscript~\ud835\udc5e\ud835\udc5fq_{r}=|\\omega/v|\\tilde{q}_{r}italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = | italic_\u03c9 / italic_v | over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, qt=|\u03c9/b|1/\u03b1\u2062q~tsubscript\ud835\udc5e\ud835\udc61superscript\ud835\udf14\ud835\udc4f1\ud835\udefcsubscript~\ud835\udc5e\ud835\udc61q_{t}=|\\omega/b|^{1/\\alpha}\\tilde{q}_{t}italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = | italic_\u03c9 / italic_b | start_POSTSUPERSCRIPT 1 / italic_\u03b1 end_POSTSUPERSCRIPT over~ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, and kt=|\u03c9/b|1/\u03b1\u2062k~tsubscript\ud835\udc58\ud835\udc61superscript\ud835\udf14\ud835\udc4f1\ud835\udefcsubscript~\ud835\udc58\ud835\udc61k_{t}=|\\omega/b|^{1/\\alpha}\\tilde{k}_{t}italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = | italic_\u03c9 / italic_b | start_POSTSUPERSCRIPT 1 / italic_\u03b1 end_POSTSUPERSCRIPT over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT.\nThe scaling functions A\u00b1(t)\u2062(k~t)subscriptsuperscript\ud835\udc34\ud835\udc61plus-or-minussubscript~\ud835\udc58\ud835\udc61A^{(t)}_{\\pm}(\\tilde{k}_{t})italic_A start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) are symmetric under k~t\u21a6\u2212k~tmaps-tosubscript~\ud835\udc58\ud835\udc61subscript~\ud835\udc58\ud835\udc61\\tilde{k}_{t}\\mapsto-\\tilde{k}_{t}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u21a6 - over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT.\nTheir behavior as a function of (positive) k~tsubscript~\ud835\udc58\ud835\udc61\\tilde{k}_{t}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is shown for various choices of \u03b1\ud835\udefc\\alphaitalic_\u03b1 in Fig.\u00a06 [21]. A numerical analysis shows that, to quartic order, A\u00b1(t)\u2062(k~t)subscriptsuperscript\ud835\udc34\ud835\udc61plus-or-minussubscript~\ud835\udc58\ud835\udc61A^{(t)}_{\\pm}(\\tilde{k}_{t})italic_A start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) can be expanded as for small k~tsubscript~\ud835\udc58\ud835\udc61\\tilde{k}_{t}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. At least to that order no non-integer powers of k~tsubscript~\ud835\udc58\ud835\udc61\\tilde{k}_{t}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, such as |k~t|\u03b1superscriptsubscript~\ud835\udc58\ud835\udc61\ud835\udefc|\\tilde{k}_{t}|^{\\alpha}| over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT, contribute. Plots of the coefficients C\u00b1subscript\ud835\udc36plus-or-minusC_{\\pm}italic_C start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT and D\u00b1subscript\ud835\udc37plus-or-minusD_{\\pm}italic_D start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT as functions of \u03b1\ud835\udefc\\alphaitalic_\u03b1 are shown in Appendix B. For large |k~t|subscript~\ud835\udc58\ud835\udc61|\\tilde{k}_{t}|| over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT |, As(t)\u2062(k~t)subscriptsuperscript\ud835\udc34\ud835\udc61\ud835\udc60subscript~\ud835\udc58\ud835\udc61A^{(t)}_{s}(\\tilde{k}_{t})italic_A start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) decays as |k~t|\u2212\u03b1superscriptsubscript~\ud835\udc58\ud835\udc61\ud835\udefc|\\tilde{k}_{t}|^{-\\alpha}| over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT - italic_\u03b1 end_POSTSUPERSCRIPT. Eqs.\u00a0(35) and (38) imply that Im\u2062\u03a3\u2062(\ud835\udc24,\u03c9)Im\u03a3\ud835\udc24\ud835\udf14{\\rm Im}\\Sigma({\\bf k},\\omega)roman_Im roman_\u03a3 ( bold_k , italic_\u03c9 ) behaves as for |\u03c9|\u226bb\u2062|kt|\u03b1much-greater-than\ud835\udf14\ud835\udc4fsuperscriptsubscript\ud835\udc58\ud835\udc61\ud835\udefc|\\omega|\\gg b|k_{t}|^{\\alpha}| italic_\u03c9 | \u226b italic_b | italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT.\nComputing \u03b4\u2062\u03a3\u2062(\ud835\udc24,0)=\u03a3\u2062(\ud835\udc24,0)\u2212\u03a3\u2062(\ud835\udc24H,0)\ud835\udeff\u03a3\ud835\udc240\u03a3\ud835\udc240\u03a3subscript\ud835\udc24\ud835\udc3b0\\delta\\Sigma({\\bf k},0)=\\Sigma({\\bf k},0)-\\Sigma({\\bf k}_{H},0)italic_\u03b4 roman_\u03a3 ( bold_k , 0 ) = roman_\u03a3 ( bold_k , 0 ) - roman_\u03a3 ( bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , 0 ) from the Kramers-Kronig relation Eq.\u00a0(21), the first term in Eq.\u00a0(39) cancels, but the second one generates an ultraviolet divergent term proportional to\n(C\u2212\u2212C+)\u2062\u039b1\u22122/\u03b1\u2062kt2subscript\ud835\udc36subscript\ud835\udc36superscript\u039b12\ud835\udefcsuperscriptsubscript\ud835\udc58\ud835\udc612(C_{-}-C_{+})\\Lambda^{1-2/\\alpha}k_{t}^{2}( italic_C start_POSTSUBSCRIPT - end_POSTSUBSCRIPT - italic_C start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ) roman_\u039b start_POSTSUPERSCRIPT 1 - 2 / italic_\u03b1 end_POSTSUPERSCRIPT italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for any \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2.\nThis term, along with generic regular many-body contributions, leads to a renormalized dispersion relation \u03be\u00af\ud835\udc24subscript\u00af\ud835\udf09\ud835\udc24\\bar{\\xi}_{\\bf k}over\u00af start_ARG italic_\u03be end_ARG start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT with a quadratic tangential momentum dependence, in conflict with our original assumption. However, the case of a dispersion with a vanishing quadratic dependence on ktsubscript\ud835\udc58\ud835\udc61k_{t}italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT can be restored by adding a quadratic contribution to the bare dispersion as a counterterm, which cancels the quadratic self-energy correction. To compute the ktsubscript\ud835\udc58\ud835\udc61k_{t}italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT dependence of the remaining contributions to \u03b4\u2062\u03a3\u2062(\ud835\udc24,0)\ud835\udeff\u03a3\ud835\udc240\\delta\\Sigma({\\bf k},0)italic_\u03b4 roman_\u03a3 ( bold_k , 0 ), we subtract also the quadratic part from Im\u2062\u03a3\u2062(\ud835\udc24,\u03c9)Im\u03a3\ud835\udc24\ud835\udf14{\\rm Im}\\Sigma({\\bf k},\\omega)roman_Im roman_\u03a3 ( bold_k , italic_\u03c9 ) in Eq.\u00a0(39), that is, we compute the Kramers-Kronig integral for\n\u03b4\u2062Im\u2062\u03a3\u2062(\ud835\udc24,\u03c9)=Im\u2062\u03a3\u2062(\ud835\udc24,\u03c9)+MN\u2062[As\u2062(\u03c9)\u2062|\u03c9|+Cs\u2062(\u03c9)\u2062b2/\u03b1\u2062|\u03c9|1\u22122/\u03b1\u2062kt2]\ud835\udeffIm\u03a3\ud835\udc24\ud835\udf14Im\u03a3\ud835\udc24\ud835\udf14\ud835\udc40\ud835\udc41delimited-[]subscript\ud835\udc34\ud835\udc60\ud835\udf14\ud835\udf14subscript\ud835\udc36\ud835\udc60\ud835\udf14superscript\ud835\udc4f2\ud835\udefcsuperscript\ud835\udf1412\ud835\udefcsuperscriptsubscript\ud835\udc58\ud835\udc612\\delta{\\rm Im}\\Sigma({\\bf k},\\omega)={\\rm Im}\\Sigma({\\bf k},\\omega)+\\frac{M}{N%\n}\\big{[}A_{s(\\omega)}|\\omega|+C_{s(\\omega)}b^{2/\\alpha}|\\omega|^{1-2/\\alpha}k_%\n{t}^{2}\\big{]}italic_\u03b4 roman_Im roman_\u03a3 ( bold_k , italic_\u03c9 ) = roman_Im roman_\u03a3 ( bold_k , italic_\u03c9 ) + divide start_ARG italic_M end_ARG start_ARG italic_N end_ARG [ italic_A start_POSTSUBSCRIPT italic_s ( italic_\u03c9 ) end_POSTSUBSCRIPT | italic_\u03c9 | + italic_C start_POSTSUBSCRIPT italic_s ( italic_\u03c9 ) end_POSTSUBSCRIPT italic_b start_POSTSUPERSCRIPT 2 / italic_\u03b1 end_POSTSUPERSCRIPT | italic_\u03c9 | start_POSTSUPERSCRIPT 1 - 2 / italic_\u03b1 end_POSTSUPERSCRIPT italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ].\nFor 2<\u03b1<42\ud835\udefc42<\\alpha<42 < italic_\u03b1 < 4 this integral is convergent and the result can be written as where where \u03b4\u2062As(t)\u2062(k~t)=As(t)\u2062(k~t)\u2212As\u2212Cs\u2062k~t2\ud835\udeffsuperscriptsubscript\ud835\udc34\ud835\udc60\ud835\udc61subscript~\ud835\udc58\ud835\udc61superscriptsubscript\ud835\udc34\ud835\udc60\ud835\udc61subscript~\ud835\udc58\ud835\udc61subscript\ud835\udc34\ud835\udc60subscript\ud835\udc36\ud835\udc60superscriptsubscript~\ud835\udc58\ud835\udc612\\delta A_{s}^{(t)}(\\tilde{k}_{t})=A_{s}^{(t)}(\\tilde{k}_{t})-A_{s}-C_{s}\\tilde%\n{k}_{t}^{2}italic_\u03b4 italic_A start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = italic_A start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) - italic_A start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT - italic_C start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT.\nThe integral in Eq.\u00a0(41) converges in the infrared (small \u03c9~~\ud835\udf14\\tilde{\\omega}over~ start_ARG italic_\u03c9 end_ARG) for any \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2 and in the ultraviolet (large \u03c9~~\ud835\udf14\\tilde{\\omega}over~ start_ARG italic_\u03c9 end_ARG) for \u03b1<4\ud835\udefc4\\alpha<4italic_\u03b1 < 4.\nThe \u03b1\ud835\udefc\\alphaitalic_\u03b1 dependence of \u03b4\u2062b/b\ud835\udeff\ud835\udc4f\ud835\udc4f\\delta b/bitalic_\u03b4 italic_b / italic_b for 2<\u03b1<42\ud835\udefc42<\\alpha<42 < italic_\u03b1 < 4 is shown in Fig.\u00a07. For \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4 the integral diverges logarithmically in the ultraviolet, and one obtains the result presented already in Ref.\u00a0[16], for b\u2062kt4\u226a\u039bmuch-less-than\ud835\udc4fsuperscriptsubscript\ud835\udc58\ud835\udc614\u039bbk_{t}^{4}\\ll\\Lambdaitalic_b italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT \u226a roman_\u039b, which suggests a power-law with the anomalous dimension [16] The renormalization group analysis in the next section reveals that \u03b7tsubscript\ud835\udf02\ud835\udc61\\eta_{t}italic_\u03b7 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is scale dependent, so that ultimately only logarithmic corrections to the quartic tangential momentum dependence are obtained.\nThe logarithmic UV divergence of \u03b4\u2062b\ud835\udeff\ud835\udc4f\\delta bitalic_\u03b4 italic_b for \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4 is reflected by a divergence of \u03b4\u2062b\ud835\udeff\ud835\udc4f\\delta bitalic_\u03b4 italic_b for \u03b1<4\ud835\udefc4\\alpha<4italic_\u03b1 < 4 in the limit \u03b1\u21924\u2192\ud835\udefc4\\alpha\\to 4italic_\u03b1 \u2192 4: for \u03f5\u21920\u2192italic-\u03f50\\epsilon\\to 0italic_\u03f5 \u2192 0, with \u03f5=4\u2212\u03b1italic-\u03f54\ud835\udefc\\epsilon=4-\\alphaitalic_\u03f5 = 4 - italic_\u03b1 and \u03b7tsubscript\ud835\udf02\ud835\udc61\\eta_{t}italic_\u03b7 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT from Eq.\u00a0(43). The logarithmic divergences encountered in the one-loop self-energy imply a breakdown of perturbation theory and indicate possible power law behavior with anomalous exponents. For a controlled treatment of these divergences, we now use the field theoretic renormalization group [22, 23]. For a renormalization group analysis it is convenient to describe our system by a quantum field theory with fermion and boson fields, where the latter represent fluctuations of the order parameter. The corresponding action has the form where \u03c8\u03c3*\u2062(k)superscriptsubscript\ud835\udf13\ud835\udf0e\ud835\udc58\\psi_{\\sigma}^{*}(k)italic_\u03c8 start_POSTSUBSCRIPT italic_\u03c3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_k ) and \u03c8\u03c3\u2062(k)subscript\ud835\udf13\ud835\udf0e\ud835\udc58\\psi_{\\sigma}(k)italic_\u03c8 start_POSTSUBSCRIPT italic_\u03c3 end_POSTSUBSCRIPT ( italic_k ) with \u03c3\u2208{1,\u2026,N}\ud835\udf0e1\u2026\ud835\udc41\\sigma\\in\\{1,\\dots,N\\}italic_\u03c3 \u2208 { 1 , \u2026 , italic_N } are fermionic fields corresponding to fermionic creation and annihilation operators, respectively, while \u03d5\u2062(q)italic-\u03d5\ud835\udc5e\\phi(q)italic_\u03d5 ( italic_q ) is a bosonic field describing the order parameter fluctuations. The variables k=(\ud835\udc24,i\u2062k0)\ud835\udc58\ud835\udc24\ud835\udc56subscript\ud835\udc580k=({\\bf k},ik_{0})italic_k = ( bold_k , italic_i italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) and q=(\ud835\udc2a,i\u2062q0)\ud835\udc5e\ud835\udc2a\ud835\udc56subscript\ud835\udc5e0q=({\\bf q},iq_{0})italic_q = ( bold_q , italic_i italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) contain frequencies and momenta; \u222bksubscript\ud835\udc58\\int_{k}\u222b start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT and \u222bqsubscript\ud835\udc5e\\int_{q}\u222b start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT are shorthand notations for \u222b\ud835\udc24\u222bk0subscript\ud835\udc24subscriptsubscript\ud835\udc580\\int_{\\bf k}\\int_{k_{0}}\u222b start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT \u222b start_POSTSUBSCRIPT italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT and \u222b\ud835\udc2a\u222bq0subscript\ud835\udc2asubscriptsubscript\ud835\udc5e0\\int_{\\bf q}\\int_{q_{0}}\u222b start_POSTSUBSCRIPT bold_q end_POSTSUBSCRIPT \u222b start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT, respectively.\nNote that the interaction term in Eq.\u00a0(45) is hermitian since \u03d5\u2062(\u2212q)=\u03d5*\u2062(q)italic-\u03d5\ud835\udc5esuperscriptitalic-\u03d5\ud835\udc5e\\phi(-q)=\\phi^{*}(q)italic_\u03d5 ( - italic_q ) = italic_\u03d5 start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_q ). An action of the form Eq.\u00a0(45) can be derived from the original purely fermionic action by decoupling the two-fermion interaction via a Hubbard-Stratonovich transformation [19]. The boson propagator is thereby obtained as D\u2062(q)=D0\u2062(q)=g\ud835\udc37\ud835\udc5esubscript\ud835\udc370\ud835\udc5e\ud835\udc54D(q)=D_{0}(q)=gitalic_D ( italic_q ) = italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_q ) = italic_g, and the bare Yukawa coupling is u=1\ud835\udc621u=1italic_u = 1.\nIn one-loop approximation the bosonic self-energy is given by u2\u2062N\u2062\u03a00\u2062(q)superscript\ud835\udc622\ud835\udc41subscript\u03a00\ud835\udc5eu^{2}N\\Pi_{0}(q)italic_u start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_N roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_q ), so that the boson propagator becomes D\u2062(q)=[g\u22121\u2212N\u2062\u03a00\u2062(q)]\u22121\ud835\udc37\ud835\udc5esuperscriptdelimited-[]superscript\ud835\udc541\ud835\udc41subscript\u03a00\ud835\udc5e1D(q)=\\left[g^{-1}-N\\Pi_{0}(q)\\right]^{-1}italic_D ( italic_q ) = [ italic_g start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT - italic_N roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_q ) ] start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, which is equal to the RPA effective interaction in Eq.\u00a0(14).\nAt the quantum critical point, where N\u2062\u03a00\u2062(\ud835\udc10,0)=g\u22121\ud835\udc41subscript\u03a00\ud835\udc100superscript\ud835\udc541N\\Pi_{0}({\\bf Q},0)=g^{-1}italic_N roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_Q , 0 ) = italic_g start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, we thus obtain D\u22121\u2062(q)=\u2212N\u2062\u03b4\u2062\u03a00\u2062(q)superscript\ud835\udc371\ud835\udc5e\ud835\udc41\ud835\udeffsubscript\u03a00\ud835\udc5eD^{-1}(q)=-N\\delta\\Pi_{0}(q)italic_D start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_q ) = - italic_N italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_q ).\nOur scaling and renormalization group analysis is based on the action Eq.\u00a0(45) with\nD\u22121\u2062(q)=\u2212N\u2062\u03b4\u2062\u03a00\u2062(q)superscript\ud835\udc371\ud835\udc5e\ud835\udc41\ud835\udeffsubscript\u03a00\ud835\udc5eD^{-1}(q)=-N\\delta\\Pi_{0}(q)italic_D start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_q ) = - italic_N italic_\u03b4 roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_q ). The one-loop boson self-energy has thus already been taken into account. An analogous procedure has been used previously for a renormalization group analysis of the Ising nematic quantum critical point [24, 25]. Since singular contributions are due to fermions with momenta near the two hot spots \u00b1\ud835\udc24Hplus-or-minussubscript\ud835\udc24\ud835\udc3b\\pm{\\bf k}_{H}\u00b1 bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT, we introduce relative momentum coordinates and expand around the hot spots as in the perturbative analysis in the preceding section. We then need to label fermion fields with an additional index l=\u00b1\ud835\udc59plus-or-minusl=\\pmitalic_l = \u00b1 to distinguish fields with momenta near \ud835\udc24Hsubscript\ud835\udc24\ud835\udc3b{\\bf k}_{H}bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT from those near \u2212\ud835\udc24Hsubscript\ud835\udc24\ud835\udc3b-{\\bf k}_{H}- bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT, and the bosonic fields are labeled by their momentum transfer being close to \ud835\udc10\ud835\udc10{\\bf Q}bold_Q or \u2212\ud835\udc10\ud835\udc10-{\\bf Q}- bold_Q as \u03d5\u2062(\u00b1\ud835\udc10+\ud835\udc2a,q0)=\u03d5\u00b1\u2062(\ud835\udc2a,q0)=\u03d5\u00b1\u2062(q)italic-\u03d5plus-or-minus\ud835\udc10\ud835\udc2asubscript\ud835\udc5e0subscriptitalic-\u03d5plus-or-minus\ud835\udc2asubscript\ud835\udc5e0subscriptitalic-\u03d5plus-or-minus\ud835\udc5e\\phi(\\pm{\\bf Q}+{\\bf q},q_{0})=\\phi_{\\pm}({\\bf q},q_{0})=\\phi_{\\pm}(q)italic_\u03d5 ( \u00b1 bold_Q + bold_q , italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = italic_\u03d5 start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT ( bold_q , italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = italic_\u03d5 start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT ( italic_q ).\nThe action Eq.\u00a0(45) can then be written as We start with a simple analysis of canonical scaling dimensions. Rescaling fermionic momenta and frequencies as and anagously for bosonic momenta and frequencies q0subscript\ud835\udc5e0q_{0}italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, qrsubscript\ud835\udc5e\ud835\udc5fq_{r}italic_q start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, and qtsubscript\ud835\udc5e\ud835\udc61q_{t}italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, implies The latter relation follows from Eq.\u00a0(8). Scaling frequencies by a linear factor s\ud835\udc60sitalic_s, the scaling of the momentum variables is determined by requiring a homogeneous scaling relation for G0\u2062(k)subscript\ud835\udc3a0\ud835\udc58G_{0}(k)italic_G start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_k ), that is, all terms contributing to G0\u22121\u2062(k)superscriptsubscript\ud835\udc3a01\ud835\udc58G_{0}^{-1}(k)italic_G start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_k ) should scale linearly with s\ud835\udc60sitalic_s.\nRequiring that the quadratic parts of the action be scale invariant, and taking into account that the integration measures in \u222bksubscript\ud835\udc58\\int_{k}\u222b start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT and \u222bqsubscript\ud835\udc5e\\int_{q}\u222b start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT scale as s2+1/\u03b1superscript\ud835\udc6021\ud835\udefcs^{2+1/\\alpha}italic_s start_POSTSUPERSCRIPT 2 + 1 / italic_\u03b1 end_POSTSUPERSCRIPT, the fields need to be rescaled as Inserting this scaling behavior of the fields into the interaction term in Eq.\u00a0(46), one finds that this term is scale invariant, so that the Yukawa coupling constant u\ud835\udc62uitalic_u is marginal. We now turn to the renormalization group analysis with fluctuations on one-loop level, which corresponds to the leading order in a 1/N1\ud835\udc411/N1 / italic_N expansion. While the bosonic one-loop self-energy is finite, the fermionic self-energy exhibits logarithmic divergences which were derived in the preceding section. Expressing the self-energy as a function of the three variables krsubscript\ud835\udc58\ud835\udc5fk_{r}italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, ktsubscript\ud835\udc58\ud835\udc61k_{t}italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, and k0subscript\ud835\udc580k_{0}italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and subtracting \u03a3\u2062(\ud835\udc24H,0)\u03a3subscript\ud835\udc24\ud835\udc3b0\\Sigma({\\bf k}_{H},0)roman_\u03a3 ( bold_k start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , 0 ), we found for any \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2, where \u03b7\ud835\udf02\\etaitalic_\u03b7 and \u03b7rsubscript\ud835\udf02\ud835\udc5f\\eta_{r}italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT are the (tentative) anomalous dimensions defined in Eqs.\u00a0(26) and (34), respectively. Note that we have explicitly included the coupling constant u=1\ud835\udc621u=1italic_u = 1, for reasons that will become clear below.\nFor \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4 there is also a logarithmic divergence in the tangential momentum dependence, with \u03b7tsubscript\ud835\udf02\ud835\udc61\\eta_{t}italic_\u03b7 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT from Eq.\u00a0(43), while for \u03b1<4\ud835\udefc4\\alpha<4italic_\u03b1 < 4 only a finite correction of the order |kt|\u03b1superscriptsubscript\ud835\udc58\ud835\udc61\ud835\udefc|k_{t}|^{\\alpha}| italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT is obtained. However, the prefactor \u03b4\u2062b\ud835\udeff\ud835\udc4f\\delta bitalic_\u03b4 italic_b of that correction diverges for \u03b1\u21924\u2192\ud835\udefc4\\alpha\\to 4italic_\u03b1 \u2192 4, see Eq.\u00a0(44). For \u03b1>4\ud835\udefc4\\alpha>4italic_\u03b1 > 4, the coefficient of the quartic contribution to the self-energy diverges as a power of the ultraviolet cutoff. In the following we focus on the cases 2<\u03b1\u226442\ud835\udefc42<\\alpha\\leq 42 < italic_\u03b1 \u2264 4. A complete one-loop calculation for an action of the form Eq.\u00a0(45) involves also a one-loop correction of the Yukawa vertex. However, for ordering wave vectors distinct from half a reciprocal lattice vector, there is no choice of momenta in the vertex correction at which the singularities of the propagators coalesce [6], so that the vertex correction is finite. Hence, the only divergences come from the fermion self-energy. Since the leading tangential momentum dependence of the self-energy diverges for \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4, while it is finite for \u03b1<4\ud835\udefc4\\alpha<4italic_\u03b1 < 4, we need to distinguish these two cases. Following the field theoretic renormalization procedure [22, 23], we define a renormalized fermionic two-point vertex function where \u0393(2)=G0\u22121\u2212\u03b4\u2062\u03a3superscript\u03932superscriptsubscript\ud835\udc3a01\ud835\udeff\u03a3\\Gamma^{(2)}=G_{0}^{-1}-\\delta\\Sigmaroman_\u0393 start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT = italic_G start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT - italic_\u03b4 roman_\u03a3 is the unrenormalized vertex function, and the renormalized parameters u\u00af\u00af\ud835\udc62\\bar{u}over\u00af start_ARG italic_u end_ARG, v\u00af\u00af\ud835\udc63\\bar{v}over\u00af start_ARG italic_v end_ARG, b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG are defined as The energy scale \u03bb\ud835\udf06\\lambdaitalic_\u03bb can be chosen arbitrarily, or it may be used to satisfy normalization conditions of the renormalized theory at specific frequencies and momenta [22, 23].\nTo second order in the coupling constant, the renormalized two-point vertex, expressed as a function of the renormalized parameters v\u00af\u00af\ud835\udc63\\bar{v}over\u00af start_ARG italic_v end_ARG, b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG, and u\u00af\u00af\ud835\udc62\\bar{u}over\u00af start_ARG italic_u end_ARG, is finite for \u039b\u2192\u221e\u2192\u039b\\Lambda\\to\\inftyroman_\u039b \u2192 \u221e: The renormalization of the Yukawa coupling, Eq.\u00a0(56), is determined by the renormalization of the Yukawa vertex Since \u0393(2,1)superscript\u039321\\Gamma^{(2,1)}roman_\u0393 start_POSTSUPERSCRIPT ( 2 , 1 ) end_POSTSUPERSCRIPT is finite at the one-loop level, the renormalization of u\ud835\udc62uitalic_u is determined exclusively by Z\ud835\udc4dZitalic_Z. Discarding non-universal finite one-loop vertex corrections, we approximate \u0393(2,1)\u2062(0,0;u;\u039b)superscript\u03932100\ud835\udc62\u039b\\Gamma^{(2,1)}(0,0;u;\\Lambda)roman_\u0393 start_POSTSUPERSCRIPT ( 2 , 1 ) end_POSTSUPERSCRIPT ( 0 , 0 ; italic_u ; roman_\u039b ) by its bare value u\ud835\udc62uitalic_u, so that u\u00af=\u0393\u00af(2,1)\u2062(0,0;u\u00af;\u03bb)=Z\u2062u\u00af\ud835\udc62superscript\u00af\u03932100\u00af\ud835\udc62\ud835\udf06\ud835\udc4d\ud835\udc62\\bar{u}=\\bar{\\Gamma}^{(2,1)}(0,0;\\bar{u};\\lambda)=Zuover\u00af start_ARG italic_u end_ARG = over\u00af start_ARG roman_\u0393 end_ARG start_POSTSUPERSCRIPT ( 2 , 1 ) end_POSTSUPERSCRIPT ( 0 , 0 ; over\u00af start_ARG italic_u end_ARG ; italic_\u03bb ) = italic_Z italic_u. The renormalization group flow is obtained from the evolution of \u0393\u00af(2)\u2062(k;v\u00af,b\u00af,u\u00af;\u03bb)superscript\u00af\u03932\ud835\udc58\u00af\ud835\udc63\u00af\ud835\udc4f\u00af\ud835\udc62\ud835\udf06\\bar{\\Gamma}^{(2)}(k;\\bar{v},\\bar{b},\\bar{u};\\lambda)over\u00af start_ARG roman_\u0393 end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( italic_k ; over\u00af start_ARG italic_v end_ARG , over\u00af start_ARG italic_b end_ARG , over\u00af start_ARG italic_u end_ARG ; italic_\u03bb ) upon varying the energy scale \u03bb\ud835\udf06\\lambdaitalic_\u03bb [22, 23]. The bare vertex \u0393(2)\u2062(k;v,b,u;\u039b)superscript\u03932\ud835\udc58\ud835\udc63\ud835\udc4f\ud835\udc62\u039b\\Gamma^{(2)}(k;v,b,u;\\Lambda)roman_\u0393 start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( italic_k ; italic_v , italic_b , italic_u ; roman_\u039b ) does not depend on \u03bb\ud835\udf06\\lambdaitalic_\u03bb, so that and thus where \u2202\u03bbsubscript\ud835\udf06\\partial_{\\lambda}\u2202 start_POSTSUBSCRIPT italic_\u03bb end_POSTSUBSCRIPT is a partial derivative with respect to \u03bb\ud835\udf06\\lambdaitalic_\u03bb, for x\u00af=v\u00af\u00af\ud835\udc65\u00af\ud835\udc63\\bar{x}=\\bar{v}over\u00af start_ARG italic_x end_ARG = over\u00af start_ARG italic_v end_ARG, b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG, u\u00af\u00af\ud835\udc62\\bar{u}over\u00af start_ARG italic_u end_ARG, and Inserting Eq.\u00a0(55) into Eq.\u00a0(56), we obtain On the right hand side we have replaced u\ud835\udc62uitalic_u by u\u00af\u00af\ud835\udc62\\bar{u}over\u00af start_ARG italic_u end_ARG, which is justified since u\u00af\u2212u\u00af\ud835\udc62\ud835\udc62\\bar{u}-uover\u00af start_ARG italic_u end_ARG - italic_u is of order (u\u00af)3superscript\u00af\ud835\udc623(\\bar{u})^{3}( over\u00af start_ARG italic_u end_ARG ) start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. The flow equation for u\u00af\u00af\ud835\udc62\\bar{u}over\u00af start_ARG italic_u end_ARG does not depend on the other variables and can be easily integrated. With the initial condition u\u00af=u\u00af0=1\u00af\ud835\udc62subscript\u00af\ud835\udc6201\\bar{u}=\\bar{u}_{0}=1over\u00af start_ARG italic_u end_ARG = over\u00af start_ARG italic_u end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 1 for \u03bb=\u03bb0\ud835\udf06subscript\ud835\udf060\\lambda=\\lambda_{0}italic_\u03bb = italic_\u03bb start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT we find Hence, u\u00af\u00af\ud835\udc62\\bar{u}over\u00af start_ARG italic_u end_ARG tends to u\u00af*=0superscript\u00af\ud835\udc620\\bar{u}^{*}=0over\u00af start_ARG italic_u end_ARG start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT = 0 for \u03bb\u21920\u2192\ud835\udf060\\lambda\\to 0italic_\u03bb \u2192 0, albeit very slowly.\nInserting Eq.\u00a0(55) into Eq.\u00a0(64) yields, to order u\u00af2superscript\u00af\ud835\udc622\\bar{u}^{2}over\u00af start_ARG italic_u end_ARG start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, Eqs.\u00a0(57) and (58) yield, respectively, Inserting the solution for u\u00af\u00af\ud835\udc62\\bar{u}over\u00af start_ARG italic_u end_ARG, Eq.\u00a0(66), the flow equations for v\u00af\u00af\ud835\udc63\\bar{v}over\u00af start_ARG italic_v end_ARG and b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG can be easily integrated to where v\u00af0subscript\u00af\ud835\udc630\\bar{v}_{0}over\u00af start_ARG italic_v end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and b\u00af0subscript\u00af\ud835\udc4f0\\bar{b}_{0}over\u00af start_ARG italic_b end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT are the initial values of v\u00af\u00af\ud835\udc63\\bar{v}over\u00af start_ARG italic_v end_ARG and b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG, repectively, at \u03bb=\u03bb0\ud835\udf06subscript\ud835\udf060\\lambda=\\lambda_{0}italic_\u03bb = italic_\u03bb start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT.\nSince \u03b7rsubscript\ud835\udf02\ud835\udc5f\\eta_{r}italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and \u03b7tsubscript\ud835\udf02\ud835\udc61\\eta_{t}italic_\u03b7 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT are both smaller than \u03b7\ud835\udf02\\etaitalic_\u03b7, the renormalized quantities v\u00af\u00af\ud835\udc63\\bar{v}over\u00af start_ARG italic_v end_ARG and b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG decrease upon decreasing \u03bb\ud835\udf06\\lambdaitalic_\u03bb. Initially this decrease is very slow, while ultimately (for \u03bb\u226a\u03bb0\u2062e\u22121/(2\u2062\u03b7)much-less-than\ud835\udf06subscript\ud835\udf060superscript\ud835\udc5212\ud835\udf02\\lambda\\ll\\lambda_{0}e^{-1/(2\\eta)}italic_\u03bb \u226a italic_\u03bb start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_e start_POSTSUPERSCRIPT - 1 / ( 2 italic_\u03b7 ) end_POSTSUPERSCRIPT) they vanish as some power of a logarithm. From the flow of the renormalized quantities and \u03b3\ud835\udefe\\gammaitalic_\u03b3 as a function of \u03bb\ud835\udf06\\lambdaitalic_\u03bb we can obtain the momentum and frequency dependences of the fermionic two-point vertex \u0393(2)superscript\u03932\\Gamma^{(2)}roman_\u0393 start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT, following the standard procedure [22, 23].\nWe begin with the frequency dependence at the hot spot. For kr=kt=0subscript\ud835\udc58\ud835\udc5fsubscript\ud835\udc58\ud835\udc610k_{r}=k_{t}=0italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0, the flow equation (62) for the renormalized vertex \u0393\u00af(2)superscript\u00af\u03932\\bar{\\Gamma}^{(2)}over\u00af start_ARG roman_\u0393 end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT can be integrated to with the normalization condition \u0393\u00af(2)\u2062(0,0,i\u2062k0)=i\u2062k0superscript\u00af\u0393200\ud835\udc56subscript\ud835\udc580\ud835\udc56subscript\ud835\udc580\\bar{\\Gamma}^{(2)}(0,0,ik_{0})=ik_{0}over\u00af start_ARG roman_\u0393 end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( 0 , 0 , italic_i italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = italic_i italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT for |k0|=\u03bbsubscript\ud835\udc580\ud835\udf06|k_{0}|=\\lambda| italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | = italic_\u03bb. A simple dimensional argument then yields This result agrees with the perturbative expression to linear order in \u03b7\ud835\udf02\\etaitalic_\u03b7. However, the naive expectation of a power law with an anomalous exponent \u03b7\ud835\udf02\\etaitalic_\u03b7 was not confirmed by the renormalization group analysis. Instead, only a weaker logarithmic correction to the bare frequency dependence is obtained.\nThis behavior is similar to the momentum dependence of the two-point vertex in the \u03d54superscriptitalic-\u03d54\\phi^{4}italic_\u03d5 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT-theory at the critical dimension dc=4subscript\ud835\udc51\ud835\udc504d_{c}=4italic_d start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 4, where the interaction is also marginally irrelevant and leads to logarithmic corrections of the momentum dependence [23]. In that case, however, the beta function is quadratic in the coupling to leading order, while in our model it is cubic, so that the renormalized coupling vanishes more slowly. From the flow of the renormalized quantities v\u00af\u00af\ud835\udc63\\bar{v}over\u00af start_ARG italic_v end_ARG and b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG in Eqs.\u00a0(70) and (71), respectively, we obtain momentum dependent coefficients of the fluctuation-corrected dispersion as via dimensional arguments. These results agree with the perturbative expressions to leading order in the anomalous dimensions \u03b7\ud835\udf02\\etaitalic_\u03b7, \u03b7rsubscript\ud835\udf02\ud835\udc5f\\eta_{r}italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, and \u03b7tsubscript\ud835\udf02\ud835\udc61\\eta_{t}italic_\u03b7 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. Since \u03b7\ud835\udf02\\etaitalic_\u03b7 is larger than \u03b7rsubscript\ud835\udf02\ud835\udc5f\\eta_{r}italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and \u03b7tsubscript\ud835\udf02\ud835\udc61\\eta_{t}italic_\u03b7 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, both v\u2062(kr)\ud835\udc63subscript\ud835\udc58\ud835\udc5fv(k_{r})italic_v ( italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) and b\u2062(kt)\ud835\udc4fsubscript\ud835\udc58\ud835\udc61b(k_{t})italic_b ( italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) vanish upon approaching the hot spot in momentum space, albeit very slowly. For \u03b1<4\ud835\udefc4\\alpha<4italic_\u03b1 < 4 the tangential momentum dependence of the fermion propagator acquires only a finite correction, as given by \u03b4\u2062b\ud835\udeff\ud835\udc4f\\delta bitalic_\u03b4 italic_b in Eq.\u00a0(41). The divergences in the self-energy corrections to the frequency and radial momentum dependence are qualitatively the same as for \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4. These divergences can therefore be treated by the same renormalization group procedure as for \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4. The defining equations of Z\ud835\udc4dZitalic_Z, u\u00af\u00af\ud835\udc62\\bar{u}over\u00af start_ARG italic_u end_ARG, and v\u00af\u00af\ud835\udc63\\bar{v}over\u00af start_ARG italic_v end_ARG, as well as their flow equations, remain the same, and one obtains the same results for the frequency and radial momentum dependence as for \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4. The dependence on \u03b1\ud835\udefc\\alphaitalic_\u03b1 enters only via the parameters \u03b7\ud835\udf02\\etaitalic_\u03b7 and \u03b7rsubscript\ud835\udf02\ud835\udc5f\\eta_{r}italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT. As to the tangential momentum dependence, a renormalized coefficient b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG could be defined as The flow of b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG is then driven only by the divergence of the Z\ud835\udc4dZitalic_Z-factor. The above procedure is satisfactory as long as \u03b4\u2062b/b\ud835\udeff\ud835\udc4f\ud835\udc4f\\delta b/bitalic_\u03b4 italic_b / italic_b is small, which is the case for \u03b1\ud835\udefc\\alphaitalic_\u03b1 staying sufficiently far away from two and four. For \u03b1\u21922\u2192\ud835\udefc2\\alpha\\to 2italic_\u03b1 \u2192 2, not only \u03b4\u2062b/b\ud835\udeff\ud835\udc4f\ud835\udc4f\\delta b/bitalic_\u03b4 italic_b / italic_b becomes large, but also \u03b7\ud835\udf02\\etaitalic_\u03b7 and \u03b7rsubscript\ud835\udf02\ud835\udc5f\\eta_{r}italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, so that the one-loop theory breaks down completely. For \u03b1\u21924\u2192\ud835\udefc4\\alpha\\to 4italic_\u03b1 \u2192 4, however, the frequency and radial momentum dependence seem to be well captured by the one-loop approximation, and we can deal with the tangential momentum dependence by resorting to an \u03f5italic-\u03f5\\epsilonitalic_\u03f5-expansion in \u03f5=4\u2212\u03b1italic-\u03f54\ud835\udefc\\epsilon=4-\\alphaitalic_\u03f5 = 4 - italic_\u03b1. To this end, we define our renormalization group analysis for a scaling of the tangential momentum variable as kt\u2192s1/4\u2062kt\u2192subscript\ud835\udc58\ud835\udc61superscript\ud835\udc6014subscript\ud835\udc58\ud835\udc61k_{t}\\to s^{1/4}k_{t}italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2192 italic_s start_POSTSUPERSCRIPT 1 / 4 end_POSTSUPERSCRIPT italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT instead of kt\u2192s1/\u03b1\u2062kt\u2192subscript\ud835\udc58\ud835\udc61superscript\ud835\udc601\ud835\udefcsubscript\ud835\udc58\ud835\udc61k_{t}\\to s^{1/\\alpha}k_{t}italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2192 italic_s start_POSTSUPERSCRIPT 1 / italic_\u03b1 end_POSTSUPERSCRIPT italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. In this way, the coefficient b\ud835\udc4fbitalic_b becomes a relevant variable for \u03b1<4\ud835\udefc4\\alpha<4italic_\u03b1 < 4 already at tree level (without loop corrections), while the Yukawa coupling u\ud835\udc62uitalic_u remains marginal.\nThe self-energy from Eq.\u00a0(40) is written accordingly in the form where \u03b7tsubscript\ud835\udf02\ud835\udc61\\eta_{t}italic_\u03b7 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT can be evaluated for \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4 to leading order in \u03f5italic-\u03f5\\epsilonitalic_\u03f5.\nThe renormalized vertex \u0393\u00af(2)=Z\u2062\u0393(2)superscript\u00af\u03932\ud835\udc4dsuperscript\u03932\\bar{\\Gamma}^{(2)}=Z\\Gamma^{(2)}over\u00af start_ARG roman_\u0393 end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT = italic_Z roman_\u0393 start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT is finite for \u039b\u2192\u221e\u2192\u039b\\Lambda\\to\\inftyroman_\u039b \u2192 \u221e and \u03f5\u21920\u2192italic-\u03f50\\epsilon\\to 0italic_\u03f5 \u2192 0 if u\u00af\u00af\ud835\udc62\\bar{u}over\u00af start_ARG italic_u end_ARG and v\u00af\u00af\ud835\udc63\\bar{v}over\u00af start_ARG italic_v end_ARG are chosen as before, and Applying \u03bb\u2062\u2202\u03bb\ud835\udf06subscript\ud835\udf06\\lambda\\partial_{\\lambda}italic_\u03bb \u2202 start_POSTSUBSCRIPT italic_\u03bb end_POSTSUBSCRIPT to b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG, and expanding in u\u00af\u00af\ud835\udc62\\bar{u}over\u00af start_ARG italic_u end_ARG and \u03f5italic-\u03f5\\epsilonitalic_\u03f5, we obtain the \u03b2\ud835\udefd\\betaitalic_\u03b2-function for the flow of b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG to order u\u00af2superscript\u00af\ud835\udc622\\bar{u}^{2}over\u00af start_ARG italic_u end_ARG start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT and order \u03f5italic-\u03f5\\epsilonitalic_\u03f5, For \u03f5\u21920\u2192italic-\u03f50\\epsilon\\to 0italic_\u03f5 \u2192 0 this \u03b2\ud835\udefd\\betaitalic_\u03b2-function reduces continuously to the \u03b2\ud835\udefd\\betaitalic_\u03b2-function for \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4 in Eq.\u00a0(69).\nThe flow equation for b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG can be integrated to where b\u00af0subscript\u00af\ud835\udc4f0\\bar{b}_{0}over\u00af start_ARG italic_b end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is the initial value of b\u00af\u00af\ud835\udc4f\\bar{b}over\u00af start_ARG italic_b end_ARG at \u03bb=\u03bb0\ud835\udf06subscript\ud835\udf060\\lambda=\\lambda_{0}italic_\u03bb = italic_\u03bb start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT.\nUsing once again the common dimensional arguments [23], we thus obtain the tangential momentum dependence of the fluctuation corrected dispersion in the form b\u2062(kt)\u2062|kt|\u03b1\ud835\udc4fsubscript\ud835\udc58\ud835\udc61superscriptsubscript\ud835\udc58\ud835\udc61\ud835\udefcb(k_{t})|k_{t}|^{\\alpha}italic_b ( italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) | italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT, with The first scale dependent factor in Eq.\u00a0(80) simply shifts the exponent from kt4superscriptsubscript\ud835\udc58\ud835\udc614k_{t}^{4}italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT to |kt|\u03b1superscriptsubscript\ud835\udc58\ud835\udc61\ud835\udefc|k_{t}|^{\\alpha}| italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT, while the second factor leads to a logarithmic correction. For \u03b1\u21924\u2192\ud835\udefc4\\alpha\\to 4italic_\u03b1 \u2192 4 we recover the behavior of b\u2062(kt)\ud835\udc4fsubscript\ud835\udc58\ud835\udc61b(k_{t})italic_b ( italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) in Eq.\u00a0(75). Since \u03b7r>\u03b7tsubscript\ud835\udf02\ud835\udc5fsubscript\ud835\udf02\ud835\udc61\\eta_{r}>\\eta_{t}italic_\u03b7 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT > italic_\u03b7 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT for all \u03b1\ud835\udefc\\alphaitalic_\u03b1, the renormalized Fermi velocity v\u2062(kr)\ud835\udc63subscript\ud835\udc58\ud835\udc5fv(k_{r})italic_v ( italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) vanishes slightly faster than b\u2062(kt)\ud835\udc4fsubscript\ud835\udc58\ud835\udc61b(k_{t})italic_b ( italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ). Hence, the renormalized Fermi surface is slightly (logarithmically) flatter than the bare one. We have analyzed quantum fluctuation effects at the onset of incommensurate 2\u2062kF2subscript\ud835\udc58\ud835\udc392k_{F}2 italic_k start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT charge- or spin-density wave order in two-dimensional metals, for a model where the ordering wave vector \ud835\udc10\ud835\udc10{\\bf Q}bold_Q connects a single pair of hot spots on the Fermi surface with vanishing Fermi surface curvature. The tangential momentum dependence of the bare dispersion near the hot spots is proportional to |kt|\u03b1superscriptsubscript\ud835\udc58\ud835\udc61\ud835\udefc|k_{t}|^{\\alpha}| italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT with \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2.\nVarying \u03b1\ud835\udefc\\alphaitalic_\u03b1 yields a smooth interpolation between the conventional parabolic case with a finite Fermi surface curvature, for \u03b1=2\ud835\udefc2\\alpha=2italic_\u03b1 = 2, and the quartic case \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4, which we have analyzed previously within RPA [16]. We have first computed the order parameter susceptibility and the fermion self-energy within RPA for generic values of \u03b1\ud835\udefc\\alphaitalic_\u03b1. The static susceptibility forms a sharp peak in momentum space at \ud835\udc10\ud835\udc10{\\bf Q}bold_Q for any \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2, while for \u03b1=2\ud835\udefc2\\alpha=2italic_\u03b1 = 2 the susceptibility becomes flat in a half-plane near \ud835\udc10\ud835\udc10{\\bf Q}bold_Q [26]. The susceptibility (as a function of momentum and frequency) can be written in a scaling form with a scaling function that depends only on one variable. For \u03b1=2\ud835\udefc2\\alpha=2italic_\u03b1 = 2 and \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4 exact analytic expressions for the scaling functions can be obtained.\nAt the hot spots the (real) frequency dependence of the imaginary part of the fermion self-energy is linear and slightly asymmetric for any \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2, while the real part exhibits a logarithmic divergence, which indicates a vanishing quasiparticle weight. The momentum dependence perpendicular to the Fermi surface also develops a logarithmic divergence for any \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2. For \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4 also the coefficient of the quartic momentum dependence diverges logarithmically, while for \u03b1<4\ud835\udefc4\\alpha<4italic_\u03b1 < 4 only a finite correction to the prefactor of the leading |kt|\u03b1superscriptsubscript\ud835\udc58\ud835\udc61\ud835\udefc|k_{t}|^{\\alpha}| italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT term is obtained. For \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4, these RPA results have already been derived in Ref.\u00a0[16], except for the exact analytic formula for the susceptibility. A field-theoretic renormalization group analysis reveals that the logarithmic divergences in RPA are not perturbative signatures of non-Fermi liquid behavior with anomalous power laws. Instead, only logarithmic corrections to Fermi liquid behavior are obtained. In particular, the quasiparticle weight and the Fermi velocity vanish logarithmically at the hot spots. Fermi liquids with a logarithmically vanishing quasiparticle weight are known as marginal Fermi liquids [18].\nThe reason for this relatively mild breakdown of Fermi liquid behavior is the vanishing renormalized coupling between the electrons and the critical order parameter fluctuations, which is due to the suppression of spectral weight at the Fermi level. The one-loop renormalization group analysis is controlled by a 1/N1\ud835\udc411/N1 / italic_N expansion, where N\ud835\udc41Nitalic_N is the number of fermion species. Higher loop orders correspond to higher orders in 1/N1\ud835\udc411/N1 / italic_N. The one-loop fluctuation corrections to the fermion self-energy are numerically quite small for N=2\ud835\udc412N=2italic_N = 2 (that is, for electrons), as long as \u03b1\ud835\udefc\\alphaitalic_\u03b1 is not close to two. Feedback of the marginal Fermi liquid behavior of the self-energy on the susceptibility occurs only at the two-loop level. Except for \u03b1\u22482\ud835\udefc2\\alpha\\approx 2italic_\u03b1 \u2248 2, it is unlikely that this feedback will significantly affect the robust peak at \ud835\udc2a=\ud835\udc10\ud835\udc2a\ud835\udc10{\\bf q}={\\bf Q}bold_q = bold_Q in the susceptibility. Hence, the 2\u2062kF2subscript\ud835\udc58\ud835\udc392k_{F}2 italic_k start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT quantum critical point is not destroyed by fluctuations. This conclusion holds, in particular, for the physically realizable case \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4. For \u03b1\u21922\u2192\ud835\udefc2\\alpha\\to 2italic_\u03b1 \u2192 2, instead, the one-loop fluctuation corrections become large for any fixed finite N\ud835\udc41Nitalic_N. Not only the RPA, but also the one-loop renormalization group becomes uncontrolled in this limit. Hence, for the parabolic case \u03b1=2\ud835\udefc2\\alpha=2italic_\u03b1 = 2, we have not gained much further insight beyond the results of Refs.\u00a0[13] and [15].\nThe fluctuation induced flattening of the Fermi surface found for \u03b1=2\ud835\udefc2\\alpha=2italic_\u03b1 = 2 in Refs.\u00a0[13, 15] has been confirmed for \u03b1>2\ud835\udefc2\\alpha>2italic_\u03b1 > 2, and may thus be a rather generic effect. The krsubscript\ud835\udc58\ud835\udc5fk_{r}italic_k start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT integral in Eq.\u00a0(4) can be easily carried out by using the residue theorem. Shifting the remaining integration variables as kt\u2192kt+qt/2\u2192subscript\ud835\udc58\ud835\udc61subscript\ud835\udc58\ud835\udc61subscript\ud835\udc5e\ud835\udc612k_{t}\\to k_{t}+q_{t}/2italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2192 italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT / 2 and k0\u2192k0+q0/2\u2192subscript\ud835\udc580subscript\ud835\udc580subscript\ud835\udc5e02k_{0}\\to k_{0}+q_{0}/2italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2192 italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT / 2 to symmetrize the integrand, one obtains Splitting the integral into contributions from positive and negative k0subscript\ud835\udc580k_{0}italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and shifting k0\u2192k0\u00b1q0/2\u2192subscript\ud835\udc580plus-or-minussubscript\ud835\udc580subscript\ud835\udc5e02k_{0}\\to k_{0}\\pm q_{0}/2italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2192 italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00b1 italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT / 2, the bubble can be written as where These expressions can be continued analytically to real frequencies by simply substituting i\u2062q0\u2192\u03c9+i\u20620+\u2192\ud835\udc56subscript\ud835\udc5e0\ud835\udf14\ud835\udc56superscript0iq_{0}\\to\\omega+i0^{+}italic_i italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2192 italic_\u03c9 + italic_i 0 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT. The justification for this step provided for the case \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4 in Ref.\u00a0[16] holds also for generic values of \u03b1\ud835\udefc\\alphaitalic_\u03b1.\nSubstituting kt=|qt|\u2062k~tsubscript\ud835\udc58\ud835\udc61subscript\ud835\udc5e\ud835\udc61subscript~\ud835\udc58\ud835\udc61k_{t}=|q_{t}|\\tilde{k}_{t}italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = | italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and k0=b\u2062|qt|\u03b1\u2062k~0subscript\ud835\udc580\ud835\udc4fsuperscriptsubscript\ud835\udc5e\ud835\udc61\ud835\udefcsubscript~\ud835\udc580k_{0}=b|q_{t}|^{\\alpha}\\tilde{k}_{0}italic_k start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_b | italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_\u03b1 end_POSTSUPERSCRIPT over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, one obtains Subtracting \u03a00\u2062(\ud835\udc10,0)subscript\u03a00\ud835\udc100\\Pi_{0}({\\bf Q},0)roman_\u03a0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( bold_Q , 0 ) yields Eqs.\u00a0(8), with the scaling function Performing the frequency integral yields I\u03b1\u2062(x)subscript\ud835\udc3c\ud835\udefc\ud835\udc65I_{\\alpha}(x)italic_I start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT ( italic_x ) in the form Eq.\u00a0(9). For \u03b1=2\ud835\udefc2\\alpha=2italic_\u03b1 = 2 and \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4, the remaining integral over k~tsubscript~\ud835\udc58\ud835\udc61\\tilde{k}_{t}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT in Eq.\u00a0(9) can be performed analytically. Here we present a derivation for the non-trivial case \u03b1=4\ud835\udefc4\\alpha=4italic_\u03b1 = 4.\nWe first factorize the numerator of the argument of the logarithm in Eq.\u00a0(9) as\n(k~t+12)4+(k~t\u221212)4\u2212(x+i\u20620+)=2\u2062(k~t2\u2212k~+2)\u2062(k~t2\u2212k~\u22122)superscriptsubscript~\ud835\udc58\ud835\udc61124superscriptsubscript~\ud835\udc58\ud835\udc61124\ud835\udc65\ud835\udc56superscript02superscriptsubscript~\ud835\udc58\ud835\udc612superscriptsubscript~\ud835\udc582superscriptsubscript~\ud835\udc58\ud835\udc612superscriptsubscript~\ud835\udc582(\\tilde{k}_{t}+\\frac{1}{2})^{4}+(\\tilde{k}_{t}-\\frac{1}{2})^{4}-(x+i0^{+})=2(%\n\\tilde{k}_{t}^{2}-\\tilde{k}_{+}^{2})(\\tilde{k}_{t}^{2}-\\tilde{k}_{-}^{2})( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + divide start_ARG 1 end_ARG start_ARG 2 end_ARG ) start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT + ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - divide start_ARG 1 end_ARG start_ARG 2 end_ARG ) start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT - ( italic_x + italic_i 0 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) = 2 ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) ( over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), where The logarithm in Eq.\u00a0(9) can then be written in the form\nln\u2061k~t2\u2212k~+2k~t2+ln\u2061k~t2\u2212k~\u22122k~t2superscriptsubscript~\ud835\udc58\ud835\udc612superscriptsubscript~\ud835\udc582superscriptsubscript~\ud835\udc58\ud835\udc612superscriptsubscript~\ud835\udc58\ud835\udc612superscriptsubscript~\ud835\udc582superscriptsubscript~\ud835\udc58\ud835\udc612\\ln\\frac{\\tilde{k}_{t}^{2}-\\tilde{k}_{+}^{2}}{\\tilde{k}_{t}^{2}}+\\ln\\frac{%\n\\tilde{k}_{t}^{2}-\\tilde{k}_{-}^{2}}{\\tilde{k}_{t}^{2}}roman_ln divide start_ARG over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG + roman_ln divide start_ARG over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG.\nFrom \u222b\ud835\udc51k\u2062ln\u2061k=k\u2062ln\u2061k\u2212kdifferential-d\ud835\udc58\ud835\udc58\ud835\udc58\ud835\udc58\ud835\udc58\\int dk\\,\\ln k=k\\ln k-k\u222b italic_d italic_k roman_ln italic_k = italic_k roman_ln italic_k - italic_k one easily derives The integrand is singular at k~t=0subscript~\ud835\udc58\ud835\udc610\\tilde{k}_{t}=0over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0 and, for real k~\u00b1subscript~\ud835\udc58plus-or-minus\\tilde{k}_{\\pm}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT, at k~t=k~\u00b1subscript~\ud835\udc58\ud835\udc61subscript~\ud835\udc58plus-or-minus\\tilde{k}_{t}=\\tilde{k}_{\\pm}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT and k~t=\u2212k~\u00b1subscript~\ud835\udc58\ud835\udc61subscript~\ud835\udc58plus-or-minus\\tilde{k}_{t}=-\\tilde{k}_{\\pm}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = - over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT. However, the right hand side of Eq.\u00a0(94) is finite and continuous at k~t=k~\u00b1subscript~\ud835\udc58\ud835\udc61subscript~\ud835\udc58plus-or-minus\\tilde{k}_{t}=\\tilde{k}_{\\pm}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT and k~t=\u2212k~\u00b1subscript~\ud835\udc58\ud835\udc61subscript~\ud835\udc58plus-or-minus\\tilde{k}_{t}=-\\tilde{k}_{\\pm}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = - over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT \u00b1 end_POSTSUBSCRIPT. Hence, the k~tsubscript~\ud835\udc58\ud835\udc61\\tilde{k}_{t}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT integral needs to be split only at k~t=0subscript~\ud835\udc58\ud835\udc610\\tilde{k}_{t}=0over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0, and we obtain where in the last step we have used Im\u2062k~+>0Imsubscript~\ud835\udc580{\\rm Im}\\,\\tilde{k}_{+}>0roman_Im over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT + end_POSTSUBSCRIPT > 0 and Im\u2062k~\u2212<0Imsubscript~\ud835\udc580{\\rm Im}\\,\\tilde{k}_{-}<0roman_Im over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT - end_POSTSUBSCRIPT < 0 (the imaginary part can be finite or infinitesimal).\nSumming the contributions from k~+subscript~\ud835\udc58\\tilde{k}_{+}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and k~\u2212subscript~\ud835\udc58\\tilde{k}_{-}over~ start_ARG italic_k end_ARG start_POSTSUBSCRIPT - end_POSTSUBSCRIPT, and using the relation one obtains the result Eq.\u00a0(13) for I4\u2062(x)subscript\ud835\udc3c4\ud835\udc65I_{4}(x)italic_I start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( italic_x ). In Fig.\u00a08 we show graphs of the expansion coefficients Assubscript\ud835\udc34\ud835\udc60A_{s}italic_A start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT, Bssubscript\ud835\udc35\ud835\udc60B_{s}italic_B start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT, Cssubscript\ud835\udc36\ud835\udc60C_{s}italic_C start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT, and Dssubscript\ud835\udc37\ud835\udc60D_{s}italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT defined in Sec.\u00a0III as functions of \u03b1\ud835\udefc\\alphaitalic_\u03b1."
    },
    {
        "id": 16,
        "title": "Mathematical models of drug delivery \nvia a contact lens during wear",
        "corpus": "In this work we develop and investigate mathematical and computational models\nthat describe drug delivery from a contact lens during wear. Our models are\ndesigned to predict the dynamics of drug release from the contact lens and subsequent transport into the adjacent pre-lens tear film and post-lens tear film as well as into the ocular tissue (e.g.\u00a0cornea), into the eyelid, and out of these regions. These processes are modeled by one dimensional diffusion\nout of the lens coupled to compartment-type models for drug concentrations\nin the various accompanying regions. In addition to numerical solutions that\nare compared with experimental data on drug release in an in vitro eye model,\nwe also identify a large diffusion limit model for which analytical solutions\ncan be written down for all quantities of interest, such as cumulative release of the drug from the contact lens. We use our models to make assessments about possible mechanisms and drug transport pathways through the pre-lens and post-lens tear films and provide interpretation of experimental observations.\nWe discuss successes and limitations of our models as well as their potential to guide further research to help understand the dynamics of ophthalmic drug delivery via\ndrug-eluting contact lenses. Ophthalmic drugs are commonly delivered via eye drops. This approach has at least two significant limitations. First, the residence time of the drug in the eye is relatively short due\nto drainage out of the eye during a blink and the resupply of fresh tears.\nThus, eye drops must be\ngiven frequently for sustained drug delivery. Second,\nrelatively large doses of drug must be delivered in each eye drop, as much of the drug goes elsewhere in the body\n\u2013 up to 95% of the drug delivered to the eye via a drop is lost through the canaliculi, lacrymal sac, nasolacrymal duct and bloodstream\n[1, 2, 3] \u2013 reducing the efficacy of the treatment and leading to the possibility of drug side effects [4]. Combined with the difficulty of a patient administering the correct dosage to the eye, the bioavailability of drugs delivered by drops intended to reach the cornea, for example, is quite low. There are a number of alternative methods to deliver ophthalmic drugs to the eye, including drug/particle injections and implants into various\ncompartments of the eye [5].\nAnother option uses drug-eluting contact lenses.\nThe possibility of using contact lenses to deliver drugs to the eye is appealing for treatment of ocular diseases/conditions (e.g.\u00a0glaucoma, fungal keratitis,\nantibacterial considerations, and myopia) [6, 7, 2, 3, 8, 9, 10, 11, 12, 13].\nIndeed, much work has appeared in the medical literature on drug-eluting contact lenses and several reviews have been written (e.g.\u00a0[6, 7, 2, 3, 8]).\nThe close proximity of the contact lens to the eye allows for much better\nefficiency in terms of drug delivery to the cornea via a drug-soaked contact lens (predictions range from 20%\u201395%) [1].\nCarvalho et al. [3] point out the difficulty in control of diseases\nsuch as glaucoma, whose treatment requires a constant level of therapeutic drug in the eye, and the possible use of drug-infused contact lenses to supply a more predictable dose in a manageable way.\nUnderstandably, there has been significant efforts towards the development of drug-eluting contact lens technology\n([14, 15, 16, 17, 18, 19]),\nincluding \u2018smart\u2019 contact lenses [13, 20] and the use of 3D printing technologies [21, 22].\nDrug transport to other parts of the eye besides the cornea may also be desirable [9]. Although contact lens drug delivery\nhas been studied as a method of ophthalmic drug delivery since at least the 1970s [23], therapeutic options have only been proposed recently and remain limited [24]. The first drug-eluting contact lens to receive regulatory approval, for allergic eye itch, was authorized in Japan in 2021 and the United States in 2022; the latter approval came after at least 18 years of development [25]. Barriers to commercial implementation include lack of in vivo and even in vitro studies [21], and lack of a full understanding and control of drug delivery rates. These rates depend not only on the diffusion and transport mechanisms in the contact lens, but also, critically, on surrounding fluid dynamics in the tear film and related reservoirs that act as the conduit for the drug to reach a target tissue.\nSome situations, such as glaucoma treatment, call for slower rates where a drug can be released over the course of\none day to one month [2], while other situations, such as applications involving drugs used to dilate eyes, require shorter time scales [26].\nMolecular diffusion is the main release mechanism, but soft contact lenses are hydrogels [27, 28] and even the diffusion of water through a lens (in the absence of drugs)\nrequires a nonlinear diffusion model that accounts for swelling and the possibility of glass formation [29].\nFor contact lens drug delivery, the most common way to load the drug into the lens is to soak the lens in a solution, which is a diffusion up-take problem [30]. However, attempts to meet the broad range of\ndesired release rates of the drug have involved novel contact lens design and drug-infusing techniques [31, 3, 32],\nincluding inkjet printing of nanoparticles onto the contact lens [33].\nSpatially-dependent diffusion properties may also be introduced, for example with the use of a drug-polymer film coated by a HEMA hydrogel (e.g.\u00a0[6, 7]) as a possible means of slowing the drug-delivery release rate from the contact lens.\nUltimately, in order to assess the effectiveness of wearing a drug-eluting contact lens, one must also track the drug after it leaves the contact lens \u2013 into the pre- and post-lens tear films,\nout underneath the eyelids, and to the desired target. The influence of blinking and evaporation during daytime contact\nlens wear as well as the impact of the closed eye configuration and eye motion (e.g.\u00a0REM sleep) during night-time wear must also be assessed for a complete understanding of drug delivery via contact lenses. Theoretical approaches have modeled drug transport in hydrogels (e.g., [34, 35]); most are diffusion-based.\nMany studies have examined drug uptake and release in well-controlled settings such as vials\n(e.g.\u00a0[30, 36, 37, 38, 39, 40]).\nRecently, Pereira-da-Mota et al. [41] (but see also [14]) reported data on ex vivo and in vivo (rabbit) drug-release from contact lenses.\nNavarro-Gil et al. [42] also studied in vivo drug release from contact lenses in rabbits over 2 hours of wear.\nAnother recent study reports drug-delivery via contact lens in an in vitro, 3D printed, realistic eye model that include effects such as blinking [21] during the\ndrug release process. This study was notable in that it reported a significant\nand measurable changes in the rate of drug loss from the lens in the vial setting versus when it was \u2018worn\u2019 in the in vitro eye model. Models have been examined for contact lens drug delivery [1] and transport across a layer separating a drug supply from a sink\n[9] that implement similar approaches.\nPrausnitz et al. [9] studied transient diffusion across the sclera (a pathway to the retina) by employing one dimensional diffusive transport across the sclera separating a donor compartment with a finite amount of a drug and a receiver compartment. The donor and receiver drug concentrations were modeled with ordinary differential equations and coupled by diffusion across the sclera. Models focusing on other regions of the eye (e.g.\u00a0anterior chamber) have also been examined [43].\nLi & Chauhan [1] studied contact lens drug delivery and predicted the fractions of\ndrug delivered to the pre-lens, post-lens, and cornea. Drug transport in the contact lens\nwas treated by one-dimensional diffusion across the lens. The post-lens tear film was modeled as a squeeze layer with an upper boundary (the contact lens) that moves laterally (superior/inferior) and orthogonally (anterior/posterior) to the eye during a blink. They did not resolve pre-lens tear film dynamics but rather modeled the drug loss out of the contact lens\non the pre-lens side using two limiting boundary conditions. Based on the assumption that the pre-lens tear film breaks up rapidly due to evaporation, the first assumed that no drug reached the pre-lens tear film, thus preventing drug transport into the pre-lens film\n(i.e.\u00a0no flux boundary condition). The second boundary condition assumed the drug concentration in the pre-lens tear film was zero.\nThe second represents the limit in which drug diffuses from the contact lens into the pre-lens film but is quickly and completely removed by mixing and drainage. To the best of our knowledge, there is little experimental evidence of the action of the upper eyelid on the tear film during a blink, but many studies have modeled its effect in various ways. Doane [44] took high-speed images of the human tear film to measure upper and lower lid dynamics, including blink time, velocity, and lid positioning. More recent imaging studies include Wu et al. [45] and Awisi-Gyau et al. [46]. Modeling examples include Anderson et al. [47] and Zubkov et al. [48], which both include Couette flow of the tear film. The latter specifically assumes that tear film fluid is supplied from under the eyelid by this flow. The model in Braun et al. [49] assumes a rectangular eyelid that moves across the tear film domain while maintaining a constant distance from the cornea. This model in particular, in contrast to ours, allows for the tear film height to vary spatially across the cornea as a result of the eyelid motion. Recently, Ramasubramanian et al. [50] created a finite element method 3D model of the \u201clid wiper\u201d, the part of the eyelid that comes in contact with the tear film, and looked at the stresses imposed on the cornea and eyelid as a result of a blink. Some models (see, e.g., [51]) incorporate the draining of fluid as part of the blink cycle. Braun et al. [49] note the difficulty in understanding tear film dynamics surrounding a blink due to imaging challenges and that further experimental evidence is needed. Drug absorption into the eyelid is also possible.\nFarkouh et al. [52] confirm this and discuss potential absorption pathways of the drug from the tear film, and include the eyelids as a minor route contributing to systemic absorption, which overall comprises more than half of the dose. See et al. [53] note that the thinner the skin layer, the greater the drug permeability and, at less than 1 mm, the eyelid is the thinnest skin layer on the human body. The authors found the permeability of the eyelid in rats to be on the order of (10\u22129\u221210\u22127)superscript109superscript107(10^{-9}-10^{-7})( 10 start_POSTSUPERSCRIPT - 9 end_POSTSUPERSCRIPT - 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT ) m/s for several drugs.\nFor the experimental setting used by Phan et al.\u00a0[21], which we examine in detail below,\nthey also report absorption into the eyelid.\nTo the best of our knowledge, no mathematical models of contact lens drug delivery have been designed specifically to include eyelid absorption; in fact, some (i.e., [54]) explicitly assume zero absorption of drug by the eyelid.\nA WHO report by Kielhorn et al. [55] on dermal absorption includes a section on mathematical models; one such model treats the skin as a single pseudo-homogeneous membrane and models absorption via Fick\u2019s first law. Models such as Kr\u00fcse et al. [56] describe the absorption equilibrium by partition and diffusion coefficients in the cornea and tear film. Selzer et al. [57] review different types of mathematical models for adsorption, including pharmacokinetic ordinary differential equations (ODEs), quantitative structure-activity relationship (QSAR) models, and diffusion and partitioning. They include models that allow for concentration variation by skin depth. The authors note that the ODE models often do not fit experimental data as well as diffusion models with spatial heterogeneity, but the latter data is not always available. In the present work, to join theoretical and experimental information, we extend a mathematical model of contact lens drug delivery by [58] to align with the experimental in vitro model eye system designed by Phan et al.\u00a0[21]. The model couples a partial differential equation for diffusion of drug inside the contact lens with ordinary differential equations governing the dynamics of the pre- and post-lens tear films and also the eyelid.\nThe model simulates tear film dynamics during blinking over a 24 hour period. We compute the total drug lost from the contact lens and compare our results to experimental data from Phan et al.\u00a0[21]. By isolating certain mechanisms or combinations of mechanisms in our models, we attempt to better understand the mechanics and dynamics of contact lens drug delivery. Our paper is organized as follows. In section 2 we describe the basic eye model configuration of interest along with key concepts and variables. In Section 3 we briefly visit the vial model configuration to identify diffusion and partition coefficients for the two different lens types examined in the Phan et al.\u00a0[21] study.\nIn Section 4 we outline the various components of our eye model and present its nondimensionalized version and some related quantities in Section 5. Section 6 presents details of a simplified model based on a large diffusion limit in which relatively simple analytical formulas can be obtained for key quantities of interest. In Section 7 we give the main results of our eye model in comparison to the Phan et al.\u00a0[21] data. Section 8 includes further discussion and avenues for additional research. Section 9 contains our conclusions. We use data from a study conducted by Phan et al. [21]. Those authors designed a 3D-printed model eye system with blinking action to measure the cumulative release of \u201cdrug\u201d (mimicked by a water-soluble red dye) from two types of contact lenses: a conventional hydrogel (etafilcon A) and a silicone hydrogel (senofilcon A). The contact lens is situated in an upright position to mimic in vivo wear, and an upper eyelid \u201cblinks\u201d every 10 seconds. Tubing delivers fluid to the eye from under the upper eyelid during a blink. The system is mounted on a collection plate so that the amount of dye released can be measured. The model eye and collection unit are printed from hydrophobic material, but the eyelid is not. See the authors\u2019 Figure 1 for a schematic [21] and our Figures 1 and 2 for example video stills. We will compare the predictions of our models with the cumulative drug release data reported by Phan et al. [21] in their Figure 3. Some aspects of our models are not directly applicable for the Phan et al. data, such as drug permeability into the cornea, but are included into our models as our longer-term goals include prediction of drug delivery to tissues such as the cornea. As much as possible, our models use parameters taken directly from Phan et al. [21].\nThe authors state that each contact lens was soaked in red dye (1.00481.00481.00481.0048 mg / \u03bc\ud835\udf07\\muitalic_\u03bcL) for 24 hours. They report an initial amount of drug in the\ncontact lens as 22.4\u00b12.0plus-or-minus22.42.022.4\\pm 2.022.4 \u00b1 2.0 mg (etafilcon A) and 47.8\u00b12.7plus-or-minus47.82.747.8\\pm 2.747.8 \u00b1 2.7 mg (senofilcon A).111We believe Phan et al. listed these values reversed with respect to the lens type \u2013 see their Figures 3 and 4 and text on the same page. That is, etafilcon A seems to release close to 100% of its dye in Figure 4 and reaches a maximum released value of around 22 mg in Figure 3 and so it seems corresponds to an initial amount of drug of 22.422.422.422.4 mg. We find corresponding contact lens volumes for each lens using Vcl=Acl\u2062hclsubscript\ud835\udc49clsubscript\ud835\udc34clsubscript\u210eclV_{\\rm cl}=A_{\\rm cl}h_{\\rm cl}italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT = italic_A start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT where Vclsubscript\ud835\udc49clV_{\\rm cl}italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT is contact lens volume, Aclsubscript\ud835\udc34clA_{\\rm cl}italic_A start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT is contact lens area, and hclsubscript\u210eclh_{\\rm cl}italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT is contact lens thickness, given in Table\u00a01. As a basis for comparison for their eye model results, Phan et al. first examined drug release from the contact lens submerged in a large fluid volume in a vial\nconfiguration.\nThe volume of fluid in the vial was reported to be Vvial=2subscript\ud835\udc49vial2V_{\\rm vial}=2italic_V start_POSTSUBSCRIPT roman_vial end_POSTSUBSCRIPT = 2 mL. Assuming spatial uniformity, the initial drug concentration in the lens is computed as Cinit=Minit/Vclsuperscript\ud835\udc36initsuperscript\ud835\udc40initsubscript\ud835\udc49clC^{\\rm init}=M^{\\rm init}/V_{\\rm cl}italic_C start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT = italic_M start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT / italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT\nand is reported in Table\u00a01 for each lens.\nWe assume that these concentrations have reached equilibrium, and thus predict the partition coefficient as\nK=Cinit/Cvialload\ud835\udc3esuperscript\ud835\udc36initsubscriptsuperscript\ud835\udc36loadvialK=C^{\\rm init}/C^{\\rm load}_{\\rm vial}italic_K = italic_C start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT / italic_C start_POSTSUPERSCRIPT roman_load end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_vial end_POSTSUBSCRIPT, which is\nreported in Table\u00a01 for each lens\n(see also Liu et al. [59], equation 2). Table 2 reports the cumulative drug release data extracted from Phan et al.\u2019s Figure 3. Values listed here are obtained via Matlab\u2019s image analysis software grabit.m (MathWorks, Natick, MA, USA).\nThe time values are those reported by Phan et al.; our approximate time values extracted from their figure were within 1111% of these\nreported values. Their reported final time values are listed in parenthesis; our approximate values are well within their reported error bars. Table 3 shows the drug release values recorded by Phan et al. [21] as well as the calculated eyelid absorption values using their percentages.\nThe authors state that 31.2 % and 17.5 % of released drug are absorbed by the eyelid for the etafilcon A and senofilcon A lenses. We estimate the model eye diameter and eyelid area via simple image analysis as shown in Figures 1 and 2. Repeating the procedure three times, the average eye diameter estimate is 21.3 mm and the eyelid area estimate is 290 mm22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT; estimates for the size of the eyeball in the transverse diameter are 21\u201327 mm [60]. Phan et al. [21] use their tear flow rate of 5 \u03bc\ud835\udf07\\muitalic_\u03bcL/min (0.083 \u03bc\ud835\udf07\\muitalic_\u03bcL/s) and blink rate of 1 blink/10 s to find that \u201capproximately 0.83 \u03bc\ud835\udf07\\muitalic_\u03bcL of tear fluid that is spread on top of the contact lens with each blink.\u201d If we assume that the volume of tear fluid (0.83 \u03bc\ud835\udf07\\muitalic_\u03bcL) is evenly spread only over the contact lens area (see Table 1), we can compute the pre-lens thickness at the start of an interblink as hpre\u2062(tblink+)=Vpre/Acl=5.39\u2062\u03bc\u2062m.subscript\u210epresuperscriptsubscript\ud835\udc61blinksubscript\ud835\udc49presubscript\ud835\udc34cl5.39\ud835\udf07mh_{\\rm pre}(t_{\\rm blink}^{+})=V_{\\rm pre}/A_{\\rm cl}=5.39\\ \\mu\\text{m}.italic_h start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) = italic_V start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT / italic_A start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT = 5.39 italic_\u03bc m .\nRealistically, the fluid spreads over more than just the contact lens. The contact lens area and the surface area of the front of the eyeball provide reasonable lower and upper bounds for the area over which the tear fluid spreads. Using our estimated eyeball diameter\nto find half the surface area of the eye sphere, 2\u2062\u03c0\u2062Reye22\ud835\udf0bsuperscriptsubscript\ud835\udc45eye22\\pi R_{\\rm eye}^{2}2 italic_\u03c0 italic_R start_POSTSUBSCRIPT roman_eye end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, the same calculation yields hpre\u2062(tblink+)=1.16\u2062\u03bcsubscript\u210epresuperscriptsubscript\ud835\udc61blink1.16\ud835\udf07h_{\\rm pre}(t_{\\rm blink}^{+})=1.16\\ \\muitalic_h start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) = 1.16 italic_\u03bcm. This may provide a realistic range of initial pre-lens tear film thicknesses of 1.16 \u2013 5.39 \u03bc\ud835\udf07\\muitalic_\u03bcm. While estimates for human tear flow rates are smaller than that used by Phan and coauthors [61], the calculated tear film thickness fall within or near experimental ranges\n[62]. In the vial release configuration, we assume that the contact lens is contained in fluid of constant volume Vvialsubscript\ud835\udc49vialV_{\\rm vial}italic_V start_POSTSUBSCRIPT roman_vial end_POSTSUBSCRIPT.\nWe assume that the transport of drug concentration C\u2062(z,t)\ud835\udc36\ud835\udc67\ud835\udc61C(z,t)italic_C ( italic_z , italic_t ) within the contact lens is dominated by diffusion across the lens (anterior/posterior) where D\ud835\udc37Ditalic_D is the diffusion coefficient.\nThis equation applies on 0<z<hcl0\ud835\udc67subscript\u210ecl0<z<h_{\\rm cl}0 < italic_z < italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT, where hclsubscript\u210eclh_{\\rm cl}italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT is a constant thickness of the contact lens, and is subject to boundary conditions where Cvial\u2062(t)subscript\ud835\udc36vial\ud835\udc61C_{\\rm vial}(t)italic_C start_POSTSUBSCRIPT roman_vial end_POSTSUBSCRIPT ( italic_t ) is the drug concentrations in the vial, and K\ud835\udc3eKitalic_K is the partition coefficient. The drug in the vial is assumed to be well-mixed\nso that the concentration Cvial\u2062(t)subscript\ud835\udc36vial\ud835\udc61C_{\\rm vial}(t)italic_C start_POSTSUBSCRIPT roman_vial end_POSTSUBSCRIPT ( italic_t ) is uniform in space and the same on both sides of the lens.\nAn initial condition corresponding to a drug-soaked contact lens is given by C\u2062(z,t=0)=Cinit\u2062(z)\ud835\udc36\ud835\udc67\ud835\udc610superscript\ud835\udc36init\ud835\udc67C(z,t=0)=C^{\\rm init}(z)italic_C ( italic_z , italic_t = 0 ) = italic_C start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT ( italic_z ). Estimates for the size of the diffusion coefficient can be obtained from recent work by Liu et al. [27], who have characterized the diffusive processes that can occur for macromolecules in hydrogels, such as those used in contact lens manufacture. We can also estimate it here using data reported by Phan et al. [21]. We assume the diffusion coefficient is constant but note that a spatially-dependent diffusion coefficient may also be of clinical interest, as would be the case for the drug-polymer film coated by a HEMA hydrogel [6, 7] investigated as a possible means to reduce the contact lens drug-delivery release rate. The flux of drug out of the contact lens is driven by concentration\ngradients in the lens. We assume the\nfluid in the vial remains well-mixed and that the mass flux out of either\nside of the lens (the \u2018pre-lens\u2019 and \u2018post-lens\u2019 sides) contributes to a\nuniformly mixed vial fluid volume. It follows that Below we will discuss solutions to this model and identify values for parameters such as the diffusion coefficient D\ud835\udc37Ditalic_D and partition coefficient K\ud835\udc3eKitalic_K.\nIn related studies (e.g.\u00a0[30, 58, 39]) a common assumption is that Vvialsubscript\ud835\udc49vialV_{\\rm vial}italic_V start_POSTSUBSCRIPT roman_vial end_POSTSUBSCRIPT is sufficiently large in comparison to the contact lens volume Vclsubscript\ud835\udc49clV_{\\rm cl}italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT so that Cvial\u22480subscript\ud835\udc36vial0C_{\\rm vial}\\approx 0italic_C start_POSTSUBSCRIPT roman_vial end_POSTSUBSCRIPT \u2248 0 (also called \u2018perfect sink conditions\u2019) and the drug diffusion problem is independent of the\npartition coefficient, K\ud835\udc3eKitalic_K.\nThis leaves the diffusion coefficient D\ud835\udc37Ditalic_D and geometric properties such as thickness hclsubscript\u210eclh_{\\rm cl}italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT and surface area Aclsubscript\ud835\udc34clA_{\\rm cl}italic_A start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT\nalong with initial drug mass Minitsuperscript\ud835\udc40initM^{\\rm init}italic_M start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT as the key parameters. We compute sample solutions with representative parameters. In Figure 3 we show the contact lens concentration at different times throughout the experiment. Note that the etafilcon lens has lost essentially all of its drug concentration by the final time (24 hours). Of interest is the amount of drug lost from the contact lens over time. We keep track of the mass of drug in the contact lens at time t\ud835\udc61titalic_t, given by From this we determine the cumulative mass of drug lost at a given time t\ud835\udc61titalic_t: In the vial setting we can set up straightforward optimizations over the few model parameters not determined from the experimental settings of Phan et al. [21]. Expressed in continuous variables, we seek to minimize \u2016Mlost\u2062(t)\u2212Mexplost\u2062(t)\u201622superscriptsubscriptnormsuperscript\ud835\udc40lost\ud835\udc61subscriptsuperscript\ud835\udc40lostexp\ud835\udc6122||M^{\\rm lost}(t)-M^{\\rm lost}_{\\rm exp}(t)||_{2}^{2}| | italic_M start_POSTSUPERSCRIPT roman_lost end_POSTSUPERSCRIPT ( italic_t ) - italic_M start_POSTSUPERSCRIPT roman_lost end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_exp end_POSTSUBSCRIPT ( italic_t ) | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT over the diffusion coefficient, D\ud835\udc37Ditalic_D. Here, Mexplostsubscriptsuperscript\ud835\udc40lostexpM^{\\rm lost}_{\\rm exp}italic_M start_POSTSUPERSCRIPT roman_lost end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_exp end_POSTSUBSCRIPT denotes the drug mass lost from the contact lens reported by Phan et al. [21]. The variable t\ud835\udc61titalic_t corresponds to the time after insertion of the contact lens into the model eye system. We use the partition coefficient K\ud835\udc3eKitalic_K found from the equilibrium balance above.\nThe norm is over all t\u2208[0,T]\ud835\udc610\ud835\udc47t\\in[0,T]italic_t \u2208 [ 0 , italic_T ], where T\ud835\udc47Titalic_T corresponds to the total length of the experiment (24 hours). The optimization problem may be written Both derivative-free and steepest descent-based algorithms are used to test consistency of the solution. These are implemented in MATLAB via fminsearch and lsqnonlin. Default step-size and objective function value tolerances are set. In another case, we\nlet K\ud835\udc3eKitalic_K vary as a second optimization parameter. We also conduct the optimization by setting the partition coefficient equal to zero, which corresponds to a max flux (perfect\nsink) situation, to test for an effect on the optimal diffusion coefficient D\ud835\udc37Ditalic_D. We fit drug lost from the contact lens computed from our model to the experimental drug lost recorded by Phan et al. [21]. The optimal values are Deta=2.25\u00d710\u221213subscript\ud835\udc37eta2.25superscript1013D_{\\rm eta}=2.25\\times 10^{-13}italic_D start_POSTSUBSCRIPT roman_eta end_POSTSUBSCRIPT = 2.25 \u00d7 10 start_POSTSUPERSCRIPT - 13 end_POSTSUPERSCRIPT m/2s{}^{2}/sstart_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT / italic_s and Dseno=7.47\u00d710\u221215subscript\ud835\udc37seno7.47superscript1015D_{\\rm seno}=7.47\\times 10^{-15}italic_D start_POSTSUBSCRIPT roman_seno end_POSTSUBSCRIPT = 7.47 \u00d7 10 start_POSTSUPERSCRIPT - 15 end_POSTSUPERSCRIPT m/2s{}^{2}/sstart_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT / italic_s.\nThe optimization converged numerically by meeting the step-size and objective function tolerances for both the etafilcon A and senofilcon A lenses. The optimal values from the two algorithms implemented are consistent. We also optimize over both the diffusion coefficient D\ud835\udc37Ditalic_D and partition coefficient K\ud835\udc3eKitalic_K. The optimal values are Deta=2.24\u00d710\u221213subscript\ud835\udc37eta2.24superscript1013D_{\\rm eta}=2.24\\times 10^{-13}italic_D start_POSTSUBSCRIPT roman_eta end_POSTSUBSCRIPT = 2.24 \u00d7 10 start_POSTSUPERSCRIPT - 13 end_POSTSUPERSCRIPT m/2s{}^{2}/sstart_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT / italic_s, Keta=2.07subscript\ud835\udc3eeta2.07K_{\\rm eta}=2.07italic_K start_POSTSUBSCRIPT roman_eta end_POSTSUBSCRIPT = 2.07, Dseno=7.50\u00d710\u221215subscript\ud835\udc37seno7.50superscript1015D_{\\rm seno}=7.50\\times 10^{-15}italic_D start_POSTSUBSCRIPT roman_seno end_POSTSUBSCRIPT = 7.50 \u00d7 10 start_POSTSUPERSCRIPT - 15 end_POSTSUPERSCRIPT m/2s{}^{2}/sstart_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT / italic_s, and Kseno=4.31subscript\ud835\udc3eseno4.31K_{\\rm seno}=4.31italic_K start_POSTSUBSCRIPT roman_seno end_POSTSUBSCRIPT = 4.31. Both optimal diffusion coefficients agree with the values from the single-variable optimization to within 0.5%. The etafilcon A partition coefficient agrees extremely well with the equilibrium balance-calculated value from above, while the senofilcon A value is about 18% larger. However, by varying the initial parameter guesses for the optimization, the fit seems highly insensitive to changes in K\ud835\udc3eKitalic_K. In fact, by setting K=0\ud835\udc3e0K=0italic_K = 0, which corresponds to a max flux (perfect sink) situation, we achieve identical-looking solutions. This is likely due to the product K\u2062Cvial\ud835\udc3esubscript\ud835\udc36vialKC_{\\rm vial}italic_K italic_C start_POSTSUBSCRIPT roman_vial end_POSTSUBSCRIPT being quite small and as\nthis only influences the concentration at the lens/fluid boundaries, it may have\na relatively small influence on the diffusive flux out of\nthe lens. A notable observation from the Phan et al. experiments (e.g.\u00a0see Figure\u00a04) is that the etafilcon A lens loses essentially all of its drug mass in 24 hours whereas\nthe senofilcon A retains a large amount of the initial drug. This is supported by our finding that the two optimized diffusion coefficients are of different orders of magnitude, and the significantly smaller value corresponds to the senofilcon A lens. It seems that diffusion within the contact lens is the rate-limiting mechanism in the vial setting. In contrast, in the Phan et al.\u00a0in vitro experiments, both lenses retain a significant\nportion of the original amount of drug in the lens. This must seemingly be explained by some limiting rate associated with the post-lens and/or pre-lens film. That is, there appears to be some other rate-limiting mechanism(s), in addition to or instead of diffusion in the contact lens,\nin the in vitro eye model. We investigate several possible mechanisms\nin the framework of the eye model outlined in the next section. In the eye model, the drug-soaked contact lens is present during normal lens wear. In this configuration, a pre-lens tear film\n(between the lens and the air) and a post-lens tear film (between the lens and the cornea) surround the contact lens. The fluid volumes of the pre- and post-lens films are both several orders of magnitude smaller than a typical vial volume. The drug transport problem is also complicated by blinking. As described in more detail below, we assume that when the eyelid moves the contact lens may also move,\nand that between blinks (the interblink) when the eyelid is assumed stationary, the contact lens is also stationary.\nEyelid motion and contact lens motion both can generate further, non-diffusive, transport of the drug. Our model outlined in this section\nattempts to describe the transport of drug from the contact lens into the pre- and post-lens films and further transport either lost during blinking or absorbed into surrounding tissue such as the cornea and/or eyelid. The following model takes the form of a compartment-type model coupled to a diffusion problem in the contact lens. We assume that the\ncontact lens concentration is a function of space and time as in the vial setting, but that the pre- and post-lens thicknesses and drug concentrations are functions of time only. In Fig. 5 we represent all the mechanisms/processes occurring during the interblink and during a blink. Vertical arrows indicate processes with z\ud835\udc67zitalic_z-direction relevance, either across a compartment boundary or within the contact lens. Horizontal arrows represent rates in or out of a compartment and have no meaningful left-to-right directionality. Motivated by the experimental data from [21], we assume that the upper eyelid partially covers the region of interest affecting the contact lens during the interblink and completely covers the region of interest during a blink. Phan et al. [21] note that \u201ctear fluid first pools underneath the eyelid and is only delivered to the eyeball by the blink.\u201d This suggests that there is no flow in/out of the pre-lens during the interblink, and that no drug is swept out during the interblink. One possible assumption is that the blink sweeps all drug out of the pre-lens, as fresh fluid is delivered with the blink, pushing out the drug-filled fluid. As a more general assumption, outlined in more detail below, we allow for partial loss of drug mass in the pre-lens as a consequence of a blink. Drug transport in the contact lens is governed by the same equation as in\nthe vial configuration for 0<z<hcl0\ud835\udc67subscript\u210ecl0<z<h_{\\rm cl}0 < italic_z < italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT. The boundary conditions take a similar form where now Cpost\u2062(t)subscript\ud835\udc36post\ud835\udc61C_{\\rm post}(t)italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT ( italic_t ) and Cpre\u2062(t)subscript\ud835\udc36pre\ud835\udc61C_{\\rm pre}(t)italic_C start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT ( italic_t ) are the drug concentrations in the post-lens tear film and pre-lens tear film whose values are determined by the models described below.\nAn alternate boundary condition on the pre-lens side that we consider in some cases\nis a no-flux boundary condition, \u2202C/\u2202z\u2062(z=hcl)=0\ud835\udc36\ud835\udc67\ud835\udc67subscript\u210ecl0\\partial C/\\partial z(z=h_{\\rm cl})=0\u2202 italic_C / \u2202 italic_z ( italic_z = italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT ) = 0.\nSimilar boundary conditions have been considered by Li & Chauhan [1].\nThe initial condition is C\u2062(z,t=0)=Cinit\u2062(z)\ud835\udc36\ud835\udc67\ud835\udc610superscript\ud835\udc36init\ud835\udc67C(z,t=0)=C^{\\rm init}(z)italic_C ( italic_z , italic_t = 0 ) = italic_C start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT ( italic_z ). The mechanisms of eyelid absorption in a blinking tear film system are not well understood, and minimal experimental evidence exists to support theories. Phan et al. [21] refer to the phenomenon as \u201cnonspecific absorption\u201d and report uptake of approximately 25 % of released drug by the upper eyelid, therefore warranting modeling attention. To this end, we postulate a reasonable model for upper eyelid absorption of drug that is motivated by their experimental videos [21]. We assume that some fraction of the eyelid remains in contact with the tear film just above the lens, and that absorption occurs during the interblink.\nFurther, we model the upper eyelid as a sink due to its large volume relative to that of the pre-lens. The concentration of drug in the upper eyelid is governed by The corresponding term in the equation for pre-lens drug enforces conservation of mass. The pre-lens thickness hpresubscript\u210epreh_{\\rm pre}italic_h start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT evolves during the interblink according to where JEsubscript\ud835\udc3d\ud835\udc38J_{E}italic_J start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a fluid volume loss per unit time due to evaporation of the pre-lens tear film. The pre-lens drug concentration is governed during the interblink by This equation represents diffusive mass transport from the contact lens and absorption of drug in the eyelid. The post-lens tear film thickness, hpostsubscript\u210eposth_{\\rm post}italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT, evolves during the interblink according to Here, Qinsubscript\ud835\udc44inQ_{\\rm in}italic_Q start_POSTSUBSCRIPT roman_in end_POSTSUBSCRIPT and Qoutsubscript\ud835\udc44outQ_{\\rm out}italic_Q start_POSTSUBSCRIPT roman_out end_POSTSUBSCRIPT are non-negative flux terms describing fluid that may enter or leave the post-lens film during the interblink.\nThe quantity Josmoticsubscript\ud835\udc3dosmoticJ_{\\rm osmotic}italic_J start_POSTSUBSCRIPT roman_osmotic end_POSTSUBSCRIPT represents an osmotic flow that may be present from the cornea into the post-lens tear film. The post-lens drug concentration is governed during the interblink by This equation represents diffusive mass transport from the contact lens, absorption of drug into the cornea, and advective transport of drug mass out of the lens. We assume that there is no advective transport of drug mass into the post-lens during the interblink associated with Qinsubscript\ud835\udc44inQ_{\\rm in}italic_Q start_POSTSUBSCRIPT roman_in end_POSTSUBSCRIPT. When we compare with the Phan et al. [21]\nexperimental data we\nnote that their \u201ccornea\u201d is made out of hydrophobic material and hence\nkc=0subscript\ud835\udc58\ud835\udc500k_{c}=0italic_k start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 0. In those comparisons we also assume that\nQin=0subscript\ud835\udc44in0Q_{\\rm in}=0italic_Q start_POSTSUBSCRIPT roman_in end_POSTSUBSCRIPT = 0, Qout=0subscript\ud835\udc44out0Q_{\\rm out}=0italic_Q start_POSTSUBSCRIPT roman_out end_POSTSUBSCRIPT = 0, and Josmotic=0subscript\ud835\udc3dosmotic0J_{\\rm osmotic}=0italic_J start_POSTSUBSCRIPT roman_osmotic end_POSTSUBSCRIPT = 0, so that the post-lens thickness remains constant during an interblink. In general, a blink is modeled by stopping the evolution defined by equations\u00a0(7), (10), (11), (12),\nand (13) at time t=tblink\ud835\udc61subscript\ud835\udc61blinkt=t_{\\rm blink}italic_t = italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT, and restarting them with new initial conditions where tblink\u2212superscriptsubscript\ud835\udc61blinkt_{\\rm blink}^{-}italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT and tblink+superscriptsubscript\ud835\udc61blinkt_{\\rm blink}^{+}italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT indicate the times just before and just after a blink.\nThe interpretations, respectively, are the concentration in the lens is assumed to be the same immediately before and after a blink, the blink washes out a certain proportion of the drug from the pre-lens where p\u2208[0,1]\ud835\udc5d01p\\in[0,1]italic_p \u2208 [ 0 , 1 ]. For\nexample, p=0\ud835\udc5d0p=0italic_p = 0 means no pre-lens drug mass is lost during a blink (the pre-lens concentration resets to its pre-blink value) and p=1\ud835\udc5d1p=1italic_p = 1 means that all pre-lens drug mass is lost as the result of a blink (the pre-lens concentration resets to zero), the pre-lens thickness resets to the initial value after a blink, the concentration in the post-lens after the blink is the determined by motion of the contact lens for either squeezing out or sliding out mechanisms (outlined in more detail below), the post-lens thickness resets to its initial value after a blink, and the concentration in the upper eyelid is assumed to be the same immediately before and after a blink. The cases for Cpost\u2062(tblink+)subscript\ud835\udc36postsuperscriptsubscript\ud835\udc61blinkC_{\\rm post}(t_{\\rm blink}^{+})italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) warrant further explanation. In general, the eyelid motion that occurs during a blink generates forces that\ncan result in motion of the contact lens in the posterior/anterior directions (in and out), superior/inferior directions (up and down), and lateral/medial directions (side to side) (e.g.\u00a0see Gilman [63] and Hayashi [64]). Lateral/medial motion is\nexpected to be small and is neglected in our study. Posterior/anterior motion is typically characterized by some type of lubrication/squeeze flow type model (e.g.\u00a0Chauhan & Radke [65] and Maki & Ross [66, 67]). Other work has explored sliding-type motion described by\nCouette flow (e.g.\u00a0Chauhan & Radke [68] and Anderson et al. [47]) or combined squeezing\u2013sliding effects (e.g.\u00a0Creech et al. [69], Li & Chauhan [1], and Dunn et al. [70]).\nAlthough posterior/anterior and superior/inferior motions of the contact lens can occur simultaneously\nduring blinking and can be included together in\nfluid dynamics models as in earlier studies noted above, we choose to examine these two types of motion independently. This treatment will allow us to examine how each of these types of motion may or may not play a role in the experimental observations of drug release in the\neye model of Phan et al. [21].\nTherefore, we outline below the reset conditions for our model that include posterior/anterior motion (squeeze out of drug) and superior/inferior motion (slide out of drug). In the case of squeeze out of drug, we assume\nthat the blink generates posterior/anterior contact lens\nmotion (normal to the ocular surface with no tangential motion of the lens along the ocular surface) such that\nthe post-lens depresses and then returns to its original thickness by the end of the blink duration. Our assumption that all of the contact lens motion occurs during the blink \u2013 the downward depression as well as the upward relaxation \u2013 is a model convenience that allows us to assign drug mass\nlost from the post-lens tear film as a result of a blink directly as a blink/reset condition.\nWe note that more sophisticated models of post-lens tear film suggest that the relaxation stage may actually occur over the entire interblink period (e.g.\u00a0see Figures 2, 4, and 6 of Maki & Ross [67]).\nWe use a classical squeeze film theory result in radial coordinates to find the depressed post-lens thickness value in order to compute the mass of drug lost.\nThe dynamics of squeezing the film are modeled by where Rclsubscript\ud835\udc45clR_{\\rm cl}italic_R start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT is the radius of the contact lens, F\ud835\udc39Fitalic_F is the force applied (F>0\ud835\udc390F>0italic_F > 0 for a downward force that generates d\u2062hpostsqueeze/d\u2062t<0\ud835\udc51superscriptsubscript\u210epostsqueeze\ud835\udc51\ud835\udc610dh_{\\rm post}^{\\rm squeeze}/dt<0italic_d italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_squeeze end_POSTSUPERSCRIPT / italic_d italic_t < 0), and \u03bc\ud835\udf07\\muitalic_\u03bc is the viscosity of the fluid.\nRearranging, integrating, and applying hpostsqueeze\u2062(t=0)=hpostinitsuperscriptsubscript\u210epostsqueeze\ud835\udc610superscriptsubscript\u210epostinith_{\\rm post}^{\\rm squeeze}(t=0)=h_{\\rm post}^{\\rm init}italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_squeeze end_POSTSUPERSCRIPT ( italic_t = 0 ) = italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT gives This gives a formula for the depressed post-lens thickness as a function of its pre-blink thickness, the time duration associated with the blink, \u0394\u2062tblink\u0394subscript\ud835\udc61blink\\Delta t_{\\rm blink}roman_\u0394 italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT, and the blink force F>0\ud835\udc390F>0italic_F > 0. Note that hpostsqueeze\u2062(\u0394\u2062tblink)<hpostinitsuperscriptsubscript\u210epostsqueeze\u0394subscript\ud835\udc61blinksuperscriptsubscript\u210epostinith_{\\rm post}^{\\rm squeeze}(\\Delta t_{\\rm blink})<h_{\\rm post}^{\\rm init}italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_squeeze end_POSTSUPERSCRIPT ( roman_\u0394 italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT ) < italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT when\n\u0394\u2062tblink>0\u0394subscript\ud835\udc61blink0\\Delta t_{\\rm blink}>0roman_\u0394 italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT > 0. We can either use the blink force F\ud835\udc39Fitalic_F as a parameter or consider a depression amount \u0394\u2062hpost=hpostinit\u2212hpostsqueeze\u2062(\u0394\u2062tblink)\u0394subscript\u210epostsuperscriptsubscript\u210epostinitsuperscriptsubscript\u210epostsqueeze\u0394subscript\ud835\udc61blink\\Delta h_{\\rm post}=h_{\\rm post}^{\\rm init}-h_{\\rm post}^{\\rm squeeze}(\\Delta t%\n_{\\rm blink})roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT = italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT - italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_squeeze end_POSTSUPERSCRIPT ( roman_\u0394 italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT ), and then express the required force F\ud835\udc39Fitalic_F via The mass of drug lost from the post-lens as a result of this squeeze out process can be found via For a schematic see Figure\u00a06.\nTo compute the concentration at the end of a blink that results from the squeeze out of drug, we determine Cpost\u2062(tblink+)=Cpostsqueezesubscript\ud835\udc36postsuperscriptsubscript\ud835\udc61blinksuperscriptsubscript\ud835\udc36postsqueezeC_{\\rm post}(t_{\\rm blink}^{+})=C_{\\rm post}^{\\rm squeeze}italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) = italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_squeeze end_POSTSUPERSCRIPT via From the video from\nPhan et al.\u00a0[21], it is evident that there is (superior/inferior) sliding motion of the contact lens as the result of a blink (it is difficult to confirm or rule out the squeeze out mechanism from the video). The geometry under consideration is approximated to be a circular disk (the contact lens) of radius Rclsubscript\ud835\udc45clR_{\\rm cl}italic_R start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT separated from a flat surface (the eye) by a thin fluid layer of thickness hpostsubscript\u210eposth_{\\rm post}italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT. In this context we assume the post-lens thickness to be constant.\nThe superior/inferior motion of the lens is characterized by a velocity component Ucl\u2062(t)subscript\ud835\udc48cl\ud835\udc61U_{\\rm cl}(t)italic_U start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT ( italic_t ). A very simple model\nfor the unidirectional fluid velocity in this post-lens region is Couette flow of the form where z\u2208[0,hpost]\ud835\udc670subscript\u210epostz\\in[0,h_{\\rm post}]italic_z \u2208 [ 0 , italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT ]. Our main objective is to estimate the net volume flux out of the post-lens region, i.e., out from under the contact lens at the lens periphery. The volumetric flow in/out of the upper half of the circular disk from time t=0\ud835\udc610t=0italic_t = 0 to time t=T\ud835\udc61\ud835\udc47t=Titalic_t = italic_T, say during downward motion of the lens, is Here j^^\ud835\udc57\\hat{j}over^ start_ARG italic_j end_ARG is a unit vector in the vertical direction (i.e.\u00a0up for a standing contact lens wearer), and n^disk=(cos\u2061\u03b8,sin\u2061\u03b8,0)subscript^\ud835\udc5bdisk\ud835\udf03\ud835\udf030\\hat{n}_{\\rm disk}=(\\cos\\theta,\\sin\\theta,0)over^ start_ARG italic_n end_ARG start_POSTSUBSCRIPT roman_disk end_POSTSUBSCRIPT = ( roman_cos italic_\u03b8 , roman_sin italic_\u03b8 , 0 )\nis the unit outward normal of the circular disk in the radial direction. Our assumption is that u\u2062(z,t)\ud835\udc62\ud835\udc67\ud835\udc61u(z,t)italic_u ( italic_z , italic_t ) is independent of \u03b8\ud835\udf03\\thetaitalic_\u03b8 and so the space portion\nof these integrals can be evaluated to give where Dc\u2062lsubscript\ud835\udc37\ud835\udc50\ud835\udc59D_{cl}italic_D start_POSTSUBSCRIPT italic_c italic_l end_POSTSUBSCRIPT is the diameter of the contact lens and \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT is the transverse distance that the contact lens travels in time T\ud835\udc47Titalic_T.\nSome experimental studies report \u0394\u2062Xcl=1\u0394subscript\ud835\udc4bcl1\\Delta X_{\\rm cl}=1roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT = 1\u20134444 mm (see Hayashi [64],\nGilman [63]) while others observe\nsmaller values \u0394\u2062Xcl=0.1\u0394subscript\ud835\udc4bcl0.1\\Delta X_{\\rm cl}=0.1roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT = 0.1\u20130.30.30.30.3mm\n(see Cui et al. [71] and Wolffsohn et al. [72]).\nTheoretical models show that even without the complications of elastic deformation of the contact lens and curvature of the lens and ocular surface, prediction of transverse contact lens motion is\nsensitive to post-lens thickness [47]. In terms of mass transfer of drug in/out of the post-lens we need to distinguish portions of the lens that are \u2018exposing\u2019 the\nprevious post-lens from those that are \u2018creating\u2019 new post-lens. A blink comprises two components:\na downstroke (eye closing) where Ucl<0subscript\ud835\udc48cl0U_{\\rm cl}<0italic_U start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT < 0 and an upstroke (eye opening) where Ucl>0subscript\ud835\udc48cl0U_{\\rm cl}>0italic_U start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT > 0 and drug\nmass can be lost in both of these stages.\nFor a schematic see Figure\u00a07.\nIn particular, we assume the following situations hold for post-lens drug mass lost as a result of lens sliding motion: Downstroke: Upstroke: We assume Couette flow occurs during the upstroke as well; this dragging flow results in an additional factor of one-half to calculate the amount of drug lost (again\nsee Figure\u00a07).\nThen, over one blink (downstroke plus upstroke), we have net loss of drug mass in the post-lens given by To compute the concentration at the end of a blink that results from the slide out of drug, we determine Cpost\u2062(tblink+)=Cpostslidesubscript\ud835\udc36postsuperscriptsubscript\ud835\udc61blinksuperscriptsubscript\ud835\udc36postslideC_{\\rm post}(t_{\\rm blink}^{+})=C_{\\rm post}^{\\rm slide}italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) = italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_slide end_POSTSUPERSCRIPT via We introduce dimensionless variables where \u03c4\ud835\udf0f\\tauitalic_\u03c4 is a typical time scale associated with blinking (e.g.\u00a010101010 seconds in Phan et al. [21]). Interblink: The corresponding dimensionless model is in the contact lens 0<z\u00af<10\u00af\ud835\udc6710<\\bar{z}<10 < over\u00af start_ARG italic_z end_ARG < 1, subject to initial condtion C\u00af\u2062(z\u00af,t\u00af=0)=1\u00af\ud835\udc36\u00af\ud835\udc67\u00af\ud835\udc6101\\bar{C}(\\bar{z},\\bar{t}=0)=1over\u00af start_ARG italic_C end_ARG ( over\u00af start_ARG italic_z end_ARG , over\u00af start_ARG italic_t end_ARG = 0 ) = 1 and the boundary conditions (or \u2202C\u00af/\u2202z\u00af=0\u00af\ud835\udc36\u00af\ud835\udc670\\partial\\bar{C}/\\partial\\bar{z}=0\u2202 over\u00af start_ARG italic_C end_ARG / \u2202 over\u00af start_ARG italic_z end_ARG = 0 at z\u00af=1\u00af\ud835\udc671\\bar{z}=1over\u00af start_ARG italic_z end_ARG = 1\ninstead for the no-flux condition on the pre-lens side).\nIn the pre-lens tear film during an interblink we have where dimensionless diffusion coefficient, evaporation parameter,\nand lid permeability constant are given by In the post-lens film during an interblink we have where\nQ\u00afin=Qin\u2062\u03c4/(Acl\u2062hcl)subscript\u00af\ud835\udc44insubscript\ud835\udc44in\ud835\udf0fsubscript\ud835\udc34clsubscript\u210ecl\\bar{Q}_{\\rm in}=Q_{\\rm in}\\tau/(A_{\\rm cl}h_{\\rm cl})over\u00af start_ARG italic_Q end_ARG start_POSTSUBSCRIPT roman_in end_POSTSUBSCRIPT = italic_Q start_POSTSUBSCRIPT roman_in end_POSTSUBSCRIPT italic_\u03c4 / ( italic_A start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT ),\nQ\u00afout=Qout\u2062\u03c4/(Acl\u2062hcl)subscript\u00af\ud835\udc44outsubscript\ud835\udc44out\ud835\udf0fsubscript\ud835\udc34clsubscript\u210ecl\\bar{Q}_{\\rm out}=Q_{\\rm out}\\tau/(A_{\\rm cl}h_{\\rm cl})over\u00af start_ARG italic_Q end_ARG start_POSTSUBSCRIPT roman_out end_POSTSUBSCRIPT = italic_Q start_POSTSUBSCRIPT roman_out end_POSTSUBSCRIPT italic_\u03c4 / ( italic_A start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT ),\nJ\u00afosmotic=Qosmotic\u2062\u03c4/(Acl\u2062hcl)subscript\u00af\ud835\udc3dosmoticsubscript\ud835\udc44osmotic\ud835\udf0fsubscript\ud835\udc34clsubscript\u210ecl\\bar{J}_{\\rm osmotic}=Q_{\\rm osmotic}\\tau/(A_{\\rm cl}h_{\\rm cl})over\u00af start_ARG italic_J end_ARG start_POSTSUBSCRIPT roman_osmotic end_POSTSUBSCRIPT = italic_Q start_POSTSUBSCRIPT roman_osmotic end_POSTSUBSCRIPT italic_\u03c4 / ( italic_A start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT ),\nand\nk\u00afc=kc\u2062\u03c4/hclsubscript\u00af\ud835\udc58\ud835\udc50subscript\ud835\udc58\ud835\udc50\ud835\udf0fsubscript\u210ecl\\bar{k}_{c}=k_{c}\\tau/h_{\\rm cl}over\u00af start_ARG italic_k end_ARG start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = italic_k start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT italic_\u03c4 / italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT. In the upper eyelid during the interblink we have where Vratio=Vcl/Vlid=(hcl\u2062Acl)/(hlid\u2062Alid)subscript\ud835\udc49ratiosubscript\ud835\udc49clsubscript\ud835\udc49lidsubscript\u210eclsubscript\ud835\udc34clsubscript\u210elidsubscript\ud835\udc34lidV_{\\rm ratio}=V_{\\rm cl}/V_{\\rm lid}=(h_{\\rm cl}A_{\\rm cl})/(h_{\\rm lid}A_{\\rm\nlid})italic_V start_POSTSUBSCRIPT roman_ratio end_POSTSUBSCRIPT = italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT / italic_V start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT = ( italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT ) / ( italic_h start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT ). Thus, we expect the nondimensional permeability constant for the lid, k\u00af\u2062Vratio\u00af\ud835\udc58subscript\ud835\udc49ratio\\bar{k}V_{\\rm ratio}over\u00af start_ARG italic_k end_ARG italic_V start_POSTSUBSCRIPT roman_ratio end_POSTSUBSCRIPT, to be much smaller than that for the pre-lens due to their relative volumes (Vratiosubscript\ud835\udc49ratioV_{\\rm ratio}italic_V start_POSTSUBSCRIPT roman_ratio end_POSTSUBSCRIPT is about 0.08 or 0.09 depending on which lens is selected). Blink/reset: Equations\u00a0(28), (30), (31), (33), and (34) are solved\nfrom t\u00af=0\u00af\ud835\udc610\\bar{t}=0over\u00af start_ARG italic_t end_ARG = 0 to t\u00af=t\u00afblink\u2212\u00af\ud835\udc61superscriptsubscript\u00af\ud835\udc61blink\\bar{t}=\\bar{t}_{\\rm blink}^{-}over\u00af start_ARG italic_t end_ARG = over\u00af start_ARG italic_t end_ARG start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT. Then, to account for the effects of a blink, we define the following reset conditions\nand restart the evolution with initial conditions at t\u00afblink+superscriptsubscript\u00af\ud835\udc61blink\\bar{t}_{\\rm blink}^{+}over\u00af start_ARG italic_t end_ARG start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT defined by: In these expressions As in the vial setting, of interest is the amount of drug in each model compartment over time. Specifically, at any\ngiven time t\ud835\udc61titalic_t, we keep track of the mass of drug in the contact lens, M\u2062(t)\ud835\udc40\ud835\udc61M(t)italic_M ( italic_t ), given by\nequation\u00a0(4) as well as the cumulative\nmass of drug lost, Mlost\u2062(t)superscript\ud835\udc40lost\ud835\udc61M^{\\rm lost}(t)italic_M start_POSTSUPERSCRIPT roman_lost end_POSTSUPERSCRIPT ( italic_t ), given by\nequation\u00a0(5).\nThe quantity Mlost\u2062(t)superscript\ud835\udc40lost\ud835\udc61M^{\\rm lost}(t)italic_M start_POSTSUPERSCRIPT roman_lost end_POSTSUPERSCRIPT ( italic_t ) is the specific one reported in the experimental work\nof Phan et al. [21] for both the vial setting and the eye model setting.\nThis drug lost from the contact lens can be decomposed into the amounts in the other compartments: Before presenting solutions of this model,\nin the next section we outline a simplification of this model that admits a closed form solution for these quantities of interest and provides some reference and context for parameter selection in the full eye model. A mathematically-appealing limit of the dimensionless model outlined in Section\u00a05\nhas D\u00af\u226b1much-greater-than\u00af\ud835\udc371\\bar{D}\\gg 1over\u00af start_ARG italic_D end_ARG \u226b 1, with a consequence being that the drug concentration in the contact lens is\napproximately uniform in space (time dependent only). Technically speaking, for the known parameter values associated with the two contact lenses of interest in this study, D\u00af\u00af\ud835\udc37\\bar{D}over\u00af start_ARG italic_D end_ARG does not have this property (for the etafilcon A lens D\u00af\u22485\u00d710\u22124\u00af\ud835\udc375superscript104\\bar{D}\\approx 5\\times 10^{-4}over\u00af start_ARG italic_D end_ARG \u2248 5 \u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT and for the senofilcon A lens D\u00af\u22481\u00d710\u22125\u00af\ud835\udc371superscript105\\bar{D}\\approx 1\\times 10^{-5}over\u00af start_ARG italic_D end_ARG \u2248 1 \u00d7 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT). Despite this, we pursue this special limit for two reasons: (1) approximately spatially-uniform concentrations in the contact lens are possible even when D\u00af\u00af\ud835\udc37\\bar{D}over\u00af start_ARG italic_D end_ARG is not\nlarge, and (2) this approximation allows analytical expressions for all quantities of interest and, as such, provides\npredictions that can be used to validate the full model and further guide analysis/interpretation. In order to frame these predictions as closely as possible to the experimental\nquantities of interest, we present the details of this approximate solution in dimensional form. Consider a limit in which diffusion in the contact lens is sufficiently fast \u2013 or the lens sufficiently thin or the interblink sufficiently long, i.e.\u00a0D\u00af\u00af\ud835\udc37\\bar{D}over\u00af start_ARG italic_D end_ARG is sufficiently large \u2013 to allow the approximation that the contact lens drug concentration becomes spatially uniform \u2013 i.e.\u00a0C=C\u2062(t)\ud835\udc36\ud835\udc36\ud835\udc61C=C(t)italic_C = italic_C ( italic_t ) \u2013 by the end of each interblink. As this particular limit\nputs emphasis on the partition coefficient concentration balance, we introduce a partition coefficient for each of the pre-lens and post-lens boundaries of the contact lens, Kpresubscript\ud835\udc3epreK_{\\rm pre}italic_K start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT and Kpostsubscript\ud835\udc3epostK_{\\rm post}italic_K start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT.\nThat is, the ratio of the spatially-uniform\ncontact lens concentration with the pre-lens concentration is fixed by the partition coefficient, Kpresubscript\ud835\udc3epreK_{\\rm pre}italic_K start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT, and\nsimilarly\nfor the post-lens by Kpostsubscript\ud835\udc3epostK_{\\rm post}italic_K start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT. Thus, the simplified model is based on the assumption that by the end of the interblink the pre-lens, contact-lens, and post-lens concentrations have together reached equilibrium levels consistent with the partition coefficients.\nFor simplicity, we ignore drug loss into the eyelid or the cornea.\nThe only loss of mass out of the whole system (pre-lens, contact-lens, and post-lens) happens at a blink\n(i.e.\u00a0between interblinks) and as in our earlier framework is treated as a reset type condition.\nTherefore, we can frame this simplified model as a discrete dynamical system and keep track of time in terms of interblink number, j=1,2,3,\u2026\ud835\udc57123\u2026j=1,2,3,\\ldotsitalic_j = 1 , 2 , 3 , \u2026.\nSince it is convenient to count blinks, we refer to blink j\ud835\udc57jitalic_j as the blink that occurs after interblink j\ud835\udc57jitalic_j. Our variables are then Cprejsuperscriptsubscript\ud835\udc36pre\ud835\udc57C_{\\rm pre}^{j}italic_C start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT, Cjsuperscript\ud835\udc36\ud835\udc57C^{j}italic_C start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT, Cpostjsuperscriptsubscript\ud835\udc36post\ud835\udc57C_{\\rm post}^{j}italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT\nfor the concentrations in the pre-lens, contact-lens, and post-lens at the end of interblink j\ud835\udc57jitalic_j. Similarly we introduce Mtotjsubscriptsuperscript\ud835\udc40\ud835\udc57totM^{j}_{\\rm tot}italic_M start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT as the total drug mass in the system (including pre-lens, contact-lens,\nand post-lens compartments) at the end of interblink j\ud835\udc57jitalic_j. We reserve j=0\ud835\udc570j=0italic_j = 0 to denote the initial conditions (i.e.\u00a0before the first interblink) where all the drug mass is in the contact lens so that Cpre0=0superscriptsubscript\ud835\udc36pre00C_{\\rm pre}^{0}=0italic_C start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = 0,\nCpost0=0superscriptsubscript\ud835\udc36post00C_{\\rm post}^{0}=0italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = 0 and C0=Cinitsuperscript\ud835\udc360superscript\ud835\udc36initC^{0}=C^{\\rm init}italic_C start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = italic_C start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT and Mtot0=Cinit\u2062Vclsubscriptsuperscript\ud835\udc400totsuperscript\ud835\udc36initsubscript\ud835\udc49clM^{0}_{\\rm tot}=C^{\\rm init}V_{\\rm cl}italic_M start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT = italic_C start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT. We apply boundary conditions associated with the partition coefficient, although below we define a switching parameter f\ud835\udc53fitalic_f that allows us to also capture the case in which a no-flux condition is imposed at the contact-lens/pre-lens boundary (more details are given below). In this situation, by the end of each interblink j\ud835\udc57jitalic_j we assume that concentrations in the pre-lens,\ncontact-lens, and post-lens regions have equilibrated so that for j=1,2,3,\u2026\ud835\udc57123\u2026j=1,2,3,\\ldotsitalic_j = 1 , 2 , 3 , \u2026,\nwhich indicates that the concentrations in the pre-lens, post-lens, and contact lens are in proportion with one another.\nAs a result of equations\u00a0(39) at the end of interblink j\ud835\udc57jitalic_j, the total drug mass, Mtotjsubscriptsuperscript\ud835\udc40\ud835\udc57totM^{j}_{\\rm tot}italic_M start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT, in the entire pre-lens, contact-lens, post-lens system can be expressed as where Vpostsubscript\ud835\udc49postV_{\\rm post}italic_V start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT, Vclsubscript\ud835\udc49clV_{\\rm cl}italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT, and Vpresubscript\ud835\udc49preV_{\\rm pre}italic_V start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT are the volumes of the post-lens, contact-lens, and pre-lens regions. The parameter\nf\ud835\udc53fitalic_f allows consideration of the case in which a no-flux boundary condition is used between the contact lens and the pre-lens. In particular, we set f=0\ud835\udc530f=0italic_f = 0\nto impose a no-flux condition into the pre-lens region (i.e.\u00a0zero drug mass escapes into the pre-lens), and f=1\ud835\udc531f=1italic_f = 1 otherwise.\nSince we assume that the volumes and partition coefficients are constants, this relation reveals that the post-lens\nconcentration at the end of interblink j\ud835\udc57jitalic_j is proportional to the total drug mass in the system at that moment. Note that Mtot1subscriptsuperscript\ud835\udc401totM^{1}_{\\rm tot}italic_M start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT represents the drug mass in the system at the end of interblink 1 and since no blink has yet happened, Mtot1=Mtot0subscriptsuperscript\ud835\udc401totsubscriptsuperscript\ud835\udc400totM^{1}_{\\rm tot}=M^{0}_{\\rm tot}italic_M start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT = italic_M start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT. However, since the drug\nhas redistributed itself according to\u00a0(39) during interblink 1, in general Cpost1\u2260Cpost0=0superscriptsubscript\ud835\udc36post1superscriptsubscript\ud835\udc36post00C_{\\rm post}^{1}\\neq C_{\\rm post}^{0}=0italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT \u2260 italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = 0, Cpre1\u2260Cpre0=0superscriptsubscript\ud835\udc36pre1superscriptsubscript\ud835\udc36pre00C_{\\rm pre}^{1}\\neq C_{\\rm pre}^{0}=0italic_C start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT \u2260 italic_C start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = 0,\nand C1\u2260C0superscript\ud835\udc361superscript\ud835\udc360C^{1}\\neq C^{0}italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT \u2260 italic_C start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. In this setting, drug mass leaves the system only during a blink. Losses of mass from the post-lens and/or pre-lens that occur as a consequence of blink j\ud835\udc57jitalic_j imply that where Mtotjsubscriptsuperscript\ud835\udc40\ud835\udc57totM^{j}_{\\rm tot}italic_M start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT is the drug mass in the system right before blink j\ud835\udc57jitalic_j (i.e.\u00a0at the end of interblink j\ud835\udc57jitalic_j), Mtotj+1subscriptsuperscript\ud835\udc40\ud835\udc571totM^{j+1}_{\\rm tot}italic_M start_POSTSUPERSCRIPT italic_j + 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT is the drug mass in the system\nright after blink j\ud835\udc57jitalic_j (i.e.\u00a0beginning of interblink j+1\ud835\udc571j+1italic_j + 1), and \u0394\u2062Mpostj\u0394superscriptsubscript\ud835\udc40post\ud835\udc57\\Delta M_{\\rm post}^{j}roman_\u0394 italic_M start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT and \u0394\u2062Mprej\u0394superscriptsubscript\ud835\udc40pre\ud835\udc57\\Delta M_{\\rm pre}^{j}roman_\u0394 italic_M start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT are the amount of drug mass lost from the\npost-lens and pre-lens regions due to blink j\ud835\udc57jitalic_j. Note that the total mass does not change during an interblink so Mtotj+1subscriptsuperscript\ud835\udc40\ud835\udc571totM^{j+1}_{\\rm tot}italic_M start_POSTSUPERSCRIPT italic_j + 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT also represents the\ndrug mass at the end of interblink j+1\ud835\udc571j+1italic_j + 1.\nWe have already argued that the drug mass lost during a blink from the pre-lens and post-lens regions is proportional to the drug concentration at the moment\nof the blink, with the proportionality factor being the total volume exiting the system, which we denote\nhere by \u0394\u2062Vpre\u0394subscript\ud835\udc49pre\\Delta V_{\\rm pre}roman_\u0394 italic_V start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT and \u0394\u2062Vpost\u0394subscript\ud835\udc49post\\Delta V_{\\rm post}roman_\u0394 italic_V start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT. That is, where we have again inserted the factor f\ud835\udc53fitalic_f so that drug loss to the pre-lens can be shut off (f=0\ud835\udc530f=0italic_f = 0) in the case of a no-flux boundary condition at the contact-lens/pre-lens boundary. Further details for \u0394\u2062Vpost\u0394subscript\ud835\udc49post\\Delta V_{\\rm post}roman_\u0394 italic_V start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT and \u0394\u2062Vpre\u0394subscript\ud835\udc49pre\\Delta V_{\\rm pre}roman_\u0394 italic_V start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT will be given below.\nThen, the drug lost due to blink j\ud835\udc57jitalic_j generates the updated total mass Mtotj+1subscriptsuperscript\ud835\udc40\ud835\udc571totM^{j+1}_{\\rm tot}italic_M start_POSTSUPERSCRIPT italic_j + 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT for j=1,2,3,\u2026\ud835\udc57123\u2026j=1,2,3,\\ldotsitalic_j = 1 , 2 , 3 , \u2026. Using\u00a0(40) to substitute for Mtotjsubscriptsuperscript\ud835\udc40\ud835\udc57totM^{j}_{\\rm tot}italic_M start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT and Mtotj+1subscriptsuperscript\ud835\udc40\ud835\udc571totM^{j+1}_{\\rm tot}italic_M start_POSTSUPERSCRIPT italic_j + 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT in equation\u00a0(43) and also using\u00a0(39) gives Therefore, the post-lens concentration at the end of interblink j+1\ud835\udc571j+1italic_j + 1 can be written as for j=1,2,3,\u2026\ud835\udc57123\u2026j=1,2,3,\\ldotsitalic_j = 1 , 2 , 3 , \u2026 where s\ud835\udc60sitalic_s is a constant given by An explicit solution follows: Cpostj=(1\u2212s)j\u22121\u2062Cpost1superscriptsubscript\ud835\udc36post\ud835\udc57superscript1\ud835\udc60\ud835\udc571superscriptsubscript\ud835\udc36post1C_{\\rm post}^{j}=(1-s)^{j-1}C_{\\rm post}^{1}italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT = ( 1 - italic_s ) start_POSTSUPERSCRIPT italic_j - 1 end_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT for j=1,2,3,\u2026\ud835\udc57123\u2026j=1,2,3,\\ldotsitalic_j = 1 , 2 , 3 , \u2026. Expressions for Cprejsuperscriptsubscript\ud835\udc36pre\ud835\udc57C_{\\rm pre}^{j}italic_C start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT, Cjsuperscript\ud835\udc36\ud835\udc57C^{j}italic_C start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT, and Mtotjsubscriptsuperscript\ud835\udc40\ud835\udc57totM^{j}_{\\rm tot}italic_M start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_tot end_POSTSUBSCRIPT also follow. It will be convenient to express these solutions in terms of a discrete time variable tjsubscript\ud835\udc61\ud835\udc57t_{j}italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. In particular, for interblink time \u03c4\ud835\udf0f\\tauitalic_\u03c4, we have the analytical solution for j=1,2,3,\u2026\ud835\udc57123\u2026j=1,2,3,\\ldotsitalic_j = 1 , 2 , 3 , \u2026 where along with t0=0subscript\ud835\udc6100t_{0}=0italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 0, Cpost\u2062(0)=0subscript\ud835\udc36post00C_{\\rm post}(0)=0italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT ( 0 ) = 0, Cpre\u2062(0)=0subscript\ud835\udc36pre00C_{\\rm pre}(0)=0italic_C start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT ( 0 ) = 0, C\u2062(0)=Minit/Vcl\ud835\udc360superscript\ud835\udc40initsubscript\ud835\udc49clC(0)=M^{\\rm init}/V_{\\rm cl}italic_C ( 0 ) = italic_M start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT / italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT.\nThese formulas constitute closed-form solutions to the multiple blink drug delivery problem in this special large diffusion limit.\nIt is also convenient to identify the total drug mass in the contact lens at time t=tj\ud835\udc61subscript\ud835\udc61\ud835\udc57t=t_{j}italic_t = italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT as so that the cumulative drug released from the contact lens, Mlost\u2062(tj)=Minit\u2212M\u2062(tj)superscript\ud835\udc40lostsubscript\ud835\udc61\ud835\udc57superscript\ud835\udc40init\ud835\udc40subscript\ud835\udc61\ud835\udc57M^{\\rm lost}(t_{j})=M^{\\rm init}-M(t_{j})italic_M start_POSTSUPERSCRIPT roman_lost end_POSTSUPERSCRIPT ( italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) = italic_M start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT - italic_M ( italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ), is for j=1,2,3,\u2026\ud835\udc57123\u2026j=1,2,3,\\ldotsitalic_j = 1 , 2 , 3 , \u2026 with Mlost\u2062(0)=0superscript\ud835\udc40lost00M^{\\rm lost}(0)=0italic_M start_POSTSUPERSCRIPT roman_lost end_POSTSUPERSCRIPT ( 0 ) = 0.\nNote that the factor since, typically, partition coefficients are \ud835\udcaa\u2062(1)\ud835\udcaa1{\\cal O}(1)caligraphic_O ( 1 ) and Vpostsubscript\ud835\udc49postV_{\\rm post}italic_V start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT and Vpresubscript\ud835\udc49preV_{\\rm pre}italic_V start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT are expected to be much smaller than Vclsubscript\ud835\udc49clV_{\\rm cl}italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT.\nThis tells us that, at least under the assumptions of the present reduced model, the single constant s\ud835\udc60sitalic_s defined in equation\u00a0(46) controls nearly completely the dynamics\nof the cumulative drug release. That is, it appears a good approximation that may allow us to gain intuition is This suggests that comparison to data on cumulative drug release in the large diffusion limit amounts to the optimal selection of a single\nparameter combination s\ud835\udc60sitalic_s through which all pre-lens and post-lens drug mass loss mechanisms are represented.\nWe show solutions below but for now we shall suppose that a particular choice s=s*\ud835\udc60superscript\ud835\udc60s=s^{*}italic_s = italic_s start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT achieves\nthis goal for a given contact lens. With respect to the Phan et al.\u00a0[21] data we recall that the \u2018vial\u2019 drug release differs significantly\nbetween the two lens types and appears to be reasonably-well described by linear diffusion in the contact lens\nwith each lens characterized by a different diffusion coefficient. On the other hand, the \u2018eye model\u2019 drug release data is effectively indistinguishable between the two contact lens types, suggesting that\na non-diffusive mechanism exerts some control on the drug release dynamics.\nFigure\u00a08 plots our prediction in equation\u00a0(54) for representative ranges of the parameter s\ud835\udc60sitalic_s\nfor each of the two contact lenses along with the\ndata from Phan et al.\u00a0[21]. Two critical contributions to the parameter s\ud835\udc60sitalic_s defined in equation\u00a0(46) come from \u0394\u2062Vpost\u0394subscript\ud835\udc49post\\Delta V_{\\rm post}roman_\u0394 italic_V start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT and \u0394\u2062Vpre\u0394subscript\ud835\udc49pre\\Delta V_{\\rm pre}roman_\u0394 italic_V start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT.\nFor the post-lens volume lost, using the results discussed in Section\u00a04.5 we have as the post-lens tear volume that moves out from under the contact lens during a blink. These values\nof \u0394\u2062Vpost\u0394subscript\ud835\udc49post\\Delta V_{\\rm post}roman_\u0394 italic_V start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT are used in \u0394\u2062Mpostj\u0394superscriptsubscript\ud835\udc40post\ud835\udc57\\Delta M_{\\rm post}^{j}roman_\u0394 italic_M start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT in\u00a0(42) with the assumption that this lost volume\ntransports drug mass out of the post-lens tear film and none of this drug returns.\nFor the pre-lens volume lost we write where p\u2208[0,1]\ud835\udc5d01p\\in[0,1]italic_p \u2208 [ 0 , 1 ] is an adjustable parameter that represents the proportion of pre-lens mass lost as a result of a blink. Here,\np=0\ud835\udc5d0p=0italic_p = 0 means no pre-lens drug mass is lost and p=1\ud835\udc5d1p=1italic_p = 1 means all pre-lens drug mass is lost as the result of a blink.\nSo in\u00a0(42) this means \u0394\u2062Mprej=f\u2062p\u2062Vpre\u2062Cprej\u0394superscriptsubscript\ud835\udc40pre\ud835\udc57\ud835\udc53\ud835\udc5dsubscript\ud835\udc49presuperscriptsubscript\ud835\udc36pre\ud835\udc57\\Delta M_{\\rm pre}^{j}=fpV_{\\rm pre}C_{\\rm pre}^{j}roman_\u0394 italic_M start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT = italic_f italic_p italic_V start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT, which involves\ntwo model parameters f\ud835\udc53fitalic_f and p\ud835\udc5dpitalic_p. The case f=0\ud835\udc530f=0italic_f = 0 corresponds to no-flux into the pre-lens and thus here the value of p\ud835\udc5dpitalic_p has no impact on the predictions because there is never any drug mass in the pre-lens tear film.\nThe case f=1\ud835\udc531f=1italic_f = 1 allows the standard diffusive flux from\nthe contact lens into the pre-lens and here the parameter p\ud835\udc5dpitalic_p establishes how much of the pre-lens drug mass is swept away as the result of a blink.\nBelow, we explore more closely the constant s\ud835\udc60sitalic_s and its dependence on the model parameters in the pre-lens and post-lens including the cases of slide out and squeeze out\nmechanisms of drug loss in the post-lens region. In this case the constant s\ud835\udc60sitalic_s in equation\u00a0(46) is Using Vpost=\u03c0\u2062Rcl2\u2062hpostsubscript\ud835\udc49post\ud835\udf0bsuperscriptsubscript\ud835\udc45cl2subscript\u210epostV_{\\rm post}=\\pi R_{\\rm cl}^{2}h_{\\rm post}italic_V start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT = italic_\u03c0 italic_R start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT, Vpre=\u03c0\u2062Rcl2\u2062hpresubscript\ud835\udc49pre\ud835\udf0bsuperscriptsubscript\ud835\udc45cl2subscript\u210epreV_{\\rm pre}=\\pi R_{\\rm cl}^{2}h_{\\rm pre}italic_V start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT = italic_\u03c0 italic_R start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_h start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT, and Vcl=\u03c0\u2062Rcl2\u2062hclsubscript\ud835\udc49cl\ud835\udf0bsuperscriptsubscript\ud835\udc45cl2subscript\u210eclV_{\\rm cl}=\\pi R_{\\rm cl}^{2}h_{\\rm cl}italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT = italic_\u03c0 italic_R start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT, we find that If we define then If s=s*\ud835\udc60superscript\ud835\udc60s=s^{*}italic_s = italic_s start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT is the value of s\ud835\udc60sitalic_s for which the large diffusion model best fits the cumulative drug release data, then we can identify a closed-form expression for the required\ncontact lens displacement, \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT, that would be necessary to achieve such a fit, given the other parameters: It remains to explore these predictions numerically to assess if the requirements for \u0394\u2062Xcl/Rcl\u0394subscript\ud835\udc4bclsubscript\ud835\udc45cl\\Delta X_{\\rm cl}/R_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT / italic_R start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT are feasible for known or estimated values\nfor the other parameters. Several particular cases are outlined below. We assume in these cases that Kpre=Kpost=Ksubscript\ud835\udc3epresubscript\ud835\udc3epost\ud835\udc3eK_{\\rm pre}=K_{\\rm post}=Kitalic_K start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT = italic_K start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT = italic_K. Since\nwe know K\ud835\udc3eKitalic_K, hclsubscript\u210eclh_{\\rm cl}italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT, and Rclsubscript\ud835\udc45clR_{\\rm cl}italic_R start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT for the experimental data and we assume s*superscript\ud835\udc60s^{*}italic_s start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT is fixed by the fit to the cumulative drug release curve,\nwe fix those parameters and explore how the predictions vary with hpostsubscript\u210eposth_{\\rm post}italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT, hpresubscript\u210epreh_{\\rm pre}italic_h start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT, f\ud835\udc53fitalic_f, and p\ud835\udc5dpitalic_p. Post-lens slide-out, pre-lens no flux: Here we examine the no-flux boundary condition on the contact-lens/pre-lens boundary, f=0\ud835\udc530f=0italic_f = 0. We find The result in equation\u00a0(66) is shown in the upper two plots of Figure\u00a09. In these plots, in addition to the large diffusion limit solution we also show several\ncomputed solutions from the full model (open circles; see Section 7). These predictions are in close agreement for the etafilcon A lens. For the senofilcon A lens, which has a much smaller value of D\u00af\u00af\ud835\udc37\\bar{D}over\u00af start_ARG italic_D end_ARG for the full model, the large diffusion limit predictions require a noticeably reduced post-lens motion for the same cumulative drug release. Post-lens slide-out, partial pre-lens loss: Here we assume f=1\ud835\udc531f=1italic_f = 1 and p\u2208[0,1]\ud835\udc5d01p\\in[0,1]italic_p \u2208 [ 0 , 1 ]. We find For \u0394\u2062Xcl\u22650\u0394subscript\ud835\udc4bcl0\\Delta X_{\\rm cl}\\geq 0roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT \u2265 0 we must limit p\u2208[0,pmax]\ud835\udc5d0subscript\ud835\udc5dmaxp\\in[0,p_{\\rm max}]italic_p \u2208 [ 0 , italic_p start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ] where \u0394\u2062Xcl=0\u0394subscript\ud835\udc4bcl0\\Delta X_{\\rm cl}=0roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT = 0 gives p=pmax\ud835\udc5dsubscript\ud835\udc5dmaxp=p_{\\rm max}italic_p = italic_p start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT and The result in equation\u00a0(67) is\nplotted versus p\ud835\udc5dpitalic_p on [0,pmax]0subscript\ud835\udc5dmax[0,p_{\\rm max}][ 0 , italic_p start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ] in the lower two plots of Figure\u00a09.\nIn these plots, we also show several computed solutions from the full model (open circles).\nNote that for the etafilcon A lens (lower left plot) there is no value of \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT when p=0.008\ud835\udc5d0.008p=0.008italic_p = 0.008 for which the cumulative drug release data of Phan et al. can be matched by the full model. For the senofilcon A lens (lower right plot) the full model values for \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT are larger than those for the large\ndiffusion limit model. We note later in Section 7 that we can find solutions of the full model with p=1\ud835\udc5d1p=1italic_p = 1 and \u0394\u2062Xcl=0\u0394subscript\ud835\udc4bcl0\\Delta X_{\\rm cl}=0roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT = 0 that, like these\npredictions, also can match the Phan et al. [21] data. Following arguments similar to the slide out case outlined above, we find that for the squeeze out post-lens flow the parameter s\ud835\udc60sitalic_s takes the form Then, given s=s*\ud835\udc60superscript\ud835\udc60s=s^{*}italic_s = italic_s start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT obtained from comparison to the cumulative drug release data of Phan et al. it follows that the required post-lens thickness change is Here we identify feasible values of \u0394\u2062hpost/hcl\u0394subscript\u210epostsubscript\u210ecl\\Delta h_{\\rm post}/h_{\\rm cl}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT / italic_h start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT for known or estimated values\nfor the other parameters. Several particular cases are outlined below. Again, we assume in these cases that Kpre=Kpost=Ksubscript\ud835\udc3epresubscript\ud835\udc3epost\ud835\udc3eK_{\\rm pre}=K_{\\rm post}=Kitalic_K start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT = italic_K start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT = italic_K. Post-lens squeeze-out, pre-lens no flux: Here we examine the no-flux boundary condition on the contact-lens/pre-lens boundary, f=0\ud835\udc530f=0italic_f = 0. We find Another way to write this is The result in equation\u00a0(72) is shown in the upper two plots of Figure\u00a010. In these plots, we also show several\ncomputed solutions from the full model (open circles). For the etafilcon A lens the full model predictions match closely with the large diffusion limit predictions while for the senofilcon A lens the full model predictions have a much larger \u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT prediction. Post-lens squeeze-out, partial pre-lens loss: Here we assume f=1\ud835\udc531f=1italic_f = 1 and p\u2208[0,1]\ud835\udc5d01p\\in[0,1]italic_p \u2208 [ 0 , 1 ]. We find For \u0394\u2062hpost\u22650\u0394subscript\u210epost0\\Delta h_{\\rm post}\\geq 0roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT \u2265 0 it is required that p\u2208[0,pmax]\ud835\udc5d0subscript\ud835\udc5dmaxp\\in[0,p_{\\rm max}]italic_p \u2208 [ 0 , italic_p start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ] where \u0394\u2062hpost=0\u0394subscript\u210epost0\\Delta h_{\\rm post}=0roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT = 0 gives p=pmax\ud835\udc5dsubscript\ud835\udc5dmaxp=p_{\\rm max}italic_p = italic_p start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT and pmaxsubscript\ud835\udc5dmaxp_{\\rm max}italic_p start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT is the same as the Slide-Out result given in equation\u00a0(68).\nThe result in equation\u00a0(73) is plotted versus p\ud835\udc5dpitalic_p on [0,pmax]0subscript\ud835\udc5dmax[0,p_{\\rm max}][ 0 , italic_p start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ] in the lower two plots of Figure\u00a010.\nIn these plots, we also show several\ncomputed solutions from the full model (open circles). Note\nthat for the etafilcon A lens (lower left plot) there is no value of \u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT when\np=0.008\ud835\udc5d0.008p=0.008italic_p = 0.008 for which the cumulative drug release data can be matched by the full model. Within the context of this large diffusion-limit model, these results demonstrate that different mechanisms associated with drug loss in the pre-lens, post-lens, contact lens system tied to blinking over a 24 hour period can be identified as candidates to characterize the dynamics of cumulative mass loss data of Phan et al.[21]. In the next section we outline results computed from our full eye model. As a final sneak preview to the full model results we show a comparison of the large diffusion limit solution and the full model in Figure\u00a011 with no-flux into the pre-lens tear film and the slide out mechanism active in the post-lens tear film. These plots show the early time predictions for cumulative drug release\nfor the two contact lenses. Three values of the diffusion coefficient\nare used in the full model \u2013 D\u00af\u00af\ud835\udc37\\bar{D}over\u00af start_ARG italic_D end_ARG, 102\u2062D\u00afsuperscript102\u00af\ud835\udc3710^{2}\\bar{D}10 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT over\u00af start_ARG italic_D end_ARG, and 104\u2062D\u00afsuperscript104\u00af\ud835\udc3710^{4}\\bar{D}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT over\u00af start_ARG italic_D end_ARG \u2013 along with the large diffusion limit solution for the first twelve blinks. It is clear in the upper plots as well as the lower, zoomed-in plots, that the full model solutions with sufficiently large diffusion coefficient agree extremely well with the discrete (individual blink) time predictions of the large diffusion model. It appears that the large diffusion limit analysis gives at least qualitatively good information about potential drug release and transport mechanisms in the eye model configuration. Here we present results from numerical solutions of the\neye model summarized in Section\u00a05. Our numerical\napproach involves the spatial discretization of the\ndiffusion equation in the contact lens which leads to a coupled system\nof ordinary differential equations for\nthe pre-lens, post-lens, and eyelid compartments and solved using Matlab\u2019s\node15s solver. Both equally-spaced finite differences as well as Chebyshev spectral methods have been implemented for the spatial discretization.\nThese results have been validated using the large\ndiffusion limit solution identified in the previous section. In our model, the drug mass is initially located only\nin the contact lens. In general, at any later time, nonzero drug mass may reside\nin one of five compartments \u2013 the contact lens, the pre-lens, the eyelid,\nthe post-lens, and the cornea \u2013 or have been lost from the system altogether\nby one or more of several mechanisms.\nOur primary comparison will be with the experimental eye model data from Phan et al., which\nreports cumulative drug loss (red dye) from two different contact lenses in 24 hours\nof simulated wear. In our model there are two pathways for the drug to leave\nthe contact lens; through the pre-lens tear film and/or through the post-lens tear film. Drug that reaches the pre-lens tear film can be subsequently absorbed\nby the eyelid and/or lost directly out of the pre-lens due to blinking.\nDrug that reaches the post-lens tear film can be lost out of the post-lens\ndue to contact lens motion-driven transport (i.e.\u00a0slide out or squeeze out mechanisms).\nAlthough in clinical settings the cornea can be a desired target for drug delivery, we note that the experimental eye in the Phan et al. configuration is not permeable to the dye and in the results we present in this paper there is no transport of\ndrug from the post-lens into the cornea. There are several candidate mechanisms that may explain the cumulative drug\nrelease observations of Phan et al. We organize these in terms of\npathways through the pre-lens (and subsequently into the eyelid) and pathways\nthrough the post-lens. In our model there is no pathway\nfor the drug to reach the eyelid through the post-lens tear film.\nThere are a host of parameters that must be specified in order to compute\nsolutions of our model. With some exceptions noted below, we hand-tune model parameters to compare with\nexperimental data from Phan et al.\n[21].\nWe outline our choices and strategy below and attempt to\nfocus on parameters that most directly characterize various\ndrug loss pathways: Fixed parameters from vial configuration:\nWe use the equilibrium balance-calculated partition coefficients, K\ud835\udc3eKitalic_K, and the diffusion coefficients, D\ud835\udc37Ditalic_D, found via the single-variable optimization of the vial model (Section 3.2). Pre-lens drug loss parameters/settings: We consider either (a) a no-flux boundary condition at the contact lens/pre-lens\nboundary, in which case no drug escapes the contact lens via the pre-lens,\nor (b) a partition coefficient boundary condition that allows drug transport\ninto the pre-lens tear film. The former case was identified by setting f=0\ud835\udc530f=0italic_f = 0 in\nthe large diffusion limit model (Section 6).\nIn the latter case, we use parameter p\u2208[0,1]\ud835\udc5d01p\\in[0,1]italic_p \u2208 [ 0 , 1 ] to\nmeasure the proportion of drug lost from the pre-lens due to a blink. Recall that\np=0\ud835\udc5d0p=0italic_p = 0 means no drug is swept out and p=1\ud835\udc5d1p=1italic_p = 1 means all drug is swept out\nas the result of a blink. The pre-lens tear\nfilm thickness hpreinitsuperscriptsubscript\u210epreinith_{\\rm pre}^{\\rm init}italic_h start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT will be fixed at 5 \u03bc\ud835\udf07\\muitalic_\u03bcm. The evaporation rate JEsubscript\ud835\udc3d\ud835\udc38J_{E}italic_J start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is set to zero; explorations in which it is allowed to vary indicate little affect on the resulting solutions.\nWe comment that the use of a no-flux boundary condition\non the contact lens/pre-lens boundary can be viewed\nas a proxy for the case of rapid evaporation where the pre-lens disappears too quickly for appreciable drug diffusion from the contact lens. Eyelid absorption parameter: For pre-lens cases with f\u22600\ud835\udc530f\\neq 0italic_f \u2260 0 there\nis a drug pathway from the contact lens to the eyelid that is controlled by the lid permeability.\nMathematically, we allow this lid permeability constant klidsubscript\ud835\udc58lidk_{\\rm lid}italic_k start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT to vary between the two\nlenses in order to achieve reasonable fits. However, the need for a lens-dependent klidsubscript\ud835\udc58lidk_{\\rm lid}italic_k start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT indicates that the combination of mechanisms may not feasibly explain the dynamics since there\nis no reason to believe the contact lens should influence eyelid permeability. Post-lens drug loss parameters: Drug loss out of the post-lens tear film is characterized by either the slide out or squeeze out mechanism.\nThe primary control parameters are \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT in the former case and\n\u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT in the latter.\nIn general, these two parameters depend on post-lens tear film thickness\nalthough, except where noted, we assume hpostinit=5\u2062\u03bcsuperscriptsubscript\u210epostinit5\ud835\udf07h_{\\rm post}^{\\rm init}=5\\muitalic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT = 5 italic_\u03bcm.\nEither \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT and/or \u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT could in general\nvary from one lens to the next due to the fit of the lens on the eye,\nits composition and material/elastic properties, as well as the presence\nof coatings that may influence friction. In Figure 12, we show representative model solutions with the slide out contact lens motion option for the final time contact lens concentration, pre- and post-lens concentrations, and drug delivery/loss to/from various model compartments. Red and blue curves correspond to the etafilcon A and senofilcon A lenses, respectively. The model is simulated for the first 12 blinks to capture the initial release of drug. We use partition coefficient boundary conditions on the pre- and post-lens sides, p=0.5\ud835\udc5d0.5p=0.5italic_p = 0.5 so that half of the drug in the pre-lens is swept out by a blink, hpreinit=hpostinit=5\u2062\u03bcsuperscriptsubscript\u210epreinitsuperscriptsubscript\u210epostinit5\ud835\udf07h_{\\rm pre}^{\\rm init}=h_{\\rm post}^{\\rm init}=5\\ \\muitalic_h start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT = italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT = 5 italic_\u03bcm, klid=3\u00d710\u22129subscript\ud835\udc58lid3superscript109k_{\\rm lid}=3\\times 10^{-9}italic_k start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT = 3 \u00d7 10 start_POSTSUPERSCRIPT - 9 end_POSTSUPERSCRIPT m/s, and \u0394\u2062Xcl=0.05\u0394subscript\ud835\udc4bcl0.05\\Delta X_{\\rm cl}=0.05roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT = 0.05 mm. Squeeze out solutions with \u0394\u2062hpost=0.015\u2062\u03bc\u0394subscript\u210epost0.015\ud835\udf07\\Delta h_{\\rm post}=0.015\\ \\muroman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT = 0.015 italic_\u03bcm (not shown) are nearly identical. Figure 12(a) shows the contact lens concentration after 12 blinks. Unlike the vial setting (see Figure 3), the profiles are not symmetric across the lens, but similar to the vial case, the etafilcon A lens loses more drug than senofilcon A due to its larger diffusion coefficient. The pre- and post-lens concentrations are shown by X and star markers at x=0\ud835\udc650x=0italic_x = 0 and x=1\ud835\udc651x=1italic_x = 1, and the partition coefficient balances at those boundaries are shown by large circular markers. Figure 12(b) shows the pre- and post-lens concentrations over the 12 blinks. Due to the reset conditions at the start of each interblink, the concentrations drop rapidly and then increase between blinks. Figure 12(c) breaks down the drug released from the contact lens into the avenues of drug delivery/loss. The drug in the post-lens and the drug delivered to the eyelid for both lenses are very close to zero. There are four categories that we organize our results into based on pre-lens drug loss or lack thereof: Full pre-lens drug loss (p=1\ud835\udc5d1p=1italic_p = 1). No flux into the pre-lens. No pre-lens drug loss (p=0\ud835\udc5d0p=0italic_p = 0). Partial pre-lens drug loss (0<p<10\ud835\udc5d10<p<10 < italic_p < 1). In all but the second category, we assume a partition coefficient boundary condition at the lens/tear film interface for both the pre- and post-lens.\nThere is a natural ordering of these four options and they are discussed in detail in the next subsections. The aggregate results of the hand-tuned parameters for each model option simulation, including subcases where appropriate, are summarized in Table 4. We use pre-lens and post-lens partition coefficient balance boundary conditions which means that the drug can diffuse into both the pre-lens and the post-lens tear films.\nWe assess the possibility that each blink sweeps away\nall drug in the pre-lens and there is no motion of the contact\nlens (so that there is no drug loss out of the post-lens tear film). Figure 13 shows this case\nin comparison with the Phan et al. data for the two lenses. The cumulative drug release corresponding to the model solutions gives a reasonable fit to the experimental data for the senofilcon A lens (right plot), which might at first suggest a drug loss pathway through the pre-lens as a dominant mechanism behind\nthe observed drug release.\nHowever, the corresponding predicted drug release for the etafilcon A lens reaches that of the vial setting by the final time and overall the drug release rate for this lens is much too large (left plot).\nIn the absence of a reason why a blink mechanism would clear out all pre-lens drug mass for one\nlens and not another, it seems that another drug release pathway should be considered.\nThis leads us to examine either no-flux on the pre-lens side or p=0\ud835\udc5d0p=0italic_p = 0 (no pre-lens drug loss due to blinking) and options for post-lens motion in order to lessen the amount of pre-lens drug lost from a blink. Since in the previous subsection the drug loss through the pre-lens was too large to explain the etafilcon A lens model eye data,\nwe next investigate a version of the model in which no drug is lost from a blink because no drug is allowed to diffuse into the pre-lens. Here the drug can only leave the contact lens via the post-lens tear film.\nIn this instance our model does not allow any eyelid drug absorption; we acknowledge that we cannot fit the final time eyelid measurement from Phan et al. [21]. The no flux condition formulation of the model is described in Li and Chahaun (2006) [23]. One can assume that the tear film evaporates instantly, so that there is no pre-lens, and therefore there is nowhere for the drug to go in the upwards direction. In this way, this version of the model acts as a proxy for very high evaporation, and sets the evaporation rate aside as a parameter that we do not consider in this paper. Full model solutions for the pre-lens no-flux and post-lens slide out and squeeze out cases are shown in Figure\u00a014 and\nreveal excellent agreement with the cumulative drug release data of Phan\net al. In the squeeze out case, the post-lens film depression amounts correspond to blink pressures of 59.6 Pa and 306 Pa for the etafilcon A and senofilcon A lenses. We also run simulations of this version of the model with the no contact lens motion option (not shown), but the model predicts a very small cumulative release from the lens that is essentially constant after an initial increase; this is far from the experimental data. Example solutions of this case were shown also in the context of the large diffusion\nlimit. In particular, for the pre-lens no-flux and post-lens slide out case, three different values of \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT corresponding to different values of hpostsubscript\u210eposth_{\\rm post}italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT were shown in the upper plots of Figure\u00a09 that achieve a good match to the cumulative drug release data of\nPhan et al. Notably for the etafilcon A lens (upper left plot\nof Figure\u00a09) the full model predictions for \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT align very well with the large diffusion predictions, despite the fact that the full model seems to have D\u00af\u226a1much-less-than\u00af\ud835\udc371\\bar{D}\\ll 1over\u00af start_ARG italic_D end_ARG \u226a 1 rather than D\u00af\u226b1much-greater-than\u00af\ud835\udc371\\bar{D}\\gg 1over\u00af start_ARG italic_D end_ARG \u226b 1.\nThe comparison between the full model predictions and the large diffusion\nlimit is not as close for the senofilcon A lens (upper right plot\nof Figure\u00a09) perhaps due to D\u00af\u00af\ud835\udc37\\bar{D}over\u00af start_ARG italic_D end_ARG being even smaller for this lens. The larger \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT values predicted by the full model appear to be consistent with the fact that to achieve the same drug release, larger post-lens drug loss due to lens motion is\nrequired for reduced diffusive flux out of the contact lens.\nOf additional note is that the observed\ntrend of decreasing \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT for increasing hpostsubscript\u210eposth_{\\rm post}italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT seems to be robust for both the large diffusion model and the full model. For the pre-lens no-flux and post-lens squeeze out case, three different values of \u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT\ncorresponding to different values of hpostsubscript\u210eposth_{\\rm post}italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT were shown in the upper plots of\nFigure\u00a010 that achieve a good match to the cumulative drug release data of Phan et al. Similar observations\nhere can be made regarding the comparison between the large diffusion model predictions and the full model predictions. We now consider a setting in which drug is lost into both the pre- and post-lens tear films. Here, a partition coefficient balance controls diffusion of drug into both the pre-lens and post-lens. However, in contrast to the first option explored, in which p=1\ud835\udc5d1p=1italic_p = 1 so that all drug is swept out by a blink, we investigate the setting where p=0\ud835\udc5d0p=0italic_p = 0 so that no drug is lost via blinking.\nIn terms of the blink effect on the pre-lens tear film, eyelid absorption,\nand post-lens drug loss, we study the following cases: Eyelid absorption. Post-lens slide out. Eyelid absorption. Post-lens squeeze out. Eyelid absorption. No post-lens drug loss (no contact lens motion). No eyelid absorption. Post-lens slide out or squeeze out. Motivated by the findings of Section 6, namely, that the proportion of pre-lens mass lost as a result of a blink p\ud835\udc5dpitalic_p may need to be much closer to 0 than to 1 in order to match the\nPhan et al. [21] data, we examine full model simulations with p=0\ud835\udc5d0p=0italic_p = 0. We observe that both the calculated total cumulative drug release from the lens and the eyelid absorption profile from the model match reasonably well with the experimental data (see\nFigure\u00a015). Most of the total drug release is lost from the system through the post-lens due to the slide out action. No drug is lost from a blink due to the assumption that p=0\ud835\udc5d0p=0italic_p = 0. The cumulative drug release profile for the etafilcon A lens is more curved than that of the senofilcon A lens. This is in part due to the larger diffusion coefficient of the etafilcon A lens, which causes more drug to be released in the first few hours, and then drug release slows as concentration gradients lessen and less drug remains to be lost. In this regime of lid permeability constant and slide out amount \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT, we find that the final time contact lens concentration profile is roughly uniform for the etafilcon A lens but not so for the senofilcon A lens (not shown).\nAt least for the etafilcon A lens, this provides support for the assumption that p=0\ud835\udc5d0p=0italic_p = 0 following the large diffusion limit in Section 6. The pre- and post-lens concentration profiles are very similar for the etafilcon A lens, but the post-lens values are much smaller than the pre-lens for the senofilcon A lens.\nThe slide out amount \u0394\u2062Xcleta\u0394superscriptsubscript\ud835\udc4bcleta\\Delta X_{\\rm cl}^{\\rm eta}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_eta end_POSTSUPERSCRIPT is smaller than \u0394\u2062Xclseno\u0394superscriptsubscript\ud835\udc4bclseno\\Delta X_{\\rm cl}^{\\rm seno}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_seno end_POSTSUPERSCRIPT, but they are both smaller than the range of 0.1-4 mm from studies cited earlier. The model simulations look similar to that of the slide out scenario and match the experimental data from Phan et al. [21] fairly well (see\nFigure\u00a016). Most of the drug is lost due to the squeeze out mechanism. The etafilcon A final time contact lens concentration is more uniform than that of the senofilcon A lens, and the pre- and post-lens concentration profiles are more similar for the etafilcon A lens. The post-lens thickness depression amounts correspond to blink pressures of 44.7 Pa and 74.7 Pa for the etafilcon A and senofilcon A lenses. The etafilcon A and senofilcon A cumulative drug release profiles look very similar to each other in this case. Neither can simultaneously match the experimental measurements of cumulative drug release and eyelid absorption from Phan et al. [21]. We also note that the model fits in Figure 17 required two different lid permeability constants, which is infeasible in reality. Thus, the fit suggests that this combination of mechanisms does not describe the dynamics of the drug release. In this setting, which allows flux on the pre-lens side and sets p=0\ud835\udc5d0p=0italic_p = 0, we find that contact lens motion is required in order to separate cumulative drug release and eyelid absorption. Unlike the slide out and squeeze out scenarios, the pre-lens drug concentration is greater than that of the post-lens. Here p=0\ud835\udc5d0p=0italic_p = 0 and klid=0subscript\ud835\udc58lid0k_{\\rm lid}=0italic_k start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT = 0.\nIn order to compare to the results of Section 6, where eyelid absorption was ignored, we set klid=0subscript\ud835\udc58lid0k_{\\rm lid}=0italic_k start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT = 0 and repeat the hand-tuned fitting for the slide out and squeeze out cases with p=0\ud835\udc5d0p=0italic_p = 0.\nDetails are shown in Figure\u00a018.\nWe also find ranges of parameter values that give reasonable fits with which to compare to the large diffusion limit scenario. The majority of drug loss will be due to either the slide out or squeeze out mechanism, and a small amount of drug will remain in the pre- and post-lens tear films.\nIn the slide out case, the slide out amount \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT is larger for both lenses as compared to the version of the model with klid\u22600subscript\ud835\udc58lid0k_{\\rm lid}\\neq 0italic_k start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT \u2260 0, as expected. We repeat for the squeeze out case. The depression amount \u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT is larger than the model with klid\u22600subscript\ud835\udc58lid0k_{\\rm lid}\\neq 0italic_k start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT \u2260 0, as in the slide out case. The blink pressures corresponding to \u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT are 53.6 Pa and 227 Pa for the etafilcon A and senofilcon A lenses. As a final example, we now study partial pre-lens drug loss (0<p<10\ud835\udc5d10<p<10 < italic_p < 1) so that a fraction of the drug in the pre-lens is swept away with each blink. We investigate the cases of post-lens slide out or squeeze out. Our comparison with the Phan et al. experimental data is shown in Figure 19. We study both the squeeze out and slide out contact lens motion scenarios and use p=0.002\ud835\udc5d0.002p=0.002italic_p = 0.002. We set klid=0subscript\ud835\udc58lid0k_{\\rm lid}=0italic_k start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT = 0 in order to compare with the large diffusion limit setting (see open circles plotted in the\nlower two plots of Figure\u00a09 and Figure\u00a010). The blink pressures corresponding to the values of \u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT used are 29.7 Pa and 41.7 Pa for the etafilcon A and senofilcon A lenses. The results that we have identified for the drug release in the vial setting follow approaches commonly used in various related studies. The experimental vial setting, typically by design, is one well-described by the so-called perfect sink conditions, which we also think of as a max flux situation. With known geometrical properties of the lens (e.g. surface area and lens thickness) along with known initial drug content in the contact lens, if one assumes one dimensional Fickian diffusion in the contact lens, then only the diffusion coefficient remains to be determined\nto characterize drug release dynamics. This perfect sink setting has contact\nlens drug concentration C=0\ud835\udc360C=0italic_C = 0 at the lens boundaries (corresponding to K\u2062Cvial\u22480\ud835\udc3esubscript\ud835\udc36vial0KC_{\\rm vial}\\approx 0italic_K italic_C start_POSTSUBSCRIPT roman_vial end_POSTSUBSCRIPT \u2248 0). The drug release prediction for the vial setting under perfect sink conditions actually gives a first prediction one might contemplate for drug release during contact lens wear. Specifically, if one assumes in the lens that C=0\ud835\udc360C=0italic_C = 0 at the boundaries with the pre-lens and post-lens tear films (obtained, for example, by assuming that K=0\ud835\udc3e0K=0italic_K = 0), then the drug release prediction for this case is exactly that of the vial release. That is, if one assumes perfect sink conditions\napply in the eye model, then the contact lens releases the drug at a rate independent of any processes external to it.\nIn this extreme limit of the in vitro eye model there is no chance for the drug that reaches the pre-lens or post-lens regions to return to the lens, as the flux term D\u2062\u2202C/\u2202z\ud835\udc37\ud835\udc36\ud835\udc67D\\partial C/\\partial zitalic_D \u2202 italic_C / \u2202 italic_z will never be directed into the contact lens. For this case, the comparison to experimental measurements is shown in Figure 20. We use hpreinit=hpostinit=5\u2062\u03bcsuperscriptsubscript\u210epreinitsuperscriptsubscript\u210epostinit5\ud835\udf07h_{\\rm pre}^{\\rm init}=h_{\\rm post}^{\\rm init}=5\\ \\muitalic_h start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT = italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT = 5 italic_\u03bcm, JE=0subscript\ud835\udc3d\ud835\udc380J_{E}=0italic_J start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT = 0, and the diffusion coefficient is set at the vial setting value. In both the etafilcon A and senofilcon A cases, the differences between model eye and vial solutions are very small. The cumulative drug release predicted by the eye model is the same independent of squeeze out, slide out, or no contact lens motion options. The choice of hand-tuned model parameters has no effect on the cumulative drug release.\nDue to its larger diffusion coefficient, the etafilcon A lens releases essentially all of the drug, whereas a non-negligible concentration profile is maintained for the senofilcon A lens.\nClearly this simple prediction for contact lens drug release for the eye model does not conform with experimental observations, as is seen from the work of Phan et al. [21]. This observation is the basis for the models developed in the current work and our objectives have been to identify\npossible mechanisms associated with processes external to the contact lens \u2013 in the pre-lens and/or the post-lens tear film along with consequences associated with blinking \u2013 that\ncan provide possible explanations for experimental observations. In that direction we have identified several mechanisms in the pre-lens tear film and post-lens tear film that suggest further exploration. The easiest way to explore potential drug release pathways through the pre-lens tear film is to shut off substantial drug\ntransport pathways into and through the post-lens tear film. We have accomplished this in our studies by assuming\nthat no contact lens motion occurs, so that no drug mass is lost out of the post-lens tear\nfilm through either the slide out or squeeze out mechanisms. With a partition coefficient balance applied at the contact lens/post-lens boundary given by C\u2062(z=0,t)=K\u2062Cpost\ud835\udc36\ud835\udc670\ud835\udc61\ud835\udc3esubscript\ud835\udc36postC(z=0,t)=KC_{\\rm post}italic_C ( italic_z = 0 , italic_t ) = italic_K italic_C start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT, the concentration in the post-lens is held in check by the concentration\nin the contact lens. In particular, with nonzero K\ud835\udc3eKitalic_K, having found K=\ud835\udcaa\u2062(1)\ud835\udc3e\ud835\udcaa1K={\\cal O}(1)italic_K = caligraphic_O ( 1 ) for both lens types, total drug mass in the post-lens is essentially limited by Cinit\u2062Vpost/Ksuperscript\ud835\udc36initsubscript\ud835\udc49post\ud835\udc3eC^{\\rm init}V_{\\rm post}/Kitalic_C start_POSTSUPERSCRIPT roman_init end_POSTSUPERSCRIPT italic_V start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT / italic_K. Typically Vpost\u226aVclmuch-less-thansubscript\ud835\udc49postsubscript\ud835\udc49clV_{\\rm post}\\ll V_{\\rm cl}italic_V start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT \u226a italic_V start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT; this suggests only a small amount of the total drug mass can be present in the post lens at any given time, and if none is removed\nby a slide out or squeeze out type mechanism, this pathway is essentially turned off. It is\nimportant to remember that in\nclinical applications, unlike the Phan et al. [21] experiments, the drug\ncan permeate into the cornea, thereby providing a drug pathway out of the post-lens with or without contact lens motion. Then, under these conditions drug mass loss is dominated by pre-lens drug pathway mechanisms.\nIn this context we have made two key observations. First, we examine the assumption that each blink removes all pre-lens drug mass as fresh tear fluid replaces the old after each blink (p=1\ud835\udc5d1p=1italic_p = 1). In this case where p=1\ud835\udc5d1p=1italic_p = 1, the senofilcon A lens cumulative drug release is reasonably\nwell matched, but\nthe corresponding prediction for etafilcon A\nis nowhere near the experimental data.\nAlthough it is possible that neither\nlens moves significantly as a result of a blink, there is no clear reason why a blink would completely replenish the tear fluid on one lens but not the other. Any lens motion would only increase the drug release rate through post-lens pathways. Second, as a consequence of a blink, it is possible that\nonly a portion 0<p<10\ud835\udc5d10<p<10 < italic_p < 1 of\nthe pre-lens tear fluid drug mass is washed away. Our large\ndiffusion limit results suggest that only a tiny amount of drug\nloss (p=\ud835\udcaa\u2062(10\u22123)\ud835\udc5d\ud835\udcaasuperscript103p={\\cal O}(10^{-3})italic_p = caligraphic_O ( 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT )) is allowed in order to match the Phan et al. cumulative drug release data.\nIn the full model simulations it appears that larger values of p\ud835\udc5dpitalic_p are allowed; as noticed\nfor the senofilcon A lens with\nno post-lens drug loss, this seems to include values up to p=1\ud835\udc5d1p=1italic_p = 1. The application of a no-flux boundary condition closes off any drug pathways through the pre-lens tear film and necessarily requires some type\nof post-lens pathway. A softening of this condition is possible via a more detailed\ntreatment of the tear film and evaporation effects.\nFor example, evaporation could remove the tear film by some intermediate time through the interblink, rather than immediately as the no-flux condition would mimic. This type of modulated no-flux effect could partially limit the pre-lens drug loss pathways. We plan to explore this in future work. In a similar manner to our investigation of pre-lens drug transport mechanisms,\nit is easiest to imagine cases in which pre-lens mechanisms are shut off by way of the boundary condition imposed at the lens/pre-lens interface. We use either no-flux, so that no drug mass reaches the pre-lens tear film,\nor the partition coefficient balance but with p=1\ud835\udc5d1p=1italic_p = 1, so that no drug mass is removed from the pre-lens as the result of a blink. Under these pre-lens conditions and for reference post-lens thicknesses within a clinically-reasonable range, there appear to be both slide out and squeeze out mechanisms with feasible parameter values in terms of translational lens motion (\u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT) or post-lens thickness depression (\u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT). As noted earlier, in the Phan et al. experimental system there is no drug transport into the cornea;\nin clinical settings with an open drug pathway to the cornea, the rate at which this occurs will factor into the overall drug release dynamics. We have not included a drug pathway through the post-lens to the eyelid within the framework of our present model. Such pathways could be included with a more detailed model of the eye and the incorporation of compartments outside of the lens periphery and under the eyelids. This is a consideration for future work. Our models make simplifying assumptions to connect to available experimental data; future work could explore modifications of all parts of the model including the contact lens, the pre-lens tear film, the post-lens tear film, as well as other compartments (e.g.\u00a0eyelid, cornea).\nOne could focus on a more realistic characterization of diffusion, absorption, blinking, lens properties, and tear film dynamics. Our models assume linear diffusion, but could be modified to allow for specific adsorption to the contact lens. Following [27], we could modify equation\u00a0(7) to differentiate between adsorption of protein to the polymer in the contact lens and the protein in the liquid-filled spaces.\nIn our model,\nthe post-lens thickness\nremains constant during the interblink since we have assumed that all lens motion occurs during the blink only.\nOne extension in the squeeze out case is to consider a restoring force after a blink that partially returns the post-lens thickness to its pre-blink height. The restorative rate could be found by knowing the elastic parameters for the lenses, or by knowing the time scale and assuming we return to hpostsqueezesuperscriptsubscript\u210epostsqueezeh_{\\rm post}^{\\rm squeeze}italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_squeeze end_POSTSUPERSCRIPT exactly after each blink. The models by Chauhan & Radke [65] and Maki & Ross [66, 67] for elastic response could serve as a starting point. Since eyelid absorption has not been previously modeled to the best of our knowledge, our formulation relies on simple assumptions and motivation from the experimental data in [21]. Our reset condition removes a fraction p\ud835\udc5dpitalic_p of pre-lens drug concentration via the blink, and our simulations suggest that p\ud835\udc5dpitalic_p is fairly small. This seems reasonable given what is known about the residence time of drugs delivered via eye drops; the extremes p=0\ud835\udc5d0p=0italic_p = 0 and p=1\ud835\udc5d1p=1italic_p = 1 would not be practical assumptions in such a context. An interesting alternative model may be to treat eyelid absorption as a transient mechanism and calculate the mass absorbed at each blink. The framework of Frasch & Barbero [73] can be adapted to model eyelid absorption as a reset condition. They assume a constant concentration is applied on the (pre-lens/eyelid) interface for 0<t<\u0394\u2062tblink0\ud835\udc61\u0394subscript\ud835\udc61blink0<t<\\Delta t_{\\rm blink}0 < italic_t < roman_\u0394 italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT and a max flux condition for the eyelid for t>\u0394\u2062tblink\ud835\udc61\u0394subscript\ud835\udc61blinkt>\\Delta t_{\\rm blink}italic_t > roman_\u0394 italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT, as we do in our model.\nFor multiple transient events (blinks), total drug mass accumulation is\nm\u221e=klid\u2062Alid\u2062\u0394\u2062tblink\u2062\u2211ti=0TfCpre\u2062(tblink\u2212),subscript\ud835\udc5asubscript\ud835\udc58lidsubscript\ud835\udc34lid\u0394subscript\ud835\udc61blinksuperscriptsubscriptsubscript\ud835\udc61\ud835\udc560subscript\ud835\udc47\ud835\udc53subscript\ud835\udc36presuperscriptsubscript\ud835\udc61blinkm_{\\infty}=k_{\\rm lid}A_{\\rm lid}\\Delta t_{\\rm blink}\\sum_{t_{i}=0}^{T_{f}}C_{%\n\\rm pre}(t_{\\rm blink}^{-}),italic_m start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT = italic_k start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT roman_lid end_POSTSUBSCRIPT roman_\u0394 italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT \u2211 start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT roman_pre end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ) ,\nwhere Tfsubscript\ud835\udc47\ud835\udc53T_{f}italic_T start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT is a final time. It is worth noting that our numerical implementation does not include a \u0394\u2062tblink\u0394subscript\ud835\udc61blink\\Delta t_{\\rm blink}roman_\u0394 italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT between interblinks; the computational time domain does not take this into account. This means that the blink is occurring in the last fraction of a second of an interblink computation time period. Diffusion should be mostly independent of this \u0394\u2062tblink\u0394subscript\ud835\udc61blink\\Delta t_{\\rm blink}roman_\u0394 italic_t start_POSTSUBSCRIPT roman_blink end_POSTSUBSCRIPT period, but there is a small effect to the pre-lens that we ignore. In fact, by this numerical implementation, there is diffusion of drug from the contact lens into the pre-lens during the blink that is perhaps at odds with the reset condition that assumes (when p=1\ud835\udc5d1p=1italic_p = 1) that all drug is swept from the pre-lens by the blink. Therefore, we may be slightly overestimating the actual amount of diffusive drug transport from the contact lens into the pre-lens. We acknowledge the balance sought in our work between proposing a realistic model, which often requires additional complexity such as spatial variation across the cornea, with the practical identifiability of model components from comparison to experimental data.\nAs one example, our model does not explicitly account for friction or lubrication of the eyelid/tear film interface. As a simplification, one can view friction as rolled into the \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT slide out parameter. As one goal of this paper was to compare with and explain a single output metric from Phan et al. [21], we chose a simple form for this element of the model in the context of available data. Perhaps more to the point, discussion of lubrication is absent from the Phan  et al. paper, and so it may be most appropriate to ignore friction here. Future work could extend the model to consider friction and propose a lipid layer or other lubricating film on the tear film/eyelid interface. In this study we have developed a mathematical model for the prediction of drug transport out of a contact lens during many hours of wear (over 8000 blinks). We are able to make predictions about cumulative drug loss from the contact lens and assess drug lost via different pathways through the pre-lens tear film, post-lens tear film, and into adjoining regions such as the eyelid. Our general model includes a pathway into the cornea, but as we have focused our comparison on the experimental data of Phan et al. [21] for which there is no uptake of drug into the eye, we have not addressed this aspect in our simulations. Our full model handles each blink by applying reset conditions on the various parameters. These reset conditions encode various drug loss mechanisms such as pre-lens drug loss via fresh supply of tear fluid and post-lens drug loss due to contact lens motion that generates fluid transport via slide out\n(Couette-type flow) and squeeze out (squeeze film flow) mechanisms. We have also analyzed a simplified model that applies to a large diffusion limit in which by the end of the\ninterblink, the contact lens concentration is assumed to have reached an equilibrium (spatially uniform) profile. The model in this limit can be solved analytically and has provided predictions that we used to validate the full numerical simulations. The large diffusion limit model offers analytical expressions that predict\nthe \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT or \u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT values in terms of the other system parameters and, as such, provide at least\nrough guidelines for parameter values that can be difficult to measure directly. Although the diffusion coefficient range characteristic of this limit is not well-matched by our numerical estimates for either contact lens in the study, the simplified model predictions agree qualitatively with the full model simulations. By setting our parameter p=1\ud835\udc5d1p=1italic_p = 1 to model all drug being swept out of the pre-lens by a blink, we are unable to match the cumulative drug release data from Phan et al. [21] for the etafilcon A lens, regardless of contact lens motion option (see Figure 13). This shows that some fraction of drug must remain in the pre-lens after a blink in order to explain the observed eye model release data. By using a no flux condition on the pre-lens side, we can match the cumulative release data for both lenses. However, we cannot replicate eyelid absorption, as the no flux condition shuts off our only drug pathway to the pre-lens. We find that the full model with either the slide out or squeeze out option can replicate both the cumulative drug release data over time and the final time eyelid absorption measurement. The hand-tuned values of \u0394\u2062Xcl\u0394subscript\ud835\udc4bcl\\Delta X_{\\rm cl}roman_\u0394 italic_X start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT in the slide out case fall near or within experimental ranges [64, 63, 71, 72], and the values of post-lens thickness depression \u0394\u2062hpost\u0394subscript\u210epost\\Delta h_{\\rm post}roman_\u0394 italic_h start_POSTSUBSCRIPT roman_post end_POSTSUBSCRIPT in the squeeze out case correspond to reasonable blink pressures\nprimarily in the range \ud835\udcaa\u2062(0.1)\ud835\udcaa0.1{\\cal O}(0.1)caligraphic_O ( 0.1 ) kPa \u2013 \ud835\udcaa\u2062(1)\ud835\udcaa1{\\cal O}(1)caligraphic_O ( 1 ) kPa\n(see Talbott et al.\u00a0[74] Section 3 and references therein). Further, our hand-tuned eyelid permeability constant values fall within experimental ranges for rat models [53]. The results from the no lens motion version of the full model suggest that this option may not be physically observed, as the final time eyelid value and cumulative drug release data cannot be simultaneously replicated by the model output. We expect that the model and its several variations that we have presented here should serve as a valuable framework under which further mathematical and computational models can be developed and tested. Further predictions of this and future models should be able to guide understanding of transport from\ndrug-eluting contact lenses to various target tissues for treatment of different ophthalmic conditions. On behalf of all authors, the corresponding author states that there is no conflict of interest. DMA and RAL note that our initial exploration into contact lens drug delivery modeling came during the week-long Graduate Student Mathematical Modeling Camp held at the University of Delaware in June 2019. We would particularly like to acknowledge the organizers of that camp as well as the other members of the contact lens modeling group."
    },
    {
        "id": 17,
        "title": "Randomized Control in Performance Analysis and Empirical Asset Pricing",
        "corpus": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on. Authors: achieve the best HTML results from your LaTeX submissions by following these best practices. The present article explores the application of randomized control techniques in empirical asset pricing and performance evaluation. It introduces geometric random walks, a class of Markov chain Monte Carlo methods, to construct flexible control groups in the form of random portfolios adhering to investor constraints. The sampling-based methods enable an exploration of the relationship between academically studied factor premia and performance in a practical setting. In an empirical application, the study assesses the potential to capture premias associated with size, value, quality, and momentum within a strongly constrained setup, exemplified by the investor guidelines of the MSCI Diversified Multifactor index. Additionally, the article highlights issues with the more traditional use case of random portfolios for drawing inferences in performance evaluation, showcasing challenges related to the intricacies of high-dimensional geometry. This paper examines the use of randomized control techniques in empirical asset pricing and performance evaluation from various perspectives, including economic, mathematical, and computational considerations. The investigation addresses the role of controlled chance as a tool for performance evaluation and emphasizes the substantial influence of design on inference. A novel approach to both, the design and application of randomized controls is presented. This new methodology serves to evaluate the performance and risk drivers of systematic investment strategies, i.e., portfolios that exhibit certain quantifiable characteristics by construction. Examples of such inherent characteristics include exposures towards classical factors such as size111Stocks with lower market capitalization tend to outperform stocks with a higher market capitalization in the future. [9], value222Stocks that have a low price relative to their fundamental value, commonly tracked via accounting ratios like price to book or price to earnings outperform high-value stocks. [109], momentum333Stocks that have outperformed in the past tend to exhibit strong returns going forward. [60] or quality444Stocks which have low debt, stable earnings, consistent asset growth, and strong corporate governance, commonly identified using metrics like return to equity, debt to equity, and earnings variability. [6]. We introduce a way to construct random controls that account for investor constraints, including but not limited to upper bounds, short-selling restrictions, risk limits, and tolerances on factor exposures, which allows to analyze the relationship between portfolio characteristic and portfolio performance within stringent investment guidelines. The suggested approach roots in geometric random walks, a special class of (continuous) Markov Chain Monte Carlo (MCMC) methods. Further, a geometric perspective will help to categorize random controls into one of three groups based on the type of constraints that are to be mapped and on the notion of randomness. Given the portfolio context, a randomized control group is hereafter referred to as a random portfolio (RP). RPs are commonly utilized within the domain of performance evaluation, an area closely aligned with the intended application scope we are proposing. In the ensuing discourse, we shall integrate this domain. However, it will become apparent that employing RPs for purposes of performance comparisons is fraught with complexities. From our perspective, insufficient attention has been directed toward these challenges in the past. Conversely, RPs prove valuable for examining the relation between systematic portfolio features and performance within real-world scenarios. In particular, the suggested RP framework based on geometric random walk enables an examination of factor effects within a constrained setup and has the capacity to unveil non-linear and asymmetric relations, if such exist, not only between characteristics and returns but also between characteristics and risks. As such, RPs constitute a novel technique for exploring asset pricing puzzles that is more versatile than classical sorting-based approaches going back to (at least)\u00a0[42]. Further, RPs can be designed to closely resemble a strategy of interest in all aspects, except for one particular characteristic in question, which enables an isolated analysis of the implication of that specific characteristic. Formally, a RP is a real-valued random vector, denoted \u03c9\ud835\udf14\\omegaitalic_\u03c9,\nhaving a probability density function (pdf) \u03c0\ud835\udf0b\\piitalic_\u03c0 with bounded support \ud835\udca6\u2282\u211dn\ud835\udca6superscript\u211d\ud835\udc5b\\mathcal{K}\\subset\\mathbb{R}^{n}caligraphic_K \u2282 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K is shaped by investor-imposed constraints and geometrically forms a convex body (which we will explore in detail later on). The components of \u03c9\ud835\udf14\\omegaitalic_\u03c9 represent the proportions of potential monetary allocations to n\ud835\udc5bnitalic_n investable assets, i.e., the random portfolio weights. Our primary interest is on statistics derived from the random weights, i.e., the RP\u2019s risk, return and characteristic, where the latter typically comes in the form of a factor score. Performance statistics and characteristics are functions of the random weights and of the coefficients obtained from market observations. Consider the following example. Let \u03b8=(\u03bc,\u03c3)\ud835\udf03\ud835\udf07\ud835\udf0e\\theta=(\\mu,\\sigma)italic_\u03b8 = ( italic_\u03bc , italic_\u03c3 ) be the vector of performance parameters, the mean \u03bc\ud835\udf07\\muitalic_\u03bc and standard deviation \u03c3\ud835\udf0e\\sigmaitalic_\u03c3 of a RP; both are (scalar) random variables.\nAt any point in time t\ud835\udc61titalic_t, we may estimate the parameters as \u03bct=\u27e8\u03c9,rt\u27e9subscript\ud835\udf07\ud835\udc61\ud835\udf14subscript\ud835\udc5f\ud835\udc61\\mu_{t}=\\langle\\omega,r_{t}\\rangleitalic_\u03bc start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = \u27e8 italic_\u03c9 , italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u27e9, where rtsubscript\ud835\udc5f\ud835\udc61r_{t}italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the vector of sample mean returns and \u03c3t=\u03c9\u22a4\u2062\u03a3t\u2062\u03c9subscript\ud835\udf0e\ud835\udc61superscript\ud835\udf14topsubscript\u03a3\ud835\udc61\ud835\udf14\\sigma_{t}=\\omega^{\\top}\\Sigma_{t}\\omegaitalic_\u03c3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_\u03c9 start_POSTSUPERSCRIPT \u22a4 end_POSTSUPERSCRIPT roman_\u03a3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_\u03c9, where \u03a3tsubscript\u03a3\ud835\udc61\\Sigma_{t}roman_\u03a3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the sample covariance matrix of securities\u2019 returns measured at t\ud835\udc61titalic_t over a specific period of stock market history. The distribution of \u03b8tsubscript\ud835\udf03\ud835\udc61\\theta_{t}italic_\u03b8 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, estimated at a given point in time t\ud835\udc61titalic_t, serves as a representation of the potential outcomes in terms of the specified performance measures, that could have been achieved over a preceding period, considering a pre-defined universe of investable assets and constraints imposed by investors. This set of counterfactual results and the corresponding probability measure provides a basis for two kinds of inferences. An option is to employ the performance distribution of the RP as a benchmark for comparing and statistically testing performance. It has been put forward as the null distribution of performance outcomes under the assumption of no skill, thereby framing performance evaluation as a hypothesis testing problem. This is the typical use case endorsed in the literature, see e.g., [121], [87], [70].\nIn the sequel, we demonstrate that this case subsumes the bootstrap approach of Efron\u00a0[40], which appears frequently in the context of performance analysis, as a particular instance of a RP. The advantage of a general RP-based analysis over simple resampling procedures is that the former offers the possibility to incorporate investor constraints. This addresses limitations associated with classical benchmark or peer group comparisons which have faced criticism for their susceptibility to biases, such as the inclusion of investment styles that do not align with the strategy of interest or for constituting portfolios that fall outside the investor\u2019s specified constraints (see e.g., [121]). The narrative supporting the RP-based performance evaluation approach primarily relies on the following two conjectures: (i) A RP forms an obvious choice of control for performance analysis as, by design, it incorporates no penchant to any investment strategy; any portfolio structure is just as likely to occur as any other, and (ii) For (i) to hold, random weights need to follow a uniform distribution over the domain of feasible allocations. Both claims are flawed; even though they are intuitively appealing and despite their many appearances in the literature (we refer the reader to the literature review in Section\u00a01.2). First, the idea that a RP is \u201danalogous to an enumeration of all feasible portfolios\u201d [70] is misleading. Although the domain is defined such as to enclose all feasible portfolios, the probability measure over the domain strongly concentrates over a thin shell of typical allocations (the high-volume area of the domain) under a uniform distribution. This concentration phenomenon arises from the intricacies of high-dimensional geometry, which we will discuss in more details in the sequel. Second, the idea that a RP \u201cby construction incorporates no investment strategy, bias or skill\u201d [36] is subject to interpretation and depends on whether one views the capitalization-weighted or the equal-weighted portfolio as the unbiased and unskilled reference (see the discussion in Section\u00a02.1). These two drawbacks lead us to conclude that the use of RP-based statistical significance tests to evaluate the (over- or under-) performance of a particular investment strategy is not appropriate. As a purely descriptive tool, however, we consider RP-based analysis to be valuable, as exemplified in the subsequent Section. The second use case, a novel concept in our understanding, pertains to exploit a RP for detecting and assessing asset pricing anomalies within real-world scenarios. Specifically, this entails exploring the interplay between factor exposure and the performance of portfolios that adhere to investor guidelines. At a time t\ud835\udc61titalic_t, the factor exposure of the RP is given by \u03b3t,h=\u27e8\u03c9,\u03b2t,h\u27e9subscript\ud835\udefe\ud835\udc61\u210e\ud835\udf14subscript\ud835\udefd\ud835\udc61\u210e\\gamma_{t,h}=\\langle\\omega,\\beta_{t,h}\\rangleitalic_\u03b3 start_POSTSUBSCRIPT italic_t , italic_h end_POSTSUBSCRIPT = \u27e8 italic_\u03c9 , italic_\u03b2 start_POSTSUBSCRIPT italic_t , italic_h end_POSTSUBSCRIPT \u27e9, where \u03b2t,hsubscript\ud835\udefd\ud835\udc61\u210e\\beta_{t,h}italic_\u03b2 start_POSTSUBSCRIPT italic_t , italic_h end_POSTSUBSCRIPT represents a cross-sectional vector of factor exposures of the firms in the investment universe. These asset-level exposures are (standardized) regression coefficients obtained by regressing the firm\u2019s return series on the series of a factor fhsubscript\ud835\udc53\u210ef_{h}italic_f start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT where the factor is a long-short portfolio formed by sorting stocks according to attribute h\u210ehitalic_h.\nAlternative to regression coefficients, company-specific characteristics could be used, e.g., fundamentals like a firm\u2019s market capitalization or it\u2019s balance sheet ratios. In accordance with the procedure of the index provider MSCI555https://www.msci.com/, which serves as the basis for our practical application presented in the empirical part (Section 5), we will sometimes employ the term (factor) score to be generic. Ultimately, we are interested in estimating the conditional distribution of \u03b8t|\u03b3t,hconditionalsubscript\ud835\udf03\ud835\udc61subscript\ud835\udefe\ud835\udc61\u210e\\theta_{t}|\\gamma_{t,h}italic_\u03b8 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_\u03b3 start_POSTSUBSCRIPT italic_t , italic_h end_POSTSUBSCRIPT, which elucidates the interrelation between portfolio score and performance. Factor scores can also form part of the constraints which define the RP, especially those not integral to the investigated investment style of interest. This grants the researcher complete control over the management and assessment of potentially confounding variables. In Section\u00a05, we will employ this approach to examine the persistence of well-studied factor premia in a practical setting. We would like to stress that our suggested use of RPs is not intended to establish causal relationships. Instead, it aims to identify statistical associations between variables and to evaluate the performance of different investment strategies under various conditions. We therefore pay attention not to confuse between causation and association. The latter is a statistical relationship between two variables, a conditional probability \u2119\u2062(Y|X)\u2119conditional\ud835\udc4c\ud835\udc4b\\mathbb{P}(Y|X)blackboard_P ( italic_Y | italic_X ), while the former means that the exposure produces the effect. Our approach thus distinguishes from the typical application of randomized control in experimental designs like, for instance, pharmaceutical studies, which aim to isolate causal effects by splitting subjects into treatment and control groups.666As stressed in [37], illuminating the causal nature of things requires more than just an experimental setup for testing but begins with a theory that outlines the causal mechanism(s) which are experimentally falsifiable.\nIn Section\u00a05, we emphasize that our use of a randomized control is not to compare treated and non-treated groups, but rather to differentiate portfolios with and without a specific characteristic. Also, it is not our intention to advocate RPs as a panacea to solve asset pricing puzzles. Rather, we view them as a valuable addition to the arsenal of statistical tools for performance related questions in financial economics. However, it is important to acknowledge the complexities involved in generating RPs that accurately reflect real-world constraints. In a first instance, RPs are theoretical constructs, and the key question is whether one can effectively determine the distribution of performance measures or portfolio characteristics for inferential purposes. In most cases of practical relevance, analytical solutions are not feasible, and we must resort to numerical techniques to obtain the desired results. Our contributions within this article are fourfold.\nFirst, we clarify the inherent challenges associated with the conventional practice of utilizing RPs for performance assessment (Section 2).\nSecond, we introduce an alternative use case focused on examining asset pricing anomalies within constrained scenarios. This use case is demonstrated in Sections\u00a02 and 4.\nThird, we provide an extensive exposition of technical methodologies for generating RPs, covering both exact and approximate sampling-based solutions within a common geometric framework (Sections 3 and 5). Specifically, we introduce geometric random walks, a class of continuous MCMC methods tailored for high-dimensional constrained scenarios from computational geometry, as an instrument to create a randomized control which is useful to evaluate asset pricing anomalies within constrained setups. We survey all existing random walks, examining the algorithms from both theoretical and practical perspectives, and include complexity results.\nLastly, we present an efficient open-source implementation in C++ with an interface in R (Sections 5 and 5.2), facilitating performance analysis via RPs with ease. With this software, assuming the reader has access to the Wharton Research Data Services (WRDS), our empirical research is fully reproducible. Ever since the claim of the economist Burton Malkiel [95] that \u201ca blindfolded monkey throwing darts at a newspaper\u2019s financial pages could select a portfolio that would do just as well as one carefully selected by experts\u201d the concept of a RP has been used to probe investment skill. Most prominently, the Wall Street Journal\u2019s Dartboard Contest, a monthly column published by the business newspaper between 1988 and 2002, put Malkiel\u2019s claim to the test by letting their staffers (acting as the allegoric monkeys) literally throw darts at a stock table, while investment experts picked their own stocks, always for a holding period of six months777Prior to January 1990, the holding period was for one month. The extension to six months was made to alleviate a possible bias from the price pressure resulting from the announcement effect.. If nothing else, the game added another animal symbolism to the jargon at Wall Street, emblematic in the ongoing debate on active versus passive management and the underlying hypothesis on market efficiency. While the results of the game are not informative, the experimental design, or rather, its deficiencies contain meaningful learnings about the use of a randomized control for research in finance. Several academic studies have examined the game pointing out biases like expert\u2019s tilt towards high risk stocks\u00a0[101], low dividend888Performances were computed on price series rather than on total return series, thus ignoring the effect of dividends and arguably incentivizing professionals to pick stocks with high growth opportunities. yield stocks\u00a0[85] and high momentum stocks\u00a0[108]. From a procedural aspect, the dartboard game forms an educative example of what we call a naive RP (a formal definition follows in Section 3.1) and sampling from it boils down to a bootstrap exercise in the spirit of [40]. Such bootstrap-like use of RPs is very common in the financial literature. One of the earliest reports we could find is [31] who used a bootstrap-type of RP in the analysis of mutual fund performances. Dedicated articles to the topic of RP-based performance analysis are [120], [121], [36], [16], [87], [13], [119], [70] and [79]. All articles advocate the benefits of RP-based performance evaluations over traditional approaches and implicitely or explicitely promote the idea to view performance evaluation as a hypothesis test. In\u00a0[121] they argue that traditional performance evaluation methods used by the finance community, namely peer group and benchmark comparisons, suffer from inevitable biases and should be replaced by Monte Carlo approaches. In\u00a0[70] they point towards inefficiencies of simulation-based methods and propose a closed-form expression for the probability distribution of the Sharpe ratio of a uniformly distributed RP. Another analytical procedure based on a geometric algorithm was suggested in [19] and applied in [18] and\n[21],\nagain imposing a uniform distribution for a otherwise unconstrained long-only RP. To our knowledge, there is currently no prior literature offering guidance on the creation of a RP with a well-defined distribution within a constrained domain. Concerning geometric random walk methods, which we posit fill the identified gap, their origin traces to a substantial body of literature which has explored sampling methods for generating randomized approximations to the volumes of polytopes and other convex bodies [39, 88, 89, 35]. Geometric random walk methods possess a distinct lineage compared to the more conventional MCMC methods widely employed in finance, particularly within Bayesian frameworks for approximating posterior distributions. The uniqueness of geometric random walk methods lies in their specialization for approximating distributions characterized by a bounded support. Geometric random walks have numerous application, including computational biology and medical statistics, where they play an important role in metabolic network studies [122, 107, 53]. Additionally, geometric random walks prove useful in solving convex programs [11, 64] and mixed integer convex programs [57]. Financial texts that use geometric random walk routines are sparse. In [29] they use a geometric random walk algorithm to optimize portfolios under qualitative input. To the best of our knowledge, the only text to use geometric random walk for performance analysis is [8]. The progress towards algorithms for volume computation, random sampling, and integration has developed deep connections between high-dimensional geometry and the efficiency of algorithms and shaped our understanding of convex geometry. Literature on those aspects include\n[127],\n[35],\n[131],\n[97]. Further important work on geometric random walk sampling include\n[117],\n[88],\n[89],\n[65] and\n[92].\nReferences to the source literature of existing geometric random walk routines are given in Section 4. The remainder of this article is structured as follows. Section 2 contextualizes random portfolios within the realm of performance analysis and factor analysis. In Section 3, we delve into the problem of RP generation from a geometric perspective. Following that, Section 4 explores geometric random walk methods for constructing RPs tailored to address complex real-world scenarios. This Section provides an overview of possible algorithms, accompanied by descriptions of their properties and complexity, with a focus on their programmatic implementation. Subsequently, Section 5 presents empirical experiments using a geometric random walk-based RP to investigate the relationship between factor tilts and performance within the framework of the MSCI Diversified Multifactor index, which we consider representative of a typical setup. Finally, Section 5.4 concludes. To characterize RP\u2019s in a performance evaluation and asset pricing context, we briefly review some classical performance analysis methods. Performance evaluation is inherently relative.\nThe capitalization-weighted benchmark-relative perspective, arguably predominant in both industry and academia, has deep roots in economic theory, e.g., [115], [86], [102], and forms the blueprint for classical performance analysis. In this context, the available tools try to identify sources of excess returns and to attribute them to active bets undertaken by the portfolio manager. Holdings-based or transaction-based performance attribution tools in the line of [14] (but applied to equity-only portfolios), building upon the work of [38] and [1], are widely employed in the industry. This is so because of their explanatory power to simultaneously outline the difference in the allocation structure between a portfolio and a benchmark by grouping stocks into easily interpretable categories like countries, sectors or currencies, and to quantify the individual contributions to overall performance coming from the allocation differences among and within the pre-defined categories. The determinants of portfolio performance [15] are however not to be understood in an etiological sense. Unless the categories, according to which the attribution is done, effectively correspond to deliberate bets undertaken by the portfolio manager which characterize the strategy, allocation and selection effects do not cause over- or underperformance. They can be seen as residuals, meaning that the strategy may generate these effects while pursuing other objectives. They can only identify what we may refer to as the \u201dcausa proxima\u201d, the immediate cause, while the \u201dcausa remota\u201d, the remote and perhaps indirect cause, which is encoded in the strategy and ultimately leads to the performance delta, remains unexplored.\nFor instance, the underperformance of a minimum variance strategy following the 2022 energy crisis might be attributed to the strategy\u2019s underweighting of the energy sector. However, it is not an inherent characteristic of minimum variance strategies to avoid investments in the energy sector. Rather, the strategy may not have selected energy-related firms due to the high volatility of stocks in that industry in response to the external shock. Thus, the cause of the performance difference is only superficially due to the sector performance but roots in the underlying variance minimizing mechanism that leads to the tendency of avoiding high-volatility assets regardless of their origin or sector. Another school of performance evaluation, initiated by [44], subsumed under the term return- or factor-based models, uses regressions to break down observed portfolio returns into a part resulting from a manager\u2019s ability to pick the best securities at a given level of risk and a part which is attributable to the dynamics of the overall market as well as to that of further risk factors which are recognized to explain security returns and are associated with a positive premium. This allows for an assessment as to whether the active performance is attributable to a particular investment style. While the Brinson-type of performance attribution is purely descriptive, the regression setup goes beyond simple performance measurement as it allows for statistical inference in terms of significance testing of the out- or underperformance (alpha) and the loadings on other return drivers (betas) and therefore provides a basis for normative conclusions (assuming that the usual assumptions for linear regression are met). A skilled manager should be able to beat the market (factor) in a statistically significant manner after controlling for alternative betas. In this sense, skill is reserved to the active manager who is able to harvest a positive return premium not explained by known factors. Any benchmark replicating strategy, since it involves no active deviation from the capitalization-weighted allocation structure in a market, is therefore called passive and comes with performance expectations which should match the performance of a market index rather than trying to outperform it. This view, that the average investor possesses no skill, conflicts (at least semantically) with the concept of a naive RP as the null of no skill. This is because a naive RP averages on the equal-weighted portfolio which forms a natural alternative benchmark. From a portfolio selection perspective the equal-weighted portfolio is rightly called the naive benchmark since the strategy implies no views on market developments. It results as the optimal solution in a Markowitz framework when expectations on returns, variances and correlations are considered constant cross-sectionally. Yet, from an asset pricing perspective, equal weighting provides exposure to systematic investment styles, foremost to the low-size factor, and is thus not so naive after all. The lack of consideration of the different points of view has led to unnecessary misinterpretations in the past. Unnecessary because, as we will show, RPs can easily be constructed to reflect either reference points in expectation, the naive investor who bets on all companies in a universe equally, or the average investor who accounts for the the number of shares a company has issued999For the computation of total market value one may want to restrict calculations to shares that are free-floating, i.e., available to public trading, giving rise to a free-float adjusted market capitalization versus a non-adjusted capitalization considering all shares outstanding, i.e., also those that are held by company insiders and which are restricted to trade. and the price they are traded for, i.e., firm capitalization (or actually any other reference point that could be relevant to an investor). In the forthcoming, we use the terms naive RP and basic RP to refer to either cases. A formal definition of the two concepts is given in Section 3 and a first educative example follows shortly. A third and more direct approach of performance analysis comes in the form of hypothesis tests for the difference in performance measures of two strategies; typically, the portfolio in question and a benchmark. For instance, Sharpe ratio tests building upon the work of [63], the correction of [100] and the extension of [78] accounting for stylized facts of asset returns. However, at least since [67] it is known that these tests suffer from low power, that is, they are unlikely to identify superior performance in the data even if there is one. A randomized procedure for performance analysis replaces the reference point with a reference set (equipped with the empirical probability measure). Using a RP is intuitively appealing as it is a model-free method. In principle, it eliminates the need for parameter estimation, thereby avoiding dependencies on extensive time series data and assumptions about the data generating process. Moreover, it offers flexibility in evaluating different performance measures while considering transaction costs and investment constraints. However, it relies on the assumption that the distribution of no-skill performance, crucial for hypothesis system evaluation, can be objectively approximated through sampling. We contend that such is not unequivocally feasible. Let us illustrate the challenges of performance evaluation and the use as well as the potential for misuse of RP-based inference through a somewhat absurd, yet genuine, example. Imagine a portfolio manager who constructs a portfolio based on the number of times the letter \u2019Z\u2019 appears in the company names of constituents within the S&P 500 index. Intuitively, this approach appears dubious and common sense would advise against entrusting this manager with our savings. However, when comparing a backtest of the manager\u2019s strategy over a 22-year period (from 2000-01-01 to 2022-12-31) to the capitalization-weighted parent index (i.e., the S&P 500), the results show an annualized outperformance of 6.26.26.26.2% (based on daily geometric returns) and the Sharpe ratio test of Ledoit and Wolf ([78])101010The test accounts for time series structures in the data by employing heteroscedasticity and autocorrelation consistent (HAC) estimates of standard error. rejects the null hypothesis of equal Sharpe ratios at the 5% tolerance level. What is going on? Is there anything special about the letter Z? Of course not. In fact, it happens to be the case that we could have chosen any letter of the alphabet and the simulated out-of-sample111111Our backtesting procedure ensures that at every point in time, only stocks that have been in the index at that point in time enter the portfolio selection (i.e., there is no look-ahead bias). The allocation is then held for three months, letting the weights float with total return (i.e., dividends are assumed to be reinvested) developments of the underlying stocks, until the portfolios are rebalanced. backtest would have shown an outperformance. We could even take the nonsense to the extreme and invert the strategies by investing in all assets except those with a particular letter in the company name. Again, all backtests outperform the benchmark. How should we make sense of this? Our absurd example is similar to the seemingly paradoxical results presented in [5] who find that the arguably nonsensical inverses of sensible investment strategies, i.e., strategies built from well-founded investment beliefs, which outperform the capitalization weighted benchmark, outperform even more. The cause is readily identified by the authors by a tilt towards the size and value factors meaning that both, sensible and senseless strategies outperform for the same (unintended) reasons. In particular, even randomly generated strategies,\ni.e., strategies generated from a Monte Carlo simulation (i.e., a RP approach), lead to outperformances for the same causes.\nAll these findings enforce the authors to conclude that \u201cvalue and size arise naturally in non-price-weighted strategies and constitute the main source of their return advantage\u201d and that, therefore, \u201ca simple performance measure becomes an unreliable gauge of skill\u201d. Also our inane letter strategies can be rationalized by their exposures to priced factors. For instance, when analyzed\nthrough the lens of the Fama-French-Carhart (FFC) 6-Factor model ([43], [20]) one finds that the majority of factor loadings are statistically significant. Coefficients are predominantely positive for size and value as well as for the two quality-related factors \u2013profitability and investment\u2013 while all coefficients for momentum are negative. Market betas are, for the most part, below one and as low as 0.820.820.820.82 for strategy Z (and 0.780.780.780.78 when not controlling for other factors). However, alphas remain positive and significant for all strategies (at the 5% level) except for strategy Q. This finding appears robust to the choice of factors, as evidenced by the qualitative consistency of alphas obtained from a regression on the 13131313 factor themes suggested by Jensen, Kelly, and Pedersen (JKP) [61]. Conversely, betas can differ substantially between the two models. Such discrepancies are to be expected, given the methodological disparities between the FFC and JKP models in constructing factors, utilizing underlying data, and selecting control factors.121212We found it interesting to study the (cross-sectional) correlation between FFC loadings and JKP loadings as they turn out to be surprisingly low. Over the analyzed period and for constituents of the S&P 500, the average correlation among exposures under the two models are 0.720.720.720.72 for SMB and size, 0.360.360.360.36 for WML and momentum, merely 0.160.160.160.16 for HML and value and are even negative \u22120.080.08-0.08- 0.08 RMW and profitability and \u22120.020.02-0.02- 0.02 for CMA and investment (the correlations are computed cross-sectionally and the average is taken over time).\nNevertheless, the observed inferential disparity can be confusing, as in various instances, one model attributes outperformance to a positive exposure to a specific factor, while the other attributes the opposite, both with compelling statistical significance131313Naturally, the regression setups should undergo thorough statistical analysis beyond a simplistic reliance on p-values, but unfortunately, such rigor is seldom practiced in reality. (especially for profitability, investment, and momentum). To arrive at a conclusive understanding, it might be necessary to forsake the convenience of the regression approach and engage in a more intricate analysis of the fundamental data related to the stocks within the letter portfolios141414For example, strategy J shows a clearly negative portfolio size score when calculated directly on the basis of company characteristics (we used the logarithm of market captitalization, standardized cross-sectionally to have mean zero), while the size exposure is positive under both FFC and JKP. For a long-only portfolio to have an exposure to a long-short factor does not necessarily mean that this translates to the portfolio having the corresponding characteristic (a portfolio with strong size exposure may nevertheless contain very large companies).. Instead, let us explore whether an RP-based approach can provide clarity. The top left chart in Figure\u00a01 shows the bivariate risk-return distribution of a RP (red to yellow level sets) together with the corresponding statistics for the 26 letter strategies (grey dots), realizations of the RP (yellow small dots), the capitalization-weighted benchmark given by the S&P 500 index (black dot) and the equal-weighted portfolio of the index constituents, rebalanced monthly (blue dot). Two immediate observations arise: Firstly, the performances of the letter strategies fall within the high-mass area of the RPs pdf, with Z and Q being outliers. Secondly, most of the mass of the RP return distribution is at levels above the return of the capitalization-weighted benchmark. The first observation suggests that any apparent performance or skill is consistent with chance and that the letter strategies could very well be instances of the RP. Analyzing the factor composition of the RP samples further reinforces this intuition. Figure\u00a02 shows the distributions of factor scores of RP samples under the FFC and the JKP models. The marks above the x-axis display the corresponding exposures of the letter strategies. While the divergence of the two models poses some concern, the consistency of the letter strategy scores with the RP distribution under either model individually paints a rather clear picture, which is that the outperformance of the letter strategies may be attributed to factor exposures that happen to be prevalent in the market. By contrast, the factor structure of the capitalization-weighted benchmark can be far-off the bulk of the RP\u2019s exposure distributions (this is evident for size where the benchmark must have a negative exposure by construction). Unlike the letter-based performances, which mostly align with the outcomes of the RP, the capitalization-weighted benchmark exhibits a notable deviation. Here is where one has to be cautious not to jump to conclusions. If we were to statistically test the benchmark return based on the RP return distribution we would conclude that the average investor is rather unskilled since most investment decisions based on chance outperformed the market. This result would be in line with the findings of [5] as well as [30] who locate the return of the capitalization-weighted benchmark far out in the left tail of a RP return distribution over a 49494949 years (1964 - 2012) and 44444444 years (1968 - 2011) period respectively. However, one should recall Sharpe\u2019s arithmetic of active management [116] that for every outperforming strategy there needs to be an underperforming one (relative to the capitalization-weighted benchmark). The fact that the RP outperforms the benchmark does not imply that any strategy, or even most strategies, outperform the benchmark. The outcome depends on the way the RP is constructed, circling back to the two previously mentioned issues in the RP narrative regarding the no-skill reference point and the misunderstanding that an RP covers the entirety of outcomes. Without delving too deeply into the subject of RP construction (a concise description follows in Sections 3 and 4), some qualitative aspects need addressing here. The RP depicted in the top left chart of Figure\u00a01 is not constructed as having a uniform distribution over the set of feasible assets. Such an approach would yield an inadequate representation of attainable performance, as it would consist solely of homogeneous and biased portfolios. Instead, it is crafted by convolving 26262626 individual RPs, each centered on an equally-weighted portfolio while considering the number of assets in the specific letter portfolio at a given rebalancing date. As the number of assets considered decreases, the risk-return distribution of the RP widens, and the distribution\u2019s center shifts right, as depicted in the bottom chart of Figure\u00a01. The chart displays three RP densities, constructed using a method commonly found in the literature. The procedure involves repeatedly sampling m\ud835\udc5amitalic_m stocks uniformly from the set of investable stocks (here, with a set cardinality of\nn=500\ud835\udc5b500n=500italic_n = 500) and forming equally-weighted portfolios. This process essentially constitutes an\nm\ud835\udc5amitalic_m-out-of-n\ud835\udc5bnitalic_n bootstrap. In the chart, we have used m={500,30,4}\ud835\udc5a500304m=\\{500,30,4\\}italic_m = { 500 , 30 , 4 } from left to right. In the first case where all assets in the index are used, the density merely provides a measure of the uncertainty in the performance of the equal-weighted strategy151515It can be understood as an estimate of the sampling distribution of the equal-weighted portfolio\u2019s performance statistics, or, if one would sample the asset space uniformly, as the posterior density of the risk-return parameters of the equal-weighted portfolio.. This is because sampled portfolios are all very close to the equally weighed portfolio (in terms of the weights). In higher dimensions, sampling according to a uniform distribution does not mean that each possible portfolio will be sampled with equal probability. Quite the contrary. With overwhelming probability, samples will be drawn from the high-volume area of the sampling space, which forms a thin shell (the region between two concentric higher dimensional spheres of differing radii)161616It can be shown that \ud835\udd3c\u2062(\u2016\u03c9\u201622)=2\u2062n\u22121n2\ud835\udd3csuperscriptsubscriptnorm\ud835\udf14222\ud835\udc5b1superscript\ud835\udc5b2\\mathds{E}(||\\omega||_{2}^{2})=\\frac{2n-1}{n^{2}}blackboard_E ( | | italic_\u03c9 | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) = divide start_ARG 2 italic_n - 1 end_ARG start_ARG italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG and that therefore, with \u03c9\u00af\u00af\ud835\udf14\\bar{\\omega}over\u00af start_ARG italic_\u03c9 end_ARG denoting the equal-weighted portfolio, \ud835\udd3c\u2062(\u2016\u03c9\u2212\u03c9\u00af\u201622)=n2\u2212nn3\ud835\udd3csuperscriptsubscriptnorm\ud835\udf14\u00af\ud835\udf1422superscript\ud835\udc5b2\ud835\udc5bsuperscript\ud835\udc5b3\\mathds{E}(||\\omega-\\bar{\\omega}||_{2}^{2})=\\frac{n^{2}-n}{n^{3}}blackboard_E ( | | italic_\u03c9 - over\u00af start_ARG italic_\u03c9 end_ARG | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) = divide start_ARG italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_n end_ARG start_ARG italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT end_ARG, which tends to zero with increasing n\ud835\udc5bnitalic_n.. Sparse or highly concentrated portfolios (such as the capitalization-weighted benchmark) are thus extremely unlikely to be sampled. In cases where m<n\ud835\udc5a\ud835\udc5bm<nitalic_m < italic_n, as exemplified by m=30\ud835\udc5a30m=30italic_m = 30 and m=4\ud835\udc5a4m=4italic_m = 4, chosen to align with the selections made by [5] and in the dartboard game, respectively, the imposed sparsity leads to a broader dispersion of portfolio weights. This translates to a more extensive distribution of performance statistics. However, the resulting distributions remain relatively compact, covering only a small area of the space of feasible solutions, refecting the homogeneity of sampled portfolios. Therefore, such RPs do not form acceptable control groups. Utilizing these distributions for significance testing would likely result in overly optimistic rejections of the Null hypothesis. Adapting the RP mechanism to center on the capitalization-weighted allocation leads to the risk-return distribution in the top right chart of Figure\u00a01. This distribution is more consistent with Sharpe\u2019s arithmetic, having mode close to the performance of the market index. In contrast, the profile of the naive index significantly deviates from the center of mass. We could have further expanded or contracted the risk-return distribution by adjusting the variance in the weights, essentially reverse-engineering the random control to achieve a desired statistical test result. A dangerous game. We therefore conclude that a RP, as we have presented it so far, does not provide a statistically acceptable experimental design to probe skill (or lack thereof). Nevertheless, we would argue that, with some care in the construction of the RP, it can serve as a visual aid to characterize the dispersion of performance for non-elaborate strategies (such as letter-based investing). Hopefully, the geometric perspective which we advocate in the subsequent discussion offers some transparency in this context. The utility of employing an RP lies in the ability to analyze the relationship between portfolio performance and portfolio characteristics. Let\u2019s consider the frequency of a letter in a company\u2019s name as a stock characteristic and examine whether there is a correlation between the returns of portfolios drawn from the RP and the characteristics of those portfolios171717For each occurrence of a specific letter in the company name, a score of one is assigned (i.e., a company having letter \u2019A\u2019 appearing three times in it\u2019s name gets a score of three). The portfolio characteristics are computed as the weighted sum of stock-level characteristic-scores times the portfolio weights.. If exposure to a particular letter, let\u2019s say \u2019Z\u2019, were a rewarded characteristic, this relationship should be reflected in the cross-section of RP samples as a correlation (or more broadly, a relation) between the loading on \u2019Z\u2019 and performance. This (cor-) relation should be present in both RPs used above, the one centered on the equal-weighted and the one centered on the capitalization-weighted benchmark. While there are simpler ways to dismiss letter-based weighting as a viable method for portfolio construction, our point with current example is that the RP approach lends itself to an analysis of the performance impact of any systematic portfolio formation approach. In Section 5, we build on this approach to investigate recognized factors and their impact on performance. The analysis aims to detect genuine anomalies and reveal whether certain characteristics are still rewarded in the market when accounting for constraints that many investors need to adhere to. To finalize our example, Figure \u00a03 shows the scatter plot of performance versus characteristics of samples from the RP visualized in the left plot of \u00a01. Unsurprisingly, there is no observable correlation for characteristic \u2019Z\u2019, neither between return and characteristic nor between risk and characteristic. In contrast, the right panel of Figure 3 illustrates the existence of a fairly strong relationship between momentum181818we measure momentum by the cumulative return of the portfolio over the last 12 months, omitting the last month. and performance at the portfolio level. The chart shows a non-linear (almost quadratic) pattern between risk and momentum. This implies that both, portfolios with the lowest and portfolios with the highest momentum scores exhibit high ex-post volatility, while volatility is low for intermediate-scoring portfolios. The correlation between portfolio\u2019s returns and momentum scores is positive (0.31) overall, with steeper segments at the low- and high-exposure endpoints, while the middle part appears to be relatively flat. The graph prompts us to contemplate whether the momentum anomaly would endure in a constrained setting where extreme exposures are no longer feasible due to constraints on asset weights and/or on additional factor exposures. This question is the focus of Section\u00a05. Additionally, the Section will provide a detailed description of the backtesting methodology, which we have also applied here. For completeness, the two charts in the third row of Figure \u00a03 shows the risk-return patter for the RP samples. The color-coding from red (low exposure) to green (high exposure) helps to identify the unstructured and the partially structured nature of the Z-characteristic versus the momentum characteristic, respectively. In this Section, we explore the design and construction of a RP. We propose a categorization of RPs into three groups of increasing complexity: naive, basic, and regularized. Among the regularized RPs, we distinguish between simply regularized (where sampling is easy) and generally regularized (where sampling is difficult). The primary objective is to gain insights into the distribution of function values of a RP, such as its return. In certain cases, these distributions have an analytic expression. However, in general, analytic solutions do not exist and sampling-based approximations are necessary. The arguably most intuitive case is to consider non-negative portfolio weights that sum up to one; these are the two defining properties of long-only portfolios. The geometric object which characterizes the space of long-only portfolios is the canonical simplex In practice, mutual funds frequently encounter legal constraints mandating full investment while prohibiting short selling. Consequently, the simplex constraint embodies a legal requirement to which they must adhere. Given its prevalence within the industry, our analysis will concentrate on this typical scenario, presuming the asset space to be defined by the standard simplex or a subset thereof, which arises when additional constraints are imposed. However, the geometric random walk routines which we propose in the sequel are by no means limited to the simplex case but readily extend to accommodate long-short applications. As for the definition of randomness, we begin with the (arguably) most intuitive case of a uniformly distributed RP, i.e., we focus on the uniform measure over the simplex. Hence, a naive RP may be given by \u03c9\u223cU\u2062(\ud835\udcae)similar-to\ud835\udf14U\ud835\udcae\\omega\\sim\\mathrm{U}(\\mathcal{S})italic_\u03c9 \u223c roman_U ( caligraphic_S ), which we parametrize it through a flat191919Flat means that the elements of the parameter vector of the Dirichlet distribution, \u03b1\ud835\udefc\\alphaitalic_\u03b1, are all equal to one.\nDirichlet model; i.e., \u03c9\u223c\ud835\udc9f\u2062(\u03b1=\ud835\udfcf)similar-to\ud835\udf14\ud835\udc9f\ud835\udefc1\\omega\\sim\\mathcal{D}(\\alpha=\\mathbf{1})italic_\u03c9 \u223c caligraphic_D ( italic_\u03b1 = bold_1 ), where \ud835\udfcf1\\mathbf{1}bold_1 is a vector of ones. The Dirichlet pdf is given by This particular setup allows for an exact characterization of the distribution of linear statistics associated with a RP. For instance, the cumulative distribution function (cdf) of the return of a RP, denoted by \u03bc\ud835\udf07\\muitalic_\u03bc, has an expression as a ratio of volumes. I.e., for some scalar \u03b3\ud835\udefe\\gammaitalic_\u03b3,\nwhere V\ud835\udc49Vitalic_V denotes the volume operator and \u210b\u2062(rt,\u03b3)={h\u2208\u211dn|rt\u22a4\u2062h\u2264\u03b3}\u210bsubscript\ud835\udc5f\ud835\udc61\ud835\udefeconditional-set\u210esuperscript\u211d\ud835\udc5bsuperscriptsubscript\ud835\udc5f\ud835\udc61top\u210e\ud835\udefe\\mathcal{H}(r_{t},\\gamma)=\\{h\\in\\mathbb{R}^{n}|r_{t}^{\\top}h\\leq\\gamma\\}caligraphic_H ( italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\u03b3 ) = { italic_h \u2208 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT | italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22a4 end_POSTSUPERSCRIPT italic_h \u2264 italic_\u03b3 } is the half-space induced by a hyperplane with normal rtsubscript\ud835\udc5f\ud835\udc61r_{t}italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT that is the empirical mean vector of the asset return distribution (see [7]). The volume in the numerator of Eq.\u00a0(3)\nhas a closed form expression, e.g., [77]. However, it has been observed that the evaluation of this expression is numerically unstable when the dimension is not small, n\u226520\ud835\udc5b20n\\geq 20italic_n \u2265 20, e.g., [19, 18].\nTo overcome this obstacle Chalkis et al [19, 18]\nsuggest the use of an efficient and exact geometric algorithm,\ndue to Varsi, see [126] and [3],\nfor the evaluation of the volume(s).\nThis is the preferable implementation strategy of naive RP applications.\nFor the sake of convenience, we include the pseudocode for Varsi\u2019s algorithm in Appendix\u00a0A.1. Another form of a naive RP is given by the mechanism underlying the dartboard game. Dart throwing monkeys are easily digitalized by drawing counts c=(c1,\u2026,cn)\ud835\udc50subscript\ud835\udc501\u2026subscript\ud835\udc50\ud835\udc5bc=(c_{1},...,c_{n})italic_c = ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_c start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) from a Multinomial distribution Mult\u2062(n,p1,\u2026,pn)Mult\ud835\udc5bsubscriptp1\u2026subscriptp\ud835\udc5b\\mathrm{Mult}(n,{\\mathrm{p}}_{1},...,{\\mathrm{p}}_{n})roman_Mult ( italic_n , roman_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , roman_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) with n\ud835\udc5bnitalic_n trials where, with uniform probabilities pi=1/nsubscriptp\ud835\udc561\ud835\udc5b{\\mathrm{p}}_{i}=1/nroman_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1 / italic_n, i=1,\u2026,n\ud835\udc561\u2026\ud835\udc5bi=1,...,nitalic_i = 1 , \u2026 , italic_n, which is exactly the setup underlying the classical bootstrap of [40]. Normalizing each count produces (RP) weights \u03c9i=ci/nsubscript\ud835\udf14\ud835\udc56subscript\ud835\udc50\ud835\udc56\ud835\udc5b\\omega_{i}=c_{i}/nitalic_\u03c9 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_n. Unlike the Dirichlet model, the weight space is no longer given by the canonical simplex but consists of a discrete grid over the canonical simplex. As a result, the bootstrap distribution of any derived RP statistic is discrete. The grid node at the centroid of the simplex represents the equal-weighted portfolio and vertices represent single-asset portfolios. Grid nodes located on the boundary of the simplex form sparse portfolios, i.e., allocations where one or more position is exactly zero. The definition of randomness of the weights depends on the type of resampling plan one chooses in the bootstrap procedure. For instance, the specifications of the dartboard game, i.e., how many darts, m\ud835\udc5amitalic_m, are thrown at a list of how many company names, n\ud835\udc5bnitalic_n, and whether a name can be hit multiple times or not (i.e., sampling with or without replacement), define the structure of the corresponding grid. In practical applications, resampling plans often involve drawing fewer than n\ud835\udc5bnitalic_n samples (m<n\ud835\udc5a\ud835\udc5bm<nitalic_m < italic_n), corresponding to an m\ud835\udc5amitalic_m out of n\ud835\udc5bnitalic_n bootstrap [12]. In this case, the induced grid is biased toward the boundaries of the simplex, resulting in a wider dispersion of the bootstrap distribution of the statistic in question compared to the classical bootstrap RP version.\nThe continuous analogue of this approach involves using a concentration parameter in the Dirichlet distribution such that \u2211in\u03b1i<nsuperscriptsubscript\ud835\udc56\ud835\udc5bsubscript\ud835\udefc\ud835\udc56\ud835\udc5b\\sum_{i}^{n}\\alpha_{i}<n\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_\u03b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < italic_n. By introducing a mapping \u03bb\u2062(n,m)=m\u22121n\ud835\udf06\ud835\udc5b\ud835\udc5a\ud835\udc5a1\ud835\udc5b\\lambda(n,m)=\\frac{m-1}{n}italic_\u03bb ( italic_n , italic_m ) = divide start_ARG italic_m - 1 end_ARG start_ARG italic_n end_ARG, the standard errors of the linear statistic of interest become equivalent under both \u03c9\u223c1n\u2062Mult\u2062(m,p1,\u2026,pn)similar-to\ud835\udf141\ud835\udc5bMult\ud835\udc5asubscriptp1\u2026subscriptp\ud835\udc5b\\omega\\sim\\frac{1}{n}\\mathrm{Mult}(m,{\\mathrm{p}}_{1},...,{\\mathrm{p}}_{n})italic_\u03c9 \u223c divide start_ARG 1 end_ARG start_ARG italic_n end_ARG roman_Mult ( italic_m , roman_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , roman_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) and \u03c9\u223cDir\u2062(\u03b1\u2062\u03bb\u2062(n,m))similar-to\ud835\udf14Dir\ud835\udefc\ud835\udf06\ud835\udc5b\ud835\udc5a\\omega\\sim\\text{Dir}(\\alpha\\lambda(n,m))italic_\u03c9 \u223c Dir ( italic_\u03b1 italic_\u03bb ( italic_n , italic_m ) ) (see [7]). Notice that the flat Dirichlet model also describes a form of bootstrap version, namely the Bayesian bootstrap of [111]. To summarize, a naive RP conforms to a classical or a Bayesian bootstrap scheme encompassing the m\ud835\udc5amitalic_m-out-of-n\ud835\udc5bnitalic_n bootstrap, where m\ud835\udc5amitalic_m can be smaller, larger, or equal to n\ud835\udc5bnitalic_n, and the case \ud835\udc9f\u2062(\u03b1=\ud835\udfcf\u2062\u03bb)\ud835\udc9f\ud835\udefc1\ud835\udf06\\mathcal{D}(\\alpha=\\mathbf{1}\\lambda)caligraphic_D ( italic_\u03b1 = bold_1 italic_\u03bb ), \u03bb>0\ud835\udf060\\lambda>0italic_\u03bb > 0 in the Bayesian paradigm202020Notice that \u03bb>1\ud835\udf061\\lambda>1italic_\u03bb > 1 leads to a more concentrated distribution around the centroid of the simplex. On the other hand, \u03bb<0\ud835\udf060\\lambda<0italic_\u03bb < 0 pushes weights outwards towards the faces, edges and vertices of the simplex (that is compared to uniform density implied by the flat base case \u03bb=1\ud835\udf061\\lambda=1italic_\u03bb = 1).. We call it naive because, in expectation, it recovers the naive benchmark, i.e., \ud835\udd3c\u2062(\u03c9)=\u03c9\u00af\ud835\udd3c\ud835\udf14\u00af\ud835\udf14\\mathds{E}(\\omega)=\\bar{\\omega}blackboard_E ( italic_\u03c9 ) = over\u00af start_ARG italic_\u03c9 end_ARG, where \u03c9\u00af\u00af\ud835\udf14\\bar{\\omega}over\u00af start_ARG italic_\u03c9 end_ARG denotes the equally-weighted portfolio. We call a RP basic if, like a naive RP, the geometric representation corresponds to a standard simplex. However, we also impose the condition that \ud835\udd3c\u2062(\u03c9)\ud835\udd3c\ud835\udf14\\mathds{E}(\\omega)blackboard_E ( italic_\u03c9 ) is not equal to the centroid, i.e., one cannot recover the (naive) equally-weighted portfolio in expectation. This occurs whenever some form of asymmetry is introduced in the parametrization of the Dirichlet or the Multinomial model which breaks the symmetry in the distribution of the weights. By that we mean that paremeter elements cannot all be equal. For instance, setting \u03b1\u221d\u03c9b\u2062mproportional-to\ud835\udefcsubscript\ud835\udf14\ud835\udc4f\ud835\udc5a\\alpha\\propto\\omega_{bm}italic_\u03b1 \u221d italic_\u03c9 start_POSTSUBSCRIPT italic_b italic_m end_POSTSUBSCRIPT, where \u03c9b\u2062msubscript\ud835\udf14\ud835\udc4f\ud835\udc5a\\omega_{bm}italic_\u03c9 start_POSTSUBSCRIPT italic_b italic_m end_POSTSUBSCRIPT is the capitilization-weighted allocation, generates a distribution of weights which has center of mass at \u03c9b\u2062msubscript\ud835\udf14\ud835\udc4f\ud835\udc5a\\omega_{bm}italic_\u03c9 start_POSTSUBSCRIPT italic_b italic_m end_POSTSUBSCRIPT. Although the full distribution of a linear RP statistic is no longer available in exact form under the non-flat parametrization, the central moments of the distribution still are (see [7]). The simplex condition is typically not the only constraint that asset managers need to adhere to. When there are additional constraint, it becomes quite challenging to obtain analytical results. These additional constraints often originate from regulatory requirements and are designed to limit the risk exposure to individual security issuers or groups of issuers212121A common example is the UCITS 5/10/40 rule, which restricts single asset representation to no more than 10% of the fund\u2019s assets and limits holdings exceeding 5% to aggregate below 40% of the fund\u2019s assets.. As a result, upper bounds are imposed on the asset weights, either individually or collectively.\nGeometrically, these linear restrictions correspond to halfspaces that intersect the simplex, resulting in a polytope Furthermore, managers may impose additional constraints to prevent concentration, or to align with the benchmark allocations, e.g., by setting lower and upper bounds on country or sector exposures relative to the benchmark or in terms of variation of the return difference (tracking-error), to limit transaction costs, to control portfolio characteristics (e.g., factor exposure, sustainability criteria, risk metrics), or to satisfy other specific requirements.\nFrom a sampling perspective, the mathematical characterization of constraints plays a crucial role, distinguishing between linear, quadratic, convex, non-linear, and other types. Certain risk measures like Value-at-Risk (VaR) are non-convex, meaning that, if a RP is subject to a maximum VaR constraint, it\u2019s domain can no longer be represented by a common convex geometric body, which makes sampling extremely hard. Other measures of risk like variance or tracking error are quadratic and geometrically form ellipsoids Sampling from (the surface) of an ellipsoid is relatively straightforward. However, when the simplex condition must also be satisfied, sampling from the intersection of the simplex with an ellipsoidal surface becomes a non-trivial task (albeit possible, as demonstrated in [8]). Under general constraints, the cdf of a RP statistic is not tractable analytically and one has to turn to numerical methods (see Section 4). The following special case forms an exception.\nRecently, [7] demonstrated that Varsi\u2019s algorithm can also be applied in the context of a shadow Dirichlet distribution ([45]), which is defined on a linearly constrained simplex. The shadow Dirichlet model allows for the consideration of linear regularizations of the weights, making it highly relevant in practical applications. If \u03c9\u223c\ud835\udc9f\u2062(\u03b1)similar-to\ud835\udf14\ud835\udc9f\ud835\udefc\\omega\\sim\\mathcal{D}(\\alpha)italic_\u03c9 \u223c caligraphic_D ( italic_\u03b1 ) and M\ud835\udc40Mitalic_M an n\u00d7n\ud835\udc5b\ud835\udc5bn\\times nitalic_n \u00d7 italic_n left-stochastic matrix (i.e., each column sums to one) of full rank, then M\u03c9=:\u03c9~\u223c\ud835\udcae\ud835\udc9f(M,\u03b1)M\\omega=:\\tilde{\\omega}\\sim\\mathcal{SD}(M,\\alpha)italic_M italic_\u03c9 = : over~ start_ARG italic_\u03c9 end_ARG \u223c caligraphic_S caligraphic_D ( italic_M , italic_\u03b1 ), where \ud835\udcae\u2062\ud835\udc9f\ud835\udcae\ud835\udc9f\\mathcal{SD}caligraphic_S caligraphic_D denotes the shadow Dirichlet model with pdf The normalizing constant is the determinant of matrix M\ud835\udc40Mitalic_M times the normalizing constant of the standard Dirichlet distribution, i.e., the multinomial beta function B\u2062(\u03b1)=\u222b\ud835\udcaen\u22121\u220fi=1n\u03c9i\u03b1i\u22121\u2062d\u2062\u03c9=\u220fi=1n\u0393\u2062(\u03b1i)\u0393\u2062(\u03b10)B\ud835\udefcsubscriptsubscript\ud835\udcae\ud835\udc5b1superscriptsubscriptproduct\ud835\udc561\ud835\udc5bsuperscriptsubscript\ud835\udf14\ud835\udc56subscript\ud835\udefc\ud835\udc561\ud835\udc51\ud835\udf14superscriptsubscriptproduct\ud835\udc561\ud835\udc5b\u0393subscript\ud835\udefc\ud835\udc56\u0393subscript\ud835\udefc0\\mathrm{B}(\\alpha)=\\int_{\\mathcal{S}_{n-1}}\\prod_{i=1}^{n}\\omega_{i}^{\\alpha_{%\ni}-1}d\\omega=\\frac{\\prod_{i=1}^{n}\\Gamma(\\alpha_{i})}{\\Gamma(\\alpha_{0})}roman_B ( italic_\u03b1 ) = \u222b start_POSTSUBSCRIPT caligraphic_S start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT \u220f start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_\u03c9 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - 1 end_POSTSUPERSCRIPT italic_d italic_\u03c9 = divide start_ARG \u220f start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT roman_\u0393 ( italic_\u03b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG roman_\u0393 ( italic_\u03b1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_ARG, where \u0393\u2062(x)=\u222b0\u221etx\u22121\u2062e\u2212t\u2062\ud835\udc51t\u0393\ud835\udc65superscriptsubscript0superscript\ud835\udc61\ud835\udc651superscript\ud835\udc52\ud835\udc61differential-d\ud835\udc61\\Gamma(x)=\\int_{0}^{\\infty}t^{x-1}e^{-t}dtroman_\u0393 ( italic_x ) = \u222b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT italic_x - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - italic_t end_POSTSUPERSCRIPT italic_d italic_t is the gamma function. Therefore, in cases where linear constraints can be expressed using the mapping M\ud835\udc40Mitalic_M, the distribution of linear functions of a random portfolio can be precisely obtained using Varsi\u2019s algorithm under the uniform measure. These cases are referred to as simply regularized. For all other cases where linear constraints cannot be directly accommodated, sampling methods need to be employed. Figure 4 visualizes the different types of RPs for the case of n=3\ud835\udc5b3n=3italic_n = 3 assets. Subplot a) shows the uniform density of a naive RP defined over the unit simplex, i.e., \u03c9\u223c\ud835\udc9f\u2062(\ud835\udfcf)similar-to\ud835\udf14\ud835\udc9f1\\omega\\sim\\mathcal{D}(\\mathbf{1})italic_\u03c9 \u223c caligraphic_D ( bold_1 ). Subplot b) also shows another naive RP since, like a), it also centers on the naive 1/n1\ud835\udc5b1/n1 / italic_n portfolio. However, the distribution of the weights is not uniform but follows a concentrated Dirichlet model with \u03c9\u223c\ud835\udc9f\u2062(\ud835\udfcf\u2062\u03bb)similar-to\ud835\udf14\ud835\udc9f1\ud835\udf06\\omega\\sim\\mathcal{D}(\\mathbf{1}\\lambda)italic_\u03c9 \u223c caligraphic_D ( bold_1 italic_\u03bb ); \u03bb=4\ud835\udf064\\lambda=4italic_\u03bb = 4, giving the distribution more mass around the center. If we would have chosen the concentration parameter \u03bb<1\ud835\udf061\\lambda<1italic_\u03bb < 1, the density colors would be reverted (i.e., distributing more mass towards the boundaries of the simplex). Subplot c) shows a simple RP with \u03c9\u223c\ud835\udc9f\u2062(\u03b1)similar-to\ud835\udf14\ud835\udc9f\ud835\udefc\\omega\\sim\\mathcal{D}(\\alpha)italic_\u03c9 \u223c caligraphic_D ( italic_\u03b1 ); \u03b1=(0.5,0.3,0.2)\ud835\udefc0.50.30.2\\alpha=(0.5,0.3,0.2)italic_\u03b1 = ( 0.5 , 0.3 , 0.2 ). d) visualizes the shadow of the Dirichlet distribution in c), i.e., \u03c9\u223c\ud835\udcae\u2062\ud835\udc9f\u2062(M,\u03b1)similar-to\ud835\udf14\ud835\udcae\ud835\udc9f\ud835\udc40\ud835\udefc\\omega\\sim\\mathcal{SD}(M,\\alpha)italic_\u03c9 \u223c caligraphic_S caligraphic_D ( italic_M , italic_\u03b1 ), restricted by a mononotic M\ud835\udc40Mitalic_M which has k\u2212limit-from\ud835\udc58k-italic_k -th column [0[0[ 0 \u2026 00 1/(n\u2212k+1)\u20261/(n\u2212k+1)]\u22a41/(n-k+1)...1/(n-k+1)]^{\\top}1 / ( italic_n - italic_k + 1 ) \u2026 1 / ( italic_n - italic_k + 1 ) ] start_POSTSUPERSCRIPT \u22a4 end_POSTSUPERSCRIPT. The so constrained weights satisfy the ordering \u03c91>\u03c92>\u2026>\u03c9nsubscript\ud835\udf141subscript\ud835\udf142\u2026subscript\ud835\udf14\ud835\udc5b\\omega_{1}>\\omega_{2}>...>\\omega_{n}italic_\u03c9 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > italic_\u03c9 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > \u2026 > italic_\u03c9 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. Subplots e) and f) show instances of generally regularized RPs defined by the intersection of the simplex with a polytope in the former case, and by the intersection of the simplex with the boundary of an ellipsoid in the latter case. In both cases, the distribution of the weights is a truncated version of the basic RP in c). The task of generating RP variates, i.e., the activity of obtaining realizations of a random composition having a specified distribution over a bounded domain, requires the implementation of a sampling engine. Ideally, the sampler is exact (results in random samples with exactly the desired distribution), efficient (in terms of storage space and execution222222Execution time has two components: Set-up time and marginal execution time. Set-up time is the time required to do some initial computing depending on the particular problem and marginal execution time is the incremental time required to generate each observation. time), robust (the algorithm is efficient for all parameter values), and not too complex (conceptually and also with respect to practical implementation). Whether these expectations can be met depends on the concrete problem specification, i.e., on the distributional assumption and the investment constraints which define the sampling space. To sample from a naive, a basic or a simply regularized RP one just has to sample a Dirichlet distribution with parameter vector \u03b1\ud835\udefc\\alphaitalic_\u03b1. To do so, it is enough to sample the marginals from a Gamma distribution with shape parameter a=ai\ud835\udc4esubscript\ud835\udc4e\ud835\udc56a=a_{i}italic_a = italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and fixed rate parameter b=1\ud835\udc4f1b=1italic_b = 1 and then standardizing by the sum: \u03c9i=xi\u2211i=1nxi,xi\u223cGamma\u2062(a=\u03b1i,b=1)formulae-sequencesubscript\ud835\udf14\ud835\udc56subscript\ud835\udc65\ud835\udc56superscriptsubscript\ud835\udc561\ud835\udc5bsubscript\ud835\udc65\ud835\udc56similar-tosubscript\ud835\udc65\ud835\udc56Gammaformulae-sequence\ud835\udc4esubscript\ud835\udefc\ud835\udc56\ud835\udc4f1\\omega_{i}=\\frac{x_{i}}{\\sum_{i=1}^{n}x_{i}},\\quad x_{i}\\sim\\mathrm{Gamma}(a=%\n\\alpha_{i},b=1)italic_\u03c9 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = divide start_ARG italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG , italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u223c roman_Gamma ( italic_a = italic_\u03b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b = 1 ). Recall that under the uniform measure, the naive as well as the simply regularized RP allow for an exact solution of the distribution function for linear statistics via Varsi\u2019s algorithm. Therefore, sampling is actually not needed. For a generally regularized RP, sampling is the only option. Under the uniform measure, the sampling problem forms an instance of the fundamental problem addressed in the seminal paper [117]: Given a bounded k\ud835\udc58kitalic_k-dimensional body \ud835\udca6\u2282\u211dn\ud835\udca6superscript\u211d\ud835\udc5b\\mathcal{K}\\subset\\mathbb{R}^{n}caligraphic_K \u2282 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, where k\u2264n\ud835\udc58\ud835\udc5bk\\leq nitalic_k \u2264 italic_n, find a way to efficiently sample pseudo-random points (X1,X2,\u2026,Xd)\u2208\ud835\udca6subscript\ud835\udc4b1subscript\ud835\udc4b2\u2026subscript\ud835\udc4b\ud835\udc51\ud835\udca6(X_{1},X_{2},...,X_{d})\\in\\mathcal{K}( italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_X start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) \u2208 caligraphic_K such that \u2119\u2062(X\u2208A\u2282\ud835\udca6)=V\u2062(A)/V\u2062(\ud835\udca6)\u2119\ud835\udc4b\ud835\udc34\ud835\udca6\ud835\udc49\ud835\udc34\ud835\udc49\ud835\udca6\\mathds{P}(X\\in A\\subset\\mathcal{K})=V(A)/V(\\mathcal{K})blackboard_P ( italic_X \u2208 italic_A \u2282 caligraphic_K ) = italic_V ( italic_A ) / italic_V ( caligraphic_K ) with V\ud835\udc49Vitalic_V denoting the k\ud835\udc58kitalic_k-dimensional content of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. While [117] considered the general case of sampling from a generic surface, here, we restrict analysis to sampling from a \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K which is either a polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P, the interior of an ellipsoid \u2130\u2130\\mathcal{E}caligraphic_E or their intersection.\nExact uniformity can only be obtained under specific circumstances which require either the applicability of transformation, composition or acceptance-rejection methods. The transformation technique maps uniformly distributed points from a hypercube C\ud835\udc36Citalic_C with a smooth deterministic function T\ud835\udc47Titalic_T onto \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K where T\u2062(x)\ud835\udc47\ud835\udc65T(x)italic_T ( italic_x ) has to preserve uniformity. A necessary and sufficient condition for this is that the Jacobian of T\ud835\udc47Titalic_T is constant over all x\u2208C\ud835\udc65\ud835\udc36x\\in Citalic_x \u2208 italic_C\u00a0[117]. In principle, this is a highly efficient method since there exist very efficient pseudo-random number generator to sample from C\ud835\udc36Citalic_C. The problem is just that T\ud835\udc47Titalic_T is known only for a very limited class of regions S\ud835\udc46Sitalic_S like spheres or simplices, not so though for general polytopes. Theoretically, one could partition any bounded polytope into a finite union of simplices, and then apply the transformation from the hypercube to each simplex yielding the composite technique. Although conceptually sound, the complexity of identifying the simplices is generally such that the approach is not tractable computationally. The idea behind the acceptance-rejection technique is to first find an enclosing set K\u2283\ud835\udca6\ud835\udca6\ud835\udc3eK\\supset\\mathcal{K}italic_K \u2283 caligraphic_K for which efficient sampling algorithms exist, take samples from K\ud835\udc3eKitalic_K and either accept them if they lie within \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K or reject them, otherwise. Accepted points will be uniformly distributed in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K because if a point is uniformly distributed within K\ud835\udc3eKitalic_K, then it is conditionally uniformly distributed in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K given it lies in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. The problem here is that even when K\ud835\udc3eKitalic_K is chosen based on certain optimality conditions, like the smallest enclosing sphere, the number of trial points in K\ud835\udc3eKitalic_K needed to get a point in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K grows, as Smith ([117]) calls it \u2019explosively\u2019232323As an example, [117] shows that when \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K is a hypercube and K\ud835\udc3eKitalic_K is a circumscribed sphere the expected number of points generated in K\ud835\udc3eKitalic_K needed to find one in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K grows from 1.5 for k=2\ud835\udc582k=2italic_k = 2 to 1030superscript103010^{30}10 start_POSTSUPERSCRIPT 30 end_POSTSUPERSCRIPT for k=100\ud835\udc58100k=100italic_k = 100.. As the dimension grows, the (only viable) solution is to sample with geometric random walks. The next Section provides a survey of existing walks\nthat we can use to sample from a RP and, ultimately, to address the finance problems of performance and factor analysis. Geometric random walk algorithms are a specific type of Markov chains that initiate from an interior point within a convex body \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. At each step, they transition to a neighboring point selected from a distribution dependent solely on the current position. The fundamental concept behind all geometric random walks is to generate a lengthy sequence of points, randomizing their order to render the sequence independent and identically distributed (i.i.d.) over \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. The complexity of the algorithms depends on its mixing time, i.e., the number of steps required to bound the distance between the current and the stationary distribution, and on the complexity of the basic geometric operations performed at each step of the walk; the latter is termed per-step complexity. The problem of sampling from a bounded convex body \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K is closely related to the problem of approximating the volume of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. The first celebrated result is given in\u00a0[39] where they sample approximately from the uniform distribution using a grid walk in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. Since then a great effort has been devoted to geometric random walks; to mention a few seminal papers, in\u00a0[117] they introduced the Hit-and-Run (HaR) algorithm, in\u00a0[65] they crucially improve rounding and sampling results using Ball walk (BaW) and in\u00a0[93] they show fast mixing for HaR even when the random walk starts from a corner point in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. Over the last 35 years various walks have been presented, each possessing distinct advantages and drawbacks. Some routines confine the sampling space to a polytope, while others are more generic, though often, there is a trade-off between flexibility and efficiency. Further, some walks are restricted to uniform sampling while others accommodate more general distributions, although they may need some pre-processing steps where uniform samples are required. The discriminating aspect among the various routines lies in their approach to take the next Markov step, i.e., in the choice of the direction, the step-length, the curvature of the trajectory and behavior when a boundary is hit. Figure \u00a05 illustrates the mechanisms of four geometric random walks which are at the basis of various descendent methods. For HaR, the logic is as follows: Start with an arbitrary point x0subscript\ud835\udc650x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT inside the convex body. Then, generate a random direction vector v\ud835\udc63vitalic_v with each component sampled independently from a standard normal distribution. Compute the intersections between the line defined by the point x0subscript\ud835\udc650x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and the direction vector v\ud835\udc63vitalic_v and the boundary of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. Finally, choose a random point on the segment defined by the two computed boundary points and repeat the process. The choice of the random distribution on the segment needs to be chosen with respect to the target distribution (for instance, uniformly, if the target is to sample uniformly distributed points).\nBilliard Walk (BiW)\u00a0[51] operates similarly to HaR, but it exclusively moves in the direction of v\ud835\udc63vitalic_v and reflects the ray upon encountering the boundary whereby the exit angle matches the entry angle. Both methods work on general \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K, but BiW is limited to sampling from the uniform distribution. Dikin walk \u00a0[103] (and other ellipsoidal procedures like Vaidya and John walk) choose their steps by sampling uniformly from an ellipsoid centered at the current point whose shape and size are determined by the shape of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K and the proximity of the current point to the boundary. Those algorithms are very efficient even in high-dimensional cases but only allow for uniform sampling from polytopes. Hamiltonian Monte Carlo (HMC)\u00a0[105] is a sophisticated technique that employs Hamiltonian dynamics to enhance sampling efficiency. It picks a random velocity according to a local distribution and then walks on a Hamiltonian trajectory, i.e., a trajectory which is given by the Hamiltonian dynamics, to obtain the next Markov point. So generated proposals exhibit less of a random-walk behavior, resulting in more effective and less correlated samples. Various versions of HMC exist, all allowing sampling from general log-concave distributions, though some versions (Riemannian HMC\u00a0[72]) are limited to polytopes. In the following we discuss important aspects that are common to all routines before moving to a detailed description of the individual procedures. We provide a survey of all existing routines. Readers seeking more in-depth understanding of the technicalities are encouraged to consult the source literature for a more comprehensive exploration. We assume that the support of the target distribution is either a full dimensional convex polytope given by a set of linear inequalities as Eq.\u00a0(4) or the intersection between a polytope and an ellipsoid (see Eq.\u00a0(5)). In either case we may refer to the support as a convex body.\nIn the case where the portfolio domain is given also by an additional set of equalities \u2013which is always the case in our examples since we require portfolios to be fully invested (simplex condition)\u2013 we transform it using an isometric transformation to obtain a full dimensional polytope and ellipsoid. In particular, let, for example, the set {x\u2208\u211dn|B\u2062x=0}conditional-set\ud835\udc65superscript\u211d\ud835\udc5b\ud835\udc35\ud835\udc650\\{x\\in{\\mathbb{R}}^{n}\\ |\\ Bx=0\\}{ italic_x \u2208 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT | italic_B italic_x = 0 } be defined by the corresponding additional equality constraints. Then, we compute an orthonormal basis of the null space of the matrix B\ud835\udc35Bitalic_B and we project the polytope and the ellipsoid onto the null space to obtain a full dimensional polytope and ellipsoid in the form of \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P and \u2130\u2130\\mathcal{E}caligraphic_E respectively. Let us demonstrate an example using the Dirichlet model in Eq.\u00a02 truncated in the intersection between a convex polytope and an ellipsoid, i.e., Notice that in this case B=[1,\u2026,1]T\ud835\udc35superscript1\u20261\ud835\udc47B=[1,\\dots,1]^{T}italic_B = [ 1 , \u2026 , 1 ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT.\nConsider the transformation \ud835\udcaf\u2062(x):=N\u2062(x\u2212x0)assign\ud835\udcaf\ud835\udc65\ud835\udc41\ud835\udc65subscript\ud835\udc650\\mathcal{T}(x):=N(x-x_{0})caligraphic_T ( italic_x ) := italic_N ( italic_x - italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ), where N\u2208\u211d(n\u22121)\u00d7n\ud835\udc41superscript\u211d\ud835\udc5b1\ud835\udc5bN\\in{\\mathbb{R}}^{(n-1)\\times n}italic_N \u2208 blackboard_R start_POSTSUPERSCRIPT ( italic_n - 1 ) \u00d7 italic_n end_POSTSUPERSCRIPT is the matrix that generates the null space of B\ud835\udc35Bitalic_B and x0subscript\ud835\udc650x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT a feasible point in the support of \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D. When we apply the transformation \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T on both \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D and its support we obtain the density, since x=NT\u2062y+x0\ud835\udc65superscript\ud835\udc41\ud835\udc47\ud835\udc66subscript\ud835\udc650x=N^{T}y+x_{0}italic_x = italic_N start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_y + italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. By replacing x\ud835\udc65xitalic_x in the constraint equations one could also obtain the support of the transformed density [\ud835\udcaf\u2218\ud835\udc9f]delimited-[]\ud835\udcaf\ud835\udc9f[\\mathcal{T}\\circ\\mathcal{D}][ caligraphic_T \u2218 caligraphic_D ]. Finally, we sample from the full dimensional body in the null space and we apply the inverse transformation to obtain the sampled portfolios in the initial space. In the sequel, we consider the case of sampling from a full dimensional convex set given by the intersection between a convex polytope and an ellipsoid, Each geometric random walk uses certain sub-routines called oracles. An oracle is an algorithm that answers a certain question that is needed for the implementation of a random walk. The oracle that every geometric random walk needs is the membership oracle that answers if a given point belongs or not in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. The simplest implementation of this oracle is to check the validity of the Eq.\u00a0(4, 5). Another useful sub-routine is the boundary oracle that computes the intersection between the boundary of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K, denoted \u2202\ud835\udca6\ud835\udca6\\partial\\mathcal{K}\u2202 caligraphic_K, and a ray that starts from a point in the interior of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K, let \u2113\u2062(t):={x+t\u2062v|x\u2208\ud835\udca6,v\u2208\u211dn,t\u2208\u211d+}assign\u2113\ud835\udc61conditional-set\ud835\udc65\ud835\udc61\ud835\udc63formulae-sequence\ud835\udc65\ud835\udca6formulae-sequence\ud835\udc63superscript\u211d\ud835\udc5b\ud835\udc61subscript\u211d\\ell(t):=\\{x+tv\\ |\\ x\\in\\mathcal{K},\\ v\\in{\\mathbb{R}}^{n},\\ t\\in{\\mathbb{R}}_%\n{+}\\}roman_\u2113 ( italic_t ) := { italic_x + italic_t italic_v | italic_x \u2208 caligraphic_K , italic_v \u2208 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_t \u2208 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT }. To compute the intersection with \u2202\ud835\udcab\ud835\udcab\\partial\\mathcal{P}\u2202 caligraphic_P we have to solve one linear equations per facet and keep the smallest positive root. We have, where m\ud835\udc5amitalic_m is the number of facets and aj\u2208\u211dnsubscript\ud835\udc4e\ud835\udc57superscript\u211d\ud835\udc5ba_{j}\\in{\\mathbb{R}}^{n}italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT are the normal vectors defining the support hyperplane of each facet. The computations in Eq.\u00a0(9) costs \ud835\udcaa\u2062(m\u2062n)\ud835\udcaa\ud835\udc5a\ud835\udc5b\\mathcal{O}(mn)caligraphic_O ( italic_m italic_n ) operations242424Here and in the remainder of the text we use Bachmann-Landau symbols to express computational complexity (in terms of oracle evaluations and arithmetic operations) as a function of the dimension of the geometric object. Additionally, the \ud835\udcaa~\u2062(\u22c5)~\ud835\udcaa\u22c5\\widetilde{\\mathcal{O}}(\\cdot)over~ start_ARG caligraphic_O end_ARG ( \u22c5 ) notation means that we are ignoring polylogarithmic factors.. To compute the intersection with \u2202\u2130\u2130\\partial\\mathcal{E}\u2202 caligraphic_E we have to solve the following equation and keep the smallest positive root, That is a second order polynomial equation for which we have a closed form to compute its roots. The computations in Eq.\u00a0(10) costs \ud835\udcaa\u2062(n2)\ud835\udcaasuperscript\ud835\udc5b2\\mathcal{O}(n^{2})caligraphic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )\noperations.\nClearly, in the case of the body \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K we solve both Eq.\u00a0(9, 10) and keep the smallest positive root t+subscript\ud835\udc61t_{+}italic_t start_POSTSUBSCRIPT + end_POSTSUBSCRIPT. Then, \u2113\u2062(t+)\u2208\u2202\ud835\udca6\u2113subscript\ud835\udc61\ud835\udca6\\ell(t_{+})\\in\\partial\\mathcal{K}roman_\u2113 ( italic_t start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ) \u2208 \u2202 caligraphic_K is the intersection point. Some random walks, like e.g., BiW, use a sub-routine called reflection oracle. This oracle computes the reflection of a ray \u2113\u2062(t)\u2113\ud835\udc61\\ell(t)roman_\u2113 ( italic_t ) when the later hits the boundary of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K so that the reflected ray continues in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. Typically, this oracle is called after the boundary oracle which computes the boundary point y\ud835\udc66yitalic_y of ray intersecting \u2202\ud835\udca6\ud835\udca6\\partial\\mathcal{K}\u2202 caligraphic_K. Let s\u2208\u211dn,\u2016s\u20162=1formulae-sequence\ud835\udc60superscript\u211d\ud835\udc5bsubscriptnorm\ud835\udc6021s\\in{\\mathbb{R}}^{n},\\ \\|s\\|_{2}=1italic_s \u2208 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , \u2225 italic_s \u2225 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1 the normal vector defining the tangent hyperplane at y\ud835\udc66yitalic_y and v\u2208\u211dn\ud835\udc63superscript\u211d\ud835\udc5bv\\in{\\mathbb{R}}^{n}italic_v \u2208 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT the direction vector of the ray \u2113\u2062(t)\u2113\ud835\udc61\\ell(t)roman_\u2113 ( italic_t ) until it hits \u2202\ud835\udca6\ud835\udca6\\partial\\mathcal{K}\u2202 caligraphic_K. Then, the update rule to obtain the direction vector of the reflected ray is the following, Thus, the reflected direction can be computed after \ud835\udcaa\u2062(n)\ud835\udcaa\ud835\udc5b\\mathcal{O}(n)caligraphic_O ( italic_n ) operations, given the normal vector s\ud835\udc60sitalic_s.\nWhen \u2113\u2062(t)\u2113\ud835\udc61\\ell(t)roman_\u2113 ( italic_t ) hits a facet of \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P the vector s\ud835\udc60sitalic_s is equal to the normal vector of that facet, i.e., equal to the normalized row of the matrix A\ud835\udc34Aitalic_A that corresponds to that facet. When \u2113\u2062(t)\u2113\ud835\udc61\\ell(t)roman_\u2113 ( italic_t ) hits \u2202\u2130\u2130\\partial\\mathcal{E}\u2202 caligraphic_E the vector s\ud835\udc60sitalic_s is equal to E\u2062y/\u2016E\u2062y\u20162\ud835\udc38\ud835\udc66subscriptnorm\ud835\udc38\ud835\udc662Ey/\\|Ey\\|_{2}italic_E italic_y / \u2225 italic_E italic_y \u2225 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, where y\ud835\udc66yitalic_y is the boundary point. Last, certain random walks need to sample uniformly from special sets, namely from the boundary and/or the interior of the unit ball and the interior of a given ellipsoid. To sample from the boundary of the unit ball \u212cnsubscript\u212c\ud835\udc5b\\mathcal{B}_{n}caligraphic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT we sample n\ud835\udc5bnitalic_n numbers g1,\u2026,gnsubscript\ud835\udc541\u2026subscript\ud835\udc54\ud835\udc5bg_{1},\\dots,g_{n}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_g start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT from the standard Gaussian distribution \ud835\udca9\u2062(0,1)\ud835\udca901\\mathcal{N}(0,1)caligraphic_N ( 0 , 1 ) and then the vector q=(g1,\u2026,gd)/\u2211gi2\ud835\udc5esubscript\ud835\udc541\u2026subscript\ud835\udc54\ud835\udc51superscriptsubscript\ud835\udc54\ud835\udc562q=(g_{1},\\dots,g_{d})/\\sqrt{\\sum g_{i}^{2}}italic_q = ( italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_g start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) / square-root start_ARG \u2211 italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG is uniformly distributed on the boundary of \u212cnsubscript\u212c\ud835\udc5b\\mathcal{B}_{n}caligraphic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. Moreover, the point u1/n\u2062qsuperscript\ud835\udc621\ud835\udc5b\ud835\udc5eu^{1/n}qitalic_u start_POSTSUPERSCRIPT 1 / italic_n end_POSTSUPERSCRIPT italic_q, where u\u2208\u211d\ud835\udc62\u211du\\in{\\mathbb{R}}italic_u \u2208 blackboard_R is uniformly distributed in [0,1]01[0,1][ 0 , 1 ], is uniformly distributed in \u212cnsubscript\u212c\ud835\udc5b\\mathcal{B}_{n}caligraphic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. Last, the point L\u2062x\ud835\udc3f\ud835\udc65Lxitalic_L italic_x, where x\ud835\udc65xitalic_x is uniformly distributed in the boundary of \u212cnsubscript\u212c\ud835\udc5b\\mathcal{B}_{n}caligraphic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT and E=LT\u2062L\ud835\udc38superscript\ud835\udc3f\ud835\udc47\ud835\udc3fE=L^{T}Litalic_E = italic_L start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_L, is uniformly distributed in the ellipsoid \u2130\u2130\\mathcal{E}caligraphic_E. To run a geometric random walk it is necessary to compute a point in the interior of the convex body we want to sample from. When the convex body is the convex polytope in Eq.\u00a0(4) one could compute the largest ball inside \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P, called Chebychev ball. Then, by definition, the center of the ball lies inside \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P. To compute the Chebychev ball we have to solve the following linear program, where ai,i=[m]subscript\ud835\udc4e\ud835\udc56\ud835\udc56delimited-[]\ud835\udc5aa_{i},\\ i=[m]italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_i = [ italic_m ] are the rows of the matrix A\ud835\udc34Aitalic_A in Eq.\u00a0(4).\nWhen the convex body is the intersection between a polytope and an ellipsoid, \ud835\udca6=\ud835\udcab\u2229\u2130\ud835\udca6\ud835\udcab\u2130\\mathcal{K}=\\mathcal{P}\\cap\\mathcal{E}caligraphic_K = caligraphic_P \u2229 caligraphic_E,\none could apply on \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K the transformation that maps the ellipsoid \u2130\u2130\\mathcal{E}caligraphic_E to the unit ball \u212cnsubscript\u212c\ud835\udc5b\\mathcal{B}_{n}caligraphic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT and consider the intersection of the transformed polytope with \u212cnsubscript\u212c\ud835\udc5b\\mathcal{B}_{n}caligraphic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. Then, the largest ball inside the latter body can be computed by solving the following Second-Order Cone Program (SOCP), where the pairs ai,bisubscript\ud835\udc4e\ud835\udc56subscript\ud835\udc4f\ud835\udc56a_{i},\\ b_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT define the facets of the transformed polytope. We can obtain a point in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K by applying the inverse transformation on the computed center in Eq.\u00a0(13). In order to evaluate the quality of a sample as an accurate approximation of the target distribution, several convergence diagnostics [110] are available like potential scale reduction factor (PSRF)\u00a0[48], maximum mean discrepancy (MMD)\u00a0[50] and the uniform tests\u00a0[33]. For a dependent sample, a powerful diagnostic is the effective sample size (ESS). It is the number of effectively independent draws from the target distribution that the Markov chain is equivalent to. In our empirical applications, we ensure that PSRF <1.1absent1.1<1.1< 1.1 and ESS >0.95\u2062nabsent0.95\ud835\udc5b>0.95n> 0.95 italic_n, where n\ud835\udc5bnitalic_n reflects the dimensionality of the problem (i.e., in general the number of assets minus the number of equality constraints). A crucial aspect for the efficiency of a random walk is its starting point, which needs to be a point in the interior of the convex body. When the starting point comes from a distribution close to the target distribution, then it is called a warm start. The mixing time analysis in the literature usually requires a warm start to bound the rate of convergence. When the starting point is a fixed or a corner point it is called a cold start. Regarding uniform sampling, in\u00a0[94] they give an algorithm that computes a warm start after \ud835\udcaa~\u2062(n4)~\ud835\udcaasuperscript\ud835\udc5b4\\widetilde{\\mathcal{O}}(n^{4})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ) calls to the membership oracle of the input convex body. In practical implementations the starting point usually is a \u201dcentral\u201d point as the Chebychev or the analytical center of the polytope\u00a0[35, 22, 72]. A common practice is to allow for a user defined positive integer that corresponds to the number of Markov points to be ignored before the implementation starts to store the generated points. Several practical methods have been developed to compute a good starting point\u00a0[41, 27, 28, 35]. Another key aspect affecting the performance of a random walk is the roundness of the target distribution, that is how close the covariance of the target distribution is to the identity matrix. Regarding uniform sampling, this is translated to body\u2019s roundness, measured by the ratio R/r\ud835\udc45\ud835\udc5fR/ritalic_R / italic_r\u00a0[65, 93]. R\ud835\udc45Ritalic_R and r\ud835\udc5fritalic_r are the radii of the largest and smallest ball centered at the origin that contains, and is contained, in \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K, respectively; i.e., r\u2062Bn\u2286\ud835\udca6\u2286R\u2062Bn\ud835\udc5fsubscript\ud835\udc35\ud835\udc5b\ud835\udca6\ud835\udc45subscript\ud835\udc35\ud835\udc5brB_{n}\\subseteq\\mathcal{K}\\subseteq RB_{n}italic_r italic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \u2286 caligraphic_K \u2286 italic_R italic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. Hence, before the actual sampling process is started, it is crucial to reduce R/r\ud835\udc45\ud835\udc5fR/ritalic_R / italic_r, i.e., to put \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K in a well-rounded position, where R/r=\ud835\udcaa~\u2062(n)\ud835\udc45\ud835\udc5f~\ud835\udcaa\ud835\udc5bR/r=\\widetilde{\\mathcal{O}}(\\sqrt{n})italic_R / italic_r = over~ start_ARG caligraphic_O end_ARG ( square-root start_ARG italic_n end_ARG ). This is particularly relevant for financial applications like the one we suggest in our empirical study in Section\u00a05 because lower and upper bounds on asset weights are typically tight, inducing a skinny polytope. A powerful approach to obtain well roundness is to put \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K in isotropic position. In general, \ud835\udca6\u2282\u211dn\ud835\udca6superscript\u211d\ud835\udc5b\\mathcal{K}\\subset{\\mathbb{R}}^{n}caligraphic_K \u2282 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is in isotropic position if the uniform distribution over \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K is in isotropic position, that is \ud835\udd3cX\u223c\ud835\udca6\u2062[X]=0subscript\ud835\udd3csimilar-to\ud835\udc4b\ud835\udca6delimited-[]\ud835\udc4b0\\mathbb{E}_{X\\sim\\mathcal{K}}[X]=0blackboard_E start_POSTSUBSCRIPT italic_X \u223c caligraphic_K end_POSTSUBSCRIPT [ italic_X ] = 0 and \ud835\udd3cX\u223c\ud835\udca6\u2062[XT\u2062X]=Insubscript\ud835\udd3csimilar-to\ud835\udc4b\ud835\udca6delimited-[]superscript\ud835\udc4b\ud835\udc47\ud835\udc4bsubscript\ud835\udc3c\ud835\udc5b\\mathbb{E}_{X\\sim\\mathcal{K}}[X^{T}X]=I_{n}blackboard_E start_POSTSUBSCRIPT italic_X \u223c caligraphic_K end_POSTSUBSCRIPT [ italic_X start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_X ] = italic_I start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, where Insubscript\ud835\udc3c\ud835\udc5bI_{n}italic_I start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT is the n\u00d7n\ud835\udc5b\ud835\udc5bn\\times nitalic_n \u00d7 italic_n identity matrix. Thus, to put \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K into isotropic position one has to generate a set of uniform points in its interior and apply to \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K the transformation that maps the point-set to isotropic position; then iterate this procedure until \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K is in \ud835\udcaa\u2062(1)\ud835\udcaa1\\mathcal{O}(1)caligraphic_O ( 1 )-isotropic position [35, 93]. In\u00a0[112] they prove that \ud835\udcaa\u2062(log\u2061(n))\ud835\udcaa\ud835\udc5b\\mathcal{O}(\\log(n))caligraphic_O ( roman_log ( italic_n ) ) iterations and \ud835\udcaa~\u2062(n)~\ud835\udcaa\ud835\udc5b\\widetilde{\\mathcal{O}}(n)over~ start_ARG caligraphic_O end_ARG ( italic_n ) uniformly distributed points per iteration suffice to achieve isotropic position. There are several algorithms based on this routine\u00a0[65, 94, 62]. In\u00a0[62] they build upon\u00a0[129] to provide the best algorithm so far that puts a convex body in isotropic position after \ud835\udcaa~\u2062(n3)~\ud835\udcaasuperscript\ud835\udc5b3\\widetilde{\\mathcal{O}}(n^{3})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) membership oracle calls.\nThe practical method in\u00a0[27] brings a convex body in near-isotropic position by using BiW with multiple starting points for uniform sampling in each phase. It successfully rounds convex polytopes in a few thousand dimensions. An alternative notion of well roundness is the John position. A convex body in John position has a sandwiching ratio of R/r=\ud835\udcaa~\u2062(n)\ud835\udc45\ud835\udc5f~\ud835\udcaa\ud835\udc5bR/r=\\widetilde{\\mathcal{O}}(n)italic_R / italic_r = over~ start_ARG caligraphic_O end_ARG ( italic_n ) which is worse than that of isotropic position. To put the body in John position one needs to compute the maximum volume ellipsoid (MVE) in it and apply to the body the transformation that maps the ellipsoid to the unit ball. To our knowledge there are specialized results only for the case of a convex polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P. In\u00a0[106, 4] they independently give an algorithm that computes the John ellipsoid of \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P in \ud835\udcaa~\u2062(m3.5)~\ud835\udcaasuperscript\ud835\udc5a3.5\\widetilde{\\mathcal{O}}(m^{3.5})over~ start_ARG caligraphic_O end_ARG ( italic_m start_POSTSUPERSCRIPT 3.5 end_POSTSUPERSCRIPT ) operations. Interestingly, in\u00a0[69] they provide a linear time transformation of the MVE problem by computing a minimum volume enclosing ellipsoid (MVEE) of a set of points. Thus, the algorithms in\u00a0[74, 123] that solve the MVEE problem can be used to compute the John ellipsoid after \ud835\udcaa\u2062(m\u2062n3/\u03f5)\ud835\udcaa\ud835\udc5asuperscript\ud835\udc5b3italic-\u03f5\\mathcal{O}(mn^{3}/\\epsilon)caligraphic_O ( italic_m italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_\u03f5 ) operations. The practical method in\u00a0[134] to compute the MVE has been used in\u00a0[53] to bring convex polytopes of thousands of dimensions in John position. However, the practical method in\u00a0[27] obtains, in almost the same runtime, both a better sandwiching ratio than\u00a0[134] \u2013as it brings the polytope to a near isotropic position\u2013 and a uniformly distributed sample in \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P. Last, in\u00a0[32, 118] they provide algorithms to compute the John ellipsoid in the special case of a centrally symmetric convex polytope achieving near optimal performance. However, those algorithms can not be used for the purpose of rounding any convex polytope. For an overview in rounding a convex body we refer to Table\u00a01. To round a log-concave distribution with density function \u03c0\ud835\udf0b\\piitalic_\u03c0, R\ud835\udc45Ritalic_R is chosen to bound the expected squared distance of the random variable from the centroid of \u03c0\ud835\udf0b\\piitalic_\u03c0, i.e., R2\u2265\ud835\udd3c\u03c0\u2062(|x\u2212z\u03c0|2)superscript\ud835\udc452subscript\ud835\udd3c\ud835\udf0bsuperscript\ud835\udc65subscript\ud835\udc67\ud835\udf0b2R^{2}\\geq\\mathbb{E}_{\\pi}(|x-z_{\\pi}|^{2})italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \u2265 blackboard_E start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ( | italic_x - italic_z start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), where z\u03c0subscript\ud835\udc67\ud835\udf0bz_{\\pi}italic_z start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT is the centroid. We say that a log-concave density function is well-rounded if R/r=\ud835\udcaa\u2062(n)\ud835\udc45\ud835\udc5f\ud835\udcaa\ud835\udc5bR/r=\\mathcal{O}(\\sqrt{n})italic_R / italic_r = caligraphic_O ( square-root start_ARG italic_n end_ARG ), where r\ud835\udc5fritalic_r is the radius of the ball contained in a level set of \u03c0\ud835\udf0b\\piitalic_\u03c0 of constant probability. In\u00a0[91] they provided the first algorithm to round a log-concave distribution \u03c0\u221de\u2212f\u2062(x)proportional-to\ud835\udf0bsuperscript\ud835\udc52\ud835\udc53\ud835\udc65\\pi\\propto e^{-f(x)}italic_\u03c0 \u221d italic_e start_POSTSUPERSCRIPT - italic_f ( italic_x ) end_POSTSUPERSCRIPT after \ud835\udcaa~\u2062(d5)~\ud835\udcaasuperscript\ud835\udc515\\widetilde{\\mathcal{O}}(d^{5})over~ start_ARG caligraphic_O end_ARG ( italic_d start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT ) membership oracle calls, where f:\u211dn\u2192\u211d:\ud835\udc53\u2192superscript\u211d\ud835\udc5b\u211df:{\\mathbb{R}}^{n}\\rightarrow{\\mathbb{R}}italic_f : blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \u2192 blackboard_R is a convex function. They introduce an iterative algorithm that brings to isotropic position a certain level set of the density function, showing that it suffices to bring it to a near isotropic position. The algorithm can use either HaR or BaW.\nIn\u00a0[92] they give an algorithm that uses HaR and rounds a log-concave distribution after \ud835\udcaa~\u2062(n4.5)~\ud835\udcaasuperscript\ud835\udc5b4.5\\widetilde{\\mathcal{O}}(n^{4.5})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 4.5 end_POSTSUPERSCRIPT ) membership oracle calls; they generalize the algorithm in\u00a0[64] that is specialized for the exponential distribution. Moreover, if a near-optimal point of \u03c0\ud835\udf0b\\piitalic_\u03c0 is given they provide a multi-phase algorithm that rounds \u03c0\ud835\udf0b\\piitalic_\u03c0 after \ud835\udcaa~\u2062(n4)~\ud835\udcaasuperscript\ud835\udc5b4\\widetilde{\\mathcal{O}}(n^{4})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ) membership oracle calls. The main idea in\u00a0[64, 92] is to consider the density function, where the parameter \u03b2>0\ud835\udefd0\\beta>0italic_\u03b2 > 0 controls the variance of \u03c0\u03b2subscript\ud835\udf0b\ud835\udefd\\pi_{\\beta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b2 end_POSTSUBSCRIPT. They introduce a new multi-phase algorithm where in each phase they set a different value of \u03b2\ud835\udefd\\betaitalic_\u03b2; the last phase sets \u03b2=1\ud835\udefd1\\beta=1italic_\u03b2 = 1 and samples from \u03c0\ud835\udf0b\\piitalic_\u03c0. Initially, the algorithm invokes the rounding algorithm outlined in\u00a0[94] to obtain a warm start for the uniform distribution over \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. In the initial phase, it samples for \u03b2=0\ud835\udefd0\\beta=0italic_\u03b2 = 0, representing the uniform distribution. As the algorithm progresses to the j\ud835\udc57jitalic_j-th phase, the parameter \u03b2jsubscript\ud835\udefd\ud835\udc57\\beta_{j}italic_\u03b2 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT incrementally increases to ensure that a sampled point from \u03c0\u03b2\u2062j\u22121subscript\ud835\udf0b\ud835\udefd\ud835\udc571\\pi_{\\beta{j-1}}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b2 italic_j - 1 end_POSTSUBSCRIPT serves as a warm start for \u03c0\u03b2jsubscript\ud835\udf0bsubscript\ud835\udefd\ud835\udc57\\pi_{\\beta_{j}}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b2 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT in accordance with the L2subscript\ud835\udc3f2L_{2}italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT norm on density functions. Furthermore, the sample generated in the j\ud835\udc57jitalic_j-th phase is utilized to estimate the covariance matrix for the subsequent phase. Upon reaching \u03b2=1\ud835\udefd1\\beta=1italic_\u03b2 = 1, the algorithm concludes by applying a linear transformation to both \u03c0\ud835\udf0b\\piitalic_\u03c0 and \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K, converting the ellipsoid defined by the approximated covariance into the unit ball. Consequently, the resulting density function is well-rounded. Lastly, it is important to state that these rounding results on constrained, log-concave density functions, highlight the importance of HaR since it can mix starting from L2subscript\ud835\udc3f2L_{2}italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT warm starts or even from cold start, which can be exploited to reduce the number of phases we need to round \u03c0\ud835\udf0b\\piitalic_\u03c0. Regarding uniform sampling from a general convex body, best mixing time is achieved by HaR and Ball walk (BaW, see Section 4.1, that is \ud835\udcaa~\u2062(n2\u2062R2/r2)~\ud835\udcaasuperscript\ud835\udc5b2superscript\ud835\udc452superscript\ud835\udc5f2\\widetilde{\\mathcal{O}}(n^{2}R^{2}/r^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) steps for a body in general position with sandwiching ratio equal to R/r\ud835\udc45\ud835\udc5fR/ritalic_R / italic_r. However, one could bring the body to a near isotropic position, as a preprocessing step, after \ud835\udcaa~\u2062(n3)~\ud835\udcaasuperscript\ud835\udc5b3\\widetilde{\\mathcal{O}}(n^{3})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) membership oracle calls. Then, both HaR and BaW can generate an almost uniformly distributed point after \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) steps. Then, the efficiency per almost unifromly distributed point depends on which oracle is cheaper (i.e., the membership or the boundary oracle). In the case of sampling uniformly from a bounded convex polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P, we have that the number facets m\u2265n+1\ud835\udc5a\ud835\udc5b1m\\geq n+1italic_m \u2265 italic_n + 1 to guarantee boundness. Therefore, for a convex polytope in a general position, the best mixing time is given between Weighted Dikin walk\u00a0[75] and Riemannian HMC\u00a0[83] while their mixing times do not depend on R/r\ud835\udc45\ud835\udc5fR/ritalic_R / italic_r. Since they have the same cost per step, which is the most efficient random walk depends on the number of facets m\ud835\udc5amitalic_m. Let m=\ud835\udcaa\u2062(nk)\ud835\udc5a\ud835\udcaasuperscript\ud835\udc5b\ud835\udc58m=\\mathcal{O}(n^{k})italic_m = caligraphic_O ( italic_n start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) where k\u22651\ud835\udc581k\\geq 1italic_k \u2265 1. For k\u226443\ud835\udc5843k\\leq\\frac{4}{3}italic_k \u2264 divide start_ARG 4 end_ARG start_ARG 3 end_ARG the most efficient random walk is Riemannian HMC and for k>43\ud835\udc5843k>\\frac{4}{3}italic_k > divide start_ARG 4 end_ARG start_ARG 3 end_ARG Weighted Dikin walk achieves a smaller mixing time. However, if one brings \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P to a near isotropic position, the most efficient option is BaW since its mixing time is \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) (same with HaR and Weighted Dikin walk) and its cost per step is the smallest among all uniform samplers, i.e., \ud835\udcaa~\u2062(m)~\ud835\udcaa\ud835\udc5a\\widetilde{\\mathcal{O}}(m)over~ start_ARG caligraphic_O end_ARG ( italic_m ) steps. Considering non-uniform sampling, there are known bounds only for the case of general log-concave distributions. The geometric random walk that achieves the best mixing time is BaW. In particular, for a log-concave in a general position BaW mixes after \ud835\udcaa~\u2062(n2\u2062D)~\ud835\udcaasuperscript\ud835\udc5b2\ud835\udc37\\widetilde{\\mathcal{O}}(n^{2}D)over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_D ) steps where D\ud835\udc37Ditalic_D is the diameter of the support of the target distribution\u00a0[81]. If the target distribution is in isotropic position then BaW mixes after \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) steps. However, when the starting point is a corner point BaW is known to mix slowly, while HaR is known to mix rapidly from any given interior point, even a corner point\u00a0[92].\nHowever, both Reflective and Riemannian HMC have shown superior performance in practice\u00a0[25, 72]. For a quick overview on the random walks that allow for non-uniform sampling we refer to the Table\u00a03. Considering uniform sampling in practice, there are several areas of application with the most effort being devoted to sampling steady states of metabolic networks in biology\u00a0[53, 27, 59] and practical volume calculation of convex polytopes\u00a0[41, 35, 22]. Until recently the dominant paradigm for random walks was Coordinate Direction Hit-and-Run (CDHR)\u00a0[68], which is a version of HaR that uses directions parallel to the axes in each step instead of random ones. The mixing time of CDHR for uniform sampling has been bounded by \ud835\udcaa~\u2062(n9\u2062(R/r)2)~\ud835\udcaasuperscript\ud835\udc5b9superscript\ud835\udc45\ud835\udc5f2\\widetilde{\\mathcal{O}}(n^{9}(R/r)^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT ( italic_R / italic_r ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )\u00a0[76, 104] which is the worst bound among uniform geometric random walk samplers. Interestingly, experiments\u00a0[41, 53] indicate that CDHR achieves a similar mixing rate with both HaR and BaW. Thus, the faster step of CDHR compared to HaR\u2019s and BaW\u2019s\u2014\ud835\udcaa\u2062(m)\ud835\udcaa\ud835\udc5a\\mathcal{O}(m)caligraphic_O ( italic_m ) vs. \ud835\udcaa\u2062(m\u2062n)\ud835\udcaa\ud835\udc5a\ud835\udc5b\\mathcal{O}(mn)caligraphic_O ( italic_m italic_n )\u2014is the main reason why CDHR overshadowed, until recently, all other random walks in practical computations on convex polytopes. However, in\u00a0[27] a new multi-phase sampler based on BiW proved to be much faster in practice than CDHR for uniform sampling over convex polytopes. Moreover, in\u00a0[22] they again show the superior performance of BiW against HaR and CDHR by developing a new practical algorithm to approximate volume of polytopes. The Riemannian HMC in\u00a0[72] is specialized for convex polytopes and its mixing rate does not depend on the roundness of the polytope. In their experiments on metabolic networks they show that it is faster than CDHR for convex polytopes in a general position. However, there are not any experimental results that compare this Riemannian HMC sampler with the multi-phase sampler in\u00a0[27] for rounded and non-rounded polytopes. Regarding non-linear convex bodies, in\u00a0[23] they provide computational oracles to implement several geometric random walks for the case of spectrahedra (the feasible region of Semidefinite Programs). Their experiments show that BiW outperforms HaR, CDHR and BaW despite the fact that its cost per step is bigger comparing to all of the rest cost per steps. Regarding non-uniform sampling from non-linear convex bodies, in\u00a0[25] they show that the Reflective HMC is the best performer for isotropic log-concave distributions. Last, for the case of log-concave sampling over a convex polytope again in\u00a0[25] they show that the Reflective HMC outperforms both HaR and CDHR. The Riemannian HMC in\u00a0[72] appears to have a relatively small cost per step and exhibits mixing times seemingly unaffected by the roundness of the distribution. These characteristics suggest that it could serve as a competitive random walk for this particular scenario. Nevertheless, there is currently a lack of empirical experiments evaluating its performance specifically on log-concave distributions. BaW can be seen as a special case of Metropolis Hastings\u00a0[54] for constrained sampling in convex domains. However, BaW was first introduced for uniform sampling over convex bodies in\u00a0[65]. They used BaW for volume approximation and rounding convex bodies. They prove a bound of \ud835\udcaa~\u2062(n2\u2062R2/r2)~\ud835\udcaasuperscript\ud835\udc5b2superscript\ud835\udc452superscript\ud835\udc5f2\\widetilde{\\mathcal{O}}(n^{2}R^{2}/r^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) on mixing time, that is \ud835\udcaa~\u2062(n3)~\ud835\udcaasuperscript\ud835\udc5b3\\widetilde{\\mathcal{O}}(n^{3})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) for an isotropic convex body. For a general isotropic log-concave distribution \u03c0\ud835\udf0b\\piitalic_\u03c0 constrained in a convex body the mixing time of BaW is \ud835\udcaa~\u2062(n2/\u03c8\u2062(\u03c0)2)~\ud835\udcaasuperscript\ud835\udc5b2\ud835\udf13superscript\ud835\udf0b2\\widetilde{\\mathcal{O}}(n^{2}/\\psi(\\pi)^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / italic_\u03c8 ( italic_\u03c0 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), where \u03c8\u2062(\u03c0)\ud835\udf13\ud835\udf0b\\psi(\\pi)italic_\u03c8 ( italic_\u03c0 ) is the isoperimetric coefficient of \u03c0\ud835\udf0b\\piitalic_\u03c0\u00a0[65]. In\u00a0[65] they bound \u03c8\u2062(\u03c0)\ud835\udf13\ud835\udf0b\\psi(\\pi)italic_\u03c8 ( italic_\u03c0 ) from below with n1/2superscript\ud835\udc5b12n^{1/2}italic_n start_POSTSUPERSCRIPT 1 / 2 end_POSTSUPERSCRIPT, that results to a mixing time of \ud835\udcaa~\u2062(n3)~\ud835\udcaasuperscript\ud835\udc5b3\\widetilde{\\mathcal{O}}(n^{3})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) for isotropic log-concave distributions. Improving the bound on \u03c8\u2062(\u03c0)\ud835\udf13\ud835\udf0b\\psi(\\pi)italic_\u03c8 ( italic_\u03c0 ) it was a very important open problem in convex geometry for years, while bounding \u03c8\u2062(\u03c0)\ud835\udf13\ud835\udf0b\\psi(\\pi)italic_\u03c8 ( italic_\u03c0 ) by a constant was a famous problem known as Kannan-Lovasz-Simonovits (KLS) conjecture\u00a0[84]. Moreover, it is known\u00a0[81] that, if KLS conjecture is true, the mixing time of ball walk is \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) when \u03b4=\ud835\udcaa\u2062(1/n)\ud835\udeff\ud835\udcaa1\ud835\udc5b\\delta=\\mathcal{O}(1/\\sqrt{n})italic_\u03b4 = caligraphic_O ( 1 / square-root start_ARG italic_n end_ARG ), while if \u03b4\ud835\udeff\\deltaitalic_\u03b4 is larger then the rejection probability in each step becomes too high and the mixing time increases. Thus, a lower bound of \u03a9\u2062(n2)\u03a9superscript\ud835\udc5b2\\Omega(n^{2})roman_\u03a9 ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) is valid for the mixing time of BaW. In\u00a0[81] they improved the bound on \u03c8\u2062(\u03c0)\ud835\udf13\ud835\udf0b\\psi(\\pi)italic_\u03c8 ( italic_\u03c0 ) to n1/4superscript\ud835\udc5b14n^{1/4}italic_n start_POSTSUPERSCRIPT 1 / 4 end_POSTSUPERSCRIPT which leads to a mixing time of \ud835\udcaa~\u2062(n2.5)~\ud835\udcaasuperscript\ud835\udc5b2.5\\widetilde{\\mathcal{O}}(n^{2.5})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2.5 end_POSTSUPERSCRIPT ) for isotropic log-concave distributions. They also extend this result and prove that the mixing time of BaW is \ud835\udcaa~\u2062(n2\u2062D)~\ud835\udcaasuperscript\ud835\udc5b2\ud835\udc37\\widetilde{\\mathcal{O}}(n^{2}D)over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_D ), where D\ud835\udc37Ditalic_D is the diameter of the convex body. Finally, in\u00a0[129] they give an almost constant bound on \u03c8\u2062(\u03c0)\ud835\udf13\ud835\udf0b\\psi(\\pi)italic_\u03c8 ( italic_\u03c0 ), meaning that for increasing dimension n\ud835\udc5bnitalic_n the mixing time of BaW is \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) for isotropic log-concave distributions \u2013 which is also a tight bound on its mixing time. Interestingly in\u00a0[97], for the case of uniform distribution and an isotropic convex polytope they provide an implementation of BaW\u2019s step that costs \ud835\udcaa~\u2062(m)~\ud835\udcaa\ud835\udc5a\\widetilde{\\mathcal{O}}(m)over~ start_ARG caligraphic_O end_ARG ( italic_m ) operations after the very first step that costs \ud835\udcaa\u2062(m\u2062n)\ud835\udcaa\ud835\udc5a\ud835\udc5b\\mathcal{O}(mn)caligraphic_O ( italic_m italic_n ) operations.\nThus, the total cost to generate an almost uniformly distributed point drops by a factor of n\ud835\udc5bnitalic_n in the case of an isotropic convex polytope. In each step, BaW picks uniformly a point y\ud835\udc66yitalic_y from a ball of radius \u03b4\ud835\udeff\\deltaitalic_\u03b4 and centered on the current Markov point p\ud835\udc5dpitalic_p. Then, if the point lies outside of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K the random walk stays on p\ud835\udc5dpitalic_p; otherwise, it applies a Metropolis filter to decide moving to y\ud835\udc66yitalic_y or not. In theory the radius \u03b4\ud835\udeff\\deltaitalic_\u03b4 should be around \ud835\udcaa~\u2062(1/n)~\ud835\udcaa1\ud835\udc5b\\widetilde{\\mathcal{O}}(1/\\sqrt{n})over~ start_ARG caligraphic_O end_ARG ( 1 / square-root start_ARG italic_n end_ARG )\u00a0[65, 34] to achieve the optimal mixing time for log-concave sampling. Since the implementation of BaW requires only membership oracle calls the cost per step is \ud835\udcaa\u2062(m\u2062n)\ud835\udcaa\ud835\udc5a\ud835\udc5b\\mathcal{O}(mn)caligraphic_O ( italic_m italic_n ) in the general case. In the case of uniform sampling from an isotropic polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P in\u00a0[97] they reduce the cost per step to \ud835\udcaa~\u2062(m)~\ud835\udcaa\ud835\udc5a\\widetilde{\\mathcal{O}}(m)over~ start_ARG caligraphic_O end_ARG ( italic_m ) operations by conducting the following analysis: First, for all the sampled points the starting point is always the \ud835\udcaa\u2062(1)\ud835\udcaa1\\mathcal{O}(1)caligraphic_O ( 1 )-warm start given as input. Then, they employ the property that any Markov chain whose stationary distribution is close to the uniform distribution on the polytope will spend on average at least 1n1\ud835\udc5b\\frac{1}{n}divide start_ARG 1 end_ARG start_ARG italic_n end_ARG of its time a distance 1n1\ud835\udc5b\\frac{1}{n}divide start_ARG 1 end_ARG start_ARG italic_n end_ARG from the boundary of the polytope. They compute a lower bound on the distance of the current Markov point to each one of the facets. Thus, they check a certain linear constraint aiT\u2062p\u2264bisuperscriptsubscript\ud835\udc4e\ud835\udc56\ud835\udc47\ud835\udc5dsubscript\ud835\udc4f\ud835\udc56a_{i}^{T}p\\leq b_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_p \u2264 italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT only if the lower bound on the distance of the point p\ud835\udc5dpitalic_p to the i\ud835\udc56iitalic_i-th facet is \ud835\udcaa\u2062(1n)\ud835\udcaa1\ud835\udc5b\\mathcal{O}(\\frac{1}{n})caligraphic_O ( divide start_ARG 1 end_ARG start_ARG italic_n end_ARG ). Finally, they prove that with at least probability 1\u2212\u03f51italic-\u03f51-\\epsilon1 - italic_\u03f5 the BaW will not violate any linear constraint, where the small \u03f5>0italic-\u03f50\\epsilon>0italic_\u03f5 > 0 is a parameter used to bound the size of BaW\u2019s step towards any facet. In\u00a0[35] they provide a BaW implementation for spherical Gaussian sampling to approximate the volume of a polytope. The mixing time in practice is \u2013as expected\u2013 \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ). After an experimental evaluation, they set the radius in each step to \u03b4=4\u2062r/max\u2061{1,\u03b1}\u2062n\ud835\udeff4\ud835\udc5f1\ud835\udefc\ud835\udc5b\\delta=4r/\\max\\{1,\\alpha\\}nitalic_\u03b4 = 4 italic_r / roman_max { 1 , italic_\u03b1 } italic_n, where \u03b1=1/2\u2062\u03c3\ud835\udefc12\ud835\udf0e\\alpha=1/2\\sigmaitalic_\u03b1 = 1 / 2 italic_\u03c3 and r\ud835\udc5fritalic_r is the radius of the largest inscribed ball in the convex body. However, due to constants the number of steps BaW needs to mix in practice is higher that the number of steps that both HaR and CDHR need. Thus, computations carried out with HaR are faster by a constant than the same computations carried out by BaW. CDHR is faster as the dimension increases than BaW since it has a smaller cost per step. Considering uniform sampling, BaW\u2019s mixing time in practice is also \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )\u00a0[24] while the radius of each step is \u03b4=4\u2062r/n\ud835\udeff4\ud835\udc5f\ud835\udc5b\\delta=4r/\\sqrt{n}italic_\u03b4 = 4 italic_r / square-root start_ARG italic_n end_ARG. BaW for Gaussian sampling is implemented in the MATLAB library cobra, based on the results in\u00a0[35]. The implementation is replicated in C++ library volesti. There exist two C++ implementation for uniform sampling; that one in volesti and a second based implemented in the C++ package PolytopeWalk\u00a0[132], which is based on the algoroithms given in\u00a0[131]. Regarding the smaller cost per step in the uniform case, to our knowledge, there is not any practical implementation that takes advantage of this result to obtain a faster software based on BaW uniform polytope sampler in\u00a0[96]. HaR was first defined by Smith in\u00a0[117] for uniform sampling from bounded convex bodies, and extended in\u00a0[17] for any density function over a (non-)convex body. HaR\u2019s mixing time has been studied extensively over the past decades. In\u00a0[90, 93] they show that HaR mixes after \ud835\udcaa~(n2(R/r)2))\\widetilde{\\mathcal{O}}(n^{2}(R/r)^{2}))over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_R / italic_r ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) ) steps for log-concave distributions (including the uniform distribution) and for both a warm and a cold start. That implies a mixing time of \ud835\udcaa~\u2062(n3)~\ud835\udcaasuperscript\ud835\udc5b3\\widetilde{\\mathcal{O}}(n^{3})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) for rounded target distributions. In the case of sampling uniformly an isotropic convex body, in\u00a0[133] they prove that its mixing time is \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) building upon the near optimal bound in KLS conjecture. There have been developed several variants of HaR, i.e., in\u00a0[68] they study optimal direction choices instead of picking a uniformly random direction in each step. It turns out that the optimal direction choice is to pick a direction from the Gaussian distribution \ud835\udca9\u2062(0,\u03a3)\ud835\udca90\u03a3\\mathcal{N}(0,\\Sigma)caligraphic_N ( 0 , roman_\u03a3 ) where \u03a3\u03a3\\Sigmaroman_\u03a3 is the covariance of the target log-concave distribution; that is equivalent of sampling from an isotropic distribution\u00a0[64]. An important property of HaR it is that it mixes from a warm start that comes from a distribution with a bounded L2subscript\ud835\udc3f2L_{2}italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT norm from the target distribution. This allows to develop fast multi-phase polynomial randomized algorithms for several important problems in computational statistics and optimization as one would need a smaller number of phases comparing to random walks that mix from an \ud835\udcaa\u2062(1)\ud835\udcaa1\\mathcal{O}(1)caligraphic_O ( 1 ) warm start, i.e., BaW. Thus, HaR is the random walk of choice to round a log-concave distribution, to approximate an integral over a convex set or solving a convex problem\u00a0[92].\nRegarding additional applications, a specific version, i.e.\u00a0artificial centering hit and run, have been widely used to study constrained based models in biology [99, 113]. HaR has been used for volume computation\u00a0[94], sampling steady states of metabolic networks\u00a0[99, 113], convex optimization\u00a0[64] and other applications\u00a0[10, 53]. Its practical performance established this random walk as one of the main paradigms for constrained log-concave sampling. At each step the algorithm picks a uniformly distributed unit vector that defines a line through the current Markov point and computes the intersection of the line with \u2202\ud835\udca6\ud835\udca6\\partial\\mathcal{K}\u2202 caligraphic_K by calling the boundary oracle of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K obtaining a segment in the interior of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. Then, the next Markov point is chosen according to \u03c0\u2113subscript\ud835\udf0b\u2113\\pi_{\\ell}italic_\u03c0 start_POSTSUBSCRIPT roman_\u2113 end_POSTSUBSCRIPT, i.e., the constraint of \u03c0\ud835\udf0b\\piitalic_\u03c0 over that segment. To sample from \u03c0\u2113subscript\ud835\udf0b\u2113\\pi_{\\ell}italic_\u03c0 start_POSTSUBSCRIPT roman_\u2113 end_POSTSUBSCRIPT one could use a univariate Metropolis Hastings algorithm for \ud835\udcaa\u2062(1)\ud835\udcaa1\\mathcal{O}(1)caligraphic_O ( 1 ) iterations, or perform exact sampling if there is a closed form of \u03c0\u2113subscript\ud835\udf0b\u2113\\pi_{\\ell}italic_\u03c0 start_POSTSUBSCRIPT roman_\u2113 end_POSTSUBSCRIPT at hand. Extended experiments\u00a0[35, 53] have shown that HaR mixes after \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) steps for well-rounded convex polytopes; this result agrees with the latest theoretical bounds on the mixing time\u00a0[133]. Moreover, the experimental results in\u00a0[35] show a convergence after \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) steps for the Gaussian distribution. Interestingly, the constant in the \ud835\udcaa~\u2062(\u22c5)~\ud835\udcaa\u22c5\\widetilde{\\mathcal{O}}(\\cdot)over~ start_ARG caligraphic_O end_ARG ( \u22c5 ) notation is many orders of magnitude smaller than in theory. For example, in\u00a0[53] they propose a step of 8\u2062n28superscript\ud835\udc5b28n^{2}8 italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. The current (competitive) implementations of HaR include, the C++ library volesti\u00a0[24, 26], the MATLAB library cobra\u00a0[55], the C++ library HOPS\u00a0[59], as well as the R packages HitAndRun\u00a0[47] and walkr\u00a0[128]. The most efficient ones are those in volesti and HOPS as they are both optimized C++ implementations. CDHR can be used to sample from any distribution \u03c0\ud835\udf0b\\piitalic_\u03c0 over a convex body \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. It was first introduced for uniform sampling in\u00a0[117]. Regarding applications, CDHR remained in the dark for years, with a few exceptions\u00a0[10] until it used in practical volume approximation algorithms\u00a0[41, 35] for either uniform or spherical Gaussian sampling. Interestingly, in both cases CDHR outperforms HaR. This success story was followed by\u00a0[53], where CDHR was used to uniformly sample steady states of metabolic networks, where the sampled region is a convex polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P. In\u00a0[53] they combine CDHR with a preprocessing step that brings the polytope into John position. They call this algorithmic pipeline as Coordinate Hit-and-Run with Rounding (CHRR). Since then, CDHR was considered as the main paradigm for sampling from polytopes until the development of a new implementation of BiW as we present in Section\u00a04.4. Considering sampling from non-linear constrained regions, in\u00a0[23] they implement CDHR for log-concave sampling from the feasible region of Semidefinite programs. In their experimental analysis they show that CDHR outperforms HaR but its performance is worse than BiW in the case of uniform sampling. The success of CDHR in practice increased the amount of effort spent from researchers to study its mixing time with\u00a0[76, 104] giving the first upper bound guarantees for uniform sampling. In each step we uniformly pick an orthonormal vector ek\u2208\u211dnsubscript\ud835\udc52\ud835\udc58superscript\u211d\ud835\udc5be_{k}\\in{\\mathbb{R}}^{n}italic_e start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT that defines the line \u2113\u2113\\ellroman_\u2113 passing thought the current Markov point p\ud835\udc5dpitalic_p (see Alg.\u00a03). When the sampled body is a convex polytope, the boundary oracle in the very first step costs O\u2062(m\u2062d)\ud835\udc42\ud835\udc5a\ud835\udc51O(md)italic_O ( italic_m italic_d ) as showed above. For the step j\ud835\udc57jitalic_j-th step with j>1\ud835\udc571j>1italic_j > 1, to compute the intersection between \u2113\u2113\\ellroman_\u2113 and \u2202\ud835\udcab\ud835\udcab\\partial\\mathcal{P}\u2202 caligraphic_P we compute th following roots, and we keep the smallest positive and the largest negative. Notice that aiT\u2062psuperscriptsubscript\ud835\udc4e\ud835\udc56\ud835\udc47\ud835\udc5da_{i}^{T}pitalic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_p is already computed in the (j\u22121)\ud835\udc571(j-1)( italic_j - 1 )-th step and aiT\u2062eksuperscriptsubscript\ud835\udc4e\ud835\udc56\ud835\udc47subscript\ud835\udc52\ud835\udc58a_{i}^{T}e_{k}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_e start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT takes 1111 operation. Sampling from the constrained \u03c0\u2113subscript\ud835\udf0b\u2113\\pi_{\\ell}italic_\u03c0 start_POSTSUBSCRIPT roman_\u2113 end_POSTSUBSCRIPT takes \ud835\udcaa~\u2062(1)~\ud835\udcaa1\\widetilde{\\mathcal{O}}(1)over~ start_ARG caligraphic_O end_ARG ( 1 ) operations and, moreover, we have to update just one coordinate per step. Thus, the amortized cost per step of CDHR for polytopes is O\u2062(m)\ud835\udc42\ud835\udc5aO(m)italic_O ( italic_m ). It has the smallest per-step cost among all the known geometric random walks together with Ball walk in the case of convex polytopes. When the sampled body is an intersection between a polytope and an ellipsoid \ud835\udca6=\ud835\udcab\u2229\u2130\ud835\udca6\ud835\udcab\u2130\\mathcal{K}=\\mathcal{P}\\cap\\mathcal{E}caligraphic_K = caligraphic_P \u2229 caligraphic_E the cost of computing the intersection of the line \u2113\u2113\\ellroman_\u2113 with the boundary of the ellipsoid \u2130\u2130\\mathcal{E}caligraphic_E is added to the cost per step of CDHR. For this we have, where the dominant computation is the dot product between p\ud835\udc5dpitalic_p and the k\ud835\udc58kitalic_k-th column of the matrix E\ud835\udc38Eitalic_E which takes \ud835\udcaa\u2062(n)\ud835\udcaa\ud835\udc5b\\mathcal{O}(n)caligraphic_O ( italic_n ) operations. Then, the real roots in the Eq.(16) correspond to the intersection \u2113\u2229\u2202\ud835\udca6\u2113\ud835\udca6\\ell\\cap\\partial\\mathcal{K}roman_\u2113 \u2229 \u2202 caligraphic_K. Thus, the amortized cost per step of CDHR for sampling \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K is \ud835\udcaa\u2062(m+n)\ud835\udcaa\ud835\udc5a\ud835\udc5b\\mathcal{O}(m+n)caligraphic_O ( italic_m + italic_n ). Extended experiments\u00a0[35, 53] have shown that CDHR mixes after \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) steps achieving the same mixing rate with HaR and BaW. In\u00a0[53] they propose a step of 8\u2062n28superscript\ud835\udc5b28n^{2}8 italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT to sample from polytopes in John position. Since CDHR achieves the same mixing rate with HaR in practice, it outperforms HaR because of its cheaper cost per step. CDHR is implemented in the C++ library volesti, the MATLAB library cobra and the C++ library HOPS. The most efficient ones are those in volesti and HOPS as they are both optimized C++ implementations. BiW method is designed for sampling exclusively from the uniform distribution over a convex (or non-convex) body. It was first introduced in\u00a0[125] and later independently by Polyak and Gryazina in\u00a0[51] where they prove asymptotic convergence for convex and non-convex bodies. Nevertheless, the mixing time is remains an open problem. In both\u00a0[125, 51], the authors experimentally showcase that the mixing rate of BiW surpasses that of HaR for a limited class of bodies. To our knowledge, considering applications that require uniform sampling, BiW has been used to address important applications in\u00a0[27, 22].\nIn\u00a0[27] they introduced an enhancement in the cost per step of BiW for convex polytopes, demonstrating superior performance over both HaR and CDHR when sampling the largest human metabolic network known at that time. The authors also present a multi-phase sampling pipeline that enhances the mixing rate of BiW from one phase to the next, ultimately providing both a rounded body and a uniformly distributed sample in the initial body upon termination.\nIn\u00a0[22], the improved version of BiW is utilized to estimate polytope volumes in thousands of dimensions for the first time. BiW exploits linear trajectories and boundary reflections. In each step it uniformly picks a unit direction as HaR. The random walk being at p\ud835\udc5dpitalic_p moves only forward. When the ray hits the boundary it is reflected, while it might be further reflected \u03c1\ud835\udf0c\\rhoitalic_\u03c1 times in total. The step is completed when traveling for a length L\ud835\udc3fLitalic_L picked from a fixed distribution. If the trajectory is reflected more than \u03c1\ud835\udf0c\\rhoitalic_\u03c1 times before travelling length L\ud835\udc3fLitalic_L, the random walk stays on p\ud835\udc5dpitalic_p. In the case of a convex polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P in\u00a0[27] they reduce the cost per step by cinducting the following analysis: To compute the intersection of the ray \u2113:={p+t\u2062v,t>0}assign\u2113\ud835\udc5d\ud835\udc61\ud835\udc63\ud835\udc610\\ell:=\\{p+tv,\\ t>0\\}roman_\u2113 := { italic_p + italic_t italic_v , italic_t > 0 } with \u2202\ud835\udcab\ud835\udcab\\partial\\mathcal{P}\u2202 caligraphic_P in the very first step, BiW uses the boundary oracle of \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P which costs \ud835\udcaa\u2062(m\u2062n)\ud835\udcaa\ud835\udc5a\ud835\udc5b\\mathcal{O}(mn)caligraphic_O ( italic_m italic_n ) operations. Let pisubscript\ud835\udc5d\ud835\udc56p_{i}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and visubscript\ud835\udc63\ud835\udc56v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT the point and the direction vector of each reflection in a BiW step, while i>1\ud835\udc561i>1italic_i > 1. To compute the next intersection we have to solve, and where ak,alsubscript\ud835\udc4e\ud835\udc58subscript\ud835\udc4e\ud835\udc59a_{k},\\ a_{l}italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT are the normal vectors of the facets that \u2113\u2113\\ellroman_\u2113 hits at iteration i\u22121\ud835\udc561i-1italic_i - 1 and i\ud835\udc56iitalic_i respectively. Index l\ud835\udc59litalic_l is computed by solving all the m\ud835\udc5amitalic_m equations in\u00a0(17) while each one of them is solved after O\u2062(1)\ud835\udc421O(1)italic_O ( 1 ) operations as we use the stored values from the previous iteration. Also the inner product \u27e8vi,al\u27e9subscript\ud835\udc63\ud835\udc56subscript\ud835\udc4e\ud835\udc59\\langle v_{i},a_{l}\\rangle\u27e8 italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT \u27e9 in Eq.\u00a0(18) is stored in the previous iteration. After computing all \u27e8ai,aj\u27e9subscript\ud835\udc4e\ud835\udc56subscript\ud835\udc4e\ud835\udc57\\langle a_{i},a_{j}\\rangle\u27e8 italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 as a preprocessing step, which takes m2\u2062dsuperscript\ud835\udc5a2\ud835\udc51m^{2}ditalic_m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d operations, the per-step cost of BiW is \ud835\udcaa\u2062((d+\u03c1)\u2062m)\ud835\udcaa\ud835\udc51\ud835\udf0c\ud835\udc5a\\mathcal{O}((d+\\rho)m)caligraphic_O ( ( italic_d + italic_\u03c1 ) italic_m ). In the case of the convex body \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K (a polytope intersected with an ellipsoid) the computations in Eq.\u00a0(17) can not be performed after \ud835\udcaa\u2062(m)\ud835\udcaa\ud835\udc5a\\mathcal{O}(m)caligraphic_O ( italic_m ) operations as in the case of polytope. In particular, the direction vi\u22121subscript\ud835\udc63\ud835\udc561v_{i-1}italic_v start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT might be reflected from the ellipsoid\u2019s boundary and thus, a constant number of dot products must be computed in the j\ud835\udc57jitalic_j-th equation resulting to a total of \ud835\udcaa\u2062(m\u2062n)\ud835\udcaa\ud835\udc5a\ud835\udc5b\\mathcal{O}(mn)caligraphic_O ( italic_m italic_n ) operation in Eq.\u00a0(17). Since the intersection between a ray and the boundary of ellipsoid is computed after \ud835\udcaa\u2062(n2)\ud835\udcaasuperscript\ud835\udc5b2\\mathcal{O}(n^{2})caligraphic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) operations, the total cost per step in this case is \ud835\udcaa\u2062(\u03c1\u2062(m\u2062n+n2))\ud835\udcaa\ud835\udf0c\ud835\udc5a\ud835\udc5bsuperscript\ud835\udc5b2\\mathcal{O}(\\rho(mn+n^{2}))caligraphic_O ( italic_\u03c1 ( italic_m italic_n + italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) ). In\u00a0[22] they experimentally show that BiW mixes after \ud835\udcaa~\u2062(1)~\ud835\udcaa1\\widetilde{\\mathcal{O}}(1)over~ start_ARG caligraphic_O end_ARG ( 1 ) steps for well-rounded convex bodies. Moreover, in both\u00a0[27, 22] they show that setting \u03c1=\ud835\udcaa\u2062(n)\ud835\udf0c\ud835\udcaa\ud835\udc5b\\rho=\\mathcal{O}(n)italic_\u03c1 = caligraphic_O ( italic_n ) suffices to both achieve this mixing rate and to avoid pathological cases where the trajectory stacks in corners. The latter implies that in practice BiW achieves a \ud835\udcaa~\u2062(1)~\ud835\udcaa1\\widetilde{\\mathcal{O}}(1)over~ start_ARG caligraphic_O end_ARG ( 1 ) mixing time while the cost per step is \ud835\udcaa\u2062(m\u2062n)\ud835\udcaa\ud835\udc5a\ud835\udc5b\\mathcal{O}(mn)caligraphic_O ( italic_m italic_n ) for well-rounded polytopes. In the case of the intersection between a polytope and an ellipsoid the cost per step becomes \ud835\udcaa\u2062(n2)\ud835\udcaasuperscript\ud835\udc5b2\\mathcal{O}(n^{2})caligraphic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ). BiW is implemented in the C++ library volesti that provides both the improved version of BiW and the multi-phase sampling method given in\u00a0[27]. BiW is also implemented in the R package Xsample\u00a0[125] where it was first introduced as a random walk. Dikin walk can be used only for uniform sampling from a convex body; here we consider only the case of a convex polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P. It was first defined in\u00a0[66] where they employ interior point methods based on Dikin ellipsoids, which by definition are enclosed in \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P. Dikin walk is invariant under affine transformations of the polytope, meaning the mixing rate does not depend on the roundness of the polytope, i.e., the sandwiching ratio R/r\ud835\udc45\ud835\udc5fR/ritalic_R / italic_r, as the previously presented random walks. In\u00a0[66] they bound the mixing time by \ud835\udcaa~\u2062(m\u2062n)~\ud835\udcaa\ud835\udc5a\ud835\udc5b\\widetilde{\\mathcal{O}}(mn)over~ start_ARG caligraphic_O end_ARG ( italic_m italic_n ) steps starting from a warm start (in\u00a0[114] they provide a shorter proof of a Gaussian variant). When it starts from the Chebychev center they prove that \ud835\udcaa~\u2062(m\u2062n2)~\ud835\udcaa\ud835\udc5asuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(mn^{2})over~ start_ARG caligraphic_O end_ARG ( italic_m italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) steps require to converge to the target distribution. Moreover, they use Dikin walk to solve linear programs after \ud835\udcaa~\u2062(m\u2062n2)~\ud835\udcaa\ud835\udc5asuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(mn^{2})over~ start_ARG caligraphic_O end_ARG ( italic_m italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) steps. To define the Dikin ellipsoids they use the Hessian of the simple log-barrier of the polytope, In\u00a0[75] they introduce the notion of strong self-concordance of a barrier function. They prove that Dikin walk mixes in \ud835\udcaa~\u2062(n\u2062\u03bd^)~\ud835\udcaa\ud835\udc5b^\ud835\udf08\\widetilde{\\mathcal{O}}(n\\hat{\\nu})over~ start_ARG caligraphic_O end_ARG ( italic_n over^ start_ARG italic_\u03bd end_ARG ) steps from a warm start in a convex body using\na strongly self-concordant barrier with symmetric self-concordance parameter \u03bd^^\ud835\udf08\\hat{\\nu}over^ start_ARG italic_\u03bd end_ARG. They show that the strong\nself-concordance of Lee-Sidford barrier is bounded from the the standard self-concordance parameter \u03bd=\ud835\udcaa\u2062(n)\ud835\udf08\ud835\udcaa\ud835\udc5b\\nu=\\mathcal{O}(n)italic_\u03bd = caligraphic_O ( italic_n ). Thus, they prove that Dikin walk, in a polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P, with Lee-Sidford barrier mixes after \ud835\udcaa~\u2062(n2)~\ud835\udcaasuperscript\ud835\udc5b2\\widetilde{\\mathcal{O}}(n^{2})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) steps. Finally, in\u00a0[103] they extend the results in\u00a0[66] for an intersection between a polytope and a spectrahedron, that is the feasible region of a Semidefinite Program, i.e., the convex set given by a Least Matrix Inequality (LMI). They prove that Dikin walk mixes after \ud835\udcaa~\u2062(m\u2062n+n\u2062\u03bdh)~\ud835\udcaa\ud835\udc5a\ud835\udc5b\ud835\udc5bsubscript\ud835\udf08\u210e\\widetilde{\\mathcal{O}}(mn+n\\nu_{h})over~ start_ARG caligraphic_O end_ARG ( italic_m italic_n + italic_n italic_\u03bd start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ), where \u03bdhsubscript\ud835\udf08\u210e\\nu_{h}italic_\u03bd start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT is the size of the matrices in LMI. Dikin walk uses the Hessian of a convex barrier function to define an ellipsoid centered at the current Markov point, which is contained in the body. In each step picks a uniformly distributed point in the ellipsoid. The new point is accepted with a probability that depends on the ratio of the volumes of the ellipsoids centered at the two points. The latter filter is applied to guarantee the convergence to the uniform distribution. Since the implementation of each step requires to compute the volumes of two ellipsoids, which involves the computation of the determinant of a positive matrix, the cost per step of Dikin walk is \ud835\udcaa\u2062(m\u2062n\u03c9\u22121)\ud835\udcaa\ud835\udc5asuperscript\ud835\udc5b\ud835\udf141\\mathcal{O}(mn^{\\omega-1})caligraphic_O ( italic_m italic_n start_POSTSUPERSCRIPT italic_\u03c9 - 1 end_POSTSUPERSCRIPT ). In\u00a0[75] they show that the step of Dikin walk with the simple log-barrier can be implemented after \ud835\udcaa\u2062(nnz\u2062(A)+n2)\ud835\udcaannz\ud835\udc34superscript\ud835\udc5b2\\mathcal{O}(\\text{nnz}(A)+n^{2})caligraphic_O ( nnz ( italic_A ) + italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), where nnz\u2062(\u22c5)nnz\u22c5\\text{nnz}(\\cdot)nnz ( \u22c5 ) denotes the number of non-zero elements in matrix A\ud835\udc34Aitalic_A. In\u00a0[132] they implement Dikin, Vaidya and John walk as given in\u00a0[131]. They compare them by performing experiments on well-rounded polytopes. In most of the cases Dikin walk beats both Vaidya and John walk. However, no extensive experimental evaluation of Dikin walk took place until now. Moreover, to our knowledge, there is not any important application that was addressed by Dikin walk. Dikin walk is implemented in the C++ package PolytopeWalk. The same implementation is integrated in volesti. Last, there is an R implementation provided by the R package walkr\u00a0[128]. Vaidya walk is closely related to Dikin walk. It can be used to sample from the uniform distribution over a convex polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P. The point of difference is the ellipsoid it uses in each step. Instead of a Dikin it uses a Vaidya ellipsoid centered on the current Markov Point which is is also included in the polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P\u00a0[124].\nIn [131] they prove an upper bound \ud835\udcaa~\u2062(m1/2\u2062n3/2)~\ud835\udcaasuperscript\ud835\udc5a12superscript\ud835\udc5b32\\widetilde{\\mathcal{O}}(m^{1/2}n^{3/2})over~ start_ARG caligraphic_O end_ARG ( italic_m start_POSTSUPERSCRIPT 1 / 2 end_POSTSUPERSCRIPT italic_n start_POSTSUPERSCRIPT 3 / 2 end_POSTSUPERSCRIPT ) for the mixing time of Vaidya walk starting from a warm start. Notice that comparing Vaidya with Dikin walk appears a trade-off between the number of facets m\ud835\udc5amitalic_m and the dimension n\ud835\udc5bnitalic_n. Vaidya walk is more efficient than Dikin walk when m\u226bnmuch-greater-than\ud835\udc5a\ud835\udc5bm\\gg nitalic_m \u226b italic_n, but when m\ud835\udc5amitalic_m is small the mixing rate of Dikin walk outperforms that of Vaidya walk. Vaidya walk uses a weighted version of the simple log-barrier function. When using the simple log-barrier, Dikin walk\u2019s efficiency relies on the representation of \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P and in particular in the number of redundant inequalities. A polytope P\ud835\udc43Pitalic_P remains unchanged if we add any number of redundant inequalities, but on the other side, they have heavy effect on the Hessian of f\ud835\udc53fitalic_f and thus, reducing significant the size of Dikin ellipsoid and affecting crucially the mixing time of Dikin walk. The main idea behind Vaidya walk is to deal with this problem and try to improve the dependence of Dikin walk on the number of facets m\ud835\udc5amitalic_m. An intuitive thought that Vaidya walk follows is to use a barrier with unequal weights for the logarithmic terms in the simple log-barrier function or, equivalently, a matrix with unequal weights in Eq.\u00a0(19) to define the ellipsoid in each step of the random walk. Such modifications has been used in optimization [124, 80] providing significant improvements. Vaidya walk instead of uniformly distributed proposals from state-dependent ellipsoids it uses a Gaussian proposal at the current Markov point p\ud835\udc5dpitalic_p of the random walk and the point-depended covariance being, where \u03b2\u03bd=n/msubscript\ud835\udefd\ud835\udf08\ud835\udc5b\ud835\udc5a\\beta_{\\nu}=n/mitalic_\u03b2 start_POSTSUBSCRIPT italic_\u03bd end_POSTSUBSCRIPT = italic_n / italic_m and the scores, A single step of Vaidya walk with radius parameter r>0\ud835\udc5f0r>0italic_r > 0 is given by the pseudocode of Alg.\u00a06. With gp\u2062(z)subscript\ud835\udc54\ud835\udc5d\ud835\udc67g_{p}(z)italic_g start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_z ) we write the probability density function of the Gaussian with covariance Vpsubscript\ud835\udc49\ud835\udc5dV_{p}italic_V start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT and centered at p\u2208\ud835\udcab\ud835\udc5d\ud835\udcabp\\in\\mathcal{P}italic_p \u2208 caligraphic_P, In\u00a0[131] they compare Vaidya walk against Dikin and John walk by performing experiments on well-rounded polytopes. In most of the cases Vaidya walk beats John walk due to a cheaper cost per step. However, no extensive experimental evaluation of Vaidya walk took place until now. Vaidya walk is implemented in the C++ package PolytopeWalk which is based on the algorithms given in\u00a0[131]. The same implementation is integrated in volesti. John walk was first introduced for uniform sampling from a convex polytope in\u00a0[52] and latter an improved version was given in\u00a0[131] introducing Approximate John walk. It is also relevant to Dikin walk and it goes one step further than Vaidya walk to establish a sublinear dependence on the number of facets m\ud835\udc5amitalic_m in the mixing time. In\u00a0[52] they compute the exact largest ellipsoid centered on the current Markov point p\ud835\udc5dpitalic_p, namely the exact John ellipsoid. Their analysis gives a mixing time of \ud835\udcaa~\u2062(n7)~\ud835\udcaasuperscript\ud835\udc5b7\\widetilde{\\mathcal{O}}(n^{7})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 7 end_POSTSUPERSCRIPT ) steps. Interestingly, in\u00a0[131] they employ the analysis in\u00a0[80] that use John\u2019s weights to improve the performance of interior point methods to solve linear programs by employing approximate John ellipsoids. In\u00a0[131] they integrate that analysis to improve the mixing time of John walk and prove a bound of \ud835\udcaa~\u2062(n2.5)~\ud835\udcaasuperscript\ud835\udc5b2.5\\widetilde{\\mathcal{O}}(n^{2.5})over~ start_ARG caligraphic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 2.5 end_POSTSUPERSCRIPT ) steps which depends logarithmic on the number of facets m\ud835\udc5amitalic_m. In each step being at a point p\u2208\ud835\udcab\ud835\udc5d\ud835\udcabp\\in\\mathcal{P}italic_p \u2208 caligraphic_P John walk approximates the largest inscribed ellipsoid in \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P centered at p\ud835\udc5dpitalic_p and employs the covariance matrix that defines the ellipsoid to compute a Gaussian proposal. The inverse covariance matrix underlying the John walk is given by, the weight vector \u03b6p\u2208\u211dmsubscript\ud835\udf01\ud835\udc5dsuperscript\u211d\ud835\udc5a\\zeta_{p}\\in{\\mathbb{R}}^{m}italic_\u03b6 start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT is obtained by solving the convex program, where \u03b2J:=d/2\u2062massignsubscript\ud835\udefd\ud835\udc3d\ud835\udc512\ud835\udc5a\\beta_{J}:=d/2mitalic_\u03b2 start_POSTSUBSCRIPT italic_J end_POSTSUBSCRIPT := italic_d / 2 italic_m, aJ:=1\u22121/l\u2062o\u2062g2\u2062(1/\u03b2J)assignsubscript\ud835\udc4e\ud835\udc3d11\ud835\udc59\ud835\udc5csubscript\ud835\udc5421subscript\ud835\udefd\ud835\udc3da_{J}:=1-1/log_{2}(1/\\beta_{J})italic_a start_POSTSUBSCRIPT italic_J end_POSTSUBSCRIPT := 1 - 1 / italic_l italic_o italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 / italic_\u03b2 start_POSTSUBSCRIPT italic_J end_POSTSUBSCRIPT ), matrix W=diag\u2062(w)\ud835\udc4adiag\ud835\udc64W=\\text{diag}(w)italic_W = diag ( italic_w ) and Spsubscript\ud835\udc46\ud835\udc5dS_{p}italic_S start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT the slackness matrix at p\ud835\udc5dpitalic_p. The convex program of Eq.\u00a0(24) was introduced in [80] and \u03b6psubscript\ud835\udf01\ud835\udc5d\\zeta_{p}italic_\u03b6 start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT are called approximate John weights. It is also closely related with the problem of computing the largest ellipsoid in P\ud835\udc43Pitalic_P centered at p\ud835\udc5dpitalic_p, which was first studied by John [58]. However, John walk step is costlier than that of Dikin and Vaidya walk by a constant factor\u00a0[131]. In\u00a0[131] they compare Vaidya walk against Dikin and John walk by performing experiments on well-rounded polytopes. Both Dikin and Vaidya presented to achieve a better performance than John walk. However, no extensive experimental evaluation of John walk took place until now. John walk is implemented in the C++ package PolytopeWalk. The same implementation is integrated in volesti. HMC can be used to sample from any probability density function \u03c0\u2062(\u22c5)\ud835\udf0b\u22c5\\pi(\\cdot)italic_\u03c0 ( \u22c5 ) in \u211dnsuperscript\u211d\ud835\udc5b{\\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. It simulates a particle moving in a conservative field determined by \u2212log\u2061\u03c0\u2062(p)\ud835\udf0b\ud835\udc5d-\\log\\pi(p)- roman_log italic_\u03c0 ( italic_p ) and \u2212\u2207log\u2061\u03c0\u2062(p)\u2207\ud835\udf0b\ud835\udc5d-\\nabla\\log\\pi(p)- \u2207 roman_log italic_\u03c0 ( italic_p ). Being at p\u2208\ud835\udca6\ud835\udc5d\ud835\udca6p\\in\\mathcal{K}italic_p \u2208 caligraphic_K, HMC introduces an auxiliary random variable v\u2208\u211dd\ud835\udc63superscript\u211d\ud835\udc51v\\in{\\mathbb{R}}^{d}italic_v \u2208 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, called the momenta, and generates samples from the joint density function Then, marginalizing out v\ud835\udc63vitalic_v recovers the target density \u03c0\u2062(p)\ud835\udf0b\ud835\udc5d\\pi(p)italic_\u03c0 ( italic_p ). Usually we consider the momenta v\ud835\udc63vitalic_v to follow the standard Gaussian distribution \ud835\udca9\u2062(0,In)\ud835\udca90subscript\ud835\udc3c\ud835\udc5b\\mathcal{N}(0,I_{n})caligraphic_N ( 0 , italic_I start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ). Then, the probability density function, where H\u2062(p,v)=\u2212log\u2061\u03c0\u2062(p,v)=\u2212log\u2061\u03c0\u2062(p)+12\u2062|v|2\ud835\udc3b\ud835\udc5d\ud835\udc63\ud835\udf0b\ud835\udc5d\ud835\udc63\ud835\udf0b\ud835\udc5d12superscript\ud835\udc632H(p,v)=-\\log\\pi(p,v)=-\\log\\pi(p)+\\frac{1}{2}|v|^{2}italic_H ( italic_p , italic_v ) = - roman_log italic_\u03c0 ( italic_p , italic_v ) = - roman_log italic_\u03c0 ( italic_p ) + divide start_ARG 1 end_ARG start_ARG 2 end_ARG | italic_v | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT is the corresponding Hamiltonian function. In each step being at p\ud835\udc5dpitalic_p, HMC draws a value for the momentum, v\u223c\ud835\udca9\u2062(0,In)similar-to\ud835\udc63\ud835\udca90subscript\ud835\udc3c\ud835\udc5bv\\sim\\mathcal{N}(0,I_{n})italic_v \u223c caligraphic_N ( 0 , italic_I start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ). Then, (p,v)\ud835\udc5d\ud835\udc63(p,v)( italic_p , italic_v ) is given by the Hamilton\u2019s system of ordinary differential equations (ODE), The solution of the ODE in Eq.\u00a0(27) gives a trajectory p\u2062(t)\u2208\u211dn\ud835\udc5d\ud835\udc61superscript\u211d\ud835\udc5bp(t)\\in{\\mathbb{R}}^{n}italic_p ( italic_t ) \u2208 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, where, ideally, the next Markov point is randomly picked from it. When a closed form solution is not known, the ODE is solved by leapfrog method\u00a0[] so that the convergence is guarantee. Thus, to discretize the Hamiltonian Dynamics we use the leapfrog integrator, where \u03b7>0\ud835\udf020\\eta>0italic_\u03b7 > 0 is the leapfrog step. The new position is accepted with a probability obtained by a regular Metropolis filter. In general, the step length and the number of steps until we obtain the next Markov point are inputs. However, there are several heuristics to determine those two parameters\u00a0[56, 25] to improve the mixing rate of the random walk. In the case where \u03c0\ud835\udf0b\\piitalic_\u03c0 is restricted over a convex body \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K there are two versions of HMC that can sample from the target distribution. The first is the Reflective HMC that employs boundary reflections in each leapfrog step so that the random walk stays inside the body. The second is the Riemannian HMC that uses the log-barrier of the convex body to satisfy the constraints in each step. The Reflective HMC using a leapfrog integrator was introduced for log-concave sampling from linear and non-linear convex bodies\u00a0[2, 25]. The mixing time is unknown and an open problem. ReNHMC is a Reflective HMC sampler that employs the NUTS criterion\u00a0[56]. NUTS exploits the fact that a Hamiltonian trajectory tends to fill the space by forming a spiral. Thus, the optimal number of leapfrog steps is that one when the trajectory starts making a U-turn and approaches the initial point. NUTS is a heuristic that checks the inner products of the position and momenta between the current and the initial position to declare stopping. When the position is updated, i.e., pi+1=pi+\u03b7\u2062v^i+1subscript\ud835\udc5d\ud835\udc561subscript\ud835\udc5d\ud835\udc56\ud835\udf02subscript^\ud835\udc63\ud835\udc561p_{i+1}=p_{i}+\\eta\\hat{v}_{i+1}italic_p start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT = italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_\u03b7 over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT, it might lie outside of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. In this case, ReHMC reflects the ray {pi+t\u2062v^i+1|t\u22650}conditional-setsubscript\ud835\udc5d\ud835\udc56\ud835\udc61subscript^\ud835\udc63\ud835\udc561\ud835\udc610\\{p_{i}+t\\hat{v}_{i+1}\\ |\\ t\\geq 0\\}{ italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_t over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT | italic_t \u2265 0 } so that the new proposal is inside \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. Notice, that the ray may need to be reflected more than once in the case where the step length \u03b7\ud835\udf02\\etaitalic_\u03b7 again leads outside of \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K after a certain reflection. The proposal is again accepted after applying a Metropolis filter. In each leapfrog step we check the NUTS criterion given in\u00a0[56]. In\u00a0[25] they show that ReHMC outperforms both HaR and CDHR for log-concave sampling from convex polytopes and spectrahedra in thousands of dimensions. ReNHMC has never been implemented for truncated sampling before this paper. ReNHMC is implemented in the C++ library volesti. CoRHMC introduced in\u00a0[72] can be used for log-concave sampling over a convex polytope \ud835\udcab\ud835\udcab\\mathcal{P}caligraphic_P.\nIn general, Riemannian HMC uses a Riemannian manifold over the convex body \ud835\udca6\ud835\udca6\\mathcal{K}caligraphic_K. For this, it defines a local distance and integrate it in the Hamiltonian function, i.e., where M\u2062(p)\u2208\u211dn\u00d7n\ud835\udc40\ud835\udc5dsuperscript\u211d\ud835\udc5b\ud835\udc5bM(p)\\in{\\mathbb{R}}^{n\\times n}italic_M ( italic_p ) \u2208 blackboard_R start_POSTSUPERSCRIPT italic_n \u00d7 italic_n end_POSTSUPERSCRIPT is a position-dependent positive definite matrix. The, the ODE solved in each step becomes, where Tr\u2062[\u22c5]Trdelimited-[]\u22c5\\text{Tr}[\\cdot]Tr [ \u22c5 ] is the regular matrix trace. Unfortunately, the discrete leapfrog integrator does not guarantee convergence to the target distribution.\nTo solve this ODE one should use a symplectic numerical integrator\u00a0[49]. However, this task seems quite challenging in practice. The main difficulty is to achieve the numerical accuracy required when the Markov point is close enough to the boundary so that the computations would not lead to numerical overflow. CoRHMC is a specialized sampler for convex polytopes. In\u00a0[73] they provide efficient methods to solve the ODE in Eq.\u00a0(29) by achieving a cost per step of \ud835\udcaa\u2062(n3/2)\ud835\udcaasuperscript\ud835\udc5b32\\mathcal{O}(n^{3/2})caligraphic_O ( italic_n start_POSTSUPERSCRIPT 3 / 2 end_POSTSUPERSCRIPT ). In\u00a0[73] they show that CoRHMC mixes after \ud835\udcaa~\u2062(m\u2062n3)~\ud835\udcaa\ud835\udc5asuperscript\ud835\udc5b3\\widetilde{\\mathcal{O}}(mn^{3})over~ start_ARG caligraphic_O end_ARG ( italic_m italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) steps which is worse than the mixing time of both HaR and BaW for rounded distributions. However, this sampler performs significantly well in practice by outperforming both HaR and CDHR as shown in\u00a0[72]. Its main advantage is that its mixing rate does not depend on the roundness of the distribution; thus, CoRHMC does not require any rounding preprocess for skinny distributions (or skinny polytopes in the case of uniform distribution). Thus, it can sample efficiently from hard instances in thousands of dimensions within minutes\u00a0[72].\nNotably, it has never been performed a comparison between CoRHMC and the MMCS with BiW given in\u00a0[27] for uniform sampling over a convex polytope. CoRHMC is implemented in the MATLAB package PolytopeSamplerMatlab\u00a0[71].\nvolesti also contains an implementation of CoRHMC in C++. We employ geometric random walks to explore factor anomalies in constrained long-only portfolios. To do so, we follow the investment guidelines of a prominent market index which we believe accurately represents the typical framework followed by many mutual funds and institutional investors. The index that we look at is the MSCI Diversified Multiple-Factor index252525See https://www.msci.com/diversified-multi-factor-index. (hereinafter referred to as the DMF index) for the U.S.\u00a0market.\nThe DMF index aims to create systematic exposure to the four factors: value, momentum, quality, and size, while maintaining a risk profile similar to that of the underlying capitalization-weighted parent index, which is the MSCI USA index. The allocation of the DMF index is determined through an optimization which maximizes the exposure to a combination of the four factors, subject to a risk tolerance set equal to the ex-ante variance of the parent index at the time of calculation. MSCI\u2019s prospectus explains that the DMF index is designed to systematically capture the additional sources of systematic return associated with the four factor investing styles. However, the MSCI approach significantly differs from the typical academic literature on factor premia (as the performance difference between a long position in a portfolio of companies with the most favorable factor characteristics and a short position in a basket of assets with the least favorable factor characteristic) in that their model operates in a long-only setup with stringent constraints on asset weights, sector allocations, risk tolerance, and bandwidths on additional factor exposures, all relative to the parent index. In particular, asset weights are bound to the allocation of the parent index by a bandwidth of \u00b12plus-or-minus2\\pm 2\u00b1 2%-points per stock and of \u00b15plus-or-minus5\\pm 5\u00b1 5%-points on sector level. Within those limits, MSCI tries to harvest the premia by tilting the capitalization-weighted allocation towards stocks with elevated factor exposure. A pertinent question arises concerning the possibility of capturing academically investigated factor premia within such a strongly constrained setup. To find out we employ a geometric random walk to sample portfolios from within the set of constraints imposed by the DMF index and analyze whether the sampled portfolio\u2019s out-of-sample262626Out-of-sample means that, at every point of the back-testing procedure, we only use information that was effectively available at that point in time. performances varies in a systematic way with their factor scores. Do portfolios with higher value-, momentum-, quality-, size- or volatility-scores deliver higher, lower, or equal return and risk than their low-scoring counterparts? The traditional method of factor analysis involves forming percentile portfolios based on a sorting of companies idiosyncratic factor scores. Backtests are then conducted where each percentile portfolio is weighting it\u2019s constituents equally or according to capitalization. Factor anomalies are identified through the outperformance of the top percentile portfolio relative to the bottom percentile. Interaction with other factors is examined through regression analysis. In contrast, our RP-based approach offers anomaly detection within investor-defined constraints, and factor interactions can be directly controlled by incorporating factor constraints, eliminating the need for indirect regression methods. In Section\u00a03, we outlined the process of constructing a RP by initially defining investment constraints geometrically and then deriving the distribution of performance statistics either analytically or through sampling and simulation. However, this construction assumes the availability of clean time series data for all stocks, of equal length, to estimate market parameters. Consequently, the described RPs represent snapshots. For an extended analysis of a stock universe over time, adjustments must consider changes in index composition and corporate actions affecting individual stocks (such as splits, mergers, and dividends). These factors complicate matters as both the number of investable assets and the geometric constraints evolve over time. Therefore, akin to quintile portfolios, RPs must undergo regular rebalancings, precluding analytical solutions even for the naive case. The method which we pursue is the following: Every month we construct a new RP by casting the constraints employed by the DMF index to a convex body. The linear constraints, which include the lower and upper bounds on asset, sector, and factor exposures, establish a polytope, and the constraint on variance shapes an ellipsoid. Notice that these bounds shift from one month to the next, adapting to changes in the allocation and risk level of the parent index. Then, we sample from the convex body using a geometric random walk. Because of the quadratic constraint, the choice of sampler is limited to either HaR, CDHR, BaW, BiW or ReNHMC. Among those, only HaR, CDHR, BaW and ReNHMC allow for a distribution other than the uniform. Since ReNHMC is considerably faster than HaR, CDHR and BaW (see [25, 35]), ReNHMC is our method of choice (without the variance constraint we would use CoRHMC). As probability model we use the Dirichlet distribution with a parameter vector equal to the weights of the capitalization-weighted parent index, i.e., \u03b1=\u03c9b\u2062m\ud835\udefcsubscript\ud835\udf14\ud835\udc4f\ud835\udc5a\\alpha=\\omega_{bm}italic_\u03b1 = italic_\u03c9 start_POSTSUBSCRIPT italic_b italic_m end_POSTSUBSCRIPT.\nThis generates samples which have \ud835\udd3c\u2062(\u03c9)=\u03c9b\u2062m\ud835\udd3c\ud835\udf14subscript\ud835\udf14\ud835\udc4f\ud835\udc5a\\mathds{E}(\\omega)=\\omega_{bm}blackboard_E ( italic_\u03c9 ) = italic_\u03c9 start_POSTSUBSCRIPT italic_b italic_m end_POSTSUBSCRIPT, yet are close to the boundary of the constraints set272727Recall that sampling with a parameter vector \u03b1\ud835\udefc\\alphaitalic_\u03b1 with sum less than n\ud835\udc5bnitalic_n results in weights towards the boundaries. We want points to be close to the boundary since the solution of the optimization problem that the DMF index is solving is always a boundary point.. For each sampled portfolio, we then simulate the cumulative returns path for the subsequent month using the returns of the portfolio\u2019s constituents. At the next rebalancing, the process is repeated and the simulated price paths are concatenated to consecutive time series spanning the entire period of analysis. Concatenation from one period to the next follows a similar logic to the formation of quintile portfolios. Portfolios are matched based on factor scores, where the portfolio with the highest exposure to a certain factor in one period is combined with the portfolio scoring highest in the following period, and so forth, down to the lowest scoring pair. Sorting the time-series by factor exposure allows for an analysis of the correlation between factor rank and performance over a long-term period. For example, if there is a monotonic relation between momentum score and return, this should be evident in the backtests through a decreasing out-of-sample return with the simulation index. In other words, the first simulation, forming a concatenation of best-momentum portfolios, should yield the largest cumulative return over the entire backtesting period, with performance gradually decreasing for subsequent simulations. To evaluate the influence of the MSCI constraints, we iterate the backtesting exercise twice, initially applying only the simplex condition before introducing the MSCI constraints in a second round. The implementation of the MSCI Multifactor framework requires a comprehensive dataset of stock price series from companies covered by the MSCI USA index, which includes large and mid-cap equities traded in the U.S282828See https://www.msci.com/our-solutions/indexes/developed-markets.. As the composition of the MSCI USA index is proprietary, we suggest utilizing data from the Center for Research in Securities Prices (CRSP) as an alternative data source. We select a subset of stocks listed on the NYSE, AMEX, and NASDAQ indexes, focusing solely on ordinary common shares of companies incorporated in the U.S. (CRSP shares code 10 and 11). Additionally, we exclude foreign shares, certificates, American depository receipts, shares of beneficial interest, depository units, American trust components, closed-end funds, and real estate investment trusts from our dataset. We found that a good approximation to mimick the MSCI universe is to filter for the largest stocks listed on the three exchanges such that in aggregate they cover 85% of total market capitalization. On average over the backtesting period, this results in about 600600600600 securities per rebalancing.\nThough this approach does not precisely emulate the MSCI methodology, a comparative analysis using both datasets indicates that the results are qualitatively identical. The ultimate aim is not an exact replication but to provide a representative framework. Through the utilization of CRSP data, all our findings can be reproduced and validated. Furthermore, to be included in our study, stocks need a consistent price history of five years without any gaps larger than two weeks. This is needed to compute the covariance matrix in the quadratic constraint bounding portfolio variance to that of the parent index. Moreover, illiquid stocks are removed from the investable universe. As a threshold, we require a median trading volume over the previous 252 trading days to be above USD 1.5 million. We do this because, on the one hand, such illiquid stocks are not easily tradable and therefore would lead to a large implementation shortfall (i.e., the difference between a simulated performance and one obtained from real investments) and on the other hand, such companies display artificially low volatility due to a lack of trading and not because they are not risky.\nThe cleaning process is necessary to ensure that at every point in time, the investable universe only contains information that was effectively available at that point in time and to avoid any positive survivorship bias. All estimations are based on discrete daily total292929Returns, i.e., the percentage changes in prices from time t\u22121\ud835\udc611t-1italic_t - 1 to t\ud835\udc61titalic_t, are termed total when adjusted for dividends (i.e., dividends are re-invested). returns using closing prices denoted in USD, covering the period 01.01.1995 to 31.12.2022. Backtests begin on 03.01.2000. All descriptive statistics are calculated on annualized discrete monthly returns, as is customary in the financial industry. The DMF index actively manages its exposure to specific target and non-target style factors relative to the parent index, not only via a weighting in the objective function, but also by setting benchmark-relative constraints. Book-to-Price, Earnings Yield, Earnings Quality, Investment Quality, Profitability, and Momentum exposures are required to fall within the range of [0.1,0.6]0.10.6[0.1,0.6][ 0.1 , 0.6 ], Earnings Variability, Leverage, and Size within [\u22120.6,\u22120.1]0.60.1[-0.6,-0.1][ - 0.6 , - 0.1 ]. Moreover, the index limits its exposure to non-target style factors, namely Beta, Residual Volatility, Growth, and Liquidity to remain within a range of \u00b10.1plus-or-minus0.1\\pm 0.1\u00b1 0.1 standard deviations relative to the parent index. For value and quality, MSCI computes scores by a weighting of sub-scores. Value, for instance, consists of one-third Price-to-Book and two-thirds Earnings Yield. The scores are further sector standardized using the GICS303030See https://www.msci.com/our-solutions/indexes/gics classification system. Details can be taken from the MSCI methodology paper. Table \u00a04 in Appendix \u00a0A.2 shows how we have mapped the MSCI factors to JKP factors. All scores (i.e., exposures) are ultimately standardized to z-scores and winsorized at \u00b13plus-or-minus3\\pm 3\u00b1 3. Note that the standardization is a monotonous transformation which does not affect the ordering of the scores. Winsorization, on the other hand, does have an influence. On a portfolio level, the factor score i.e., the exposure of a portfolio \u03c9\ud835\udf14\\omegaitalic_\u03c9 to some factor fssubscript\ud835\udc53\ud835\udc60f_{s}italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT is simply taken to be the weighted sum of the portfolio weights times the company factor scores, i.e., \u2211i\u03c9i\u2062\u03b2i,ssubscript\ud835\udc56subscript\ud835\udf14\ud835\udc56subscript\ud835\udefd\ud835\udc56\ud835\udc60\\sum_{i}\\omega_{i}\\beta_{i,s}\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_\u03c9 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_\u03b2 start_POSTSUBSCRIPT italic_i , italic_s end_POSTSUBSCRIPT. We notice that, because of the winsorization step., the weighted sum method is not exactly the same as when we would regress the portfolio returns on the factors. We use the C++ library volesti\u00a0[24, 26], an open-source library for high dimensional MCMC sampling and volume approximation. volesti provides the implementations of all the geometric random walks in Section\u00a04.\nThe core of its implementation is in C++ to optimize performance while the user interface is implemented in R. The library employs\neigen\u00a0[46] for linear algebra and boost\u00a0[98] for random number generation. It has been successfully used for analyzing and sampling steady states of metabolic networks\u00a0[27], for volume estimation of convex bodies\u00a0[22] and economical crises detection\u00a0[19] as well as volatility anomaly detection in stock markets\u00a0[8]. Figures \u00a06 and \u00a07 contain scatter-plots depicting the relation between portfolio factor exposure and portfolio risk (first column), portfolio factor exposure and portfolio return (second column) and portfolio risk and portfolio return (third column). Factor exposure levels are scaled for all factors to live on the interval [-1, 1]. Figure \u00a06 reflects the case where no constraints are applied other than the simplex condition. The plots are overlayed by grey points, labeled one to five, indicating the performance statistics of five sorting-based quintile portfolios. The blue line indicates the fit of a polynomial regression (of degree two).\nFigure \u00a07 shows the results when the constraints imposed by the DMF index are met. We note the following observations. In the first backtests, where only the simplex constraint is applied, the results confirm the presence of a positive relation between portfolio factor scores and returns in all factors except size. For size, the relation is slightly negative. This may be due to the fact the asset universe considered by MSCI contains only large and medium-sized companies. Value and momentum display a non-linearity with slopes becoming steeper at both ends. The relation between portfolio factor score and risk is U-shaped meaning that both, portfolios with particularly high and particularly low factor exposure exhibit higher variance than their unexposed counterparts. This pattern is seen with all four factors. The results are mostly in line with classical sorting-based simulations which are overlayed in Figure \u00a06 as grey dots labeled 1111 to 5555 indicating the corresponding (equally-weighted) quintile portfolios. The primary benefit of the sampling-based approach over the sorting-based method lies in its independence from the weighting within percentile portfolios, eliminating potential strong influences on the results. Additionally, the sampling method provides greater granularity by illustrating the uncertainty in the outcomes of percentile portfolios. Also, it can be seen that some of the quantile portfolio are rather outlying relative to the conditional performance distributions. However, we view this initial application more as a proof-of-concept. The true advantage emerges when additional constraints are introduced, rendering sorting-based methods impractical. The addition of the benchmark-relative bounds used by the DMF index has different effects. For momentum, the relation between factor exposure and return remains clearly positive with a correlation coefficient of 0.229, compared to 0.251 for the long-only case. For value, the correlation remains positive but weakens from initially 0.266 to 0.128. For quality, the positive correlation of 0.189 vanishes to 0.038. For size, where the relation was negative, the effect is further strengthened, showing in correlations dropping from initially -0.106 to -0.168. The non-linear relationships between factor scores and risk are significantly influenced. The graphs indicate that imposing constraints limits allocations\nin such a way that one ends up in one of the two legs of the previously identified U-shaped patterns. For size, value, and momentum, this corresponds to the right leg, exhibiting positive (near-linear) relations with correlations of 0.553, 0.693, and 0.813, respectively. Conversely, for quality, it corresponds to the left leg, displaying a negative correlation of -0.580. Given the observable patterns in the constrained setup we draw the following conclusion: Tilts towards value and momentum are rewarded with higher returns but come at the price of increased volatility. The tilt towards quality has a risk reducing effect without impacting returns, thus increasing overall efficiency. The size tilt should not be actively sought as the relation between size exposure and both, risk and return, is unfavorable. However, we have to keep in mind that, due to the concentration of the capitalization-weighted allocation, any deviation from it will likely increase the size exposure. Value, momentum and quality tilts each imply a size tilt, though without the performance drag of an isolated size tilting. Overall, factor patterns appear to be present even within the very strong bounds implied by the DMF index and an active investment approach trying to harvest them seems justified. Our method for sampling portfolios within given constraints would allow us to analyse the impact of specific constraints in isolation. For instance, it would be interesting to repeat the analysis after removing one of the constraints, like the bound on variance, or a group of constraints, like the control on non-target factor exposures. We leave this idea for future applied research. To finalize, let us challenge once more the option to use the RP for statistical testing; here, to test the outperformance of the DMF index relative to its parent. With an Information ratio (IR) of 0.42, the DMF index resides at the 0.025 quantile of the distribution of IR\u2019s measured from the RP backtests. We could consider this as indication of skill for MSCI\u2019s factor team. However, the quantile value is in direct dependence of the parameter of the Dirichlet distribution which we chose to sample weights from. Although our choice of parametrization is economically justified, the sensitivity on inferential results is hardly acceptable. Conversely, the relation between factor exposure and performance is robust to a wide range of parameter values (we have tested \u03b1=\u03c9b\u2062m\u00d7{0.01,0.1,1,5,10}\ud835\udefcsubscript\ud835\udf14\ud835\udc4f\ud835\udc5a0.010.11510\\alpha=\\omega_{bm}\\times\\{0.01,0.1,1,5,10\\}italic_\u03b1 = italic_\u03c9 start_POSTSUBSCRIPT italic_b italic_m end_POSTSUBSCRIPT \u00d7 { 0.01 , 0.1 , 1 , 5 , 10 }, all giving qualitatively similar results. Only with a scaling factor >10absent10>10> 10 do the resulting samples become too homogenous). We discussed the use of randomized control techniques in the context of empirical asset pricing and performance evaluation. We examined the scenario where the performance distribution of a random portfolio , serving as the random control group, forms the basis for assessing the performance of an elaborated investment strategy relative to the distribution of performances under chance. A random portfolio was defined as a portfolio whose weights constitute a random vector with a specific probability distribution supported on a bounded space, reflecting the investor\u2019s investment constraints, such as bounds on asset weights or risk limits. We explained that commonly employed random portfolios do not offer a statistically acceptable experimental design for performance comparisons and cautioned the reader against such a use case with the aid of an illustrative example. However, under consideration of the random portfolios construction methodology, we found random portfolios to be a helpful tool for visual and descriptive perform analysis. Furthermore, we suggested a novel use case, involving the investigation of the relationship between portfolio factor scores and performance in a constrained setup, which allows to empirically test for the presence of factor anomalies under stringent investment guidelines. We proposed a categorization of random portfolios into three groups \u2014 naive, basic, and regularized \u2014 based on weight distribution and geometric structure of the distribution\u2019s support. Additionally, we introduced geometric random walks, a class of Markov chain Monte Carlo methods, as a novel and powerful paradigm to sample random portfolio weights adhering to linear and quadratic constraints under various models. We provided a survey of all existing geometric random walks, explaining their strengths, limitations, and computational complexities. Ultimately, we performed experiments on real-world datasets using the open-source software project GeomScale which implements various geometric random walk samplers. We replicated the investment guidelines of the MSCI Diversified Multi-Factor index, a well-known index in the industry. This index aims to harvest sources of active returns by tilting the allocation of the capitalization-weighted parent index towards the four factors: value, quality, size, and momentum, while respecting bounds on risk, weights, and factor exposures relative to the parent index. Our study revealed diverse impacts of DMF index constraints on factor-exposure-performance relations, compared to an otherwise unconstrained long-only framework. Momentum maintained a positive relation to returns, nearly as strong as in the long-only case. Value showed a diminishing positive relation, while quality\u2019s positive relation vanished under constraints. Size exhibited a negative relation, which intensified with constraints. Regarding risk, there was a truncation of the initial U-shaped relation, with momentum, value, and size showing increased volatility with higher factor exposures, while quality exhibited a negative correlation with volatility. In summary, tilts towards value and momentum offered higher returns with increased volatility, quality tilts reduced risk without affecting returns, and size tilts led to lower returns and higher risk. Our findings suggest that factor patterns persist even within stringent constraints, justifying an active investment approach to capitalize on the positive ones."
    },
    {
        "id": 18,
        "title": "Self-testing of multipartite non-maximal entangled states exhibiting genuine non-locality",
        "corpus": "Self-testing enables the characterization of quantum systems with minimal assumptions their internal working. As such it represents the strongest form of certification for quantum systems. In the existing self-testing literature, self-testing states which are not maximally entangled, but exhibit genuine multipartite nonlocality, have remained an open problem. This is particularly important because, for many-body systems, genuine multipartite nonlocality has been recognized as the strongest form of multipartite quantum correlation. In this work, we present a Hardy-like paradox for scenarios involving arbitrary number of parties. This paradox is a tool for detecting genuine multipartite nonlocality, allowing for the specific identification and self-testing of states that defy the paradox\u2019s limits the most, which turn out to be non-maximally multipartite entangled states. Since the 1920s, quantum mechanics has not only revolutionized our understanding of fundamental physics but has also driven technological progress. This field has been instrumental in the development of everyday technologies, such as lasers, transistors, and the Global Positioning System (GPS). In recent years, advancements in quantum theory have led to the emergence of innovative applications like quantum computing, quantum networks, and quantum-encrypted communication. At the forefront of these advancements is the phenomenon of quantum entanglement\u00a0[1, 2], a unique aspect of quantum theory that was recognized by the 2022 Nobel Prize for its critical role in quantum information theory and the foundations of quantum mechanics. The exploration of quantum entanglement\u2019s complex theory remains a dynamic and rich area of research, full of unanswered questions that, once solved, could pave the way for new technological applications\u00a0[3, 4, 5]. As the scale of quantum devices increases, certifying their internal workings becomes increasingly complex due to the vastness of the associated Hilbert space\u00a0[6]. To fully describe an n\ud835\udc5bnitalic_n-qubit pure state, one needs 2n\u22121superscript2\ud835\udc5b12^{n}-12 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT - 1 complex parameters. Quantum state tomography, a common approach for system certification, involves obtaining the description of a quantum state by performing measurements on an ensemble of identical quantum states. However, estimating an unknown quantum state within a dimension d\ud835\udc51ditalic_d to an error \u03b5\ud835\udf00\\varepsilonitalic_\u03b5 (in l1subscript\ud835\udc591l_{1}italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT norm) requires \u0398\u2062(d2\u03b52)\u0398superscript\ud835\udc512superscript\ud835\udf002\\Theta\\left(\\frac{d^{2}}{\\varepsilon^{2}}\\right)roman_\u0398 ( divide start_ARG italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_\u03b5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ) copies of that state\u00a0[7]. This requirement makes tomography impractical for large systems. Additionally, tomography is device-dependent, assuming characterized measurements, which is not always feasible in scenarios involving third-party devices. The necessity to overcome these challenges has led to the development of self-testing protocols\u00a0[8]. Crucially, these protocols are device-independent, meaning they do not require any prior knowledge or characterization of the quantum devices being tested. Moreover, the number of measurements scales linearly with number of qubits. This makes them highly valuable for scalable and assumption-minimal certification of quantum systems\u00a0[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 9, 20, 21, 22, 23, 24, 25, 26, 27, 26, 28, 29, 30, 31, 32, 33, panwar2023elegant]. In their study, Mayers and Yao demonstrated that certain statistical correlations exist which necessitate that black boxes replicating these correlations must inherently produce the maximally entangled state |\u03d5+\u27e9=12\u2062(|00\u27e9+|11\u27e9)ketsubscriptitalic-\u03d512ket00ket11|\\phi_{+}\\rangle=\\frac{1}{\\sqrt{2}}(|00\\rangle+|11\\rangle)| italic_\u03d5 start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \u27e9 = divide start_ARG 1 end_ARG start_ARG square-root start_ARG 2 end_ARG end_ARG ( | 00 \u27e9 + | 11 \u27e9 ). Consequently, these Bell correlations serve as a self-test for the state |\u03d5+\u27e9ketsubscriptitalic-\u03d5|\\phi_{+}\\rangle| italic_\u03d5 start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \u27e9. The entanglement in the quantum state allows for correlations that allow the underlying entangled state to be self-tested. A natural question arises: which entangled states can be self-tested? In a breakthrough paper, Coladangelo et al. demonstrated that all pure bipartite states are amenable to self-testing\u00a0[32]. However, in the broader context of multipartite states, our understanding remains limited. This lack of comprehensive knowledge is not unexpected, given that entanglement presents more complexity and challenges in characterization when it involves multiple parties. In particular, self-testing for entangled states in the multipartite setting that admit genuine multipartite nonlocality\u00a0[34] has remained poorly understood. Genuine multipartite nonlocality is a stronger form of nonlocality and understanding entangled states that manifest them can deepen our understanding of quantum theory. For multipartite systems, genuine multipartite nonlocality has been recognized as the strongest form of multipartite quantum correlation\u00a0[35, 36]. Previous works focused on self-testing for maximally entangled states [panwar2023elegant] that admit genuine multipartite nonlocality and it is unclear whether the non-maximally entangled states that admit genuine multipartite nonlocality can be self-tested. In this Letter, we answer the above question in the affirmative. We present a Hardy-like paradox for a scenario involving an arbitrary number of participants, each having access to two measurements that can yield any arbitrary number of outcomes. Our paradox helps witness genuine multipartite nonlocality. The state maximally violating the constraints of our paradox can be self-tested. Regarding robust self-testing, we provide a partial robustness result in the three-party scenario where we consider the non-ideal state to be a three-qubit state. Moreover, it is important to note that the aforementioned state is non-maximally entangled. We highlight that unlike Ref\u00a0[33], our work does not require quantum networks. We operate in the standard Bell-test based self-testing framework and do not need any additional assumptions unlike Ref\u00a0[33]. Consider three distant observers denoted as \ud835\udc9c1subscript\ud835\udc9c1\\mathcal{A}_{1}caligraphic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \ud835\udc9c2subscript\ud835\udc9c2\\mathcal{A}_{2}caligraphic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and \ud835\udc9c3subscript\ud835\udc9c3\\mathcal{A}_{3}caligraphic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT engaged in rounds of measurements on tripartite quantum systems. In each round, every party selects a local measurement denoted as x^isubscript^\ud835\udc65\ud835\udc56\\hat{x}_{i}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and subsequently records the resulting outcome as xisubscript\ud835\udc65\ud835\udc56x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. The resultant joint conditional probability distribution, denoted as PA1\u2062A2\u2062A3\u2062(x1\u2062x2\u2062x3|x^1\u2062x^2\u2062x^3)subscript\ud835\udc43subscript\ud835\udc341subscript\ud835\udc342subscript\ud835\udc343conditionalsubscript\ud835\udc651subscript\ud835\udc652subscript\ud835\udc653subscript^\ud835\udc651subscript^\ud835\udc652subscript^\ud835\udc653P_{A_{1}A_{2}A_{3}}(x_{1}x_{2}x_{3}|\\hat{x}_{1}\\hat{x}_{2}\\hat{x}_{3})italic_P start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ), is classified as local if it can be factorized. This factorization holds under the additional condition of possessing knowledge about a potentially concealed shared classical cause \u03bb\ud835\udf06\\lambdaitalic_\u03bb: The discrete random variable representing the common cause is denoted as \u03bb\ud835\udf06\\lambdaitalic_\u03bb, with a distribution \u03bd\u2062(\u03bb)\u22650\ud835\udf08\ud835\udf060\\nu(\\lambda)\\geq 0italic_\u03bd ( italic_\u03bb ) \u2265 0 and the normalization condition \u2211\u03bb\u03bd\u2062(\u03bb)=1subscript\ud835\udf06\ud835\udf08\ud835\udf061\\sum_{\\lambda}\\nu(\\lambda)=1\u2211 start_POSTSUBSCRIPT italic_\u03bb end_POSTSUBSCRIPT italic_\u03bd ( italic_\u03bb ) = 1. The conditional probability distribution PAi\u2062(xi|x^i,\u03bb)subscript\ud835\udc43subscript\ud835\udc34\ud835\udc56conditionalsubscript\ud835\udc65\ud835\udc56subscript^\ud835\udc65\ud835\udc56\ud835\udf06P_{A_{i}}(x_{i}|\\hat{x}_{i},\\lambda)italic_P start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_\u03bb ) characterizes the behavior of party \ud835\udc9cisubscript\ud835\udc9c\ud835\udc56\\mathcal{A}_{i}caligraphic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. A distribution P\u2062(x1\u2062x2\u2062x3|x^1\u2062x^2\u2062x^3)\ud835\udc43conditionalsubscript\ud835\udc651subscript\ud835\udc652subscript\ud835\udc653subscript^\ud835\udc651subscript^\ud835\udc652subscript^\ud835\udc653P(x_{1}x_{2}x_{3}|\\hat{x}_{1}\\hat{x}_{2}\\hat{x}_{3})italic_P ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) is considered non-local if it cannot be decomposed as described in equation 1. Given the measurement setups, we work under the assumption of the NS principle [37]. This implies that party \ud835\udc9c1subscript\ud835\udc9c1\\mathcal{A}_{1}caligraphic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is unable to communicate with other parties through the choice of measurement. Specifically, the equality PA2\u2062A3\u2062(x2\u2062x3|x^2\u2062x^3)=PA2\u2062A3\u2062(x2\u2062x3|x^1\u2062x^2\u2062x^3)=\u2211x1P\u2062(x1\u2062x2\u2062x3|x^1\u2062x^2\u2062x^3),\u2200x1formulae-sequencesubscript\ud835\udc43subscript\ud835\udc342subscript\ud835\udc343conditionalsubscript\ud835\udc652subscript\ud835\udc653subscript^\ud835\udc652subscript^\ud835\udc653subscript\ud835\udc43subscript\ud835\udc342subscript\ud835\udc343conditionalsubscript\ud835\udc652subscript\ud835\udc653subscript^\ud835\udc651subscript^\ud835\udc652subscript^\ud835\udc653subscriptsubscript\ud835\udc651\ud835\udc43conditionalsubscript\ud835\udc651subscript\ud835\udc652subscript\ud835\udc653subscript^\ud835\udc651subscript^\ud835\udc652subscript^\ud835\udc653for-allsubscript\ud835\udc651P_{A_{2}A_{3}}(x_{2}x_{3}|\\hat{x}_{2}\\hat{x}_{3})=P_{A_{2}A_{3}}(x_{2}x_{3}|%\n\\hat{x}_{1}\\hat{x}_{2}\\hat{x}_{3})=\\sum_{x_{1}}P(x_{1}x_{2}x_{3}|\\hat{x}_{1}%\n\\hat{x}_{2}\\hat{x}_{3}),\\forall x_{1}italic_P start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = italic_P start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = \u2211 start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_P ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) , \u2200 italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT holds, and the analogous statements apply to parties \ud835\udc9c2subscript\ud835\udc9c2\\mathcal{A}_{2}caligraphic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and \ud835\udc9c3subscript\ud835\udc9c3\\mathcal{A}_{3}caligraphic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. Suppose we relax the locality assumption such that any pair of parties can group and share non-local resources. This type of hybrid local and non-local model leads to joint conditional probability distributions, with \u03bdi\u2062(\u03bbi)\u22650subscript\ud835\udf08\ud835\udc56subscript\ud835\udf06\ud835\udc560\\nu_{i}(\\lambda_{i})\\geq 0italic_\u03bd start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\u03bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \u2265 0 and \u2211i,\u03bbi\u03bdi\u2062(\u03bbi)=1subscript\ud835\udc56subscript\ud835\udf06\ud835\udc56subscript\ud835\udf08\ud835\udc56subscript\ud835\udf06\ud835\udc561\\sum_{i,\\lambda_{i}}\\nu_{i}(\\lambda_{i})=1\u2211 start_POSTSUBSCRIPT italic_i , italic_\u03bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_\u03bd start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\u03bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = 1.\nDistributions denoted as P\u2062(x1\u2062x2\u2062x3|x^1\u2062x^2\u2062x^3)\ud835\udc43conditionalsubscript\ud835\udc651subscript\ud835\udc652subscript\ud835\udc653subscript^\ud835\udc651subscript^\ud835\udc652subscript^\ud835\udc653P(x_{1}x_{2}x_{3}|\\hat{x}_{1}\\hat{x}_{2}\\hat{x}_{3})italic_P ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) that cannot be expressed in the form described in equation 2 are termed as genuine tripartite non-local distributions. According to findings in [38], the original concept of multipartite non-locality introduced by Svetlichny [34] encounters practical challenges when operationalized. To address these challenges, it is assumed that the NS principle [39] also holds at the level of distributions PAi\u2062Aj\u2062(xi\u2062xj|x^i\u2062x^j,\u03bb)subscript\ud835\udc43subscript\ud835\udc34\ud835\udc56subscript\ud835\udc34\ud835\udc57conditionalsubscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57subscript^\ud835\udc65\ud835\udc56subscript^\ud835\udc65\ud835\udc57\ud835\udf06P_{A_{i}A_{j}}(x_{i}x_{j}|\\hat{x}_{i}\\hat{x}_{j},\\lambda)italic_P start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_\u03bb ), implying that the conditional probabilities P\u2062(xi|x^i,\u03bb)=P\u2062(xi|x^i\u2062x^j,\u03bb)=\u2211xjP\u2062(xi\u2062xj|x^i\u2062x^j,\u03bb),\u2200x^jformulae-sequence\ud835\udc43conditionalsubscript\ud835\udc65\ud835\udc56subscript^\ud835\udc65\ud835\udc56\ud835\udf06\ud835\udc43conditionalsubscript\ud835\udc65\ud835\udc56subscript^\ud835\udc65\ud835\udc56subscript^\ud835\udc65\ud835\udc57\ud835\udf06subscriptsubscript\ud835\udc65\ud835\udc57\ud835\udc43conditionalsubscript\ud835\udc65\ud835\udc56subscript\ud835\udc65\ud835\udc57subscript^\ud835\udc65\ud835\udc56subscript^\ud835\udc65\ud835\udc57\ud835\udf06for-allsubscript^\ud835\udc65\ud835\udc57P(x_{i}|\\hat{x}_{i},\\lambda)=P(x_{i}|\\hat{x}_{i}\\hat{x}_{j},\\lambda)=\\sum_{x_{%\nj}}P(x_{i}x_{j}|\\hat{x}_{i}\\hat{x}_{j},\\lambda),\\forall\\hat{x}_{j}italic_P ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_\u03bb ) = italic_P ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_\u03bb ) = \u2211 start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_P ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_\u03bb ) , \u2200 over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, are well defined for all \u03bb\ud835\udf06\\lambdaitalic_\u03bb. Let us consider a scenario where all three parties Alice, Bob, and Charlie have two possible measurement choices x^1\u2208{A0,A1}subscript^\ud835\udc651subscript\ud835\udc340subscript\ud835\udc341\\hat{x}_{1}\\in\\{A_{0},A_{1}\\}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2208 { italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT }, x^2\u2208{B0,B1}subscript^\ud835\udc652subscript\ud835\udc350subscript\ud835\udc351\\hat{x}_{2}\\in\\{B_{0},B_{1}\\}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2208 { italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } and x^3\u2208{C0,C1}subscript^\ud835\udc653subscript\ud835\udc360subscript\ud835\udc361\\hat{x}_{3}\\in\\{C_{0},C_{1}\\}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2208 { italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } respectively. Each measurement has two possible outcomes, say {+,\u2212}\\{+,-\\}{ + , - }. We define a tripartite correlation P\u2062(x1,x2,x3|x^1,x^2,x^3)\ud835\udc43subscript\ud835\udc651subscript\ud835\udc652conditionalsubscript\ud835\udc653subscript^\ud835\udc651subscript^\ud835\udc652subscript^\ud835\udc653P(x_{1},x_{2},x_{3}|\\hat{x}_{1},\\hat{x}_{2},\\hat{x}_{3})italic_P ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) that satisfies the following equality constraint, Let us define p3\u2261P(+++|A0B0C0)p_{3}\\equiv P(+++|A_{0}B_{0}C_{0})italic_p start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2261 italic_P ( + + + | italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) and q3\u2261P(\u2212\u2212\u2212|A1B1C1)q_{3}\\equiv P(---|A_{1}B_{1}C_{1})italic_q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2261 italic_P ( - - - | italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ). We define their difference to be \ud835\udcae3:=p3\u2212q3assignsubscript\ud835\udcae3subscript\ud835\udc5d3subscript\ud835\udc5e3\\mathcal{S}_{3}:=p_{3}-q_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT := italic_p start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. We will first show that no local theory can satisfy \ud835\udcae3>0subscript\ud835\udcae30\\mathcal{S}_{3}>0caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0. Further, we will see that it is not just any non-local correlation; rather, it is a genuine non-local correlation. If a non-local correlation satisfies the conditions in 3 with \ud835\udcae3>0subscript\ud835\udcae30\\mathcal{S}_{3}>0caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0, then it is a genuine tripartite non-local correlation. The proof has been deferred to the Appendix.\n\u220e Let\u2019s consider a scenario where N\ud835\udc41Nitalic_N subsystems are distributed among N\ud835\udc41Nitalic_N separate parties \ud835\udc9c1subscript\ud835\udc9c1\\mathcal{A}_{1}caligraphic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \ud835\udc9c2subscript\ud835\udc9c2\\mathcal{A}_{2}caligraphic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, \u2026\u2026\\ldots\u2026, and \ud835\udc9cNsubscript\ud835\udc9c\ud835\udc41\\mathcal{A}_{N}caligraphic_A start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT. Each party, \ud835\udc9cisubscript\ud835\udc9c\ud835\udc56\\mathcal{A}_{i}caligraphic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, can measure one of two observables: either u^isubscript^\ud835\udc62\ud835\udc56\\hat{u}_{i}over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT or v^isubscript^\ud835\udc63\ud835\udc56\\hat{v}_{i}over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, on their local subsystem. The measurement outcomes, denoted as xisubscript\ud835\udc65\ud835\udc56x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, can take values from 1 to disubscript\ud835\udc51\ud835\udc56d_{i}italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, where disubscript\ud835\udc51\ud835\udc56d_{i}italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT represents the dimension of the Hilbert space associated with the i\ud835\udc56iitalic_i-th subsystem \ud835\udc9cisubscript\ud835\udc9c\ud835\udc56\\mathcal{A}_{i}caligraphic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. We are interested in examining the joint probabilities P\u2062(x1,x2,\u2026,xN|x^1,x^2,\u2026,x^N)\ud835\udc43subscript\ud835\udc651subscript\ud835\udc652\u2026conditionalsubscript\ud835\udc65\ud835\udc41subscript^\ud835\udc651subscript^\ud835\udc652\u2026subscript^\ud835\udc65\ud835\udc41P(x_{1},x_{2},\\dots,x_{N}|\\hat{x}_{1},\\hat{x}_{2},\\dots,\\hat{x}_{N})italic_P ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_x start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ), where x^isubscript^\ud835\udc65\ud835\udc56\\hat{x}_{i}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can be either u^isubscript^\ud835\udc62\ud835\udc56\\hat{u}_{i}over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT or v^isubscript^\ud835\udc63\ud835\udc56\\hat{v}_{i}over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Let us consider the following set of conditions: We consider the subsystem \ud835\udc9cN+1subscript\ud835\udc9c\ud835\udc411\\mathcal{A}_{N+1}caligraphic_A start_POSTSUBSCRIPT italic_N + 1 end_POSTSUBSCRIPT to be \ud835\udc9c1subscript\ud835\udc9c1\\mathcal{A}_{1}caligraphic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Similar to the tripartite case, we define pN\u2261P\u2062(1,1,\u2026,1|u^1,u^2,\u2026,u^N)subscript\ud835\udc5d\ud835\udc41\ud835\udc4311\u2026conditional1subscript^\ud835\udc621subscript^\ud835\udc622\u2026subscript^\ud835\udc62\ud835\udc41p_{N}\\equiv P(1,1,\\dots,1|\\hat{u}_{1},\\hat{u}_{2},\\dots,\\hat{u}_{N})italic_p start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT \u2261 italic_P ( 1 , 1 , \u2026 , 1 | over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ), qN\u2261P\u2062(d1,d2,\u2026,dN|v^1,v^2,\u2026,v^N)subscript\ud835\udc5e\ud835\udc41\ud835\udc43subscript\ud835\udc511subscript\ud835\udc512\u2026conditionalsubscript\ud835\udc51\ud835\udc41subscript^\ud835\udc631subscript^\ud835\udc632\u2026subscript^\ud835\udc63\ud835\udc41q_{N}\\equiv P(d_{1},d_{2},\\dots,d_{N}|\\hat{v}_{1},\\hat{v}_{2},\\dots,\\hat{v}_{N})italic_q start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT \u2261 italic_P ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_d start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ) and their difference to be \ud835\udcaeN:=pN\u2212qNassignsubscript\ud835\udcae\ud835\udc41subscript\ud835\udc5d\ud835\udc41subscript\ud835\udc5e\ud835\udc41\\mathcal{S}_{N}:=p_{N}-q_{N}caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT := italic_p start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT - italic_q start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT. We will show that only non-local correlation can satisfy 4 with \ud835\udcaeN>0subscript\ud835\udcae\ud835\udc410\\mathcal{S}_{N}>0caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0 and furthermore, this non-locality is genuine. If a non-local correlation satisfies the conditions in 4 with \ud835\udcaeN>0subscript\ud835\udcae\ud835\udc410\\mathcal{S}_{N}>0caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0, then it is a genuine multipartite non-local correlation. The proof has been deferred to the Appendix.\n\u220e First, we demonstrate self-testing for the tripartite case, then extend to the N\ud835\udc41Nitalic_N-partite scenario. Alice, Bob, and Charlie each choose measurements x^1\u2208{A0,A1}subscript^\ud835\udc651subscript\ud835\udc340subscript\ud835\udc341\\hat{x}_{1}\\in\\{A_{0},A_{1}\\}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2208 { italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT }, x^2\u2208{B0,B1}subscript^\ud835\udc652subscript\ud835\udc350subscript\ud835\udc351\\hat{x}_{2}\\in\\{B_{0},B_{1}\\}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2208 { italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT }, and x^3\u2208{C0,C1}subscript^\ud835\udc653subscript\ud835\udc360subscript\ud835\udc361\\hat{x}_{3}\\in\\{C_{0},C_{1}\\}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2208 { italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT }, respectively. Their binary outcomes are denoted as x1\u2208{\u00b11}subscript\ud835\udc651plus-or-minus1x_{1}\\in\\{\\pm 1\\}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2208 { \u00b1 1 }, x2\u2208{\u00b11}subscript\ud835\udc652plus-or-minus1x_{2}\\in\\{\\pm 1\\}italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2208 { \u00b1 1 }, and x3\u2208{\u00b11}subscript\ud835\udc653plus-or-minus1x_{3}\\in\\{\\pm 1\\}italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2208 { \u00b1 1 }. To illustrate genuine non-locality, consider that Alice, Bob, and Charlie share the following general pure three-qubit state, such that \u2211i,j,k\u2208{0,1}|ai\u2062j\u2062k|2=1subscript\ud835\udc56\ud835\udc57\ud835\udc5801superscriptsubscript\ud835\udc4e\ud835\udc56\ud835\udc57\ud835\udc5821\\sum_{i,j,k\\in\\{0,1\\}}|a_{ijk}|^{2}=1\u2211 start_POSTSUBSCRIPT italic_i , italic_j , italic_k \u2208 { 0 , 1 } end_POSTSUBSCRIPT | italic_a start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 1. We consider x^1=|ux1+\u27e9\u2062\u27e8ux1+|\u2212|ux1\u2212\u27e9\u2062\u27e8ux1\u2212|subscript^\ud835\udc651ketsuperscriptsubscript\ud835\udc62subscript\ud835\udc651brasuperscriptsubscript\ud835\udc62subscript\ud835\udc651ketsuperscriptsubscript\ud835\udc62subscript\ud835\udc651brasuperscriptsubscript\ud835\udc62subscript\ud835\udc651\\hat{x}_{1}=|u_{x_{1}}^{+}\\rangle\\langle u_{x_{1}}^{+}|-|u_{x_{1}}^{-}\\rangle%\n\\langle u_{x_{1}}^{-}|over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = | italic_u start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT \u27e9 \u27e8 italic_u start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT | - | italic_u start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT \u27e9 \u27e8 italic_u start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT |, x^2=|vx2+\u27e9\u2062\u27e8vx2+|\u2212|vx2\u2212\u27e9\u2062\u27e8vx2\u2212|subscript^\ud835\udc652ketsuperscriptsubscript\ud835\udc63subscript\ud835\udc652brasuperscriptsubscript\ud835\udc63subscript\ud835\udc652ketsuperscriptsubscript\ud835\udc63subscript\ud835\udc652brasuperscriptsubscript\ud835\udc63subscript\ud835\udc652\\hat{x}_{2}=|v_{x_{2}}^{+}\\rangle\\langle v_{x_{2}}^{+}|-|v_{x_{2}}^{-}\\rangle%\n\\langle v_{x_{2}}^{-}|over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = | italic_v start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT \u27e9 \u27e8 italic_v start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT | - | italic_v start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT \u27e9 \u27e8 italic_v start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT | and x^3=|wx3+\u27e9\u2062\u27e8wx3+|\u2212|wx3\u2212\u27e9\u2062\u27e8wx3\u2212|subscript^\ud835\udc653ketsuperscriptsubscript\ud835\udc64subscript\ud835\udc653brasuperscriptsubscript\ud835\udc64subscript\ud835\udc653ketsuperscriptsubscript\ud835\udc64subscript\ud835\udc653brasuperscriptsubscript\ud835\udc64subscript\ud835\udc653\\hat{x}_{3}=|w_{x_{3}}^{+}\\rangle\\langle w_{x_{3}}^{+}|-|w_{x_{3}}^{-}\\rangle%\n\\langle w_{x_{3}}^{-}|over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = | italic_w start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT \u27e9 \u27e8 italic_w start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT | - | italic_w start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT \u27e9 \u27e8 italic_w start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT | to be the measurement of Alice, Bob and Charlie respectively. We can choose the following measurements with x^1\u2208{A0,A1}subscript^\ud835\udc651subscript\ud835\udc340subscript\ud835\udc341\\hat{x}_{1}\\in\\{A_{0},A_{1}\\}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2208 { italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } and x^2\u2208{B0,B1}subscript^\ud835\udc652subscript\ud835\udc350subscript\ud835\udc351\\hat{x}_{2}\\in\\{B_{0},B_{1}\\}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2208 { italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } and x^3\u2208{C0,C1}subscript^\ud835\udc653subscript\ud835\udc360subscript\ud835\udc361\\hat{x}_{3}\\in\\{C_{0},C_{1}\\}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2208 { italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } as, where 0<\u03b11,\u03b12,\u03b13<\u03c0formulae-sequence0subscript\ud835\udefc1subscript\ud835\udefc2subscript\ud835\udefc3\ud835\udf0b0<\\alpha_{1},\\alpha_{2},\\alpha_{3}<\\pi0 < italic_\u03b1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03b1 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_\u03b1 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT < italic_\u03c0 and 0\u2264\u03d51,\u03d52,\u03d53<2\u2062\u03c0formulae-sequence0subscriptitalic-\u03d51subscriptitalic-\u03d52subscriptitalic-\u03d532\ud835\udf0b0\\leq\\phi_{1},\\phi_{2},\\phi_{3}<2\\pi0 \u2264 italic_\u03d5 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03d5 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_\u03d5 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT < 2 italic_\u03c0. Without loss of generality we can choose observable A0=B0=C0=\u03c3z\u2261|0\u27e9\u2062\u27e80|\u2212|1\u27e9\u2062\u27e81|subscript\ud835\udc340subscript\ud835\udc350subscript\ud835\udc360subscript\ud835\udf0e\ud835\udc67ket0bra0ket1bra1A_{0}=B_{0}=C_{0}=\\sigma_{z}\\equiv|0\\rangle\\langle 0|-|1\\rangle\\langle 1|italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_\u03c3 start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT \u2261 | 0 \u27e9 \u27e8 0 | - | 1 \u27e9 \u27e8 1 | as long as we consider the general form of the state |\u03a8\u27e9A\u2062B\u2062Csubscriptket\u03a8\ud835\udc34\ud835\udc35\ud835\udc36|\\Psi\\rangle_{ABC}| roman_\u03a8 \u27e9 start_POSTSUBSCRIPT italic_A italic_B italic_C end_POSTSUBSCRIPT and of the three observables A1subscript\ud835\udc341A_{1}italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, B1subscript\ud835\udc351B_{1}italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, C1subscript\ud835\udc361C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. The class of pure three-qubit state that satisfies the condition 3 is of the form: where a\ud835\udc4eaitalic_a and \u03b4\ud835\udeff\\deltaitalic_\u03b4 satisfy 0\u2264a\u226410\ud835\udc4e10\\leq a\\leq 10 \u2264 italic_a \u2264 1 and 0\u2264\u03b4<2\u2062\u03c00\ud835\udeff2\ud835\udf0b0\\leq\\delta<2\\pi0 \u2264 italic_\u03b4 < 2 italic_\u03c0. Then, maximizing \ud835\udcae3subscript\ud835\udcae3\\mathcal{S}_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT over these parameters yields, 18\u2062(2\u2062(7\u2062a\u20621\u22127\u2062a2\u221217\u2062a2)\u22121)\u22480.020351827\ud835\udc4e17superscript\ud835\udc4e217superscript\ud835\udc4e210.02035\\frac{1}{8}\\left(2\\left(7a\\sqrt{1-7a^{2}}-17a^{2}\\right)-1\\right)\\approx 0.02035divide start_ARG 1 end_ARG start_ARG 8 end_ARG ( 2 ( 7 italic_a square-root start_ARG 1 - 7 italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG - 17 italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) - 1 ) \u2248 0.02035 for \u03b11=\u03b12=\u03b13=\u03c02subscript\ud835\udefc1subscript\ud835\udefc2subscript\ud835\udefc3\ud835\udf0b2\\alpha_{1}=\\alpha_{2}=\\alpha_{3}=\\frac{\\pi}{2}italic_\u03b1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_\u03b1 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_\u03b1 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG, a=12\u2062316\u221217\u20621581106\u22480.15207\ud835\udc4e123161715811060.15207a=\\frac{1}{2}\\sqrt{\\frac{316-17\\sqrt{158}}{1106}}\\approx 0.15207italic_a = divide start_ARG 1 end_ARG start_ARG 2 end_ARG square-root start_ARG divide start_ARG 316 - 17 square-root start_ARG 158 end_ARG end_ARG start_ARG 1106 end_ARG end_ARG \u2248 0.15207 and \u03b4=\u03d51+\u03d52+\u03d53\ud835\udeffsubscriptitalic-\u03d51subscriptitalic-\u03d52subscriptitalic-\u03d53\\delta=\\phi_{1}+\\phi_{2}+\\phi_{3}italic_\u03b4 = italic_\u03d5 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_\u03d5 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_\u03d5 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. The maximum value of \ud835\udcae3subscript\ud835\udcae3\\mathcal{S}_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is attainable by the following pure three-qubit state, The maximum achievable value of \ud835\udcae3subscript\ud835\udcae3\\mathcal{S}_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT among all three-qubit states represents the optimal value attainable within tri-partite quantum states of any finite dimension. The proof has been deferred to the Appendix.\n\u220e Based on the findings presented in the preceding paragraphs, we are now ready to demonstrate the self-test of |\u03a8m\u2062a\u2062x\u22c63\u27e9A\u2062B\u2062Csubscriptketsuperscriptsubscript\u03a8\ud835\udc5a\ud835\udc4e\ud835\udc65\u22c6absent3\ud835\udc34\ud835\udc35\ud835\udc36|\\Psi_{max}^{\\star 3}\\rangle_{ABC}| roman_\u03a8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 3 end_POSTSUPERSCRIPT \u27e9 start_POSTSUBSCRIPT italic_A italic_B italic_C end_POSTSUBSCRIPT. If the maximum value of \ud835\udcae3subscript\ud835\udcae3\\mathcal{S}_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is observed, then the state of the system is equivalent up to local isometries\nto |\u03c3\u27e9A\u2062B\u2062C\u2297|\u03a8m\u2062a\u2062x\u22c63\u27e9A\u2032\u2062B\u2032\u2062C\u2032tensor-productsubscriptket\ud835\udf0e\ud835\udc34\ud835\udc35\ud835\udc36subscriptketsuperscriptsubscriptnormal-\u03a8\ud835\udc5a\ud835\udc4e\ud835\udc65normal-\u22c6absent3superscript\ud835\udc34normal-\u2032superscript\ud835\udc35normal-\u2032superscript\ud835\udc36normal-\u2032|\\sigma\\rangle_{ABC}\\otimes|\\Psi_{max}^{\\star 3}\\rangle_{A^{\\prime}B^{\\prime}C%\n^{\\prime}}| italic_\u03c3 \u27e9 start_POSTSUBSCRIPT italic_A italic_B italic_C end_POSTSUBSCRIPT \u2297 | roman_\u03a8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 3 end_POSTSUPERSCRIPT \u27e9 start_POSTSUBSCRIPT italic_A start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_B start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_C start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT, where |\u03a8m\u2062a\u2062x\u22c63\u27e9ketsuperscriptsubscriptnormal-\u03a8\ud835\udc5a\ud835\udc4e\ud835\udc65normal-\u22c6absent3|\\Psi_{max}^{\\star 3}\\rangle| roman_\u03a8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 3 end_POSTSUPERSCRIPT \u27e9 attains the maximum value of \ud835\udcae3subscript\ud835\udcae3\\mathcal{S}_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and |\u03c3\u27e9ket\ud835\udf0e|\\sigma\\rangle| italic_\u03c3 \u27e9 is an arbitrary tripartite state. The proof has been deferred to the Appendix.\n\u220e Now we will provide self-testing of genuine N\ud835\udc41Nitalic_N-partite non-local correlations. We will consider \u2200i,di=2for-all\ud835\udc56subscript\ud835\udc51\ud835\udc562\\forall i,d_{i}=2\u2200 italic_i , italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 2. So our conditions become: We have already seen that no local theory will satisfy \ud835\udcaeN>0subscript\ud835\udcae\ud835\udc410\\mathcal{S}_{N}>0caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0. Let us consider the following general N\ud835\udc41Nitalic_N-qubit pure state shared between N\ud835\udc41Nitalic_N parties \ud835\udc9c1,\ud835\udc9c2,\u2026,subscript\ud835\udc9c1subscript\ud835\udc9c2\u2026\\mathcal{A}_{1},\\mathcal{A}_{2},\\dots,caligraphic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , and \ud835\udc9cNsubscript\ud835\udc9c\ud835\udc41\\mathcal{A}_{N}caligraphic_A start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT: such that \u2211i1,\u2026\u2062iN\u2208{0,1}|ai1,\u2026\u2062iN|2=1subscriptsubscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc4101superscriptsubscript\ud835\udc4esubscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc4121\\sum_{i_{1},\\dots i_{N}\\in\\{0,1\\}}|a_{i_{1},\\dots i_{N}}|^{2}=1\u2211 start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 italic_i start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT \u2208 { 0 , 1 } end_POSTSUBSCRIPT | italic_a start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 italic_i start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 1, and let the projective measurement of Aisubscript\ud835\udc34\ud835\udc56A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be x^ij=|Aixj,+\u27e9\u2062\u27e8Aixj,+|\u2212|Aixj,\u2212\u27e9\u2062\u27e8Aixj,\u2212|superscriptsubscript^\ud835\udc65\ud835\udc56\ud835\udc57ketsuperscriptsubscript\ud835\udc34\ud835\udc56superscript\ud835\udc65\ud835\udc57brasuperscriptsubscript\ud835\udc34\ud835\udc56superscript\ud835\udc65\ud835\udc57ketsuperscriptsubscript\ud835\udc34\ud835\udc56superscript\ud835\udc65\ud835\udc57brasuperscriptsubscript\ud835\udc34\ud835\udc56superscript\ud835\udc65\ud835\udc57\\hat{x}_{i}^{j}=|A_{i}^{x^{j},+}\\rangle\\langle A_{i}^{x^{j},+}|-|A_{i}^{x^{j},%\n-}\\rangle\\langle A_{i}^{x^{j},-}|over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT = | italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_x start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT , + end_POSTSUPERSCRIPT \u27e9 \u27e8 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_x start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT , + end_POSTSUPERSCRIPT | - | italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_x start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT , - end_POSTSUPERSCRIPT \u27e9 \u27e8 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_x start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT , - end_POSTSUPERSCRIPT |. One can choose the basis for the measurements x^ijsuperscriptsubscript^\ud835\udc65\ud835\udc56\ud835\udc57\\hat{x}_{i}^{j}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT where j\u2208{0,1}\ud835\udc5701j\\in\\{0,1\\}italic_j \u2208 { 0 , 1 } as follows: where 0<\u03b1i<\u03c00subscript\ud835\udefc\ud835\udc56\ud835\udf0b0<\\alpha_{i}<\\pi0 < italic_\u03b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < italic_\u03c0 and 0\u2264\u03d5i<2\u2062\u03c00subscriptitalic-\u03d5\ud835\udc562\ud835\udf0b0\\leq\\phi_{i}<2\\pi0 \u2264 italic_\u03d5 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < 2 italic_\u03c0. Now the state that will satisfy the equation 8 has amplitude of the following form: where a\ud835\udc4eaitalic_a and \u03b4\ud835\udeff\\deltaitalic_\u03b4 satisfy 0\u2264a\u226410\ud835\udc4e10\\leq a\\leq 10 \u2264 italic_a \u2264 1 and 0\u2264\u03b4<2\u2062\u03c00\ud835\udeff2\ud835\udf0b0\\leq\\delta<2\\pi0 \u2264 italic_\u03b4 < 2 italic_\u03c0. We will find the maximum value of \ud835\udcaeNsubscript\ud835\udcae\ud835\udc41\\mathcal{S}_{N}caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT using equation 9, 10, and 11. The result in [40] works for any N\ud835\udc41Nitalic_N-party with two input and two output scenarios. Hence, our calculations for triparty case easily generalize for N\ud835\udc41Nitalic_N-party also. Hence, we have self-testing of the state which gives the maximum value for \ud835\udcaeNsubscript\ud835\udcae\ud835\udc41\\mathcal{S}_{N}caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT. If the maximum value of \ud835\udcaeNsubscript\ud835\udcae\ud835\udc41\\mathcal{S}_{N}caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT is observed, then the state of the system is equivalent up to local isometries\nto |\u03c3N\u27e9A1\u2062\u2026\u2062AN\u2297|\u03a8m\u2062a\u2062x\u22c6N\u27e9A1\u2032\u2062\u2026\u2062AN\u2032tensor-productsubscriptketsubscript\ud835\udf0e\ud835\udc41subscript\ud835\udc341normal-\u2026subscript\ud835\udc34\ud835\udc41subscriptketsuperscriptsubscriptnormal-\u03a8\ud835\udc5a\ud835\udc4e\ud835\udc65normal-\u22c6absent\ud835\udc41subscriptsuperscript\ud835\udc34normal-\u20321normal-\u2026subscriptsuperscript\ud835\udc34normal-\u2032\ud835\udc41|\\sigma_{N}\\rangle_{A_{1}\\ldots A_{N}}\\otimes|\\Psi_{max}^{\\star N}\\rangle_{A^{%\n\\prime}_{1}\\ldots A^{\\prime}_{N}}| italic_\u03c3 start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT \u27e9 start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2026 italic_A start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT end_POSTSUBSCRIPT \u2297 | roman_\u03a8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 italic_N end_POSTSUPERSCRIPT \u27e9 start_POSTSUBSCRIPT italic_A start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2026 italic_A start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT end_POSTSUBSCRIPT, where |\u03a8m\u2062a\u2062x\u22c6N\u27e9ketsuperscriptsubscriptnormal-\u03a8\ud835\udc5a\ud835\udc4e\ud835\udc65normal-\u22c6absent\ud835\udc41|\\Psi_{max}^{\\star N}\\rangle| roman_\u03a8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 italic_N end_POSTSUPERSCRIPT \u27e9 attains the maximum value of \ud835\udcaeNsubscript\ud835\udcae\ud835\udc41\\mathcal{S}_{N}caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT and |\u03c3N\u27e9ketsubscript\ud835\udf0e\ud835\udc41|\\sigma_{N}\\rangle| italic_\u03c3 start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT \u27e9 is an arbitrary N\ud835\udc41Nitalic_N-partite state. We omit the proof as it is similar to the proof of Theorem 3.\n\u220e In an ideal case for three party scenario, the paradox demands that marginal probabilities should be equal to zero. But in a real experiment, this demand is very difficult to ensure. Hence a modified paradox that accounts real experiment can be of the form, where \u03f5\u22650italic-\u03f50\\epsilon\\geq 0italic_\u03f5 \u2265 0 is some noise parameter. Without loss of generality, we can always choose the same noise parameter for each of the marginals. The local bound for the modified paradox takes the form, Now we will show that even with this modified paradox the maximum value of \ud835\udcae3\u03f5superscriptsubscript\ud835\udcae3italic-\u03f5\\mathcal{S}_{3}^{\\epsilon}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03f5 end_POSTSUPERSCRIPT still can be achieved by performing projective measurements on pure three-qubits states. The analytical technique being introduced is not suitable for this scenario, necessitating a numerical demonstration. To begin, we will ascertain the upper limit of \ud835\udcae3\u03f5superscriptsubscript\ud835\udcae3italic-\u03f5\\mathcal{S}_{3}^{\\epsilon}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03f5 end_POSTSUPERSCRIPT by employing the NPA method pioneered by Navascues, Pironio, and Acin. Next, we show that for a particular class of three-qubit state, there exist projective measurements that achieve this upper bound with a very high order of accuracy. Note that, we only need to consider the noise parameter to be 0\u2264\u03f5<1/30italic-\u03f5130\\leq\\epsilon<1/30 \u2264 italic_\u03f5 < 1 / 3. We obtain the upper bound on \ud835\udcae3\u03f5superscriptsubscript\ud835\udcae3italic-\u03f5\\mathcal{S}_{3}^{\\epsilon}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03f5 end_POSTSUPERSCRIPT by maximizing it over \ud835\udcac3subscript\ud835\udcac3\\mathcal{Q}_{3}caligraphic_Q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT (NPA Hierarchy of level three). Next, we examined a specific category of pure states involving three qubits and projective measurements defined by equation 6. We performed numerical maximization of \ud835\udcae3\u03f5superscriptsubscript\ud835\udcae3italic-\u03f5\\mathcal{S}_{3}^{\\epsilon}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03f5 end_POSTSUPERSCRIPT across all states of the form 13 and measurement parameters, subject to the constraints outlined in equation 12. This process yielded \ud835\udcae3\u03f5superscriptsubscript\ud835\udcae3italic-\u03f5\\mathcal{S}_{3}^{\\epsilon}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03f5 end_POSTSUPERSCRIPT values for various noise parameter settings, ranging from 00 to 1313\\frac{1}{3}divide start_ARG 1 end_ARG start_ARG 3 end_ARG. Fig. 1 illustrates the maximum \ud835\udcae3\u03f5superscriptsubscript\ud835\udcae3italic-\u03f5\\mathcal{S}_{3}^{\\epsilon}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03f5 end_POSTSUPERSCRIPT values under \ud835\udcac3subscript\ud835\udcac3\\mathcal{Q}_{3}caligraphic_Q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, three-qubit quantum states, and local model. Notably, we observed convergence between the maximum \ud835\udcae3\u03f5superscriptsubscript\ud835\udcae3italic-\u03f5\\mathcal{S}_{3}^{\\epsilon}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u03f5 end_POSTSUPERSCRIPT values under \ud835\udcac3subscript\ud835\udcac3\\mathcal{Q}_{3}caligraphic_Q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and three-qubit quantum states, with an accuracy of approximately 10\u22126superscript10610^{-6}10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT within the error margin 0\u2264\u03f5\u22640.080italic-\u03f50.080\\leq\\epsilon\\leq 0.080 \u2264 italic_\u03f5 \u2264 0.08. We have also calculated different entanglement monotones for these states against G\u2062H\u2062Z\ud835\udc3a\ud835\udc3b\ud835\udc4dGHZitalic_G italic_H italic_Z and W\ud835\udc4aWitalic_W states in three and four parties, respectively. These results are depicted in 2. These states require very few resources to G\u2062H\u2062Z\ud835\udc3a\ud835\udc3b\ud835\udc4dGHZitalic_G italic_H italic_Z and W\ud835\udc4aWitalic_W states. To sum up, we\u2019ve introduced a paradox similar to Hardy\u2019s paradox [41], designed for arbitrary N\ud835\udc41Nitalic_N-partite systems where each parties have the choice of two measurements with arbitrary outcomes. Detecting a breach of our paradox witnesses genuine multipartite non-local behavior. Additionally, we\u2019ve proved self-testing statements for genuinely non-local, but non-maximally multipartite entangled states. Genuine multipartite non-local correlations are regarded as the most potent manifestation of genuine multipartite quantum correlations. The process of self-testing these quantum states serves to enhance the security and efficiency of quantum communication protocols and quantum key distribution. Moreover, it contributes to a deeper understanding of the intricate geometry of quantum boundaries. The inherent genuine non-locality displayed by our self-testing state makes it a valuable asset for secure quantum key distribution applications. In a bipartite scenario, the Bell state is the unique maximally entangled state. However, in a multiparty setting, this uniqueness does not hold. Take, for instance, the tripartite scenario where two types of maximally entangled states exist: the G\u2062H\u2062Z\ud835\udc3a\ud835\udc3b\ud835\udc4dGHZitalic_G italic_H italic_Z state and the W\ud835\udc4aWitalic_W state. Interestingly, when the party count exceeds three, there is no such well-defined characterization found in the existing literature. It is important to note that both the G\u2062H\u2062Z\ud835\udc3a\ud835\udc3b\ud835\udc4dGHZitalic_G italic_H italic_Z and W\ud835\udc4aWitalic_W states qualify as genuine entangled states. Our numerical findings, showcased in Tables 2 and 2, reveal that the quantum state leading to maximal violation in our inequality requires fewer resources compared to the G\u2062H\u2062Z\ud835\udc3a\ud835\udc3b\ud835\udc4dGHZitalic_G italic_H italic_Z and W\ud835\udc4aWitalic_W states. It is worth emphasizing that in measuring entangled monotone, we employ bipartition, leveraging the presence of a unique maximally entangled state in the bipartite scenario. In the context of robust self-testing, a typically expected outcome is that any quantum state corresponding to \u03f5italic-\u03f5\\epsilonitalic_\u03f5 sub-optimal scenario should be approximately \ud835\udcaa\u2062(\u03f5)\ud835\udcaaitalic-\u03f5\\mathcal{O}(\\sqrt{\\epsilon})caligraphic_O ( square-root start_ARG italic_\u03f5 end_ARG ) close to the quantum state associated with the ideal case upto local isometries in terms of trace distance. In this work, we have demonstrated partially robust self-testing, specifically showcasing that the trace distance between the quantum state linked to the ideal case and the one associated with a non-ideal scenario is upper-bounded by \u03f5114superscriptitalic-\u03f5114\\epsilon^{\\frac{1}{14}}italic_\u03f5 start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 14 end_ARG end_POSTSUPERSCRIPT. It\u2019s noteworthy that we consider the quantum state related to the non-ideal scenario as a three-qubit state. The numerical data that provides the substance for the aforementioned claim has been plotted in Figure 1. Moving forward, our immediate agenda involves developing a comprehensive robust self-testing scheme. Additionally, we plan to delve into the exploration of the amount of randomness that can be extracted from these correlations corresponding to various noise scales. This exploration will be the subject of our forthcoming research efforts. Ranendu Adhikary acknowledges funding and support from ISI DCSW Project No. PU/506/PL-MISC/521. We would like to acknowledge stimulating discussions with Kishor Bharti, Ashutosh Rai, Tamal Guha, Subhendu B. Ghosh, and Snehasish Roy Chowdhury. We will first show the genuine non-locality for the tripartite scenario. The proof consists of two parts. In the first part, we show the non-locality and then prove this non-locality is genuine. If a non-local correlation satisfies the conditions in 3 with \ud835\udcae3>0subscript\ud835\udcae30\\mathcal{S}_{3}>0caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0, then it is a genuine tripartite non-local correlation. We will first show that no local theory can satisfy conditions 3 with \ud835\udcae3>0subscript\ud835\udcae30\\mathcal{S}_{3}>0caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0. Let us define a local hidden variable \u03bb\ud835\udf06\\lambdaitalic_\u03bb that captures the full description of the system. This \u03bb\ud835\udf06\\lambdaitalic_\u03bb takes values from a set \u03a9\u03a9\\Omegaroman_\u03a9. Moreover, we assert that the comprehensive depiction of the joint system is denoted by \u03bd\u2062(\u03bb)\ud835\udf08\ud835\udf06\\nu(\\lambda)italic_\u03bd ( italic_\u03bb ). In a local description, the joint probability can be expressed as follows: P\u2062(x1,x2,x3|x^1,x^2,x^3)=\u2211\u03bb\u2208\u03a9\u03bd\u2062(\u03bb)\u2062\u220fj=13p\u2062(xj|x^j,\u03bb)\ud835\udc43subscript\ud835\udc651subscript\ud835\udc652conditionalsubscript\ud835\udc653subscript^\ud835\udc651subscript^\ud835\udc652subscript^\ud835\udc653subscript\ud835\udf06\u03a9\ud835\udf08\ud835\udf06superscriptsubscriptproduct\ud835\udc5713\ud835\udc5dconditionalsubscript\ud835\udc65\ud835\udc57subscript^\ud835\udc65\ud835\udc57\ud835\udf06P(x_{1},x_{2},x_{3}|\\hat{x}_{1},\\hat{x}_{2},\\hat{x}_{3})=\\sum_{\\lambda\\in%\n\\Omega}\\nu(\\lambda)\\prod_{j=1}^{3}p(x_{j}|\\hat{x}_{j},\\lambda)italic_P ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = \u2211 start_POSTSUBSCRIPT italic_\u03bb \u2208 roman_\u03a9 end_POSTSUBSCRIPT italic_\u03bd ( italic_\u03bb ) \u220f start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_p ( italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_\u03bb ), where \u03bd\u2062(\u03bb)\u22650\ud835\udf08\ud835\udf060\\nu(\\lambda)\\geq 0italic_\u03bd ( italic_\u03bb ) \u2265 0, \u2211\u03bb\u03bd\u2062(\u03bb)=1subscript\ud835\udf06\ud835\udf08\ud835\udf061\\sum_{\\lambda}\\nu(\\lambda)=1\u2211 start_POSTSUBSCRIPT italic_\u03bb end_POSTSUBSCRIPT italic_\u03bd ( italic_\u03bb ) = 1. Let\u2019s assume that \ud835\udcae3>0subscript\ud835\udcae30\\mathcal{S}_{3}>0caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0, which indicates that p3subscript\ud835\udc5d3p_{3}italic_p start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is greater than 00. This implies the existence of a nonempty subset \u039b\u2286\u03a9\u039b\u03a9\\Lambda\\subseteq\\Omegaroman_\u039b \u2286 roman_\u03a9, such that for all \u03bb\u2208\u039b\ud835\udf06\u039b\\lambda\\in\\Lambdaitalic_\u03bb \u2208 roman_\u039b, P(+|A0,\u03bb)=P(+|B0,\u03bb)=P(+|C0,\u03bb)=1P(+|A_{0},\\lambda)=P(+|B_{0},\\lambda)=P(+|C_{0},\\lambda)=1italic_P ( + | italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\u03bb ) = italic_P ( + | italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\u03bb ) = italic_P ( + | italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\u03bb ) = 1. By equation 3 we have P(\u2212|A1,\u03bb)=P(\u2212|B1,\u03bb)=P(\u2212|C1,\u03bb)=1P(-|A_{1},\\lambda)=P(-|B_{1},\\lambda)=P(-|C_{1},\\lambda)=1italic_P ( - | italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03bb ) = italic_P ( - | italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03bb ) = italic_P ( - | italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03bb ) = 1. Therefore, we can deduce that P(\u2212,\u2212,\u2212|A1,B1,C1,\u039b)=P(+,+,+|A0,B0,C0)P(-,-,-|A_{1},B_{1},C_{1},\\Lambda)=P(+,+,+|A_{0},B_{0},C_{0})italic_P ( - , - , - | italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , roman_\u039b ) = italic_P ( + , + , + | italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ). However, since \u039b\u2286\u03a9\u039b\u03a9\\Lambda\\subseteq\\Omegaroman_\u039b \u2286 roman_\u03a9, it follows that P(\u2212,\u2212,\u2212|A1,B1,C1,\u039b)\u2264P(\u2212,\u2212,\u2212|A1,B1,C1)P(-,-,-|A_{1},B_{1},C_{1},\\Lambda)\\leq P(-,-,-|A_{1},B_{1},C_{1})italic_P ( - , - , - | italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , roman_\u039b ) \u2264 italic_P ( - , - , - | italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ). In other words, \ud835\udcae3\u22640subscript\ud835\udcae30\\mathcal{S}_{3}\\leq 0caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2264 0, which contradicts the initial assumption of \ud835\udcae3>0subscript\ud835\udcae30\\mathcal{S}_{3}>0caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0. Therefore, we can conclude that if any correlation satisfies 3 and gives \ud835\udcae3>0subscript\ud835\udcae30\\mathcal{S}_{3}>0caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0, then it must be non-local. Now we will show that the non-locality we have is a genuine one. If this correlation were not genuine, it could be broken down according to the expression provided in equation 2. Given that p3>0subscript\ud835\udc5d30p_{3}>0italic_p start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0, at least one component within the decomposition must yield a non-zero value for P(+++|A0B0C0)P(+++|A_{0}B_{0}C_{0})italic_P ( + + + | italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ). Let\u2019s consider this specific component to be the initial one: PA\u2062B\u2062(x1\u2062x2|x^1\u2062x^2,\u03bb1)\u2062PC\u2062(x3|x^3,\u03bb1)subscript\ud835\udc43\ud835\udc34\ud835\udc35conditionalsubscript\ud835\udc651subscript\ud835\udc652subscript^\ud835\udc651subscript^\ud835\udc652subscript\ud835\udf061subscript\ud835\udc43\ud835\udc36conditionalsubscript\ud835\udc653subscript^\ud835\udc653subscript\ud835\udf061P_{AB}(x_{1}x_{2}|\\hat{x}_{1}\\hat{x}_{2},\\lambda_{1})P_{C}(x_{3}|\\hat{x}_{3},%\n\\lambda_{1})italic_P start_POSTSUBSCRIPT italic_A italic_B end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_P start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ). Consequently, PA\u2062B(++|A0B0,\u03bb1)PC(+|C0,\u03bb1)\u22600P_{AB}(++|A_{0}B_{0},\\lambda_{1})P_{C}(+|C_{0},\\lambda_{1})\\neq 0italic_P start_POSTSUBSCRIPT italic_A italic_B end_POSTSUBSCRIPT ( + + | italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_P start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( + | italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) \u2260 0. The condition PB\u2062C(++|B1C0)=0P_{BC}(++|B_{1}C_{0})=0italic_P start_POSTSUBSCRIPT italic_B italic_C end_POSTSUBSCRIPT ( + + | italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = 0 leads to the conclusion that PB(+|B1,\u03bb1)PC(+|C0,\u03bb1)P_{B}(+|B_{1},\\lambda_{1})P_{C}(+|C_{0},\\lambda_{1})italic_P start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( + | italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_P start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( + | italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) must be zero. This, in turn, implies that PB(+|B1,\u03bb1)=0P_{B}(+|B_{1},\\lambda_{1})=0italic_P start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( + | italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = 0, given that PC(+|C0,\u03bb1)P_{C}(+|C_{0},\\lambda_{1})italic_P start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( + | italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) cannot be zero. Therefore, we deduce that PB(\u2212|B1,\u03bb1)=1P_{B}(-|B_{1},\\lambda_{1})=1italic_P start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( - | italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = 1. Consequently, party B\ud835\udc35Bitalic_B can jointly measure both B0subscript\ud835\udc350B_{0}italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and B1subscript\ud835\udc351B_{1}italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. By utilizing the findings from [42] that joint measureability within any no-signaling theory never violates a Bell inequality, we can ascertain that PA\u2062B\u2062(x1\u2062x2|x^1\u2062x^2,\u03bb1)=PA\u2062(x1|x^1,\u03bb1)\u2062PB\u2062(x2|x^2,\u03bb1)subscript\ud835\udc43\ud835\udc34\ud835\udc35conditionalsubscript\ud835\udc651subscript\ud835\udc652subscript^\ud835\udc651subscript^\ud835\udc652subscript\ud835\udf061subscript\ud835\udc43\ud835\udc34conditionalsubscript\ud835\udc651subscript^\ud835\udc651subscript\ud835\udf061subscript\ud835\udc43\ud835\udc35conditionalsubscript\ud835\udc652subscript^\ud835\udc652subscript\ud835\udf061P_{AB}(x_{1}x_{2}|\\hat{x}_{1}\\hat{x}_{2},\\lambda_{1})=P_{A}(x_{1}|\\hat{x}_{1},%\n\\lambda_{1})P_{B}(x_{2}|\\hat{x}_{2},\\lambda_{1})italic_P start_POSTSUBSCRIPT italic_A italic_B end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = italic_P start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_P start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ). Similarly, all the other components within the decomposition become fully product-based. As a result, the distributions PA1\u2062A2\u2062A3\u2062(x1\u2062x2\u2062x3|x^1\u2062x^2\u2062x^3)subscript\ud835\udc43subscript\ud835\udc341subscript\ud835\udc342subscript\ud835\udc343conditionalsubscript\ud835\udc651subscript\ud835\udc652subscript\ud835\udc653subscript^\ud835\udc651subscript^\ud835\udc652subscript^\ud835\udc653P_{A_{1}A_{2}A_{3}}(x_{1}x_{2}x_{3}|\\hat{x}_{1}\\hat{x}_{2}\\hat{x}_{3})italic_P start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) transform into fully local distribution, which contradicts the initial premise considering p3>0subscript\ud835\udc5d30p_{3}>0italic_p start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0.\n\u220e We will now show the genuine non-locality for more than three party scenarios. The proof follows the same methodology as the previous one. If a non-local correlation satisfies the conditions in 4 with \ud835\udcaeN>0subscript\ud835\udcae\ud835\udc410\\mathcal{S}_{N}>0caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0, then it is a genuine multipartite non-local correlation. We will first show that no local theory can satisfy conditions 4 with \ud835\udcaeN>0subscript\ud835\udcae\ud835\udc410\\mathcal{S}_{N}>0caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0. Let us define a local hidden variable \u03bb\ud835\udf06\\lambdaitalic_\u03bb that captures the full description of the system. This \u03bb\ud835\udf06\\lambdaitalic_\u03bb takes values from a set \u03a9\u03a9\\Omegaroman_\u03a9. Moreover, we assert that the comprehensive depiction of the joint system is denoted by \u03bd\u2062(\u03bb)\ud835\udf08\ud835\udf06\\nu(\\lambda)italic_\u03bd ( italic_\u03bb ). In a local description, there exist conditional probabilities pAj\u2062(uj|u^j,\u03bb)subscript\ud835\udc5dsubscript\ud835\udc34\ud835\udc57conditionalsubscript\ud835\udc62\ud835\udc57subscript^\ud835\udc62\ud835\udc57\ud835\udf06p_{A_{j}}(u_{j}|\\hat{u}_{j},\\lambda)italic_p start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_u start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_\u03bb ) and pAj\u2062(vj|v^j,\u03bb)subscript\ud835\udc5dsubscript\ud835\udc34\ud835\udc57conditionalsubscript\ud835\udc63\ud835\udc57subscript^\ud835\udc63\ud835\udc57\ud835\udf06p_{A_{j}}(v_{j}|\\hat{v}_{j},\\lambda)italic_p start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_\u03bb ) such that the joint probability can be expressed as follows: P\u2062(x1,x2,\u2026,xN|x^1,x^2,\u2026,x^N)=\u2211\u03bb\u2208\u03a9\u03bd\u2062(\u03bb)\u2062\u220fj=1NpAj\u2062(xj|x^j,\u03bb)\ud835\udc43subscript\ud835\udc651subscript\ud835\udc652\u2026conditionalsubscript\ud835\udc65\ud835\udc41subscript^\ud835\udc651subscript^\ud835\udc652\u2026subscript^\ud835\udc65\ud835\udc41subscript\ud835\udf06\u03a9\ud835\udf08\ud835\udf06superscriptsubscriptproduct\ud835\udc571\ud835\udc41subscript\ud835\udc5dsubscript\ud835\udc34\ud835\udc57conditionalsubscript\ud835\udc65\ud835\udc57subscript^\ud835\udc65\ud835\udc57\ud835\udf06P(x_{1},x_{2},\\dots,x_{N}|\\hat{x}_{1},\\hat{x}_{2},\\dots,\\hat{x}_{N})=\\sum_{%\n\\lambda\\in\\Omega}\\nu(\\lambda)\\prod_{j=1}^{N}p_{A_{j}}(x_{j}|\\hat{x}_{j},\\lambda)italic_P ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_x start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ) = \u2211 start_POSTSUBSCRIPT italic_\u03bb \u2208 roman_\u03a9 end_POSTSUBSCRIPT italic_\u03bd ( italic_\u03bb ) \u220f start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_\u03bb ), where x^j\u2208{u^j,v^j}subscript^\ud835\udc65\ud835\udc57subscript^\ud835\udc62\ud835\udc57subscript^\ud835\udc63\ud835\udc57\\hat{x}_{j}\\in\\{\\hat{u}_{j},\\hat{v}_{j}\\}over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u2208 { over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT }. Now, let\u2019s assume that \ud835\udcaeN>0subscript\ud835\udcae\ud835\udc410\\mathcal{S}_{N}>0caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0, indicating that pN>0subscript\ud835\udc5d\ud835\udc410p_{N}>0italic_p start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0. This implies the existence of a nonempty subset \u039b\u2286\u03a9\u039b\u03a9\\Lambda\\subseteq\\Omegaroman_\u039b \u2286 roman_\u03a9, such that for all \u03bb\u2208\u039b\ud835\udf06\u039b\\lambda\\in\\Lambdaitalic_\u03bb \u2208 roman_\u039b, PAi\u2062(1|u^i,\u03bb)=1subscript\ud835\udc43subscript\ud835\udc34\ud835\udc56conditional1subscript^\ud835\udc62\ud835\udc56\ud835\udf061P_{A_{i}}(1|\\hat{u}_{i},\\lambda)=1italic_P start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( 1 | over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_\u03bb ) = 1 for all i\ud835\udc56iitalic_i. Consequently, for all r\ud835\udc5fritalic_r where vr\u2260disubscript\ud835\udc63\ud835\udc5fsubscript\ud835\udc51\ud835\udc56v_{r}\\neq d_{i}italic_v start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \u2260 italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, we have PAi\u2062(vr|v^i,\u03bb)=0subscript\ud835\udc43subscript\ud835\udc34\ud835\udc56conditionalsubscript\ud835\udc63\ud835\udc5fsubscript^\ud835\udc63\ud835\udc56\ud835\udf060P_{A_{i}}(v_{r}|\\hat{v}_{i},\\lambda)=0italic_P start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_v start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_\u03bb ) = 0, which further implies P\u2062(di|v^i,\u03bb)=1\ud835\udc43conditionalsubscript\ud835\udc51\ud835\udc56subscript^\ud835\udc63\ud835\udc56\ud835\udf061P(d_{i}|\\hat{v}_{i},\\lambda)=1italic_P ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_\u03bb ) = 1. Therefore, we can deduce that P\u2062(d1,d2,\u2026,dN|v^1,v^2,\u2026,v^N,\u039b)=P\u2062(1,1,\u2026,1|u^1,u^2,\u2026,u^N)=pN\ud835\udc43subscript\ud835\udc511subscript\ud835\udc512\u2026conditionalsubscript\ud835\udc51\ud835\udc41subscript^\ud835\udc631subscript^\ud835\udc632\u2026subscript^\ud835\udc63\ud835\udc41\u039b\ud835\udc4311\u2026conditional1subscript^\ud835\udc621subscript^\ud835\udc622\u2026subscript^\ud835\udc62\ud835\udc41subscript\ud835\udc5d\ud835\udc41P(d_{1},d_{2},\\dots,d_{N}|\\hat{v}_{1},\\hat{v}_{2},\\dots,\\hat{v}_{N},\\Lambda)=P%\n(1,1,\\dots,1|\\hat{u}_{1},\\hat{u}_{2},\\dots,\\hat{u}_{N})=p_{N}italic_P ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_d start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT , roman_\u039b ) = italic_P ( 1 , 1 , \u2026 , 1 | over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ) = italic_p start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT. However, since \u039b\u2286\u03a9\u039b\u03a9\\Lambda\\subseteq\\Omegaroman_\u039b \u2286 roman_\u03a9, it follows that P\u2062(d1,d2,\u2026,dN|v^1,v^2,\u2026,v^N,\u039b)\u2264P\u2062(d1,d2,\u2026,dN|v^1,v^2,\u2026,v^N)\ud835\udc43subscript\ud835\udc511subscript\ud835\udc512\u2026conditionalsubscript\ud835\udc51\ud835\udc41subscript^\ud835\udc631subscript^\ud835\udc632\u2026subscript^\ud835\udc63\ud835\udc41\u039b\ud835\udc43subscript\ud835\udc511subscript\ud835\udc512\u2026conditionalsubscript\ud835\udc51\ud835\udc41subscript^\ud835\udc631subscript^\ud835\udc632\u2026subscript^\ud835\udc63\ud835\udc41P(d_{1},d_{2},\\dots,d_{N}|\\hat{v}_{1},\\hat{v}_{2},\\dots,\\hat{v}_{N},\\Lambda)%\n\\leq P(d_{1},d_{2},\\dots,d_{N}|\\hat{v}_{1},\\hat{v}_{2},\\dots,\\hat{v}_{N})italic_P ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_d start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT , roman_\u039b ) \u2264 italic_P ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_d start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ). In other words, \ud835\udcaeN\u22640subscript\ud835\udcae\ud835\udc410\\mathcal{S}_{N}\\leq 0caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT \u2264 0, which contradicts the initial assumption of \ud835\udcaeNsubscript\ud835\udcae\ud835\udc41\\mathcal{S}_{N}caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT. Therefore, we can conclude that if any correlation satisfies 4 and gives \ud835\udcaeN>0subscript\ud835\udcae\ud835\udc410\\mathcal{S}_{N}>0caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0, then it must be non-local. Now we will show the genuineness of the non-locality. Consider a N\ud835\udc41Nitalic_N-partite probability distribution P\u2062(x1,x2,\u2026,xN|x^1,x^2,\u2026,x^N)\ud835\udc43subscript\ud835\udc651subscript\ud835\udc652\u2026conditionalsubscript\ud835\udc65\ud835\udc41subscript^\ud835\udc651subscript^\ud835\udc652\u2026subscript^\ud835\udc65\ud835\udc41P(x_{1},x_{2},\\dots,x_{N}|\\hat{x}_{1},\\hat{x}_{2},\\dots,\\hat{x}_{N})italic_P ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_x start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ) satisfying conditions in 4 with \ud835\udcaeN>0subscript\ud835\udcae\ud835\udc410\\mathcal{S}_{N}>0caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0, which is not genuine. Hence, it is a convex mixture of bi-local correlation. Let\u2019s consider a partition (1,2,\u2026,m)12\u2026\ud835\udc5a(1,2,\\dots,m)( 1 , 2 , \u2026 , italic_m ) versus (m+1,m+2,\u2026,N)\ud835\udc5a1\ud835\udc5a2\u2026\ud835\udc41(m+1,m+2,\\dots,N)( italic_m + 1 , italic_m + 2 , \u2026 , italic_N ). Consequently, there must be at least one element within the convex combination that contributes non-zero value to the condition P\u2062(1,1,\u2026,1|u^1,u^2,\u2026,u^N)>0\ud835\udc4311\u2026conditional1subscript^\ud835\udc621subscript^\ud835\udc622\u2026subscript^\ud835\udc62\ud835\udc410P(1,1,\\dots,1|\\hat{u}_{1},\\hat{u}_{2},\\dots,\\hat{u}_{N})>0italic_P ( 1 , 1 , \u2026 , 1 | over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ) > 0, given pN>qN\u22650subscript\ud835\udc5d\ud835\udc41subscript\ud835\udc5e\ud835\udc410p_{N}>q_{N}\\geq 0italic_p start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > italic_q start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT \u2265 0. Let\u2019s assume such an element takes the form P1\u2062(x1,\u2026,xm|x^1,\u2026,x^m)\u2062P2\u2062(xm+1,\u2026,xN|x^m+1,\u2026,x^N)subscript\ud835\udc431subscript\ud835\udc651\u2026conditionalsubscript\ud835\udc65\ud835\udc5asubscript^\ud835\udc651\u2026subscript^\ud835\udc65\ud835\udc5asubscript\ud835\udc432subscript\ud835\udc65\ud835\udc5a1\u2026conditionalsubscript\ud835\udc65\ud835\udc41subscript^\ud835\udc65\ud835\udc5a1\u2026subscript^\ud835\udc65\ud835\udc41P_{1}(x_{1},\\dots,x_{m}|\\hat{x}_{1},\\dots,\\hat{x}_{m})P_{2}(x_{m+1},\\dots,x_{N%\n}|\\hat{x}_{m+1},\\dots,\\hat{x}_{N})italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_x start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_m + 1 end_POSTSUBSCRIPT , \u2026 , italic_x start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_m + 1 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ). As pN>0subscript\ud835\udc5d\ud835\udc410p_{N}>0italic_p start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0 we must have, whereas the equation 4 imply two important relations, The form of P1subscript\ud835\udc431P_{1}italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT: Since by 14, one definitely have P2\u2062(1|u^m+1)\u22600subscript\ud835\udc432conditional1subscript^\ud835\udc62\ud835\udc5a10P_{2}(1|\\hat{u}_{m+1})\\neq 0italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 | over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_m + 1 end_POSTSUBSCRIPT ) \u2260 0, we get P1\u2062(vm\u2260dm|v^m)=0subscript\ud835\udc431subscript\ud835\udc63\ud835\udc5aconditionalsubscript\ud835\udc51\ud835\udc5asubscript^\ud835\udc63\ud835\udc5a0P_{1}(v_{m}\\neq d_{m}|\\hat{v}_{m})=0italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_v start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT \u2260 italic_d start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) = 0, hence P1\u2062(dm|v^m)=1subscript\ud835\udc431conditionalsubscript\ud835\udc51\ud835\udc5asubscript^\ud835\udc63\ud835\udc5a1P_{1}(d_{m}|\\hat{v}_{m})=1italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_d start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) = 1. By utilizing the findings from [42] that joint measureability within any no-signaling theory never violates a Bell inequality, P1\u2062(x1,\u2026,xm|x^1,\u2026,x^m)subscript\ud835\udc431subscript\ud835\udc651\u2026conditionalsubscript\ud835\udc65\ud835\udc5asubscript^\ud835\udc651\u2026subscript^\ud835\udc65\ud835\udc5aP_{1}(x_{1},\\dots,x_{m}|\\hat{x}_{1},\\dots,\\hat{x}_{m})italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_x start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) factorizes to certain P1\u2032\u2062(x1,\u2026,xm\u22121|x^1,\u2026,x^m\u22121)\u2062P1m\u2062(xm|x^m)subscriptsuperscript\ud835\udc43\u20321subscript\ud835\udc651\u2026conditionalsubscript\ud835\udc65\ud835\udc5a1subscript^\ud835\udc651\u2026subscript^\ud835\udc65\ud835\udc5a1subscriptsuperscript\ud835\udc43\ud835\udc5a1conditionalsubscript\ud835\udc65\ud835\udc5asubscript^\ud835\udc65\ud835\udc5aP^{\\prime}_{1}(x_{1},\\dots,x_{m-1}|\\hat{x}_{1},\\dots,\\hat{x}_{m-1})P^{m}_{1}(x%\n_{m}|\\hat{x}_{m})italic_P start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_x start_POSTSUBSCRIPT italic_m - 1 end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_m - 1 end_POSTSUBSCRIPT ) italic_P start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ). The conditions in 4 also implies that P1\u2032\u2062(vm\u22121\u2260dm\u22121|v^m\u22121)\u2062P1m\u2062(1|u^m)=0subscriptsuperscript\ud835\udc43\u20321subscript\ud835\udc63\ud835\udc5a1conditionalsubscript\ud835\udc51\ud835\udc5a1subscript^\ud835\udc63\ud835\udc5a1subscriptsuperscript\ud835\udc43\ud835\udc5a1conditional1subscript^\ud835\udc62\ud835\udc5a0P^{\\prime}_{1}(v_{m-1}\\neq d_{m-1}|\\hat{v}_{m-1})P^{m}_{1}(1|\\hat{u}_{m})=0italic_P start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_v start_POSTSUBSCRIPT italic_m - 1 end_POSTSUBSCRIPT \u2260 italic_d start_POSTSUBSCRIPT italic_m - 1 end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_m - 1 end_POSTSUBSCRIPT ) italic_P start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1 | over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) = 0,\nhowever again since P1m\u2062(1|u^m)\u22600subscriptsuperscript\ud835\udc43\ud835\udc5a1conditional1subscript^\ud835\udc62\ud835\udc5a0P^{m}_{1}(1|\\hat{u}_{m})\\neq 0italic_P start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1 | over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) \u2260 0 one has P1\u2032\u2062(dm\u22121|v^m\u22121)=1subscriptsuperscript\ud835\udc43\u20321conditionalsubscript\ud835\udc51\ud835\udc5a1subscript^\ud835\udc63\ud835\udc5a11P^{\\prime}_{1}(d_{m-1}|\\hat{v}_{m-1})=1italic_P start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_d start_POSTSUBSCRIPT italic_m - 1 end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_m - 1 end_POSTSUBSCRIPT ) = 1. Using the same argument it is easy to see that P1subscript\ud835\udc431P_{1}italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT fully factorizes. The form of P2subscript\ud835\udc432P_{2}italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT: We have P2\u2062(vN\u2260dN|v^N)\u2062P1\u2062(1|u^1)=0subscript\ud835\udc432subscript\ud835\udc63\ud835\udc41conditionalsubscript\ud835\udc51\ud835\udc41subscript^\ud835\udc63\ud835\udc41subscript\ud835\udc431conditional1subscript^\ud835\udc6210P_{2}(v_{N}\\neq d_{N}|\\hat{v}_{N})P_{1}(1|\\hat{u}_{1})=0italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_v start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT \u2260 italic_d start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ) italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1 | over^ start_ARG italic_u end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = 0, from which P2\u2062(vN\u2260dN|v^N)=0subscript\ud835\udc432subscript\ud835\udc63\ud835\udc41conditionalsubscript\ud835\udc51\ud835\udc41subscript^\ud835\udc63\ud835\udc410P_{2}(v_{N}\\neq d_{N}|\\hat{v}_{N})=0italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_v start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT \u2260 italic_d start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ) = 0, thus P2\u2062(dN|v^N)=1subscript\ud835\udc432conditionalsubscript\ud835\udc51\ud835\udc41subscript^\ud835\udc63\ud835\udc411P_{2}(d_{N}|\\hat{v}_{N})=1italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_d start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ) = 1. Hence P2subscript\ud835\udc432P_{2}italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT also fully factories as P1subscript\ud835\udc431P_{1}italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Thus the distribution P\u2062(x1,x2,\u2026,xN|x^1,x^2,\u2026,x^N)\ud835\udc43subscript\ud835\udc651subscript\ud835\udc652\u2026conditionalsubscript\ud835\udc65\ud835\udc41subscript^\ud835\udc651subscript^\ud835\udc652\u2026subscript^\ud835\udc65\ud835\udc41P(x_{1},x_{2},\\dots,x_{N}|\\hat{x}_{1},\\hat{x}_{2},\\dots,\\hat{x}_{N})italic_P ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_x start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT | over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ) become fully local. Such probability distribution cannot satisfy the equation 4 for \ud835\udcaeN>0subscript\ud835\udcae\ud835\udc410\\mathcal{S}_{N}>0caligraphic_S start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT > 0. Hence we are done. Since the proof is the same for all cuts, no mixture of bi-local probability distribution for different cuts can satisfy all the conditions.\n\u220e The next two theorems provide the self-testing argument for the tripartite scenario. The maximum achievable value of \ud835\udcae3subscript\ud835\udcae3\\mathcal{S}_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT among all three-qubit states represents the optimal value attainable within tri-partite quantum states of any finite dimension. Here we only present the outline of the proof as the details are quite similar to the proof given in [43]. Consider a general tripartite state \u03c1\ud835\udf0c\\rhoitalic_\u03c1 shared among Alice, Bob, and Charlie. The operator \u03a0x|x^subscript\u03a0conditional\ud835\udc65^\ud835\udc65\\Pi_{x|\\hat{x}}roman_\u03a0 start_POSTSUBSCRIPT italic_x | over^ start_ARG italic_x end_ARG end_POSTSUBSCRIPT represents the outcome x\ud835\udc65xitalic_x obtained by Alice when she measures the observable x^^\ud835\udc65\\hat{x}over^ start_ARG italic_x end_ARG. Similarly, we define \u03a0y|y^subscript\u03a0conditional\ud835\udc66^\ud835\udc66\\Pi_{y|\\hat{y}}roman_\u03a0 start_POSTSUBSCRIPT italic_y | over^ start_ARG italic_y end_ARG end_POSTSUBSCRIPT and \u03a0z|z^subscript\u03a0conditional\ud835\udc67^\ud835\udc67\\Pi_{z|\\hat{z}}roman_\u03a0 start_POSTSUBSCRIPT italic_z | over^ start_ARG italic_z end_ARG end_POSTSUBSCRIPT for Bob and Charlie respectively. Thus, Considering no constraints on dimensionality, we employ Neumark\u2019s dilation theorem, restricting our focus to projective measurements. Thus, the observables associated with Alice, Bob, and Charlie consist of Hermitian operators having eigenvalues of \u00b11plus-or-minus1\\pm 1\u00b1 1, depicted as: Now using the lemma stated in [40] applies to Alice\u2019s observable {A0,A1}subscript\ud835\udc340subscript\ud835\udc341\\{A_{0},A_{1}\\}{ italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } inducing a decomposition HA=\u2a01iHAisubscript\ud835\udc3b\ud835\udc34subscriptdirect-sum\ud835\udc56superscriptsubscript\ud835\udc3b\ud835\udc34\ud835\udc56H_{A}=\\bigoplus_{i}H_{A}^{i}italic_H start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT = \u2a01 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_H start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT, Bob\u2019s observable {B0,B1}subscript\ud835\udc350subscript\ud835\udc351\\{B_{0},B_{1}\\}{ italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } inducing a decomposition HB=\u2a01jHBjsubscript\ud835\udc3b\ud835\udc35subscriptdirect-sum\ud835\udc57superscriptsubscript\ud835\udc3b\ud835\udc35\ud835\udc57H_{B}=\\bigoplus_{j}H_{B}^{j}italic_H start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT = \u2a01 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_H start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT, and Charlie\u2019s observable {C0,C1}subscript\ud835\udc360subscript\ud835\udc361\\{C_{0},C_{1}\\}{ italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } inducing a decomposition HC=\u2a01kHCksubscript\ud835\udc3b\ud835\udc36subscriptdirect-sum\ud835\udc58superscriptsubscript\ud835\udc3b\ud835\udc36\ud835\udc58H_{C}=\\bigoplus_{k}H_{C}^{k}italic_H start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT = \u2a01 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_H start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT. Consequently, the following expression is derived: where \u03c1i\u2062j\u2062k=\u03a0i\u2297\u03a0j\u2297\u03a0k\u2062\u03c1\u2062\u03a0i\u2297\u03a0j\u2297\u03a0k\u03bbi\u2062j\u2062ksubscript\ud835\udf0c\ud835\udc56\ud835\udc57\ud835\udc58tensor-producttensor-productsubscript\u03a0\ud835\udc56subscript\u03a0\ud835\udc57subscript\u03a0\ud835\udc58\ud835\udf0csubscript\u03a0\ud835\udc56subscript\u03a0\ud835\udc57subscript\u03a0\ud835\udc58subscript\ud835\udf06\ud835\udc56\ud835\udc57\ud835\udc58\\rho_{ijk}=\\frac{\\Pi_{i}\\otimes\\Pi_{j}\\otimes\\Pi_{k}\\rho\\Pi_{i}\\otimes\\Pi_{j}%\n\\otimes\\Pi_{k}}{\\lambda_{ijk}}italic_\u03c1 start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT = divide start_ARG roman_\u03a0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2297 roman_\u03a0 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u2297 roman_\u03a0 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_\u03c1 roman_\u03a0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2297 roman_\u03a0 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u2297 roman_\u03a0 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG start_ARG italic_\u03bb start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT end_ARG is, at most, a three-qubit state. The coefficients \u03bbi\u2062j\u2062ksubscript\ud835\udf06\ud835\udc56\ud835\udc57\ud835\udc58\\lambda_{ijk}italic_\u03bb start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT are determined as \u03bbi\u2062j\u2062k=Tr\u2061(\u03c1\u2062\u03a0i\u2297\u03a0j\u2297\u03a0k)subscript\ud835\udf06\ud835\udc56\ud835\udc57\ud835\udc58Trtensor-product\ud835\udf0csubscript\u03a0\ud835\udc56subscript\u03a0\ud835\udc57subscript\u03a0\ud835\udc58\\lambda_{ijk}=\\operatorname{Tr}(\\rho\\Pi_{i}\\otimes\\Pi_{j}\\otimes\\Pi_{k})italic_\u03bb start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT = roman_Tr ( italic_\u03c1 roman_\u03a0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2297 roman_\u03a0 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u2297 roman_\u03a0 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ), with \u03bbi\u2062j\u2062k\u22650subscript\ud835\udf06\ud835\udc56\ud835\udc57\ud835\udc580\\lambda_{ijk}\\geq 0italic_\u03bb start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT \u2265 0 \u2200i,j,kfor-all\ud835\udc56\ud835\udc57\ud835\udc58\\forall i,j,k\u2200 italic_i , italic_j , italic_k and \u2211i,j,k\u03bbi\u2062j\u2062k=1subscript\ud835\udc56\ud835\udc57\ud835\udc58subscript\ud835\udf06\ud835\udc56\ud835\udc57\ud835\udc581\\sum_{i,j,k}\\lambda_{ijk}=1\u2211 start_POSTSUBSCRIPT italic_i , italic_j , italic_k end_POSTSUBSCRIPT italic_\u03bb start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT = 1. If the joint probability P\u2062(x,y,z|x^,y^,z^)\ud835\udc43\ud835\udc65\ud835\udc66conditional\ud835\udc67^\ud835\udc65^\ud835\udc66^\ud835\udc67P(x,y,z|\\hat{x},\\hat{y},\\hat{z})italic_P ( italic_x , italic_y , italic_z | over^ start_ARG italic_x end_ARG , over^ start_ARG italic_y end_ARG , over^ start_ARG italic_z end_ARG ) meets the conditions outlined in 3, then it implies that the joint probability Pi\u2062j\u2062k\u2062(x,y,z|x^,y^,z^)subscript\ud835\udc43\ud835\udc56\ud835\udc57\ud835\udc58\ud835\udc65\ud835\udc66conditional\ud835\udc67^\ud835\udc65^\ud835\udc66^\ud835\udc67P_{ijk}(x,y,z|\\hat{x},\\hat{y},\\hat{z})italic_P start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT ( italic_x , italic_y , italic_z | over^ start_ARG italic_x end_ARG , over^ start_ARG italic_y end_ARG , over^ start_ARG italic_z end_ARG ) will also adhere to the constraint equations. Consequently, the maximum attainable value of \ud835\udcae3subscript\ud835\udcae3\\mathcal{S}_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT across all three-qubit states denotes the optimal value achievable within tri-partite quantum states. \u220e If the maximum value of \ud835\udcae3subscript\ud835\udcae3\\mathcal{S}_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is observed, then the state of the system is equivalent up to local isometries\nto |\u03c3\u27e9A\u2062B\u2062C\u2297|\u03a8m\u2062a\u2062x\u22c63\u27e9A\u2032\u2062B\u2032\u2062C\u2032tensor-productsubscriptket\ud835\udf0e\ud835\udc34\ud835\udc35\ud835\udc36subscriptketsuperscriptsubscriptnormal-\u03a8\ud835\udc5a\ud835\udc4e\ud835\udc65normal-\u22c6absent3superscript\ud835\udc34normal-\u2032superscript\ud835\udc35normal-\u2032superscript\ud835\udc36normal-\u2032|\\sigma\\rangle_{ABC}\\otimes|\\Psi_{max}^{\\star 3}\\rangle_{A^{\\prime}B^{\\prime}C%\n^{\\prime}}| italic_\u03c3 \u27e9 start_POSTSUBSCRIPT italic_A italic_B italic_C end_POSTSUBSCRIPT \u2297 | roman_\u03a8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 3 end_POSTSUPERSCRIPT \u27e9 start_POSTSUBSCRIPT italic_A start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_B start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_C start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT, where |\u03a8m\u2062a\u2062x\u22c63\u27e9ketsuperscriptsubscriptnormal-\u03a8\ud835\udc5a\ud835\udc4e\ud835\udc65normal-\u22c6absent3|\\Psi_{max}^{\\star 3}\\rangle| roman_\u03a8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 3 end_POSTSUPERSCRIPT \u27e9 attains the maximum value of \ud835\udcae3subscript\ud835\udcae3\\mathcal{S}_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and |\u03c3\u27e9ket\ud835\udf0e|\\sigma\\rangle| italic_\u03c3 \u27e9 is an arbitrary tripartite state. We can choose eigenstates of the observables A0subscript\ud835\udc340A_{0}italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, B0subscript\ud835\udc350B_{0}italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and C0subscript\ud835\udc360C_{0}italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT to be computational eigenbasis: where i\ud835\udc56iitalic_i, j\ud835\udc57jitalic_j, and k\ud835\udc58kitalic_k belong to the set {0,1,2,\u2026}012\u2026\\{0,1,2,\\dots\\}{ 0 , 1 , 2 , \u2026 }. Now, the difference pi\u2062j\u2062k\u2212qi\u2062j\u2062ksubscript\ud835\udc5d\ud835\udc56\ud835\udc57\ud835\udc58subscript\ud835\udc5e\ud835\udc56\ud835\udc57\ud835\udc58p_{ijk}-q_{ijk}italic_p start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT - italic_q start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT, where pi\u2062j\u2062k=Pi\u2062j\u2062k(+,+,+|A0,B0,C0)p_{ijk}=P_{ijk}(+,+,+|A_{0},B_{0},C_{0})italic_p start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT = italic_P start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT ( + , + , + | italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) and qi\u2062j\u2062k=Pi\u2062j\u2062k(\u2212,\u2212,\u2212|A1,B1,C1)q_{ijk}=P_{ijk}(-,-,-|A_{1},B_{1},C_{1})italic_q start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT = italic_P start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT ( - , - , - | italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ), in the subspace HAi\u2297HBj\u2297HCktensor-productsuperscriptsubscript\ud835\udc3b\ud835\udc34\ud835\udc56superscriptsubscript\ud835\udc3b\ud835\udc35\ud835\udc57superscriptsubscript\ud835\udc3b\ud835\udc36\ud835\udc58H_{A}^{i}\\otimes H_{B}^{j}\\otimes H_{C}^{k}italic_H start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT \u2297 italic_H start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT \u2297 italic_H start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT can attain the maximum value if and only if \u03c1i\u2062j\u2062k=|\u03a8m\u2062a\u2062x\u22c63\u27e9i\u2062j\u2062k\u2062\u27e8\u03a8m\u2062a\u2062x\u22c63|subscript\ud835\udf0c\ud835\udc56\ud835\udc57\ud835\udc58subscriptketsuperscriptsubscript\u03a8\ud835\udc5a\ud835\udc4e\ud835\udc65\u22c6absent3\ud835\udc56\ud835\udc57\ud835\udc58brasuperscriptsubscript\u03a8\ud835\udc5a\ud835\udc4e\ud835\udc65\u22c6absent3\\rho_{ijk}=|\\Psi_{max}^{\\star 3}\\rangle_{ijk}\\langle\\Psi_{max}^{\\star 3}|italic_\u03c1 start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT = | roman_\u03a8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 3 end_POSTSUPERSCRIPT \u27e9 start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT \u27e8 roman_\u03a8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 3 end_POSTSUPERSCRIPT |, where |\u03a8m\u2062a\u2062x\u22c63\u27e9i\u2062j\u2062ksubscriptketsuperscriptsubscript\u03a8\ud835\udc5a\ud835\udc4e\ud835\udc65\u22c6absent3\ud835\udc56\ud835\udc57\ud835\udc58|\\Psi_{max}^{\\star 3}\\rangle_{ijk}| roman_\u03a8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 3 end_POSTSUPERSCRIPT \u27e9 start_POSTSUBSCRIPT italic_i italic_j italic_k end_POSTSUBSCRIPT represents the three-qubit state. Therefore, the unknown state |\u03c7\u27e9ket\ud835\udf12|\\chi\\rangle| italic_\u03c7 \u27e9 can give the maximum value of \ud835\udcae3subscript\ud835\udcae3\\mathcal{S}_{3}caligraphic_S start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, if and only if, Hence if we choose the local isometries in the following way, where X\u2062X\u2032\u2208{A\u2062A\u2032,B\u2062B\u2032,C\u2062C\u2032}\ud835\udc4bsuperscript\ud835\udc4b\u2032\ud835\udc34superscript\ud835\udc34\u2032\ud835\udc35superscript\ud835\udc35\u2032\ud835\udc36superscript\ud835\udc36\u2032XX^{\\prime}\\in\\{AA^{\\prime},BB^{\\prime},CC^{\\prime}\\}italic_X italic_X start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2208 { italic_A italic_A start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , italic_B italic_B start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , italic_C italic_C start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT }, then we have, where |\u03c3\u27e9A\u2062B\u2062Csubscriptket\ud835\udf0e\ud835\udc34\ud835\udc35\ud835\udc36|\\sigma\\rangle_{ABC}| italic_\u03c3 \u27e9 start_POSTSUBSCRIPT italic_A italic_B italic_C end_POSTSUBSCRIPT some junk state. \u220e"
    },
    {
        "id": 19,
        "title": "Uso de herramientas digitales matem\u00e1ticas en la Educaci\u00f3n Secundaria",
        "corpus": "Las Tecnolog\u00edas de la Informaci\u00f3n y la Comunicaci\u00f3n (TIC) est\u00e1n cada d\u00eda m\u00e1s presentes en nuestra sociedad y por tanto en el \u00e1mbito educativo. En apenas dos d\u00e9cadas hemos pasado de una ense\u00f1anza basada, en muchos casos, en las clases magistrales a una ense\u00f1anza en la que metodolog\u00edas como el aula invertida o la gamificaci\u00f3n tienen m\u00e1s fuerza que nunca. A lo largo del trabajo hemos realizado una encuesta a docentes y alumnado con el objetivo de comparar los conocimientos en herramientas digitales, su uso y su aceptaci\u00f3n. Hemos utilizado WxMaxima y Geogebra como herramientas did\u00e1cticas. Para ello propondremos un ejercicio de la Evaluaci\u00f3n de Bachillerato para el Acceso a la Universidad (EBAU) relacionado con la geometr\u00eda, analizando sus puntos fuertes y d\u00e9biles en comparaci\u00f3n con la resoluci\u00f3n manual. Por \u00fatlimo, expondremos algunas conclusiones y posibles l\u00edneas de investigaci\u00f3n acerca de las herramientas digitales, as\u00ed como una propuesta de curso introductorio a WxMaxima y Geogebra con el que formar al docente de secundaria. Abstract Information and Community Technologies (ICT) are very present in our society nowadays and particularly in the educative field. In just two decades, we have passed from a learning based, in many cases, on the master lessons to one such that methodologies like the flipped classroom or the gamification are stronger than ever. Along this work, we have done a study to teachers and students with the main objective to compare the knowledge on digital tools, their use and their acceptation. We use WxMaxima and Geogebra in order to solve an exercise of Evaluaci\u00f3n de Bachillerato para el Acceso a la Universidad (EBAU) related with Geometry, comparing their ins and outs with the manual solution. Finally, we expose some conclusions and some possible research lines about digital tools, as well as a proposition of an introductory course on WxMaxima and Geogebra in order to teach the teachers. Keywords: TIC; Geogebra; WxMaxima; Herramientas digitales; Educaci\u00f3n Matem\u00e1tica; Competencia Digital. MSC2020:\n97D10; 97N80; 97U10. La Ley Org\u00e1nica 2/2006, de 3 de mayo, de Educaci\u00f3n, LOE en adelante, define las competencias como \u201clas capacidades para aplicar de forma integrada los contenidos propios de cada ense\u00f1anza y etapa educativa, con el fin de lograr la realizaci\u00f3n adecuada de actividades y la resoluci\u00f3n eficaz de problemas complejos\u201d. Todas las leyes que han sucedido a esta, han apostado por un car\u00e1cter competencial y cada vez tienen m\u00e1s fuerza dentro de la ense\u00f1anza. En la vigente Ley Org\u00e1nica 3/2020, de 29 de diciembre, por la que se modifica la Ley Org\u00e1nica 2/2006, de 3 de mayo, de Educaci\u00f3n (LOMLOE en adelante), podemos encontrar la \u201cCompetencia Matem\u00e1tica y de ciencias, tecnolog\u00eda e ingenier\u00eda\u201d (STEM) y la \u201cCompetencia digital\u201d. Seg\u00fan el Ministerio de Educaci\u00f3n y Formaci\u00f3n Profesional, la competencia matem\u00e1tica \u201cimplica la capacidad de aplicar el razonamiento matem\u00e1tico y sus herramientas para describir, interpretar y predecir distintos fen\u00f3menos en su contexto\u201d, mientras que la competencia digital implica el uso creativo y cr\u00edtico de las tecnolog\u00edas de la informaci\u00f3n y la comunicaci\u00f3n, siempre de manera segura y controlada, por lo que no s\u00f3lo implicar\u00e1 destrezas en el acceso o procesamiento de la informaci\u00f3n, sino tambi\u00e9n del filtrado y comprobaci\u00f3n de la veracidad de dicha informaci\u00f3n. Es evidente la relaci\u00f3n directa entre las matem\u00e1ticas y el uso de las tecnolog\u00edas, ya que los nuevos avances cient\u00edficos permiten, por ejemplo, el mejor cifrado y encriptado de contrase\u00f1as en internet, pero la relaci\u00f3n entre inform\u00e1tica y matem\u00e1ticas parece m\u00e1s difusa. Esta relaci\u00f3n se propicia cuando, para descubrir nuevos resultados matem\u00e1ticos, se hace uso de las herramientas inform\u00e1ticas para realizar c\u00e1lculos que hacerlos manualmente nos llevar\u00edan una eternidad. Si echamos la vista atr\u00e1s, no hace mucho los logaritmos se calculaban mediante interpolaciones a partir de valores ya calculados en unas tablas. Estas tablas quedaron obsoletas cuando aparecieron las calculadoras. Estamos quiz\u00e1s ante la siguiente brecha digital, donde los ordenadores han venido a sustituir a las calculadoras, como estas hicieron con las tablas de logaritmos y otros muchos c\u00e1lculos manuales. No podemos dar el siguiente paso tecnol\u00f3gico a los ordenadores, tablets o pizarras digitales si el personal docente no tiene suficientes conocimientos sobre su utilizaci\u00f3n. Es evidente entonces, que la incorporaci\u00f3n de nuevas herramientas digitales a la docencia de las matem\u00e1ticas es inevitable y se intensificar\u00e1 en los pr\u00f3ximos a\u00f1os. El uso de los ordenadores para resolver problemas no implica la desaparici\u00f3n del razonamiento l\u00f3gico, adem\u00e1s, ambas formas de trabajar se complementan y pueden, incluso, potenciarse entre s\u00ed. Por tanto, debemos formar a los alumnos en el uso de las nuevas tecnolog\u00edas para resolver, visualizar o interactuar con un problema matem\u00e1tico y su aplicaci\u00f3n en la vida diaria. Un libro que aborda estas y otras inquietudes relacionadas con las matem\u00e1ticas y la educaci\u00f3n es [2]. En \u00e9l se hace un repaso de distintos \u00e1mbitos relacionados con la educaci\u00f3n matem\u00e1tica tanto en las etapas obligatorias como en la post-obligatoria, as\u00ed como cuestiones que deben ser transversales a lo largo de toda la ense\u00f1anza de las matem\u00e1ticas. Tambi\u00e9n se detallan algunos aspectos sobre la formaci\u00f3n profesional del profesorado de matem\u00e1ticas. Por tanto, ha sido una obra de referencia en las dos \u00faltimas d\u00e9cadas y puede ser un complemento a la lectura de este art\u00edculo. A lo largo del art\u00edculo trataremos los siguientes aspectos: En primer lugar, sentaremos el marco normativo, m\u00e1s concretamente, hablaremos sobre las competencias STEM y digital. Analizaremos el manejo que tienen los profesores y los alumnos en las herramientas digitales relacionadas con las matem\u00e1ticas. Para ello, se ha llevado a cabo una encuesta a docentes y alumnos sobre el uso de diferentes herramientas como LaTeX, Wolfram Alpha o Geogebra. Utilizaremos los programas de libre acceso WxMaxima y Geogebra para resolver un ejercicio de la prueba de acceso a la Universidad de Extremaudra y analizar c\u00f3mo podr\u00edan ayudar al alumnado. Dada la necesidad de formaci\u00f3n en herramientas digitales espec\u00edficas de matem\u00e1ticas, propondremos un curso para iniciar a docentes y alumnos en el manejo de WxMaxima y Geogebra. Finalmente, cerraremos el documento con una secci\u00f3n dedicada a conclusiones obtenidas y posibles l\u00edneas de investigaci\u00f3n que se podr\u00edan explorar a partir de este trabajo. La educaci\u00f3n de nuestros d\u00edas se basa en el desarrollo del curr\u00edculo mediante las competencias b\u00e1sicas o clave (seg\u00fan la ley a la que hagamos referencia). Aunque en el panorama internacional ya se hablaba sobre la educaci\u00f3n por competencias desde que Philippe Perrenoud las introdujese en 1998 [16] y, posteriormente, la Recomendaci\u00f3n del Parlamento Europeo y del Consejo 2006/962/CE, de 18 de diciembre de 2006, sobre las competencias clave para el aprendizaje es la primera vez que un organismo europeo recomendaba la implantaci\u00f3n de este tipo de educaci\u00f3n. En Espa\u00f1a hicieron su aparici\u00f3n en la Ley Org\u00e1nica 2/2006, de 3 de mayo, de Educaci\u00f3n, aunque no se mencionaban las mismas de forma expresa, ya dejaba ver el car\u00e1cter europe\u00edsta del que se quer\u00eda dotar a la eduaci\u00f3n. Las competencias se fueron asentando con el paso de los a\u00f1os, hasta que a finales de 2013 la Ley Org\u00e1nica 8/2013, de 9 de diciembre, para la mejora de la calidad educativa, LOMCE en adelante, recoge por primera vez en Espa\u00f1a las siete competencias claves del sistema educativo espa\u00f1ol y sienta las relaciones entre las competencias, los contenidos y los criterios de evaluaci\u00f3n de los distintos niveles educativos a trav\u00e9s de la Orden ECD/65/2015, de 21 de enero, por la que se describen las relaciones entre las competencias, los contenidos y los criterios de evaluaci\u00f3n de la educaci\u00f3n primaria, la eduaci\u00f3n secundaria obligatoria y el bachillerato. El caracter competencial en la educaci\u00f3n secundaria sigue vigente con la nueva legislaci\u00f3n, la Ley Org\u00e1nica 3/2020, de 29 de diciembre, por la que se modifica la Ley Org\u00e1nica 2/2006, de 3 de mayo, de Educaci\u00f3n (LOMLOE). En ella se describen las competencias clave, entre las que se encuentran la competencia Matem\u00e1tica y de ciencias, tecnolog\u00eda e ingenier\u00eda (STEM) y la competencia digital. Se establece que la competencia matem\u00e1tica es aquella que \u201cimplica la capacidad de aplicar el razonamiento matem\u00e1tico y sus herramientas para describir, interpretar y predecir distintos fen\u00f3menos\u201d [4, Anexo I,2.a]. Por tanto, el estudio de las asignaturas de matem\u00e1ticas no debe buscar la memorizaci\u00f3n de f\u00f3rmulas, problemas t\u00edpicos o definiciones concretas, sino que, a partir de ciertos conocimientos te\u00f3ricos, ha de permitir interpretar el mundo que nos rodea para resolver ploblemas con herramientas matem\u00e1ticas. No se trata entonces de aprender cu\u00e1les son las herramientas matem\u00e1ticas, sino c\u00f3mo aplicar estas herramientas en el mundo exterior. Por ejemplo, no hay raz\u00f3n ninguna para memorizar la famosa f\u00f3rmula del Teorema de Pit\u00e1goras si no sabemos en qu\u00e9 situaciones es pertinente el uso de este conocimiento matem\u00e1tico. As\u00ed, esta f\u00f3rmula puede servir como mero ejercicio mental de memorizaci\u00f3n, o puede servirnos para analizar una rampa de un acceso para minusv\u00e1lidos que nos encontremos en cualquier acera de nuestra ciudad. Por ejemplo, si el tri\u00e1ngulo de la Figura 1 representa una de dichas rampas entonces podemos calcular la longitud de dicha rampa gracias a que a2=b2+c2superscript\ud835\udc4e2superscript\ud835\udc4f2superscript\ud835\udc502a^{2}=b^{2}+c^{2}italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_b start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_c start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT y tambi\u00e9n podemos ver el \u00e1ngulo de inclinaci\u00f3n de la rampa con las relaciones trigonom\u00e9tricas y establecer si la rampa cumple o no con las medidas para la accesibilidad del moviliario urbano. Se trata por tanto de relacionar las f\u00f3rmulas y herramientas matem\u00e1ticas con el mundo que nos rodea, de forma que lo hagamos entendible desde un punto de vista matem\u00e1tico. De todo ello trata el libro Mirar la ciudad con ojos matem\u00e1ticos, [1], L. Blanco establece distintos itinerarios por la ciudad de Badajoz en los que iremos paseando a la vez que realizamos peque\u00f1as actividades de reflexi\u00f3n o de c\u00e1lculo matem\u00e1tico en las que emplearemos algunas de las herramientas que aprendemos en la escuela y que muchos alumnos piensan que no tienen utilidad. En el informe PISA [15, p. 7] se introduce el concepto de alfabetizaci\u00f3n matem\u00e1tica que, a su vez es recogido en castellano en [8, p. 10]: La alfabetizaci\u00f3n matem\u00e1tica es la capacidad de un individuo de razonar matem\u00e1ticamente y de formular, emplear e interpretar las matem\u00e1ticas para resolver problemas en una amplia variedad de contextos de la vida real. Esto incluye conceptos, procedimientos, datos y herramientas para describir, explicar y predecir fen\u00f3menos. Ayuda a los individuos a conocer el papel que cumplen las matem\u00e1ticas en el mundo y hacer los juicios y tomar las decisiones bien fundamentadas que necesitan los ciudadanos reflexivos, constructivos y comprometidos del siglo XXI. Continuando con el mismo documento, el CEMat aporta algunas indicaciones que deben dejar de realizarse en la Educaci\u00f3n Secundaria Obligatoria y el Bachillerato, por ejemplo \u201cutilizar f\u00f3rmulas dadas como modelos de problemas del mundo real, sin analizar de d\u00f3nde surge el modelo\u201d o \u201cexpresar ecuaciones de una funci\u00f3n de forma anal\u00edtica, con el exclusivo objeto de representarlas gr\u00e1ficamente\u201d. Todo ello sugiere que las matem\u00e1ticas y el mundo que conocemos deben estar relacionados y el objeto de estudio de las matem\u00e1ticas debe ser precisamente entender dicha relaci\u00f3n. Respecto a la competencia digital [4, Anexo I, 3] \u201ces aquella que implica el uso creativo, cr\u00edtico y seguro de las tecnolog\u00edas de la informaci\u00f3n y la comunicaci\u00f3n\u201d. De forma que Esta competencia supone, adem\u00e1s de la adecuaci\u00f3n a los cambios que introducen las nuevas tecnolog\u00edas [\u2026] para ser competente en un entorno digital. Requiere de conocimientos relacionados con el lenguaje espec\u00edfico b\u00e1sico: textual, num\u00e9rico, ic\u00f3nico, visual, gr\u00e1fico y sonoro, as\u00ed como sus pautas de decodificaci\u00f3n y transferencia. Esto conlleva el conocimiento de las principales aplicaciones inform\u00e1ticas. Por tanto, con ojos matem\u00e1ticos, el uso de las nuevas tecnolog\u00edas puede servirnos para complementar las explicaciones te\u00f3ricas. Al igual que el uso de la calculadora no implica que la suma de fracciones no tenga que ser estudiada, por ejemplo, el aprendizaje en el uso de herramientas inform\u00e1ticas para el c\u00e1lculo matem\u00e1tico no implica que esos contenidos te\u00f3ricos no deban ser explicados, sino que el alumno tendr\u00e1 una forma m\u00e1s de comprobar si los resultados que va obteniendo son correctos. En el [17] se pone este mismo ejemplo de la calculadora como herramienta plenamente instaurada en el aula, pero que \u201ccomo toda herramienta, es indispensable aprender a utilizarla para que el alumnado no la considere un sustituto del razonamiento matem\u00e1tico\u201d, es decir, no deben verse las herramientas digitales como un sutitutivo del razonamiento, sino como herramientas que exploten \u201clas posibilidades que ofrece para agilizar procesos de c\u00e1lculo en las aulas y para que los alumnos puedan centrarse en la comprensi\u00f3n de los nuevos conceptos\u201d. Seg\u00fan [14], \u201cLa tecnolog\u00eda como recurso de aprendizaje tiene que estar integrada en el curr\u00edculum, es decir, el maestro formado tiene que saber a la hora de dise\u00f1ar una actividad si decide emplear un recurso tecnol\u00f3gico, cu\u00e1ndo y c\u00f3mo hacerlo\u201d y as\u00ed se establece en la Orden ECD/65/2015. En ella podemos apreciar que se indica textualmente que se debe conocer el lenguaje b\u00e1sico de las herramientas digitales en relaci\u00f3n con conocimientos num\u00e9ricos y gr\u00e1ficos, lo que implica el conocimiento de las principales aplicaciones inform\u00e1ticas. Parece, por tanto, necesario relacionar las dos competencias con las que estamos tratanto, la matem\u00e1tica y la digital, de manera que se complementen mutuamente. A pesar de que el uso de herramientas digitales est\u00e1 expresamente recogido en el curr\u00edculo de la educaci\u00f3n secundaria de las asignaturas de matem\u00e1ticas, el informe realizado por la Real Sociedad Matem\u00e1tica Espa\u00f3la y la Sociedad Cient\u00edfica Inform\u00e1tica de Espa\u00f1a en 2020 [18] reconoce que \u201cla gran mayor\u00eda de los libros sigue incorporando la tecnolog\u00eda de modo anecd\u00f3tico y muy ligada a la calculadora\u201d, adem\u00e1s de reflejar la gran diferencia que hay en los docentes, \u201cdesde profesorado muy tecnologizado que incorpora geometr\u00eda din\u00e1mica, hojas de c\u00e1lculo, software de representaci\u00f3n gr\u00e1fica y hasta lenguajes de programaci\u00f3n en su docencia de matem\u00e1tica, hasta profesorado que proh\u00edbe el uso de la calculadora en ESO\u201d. En [10], se propuso una serie de actividades con Geogebra basados en rompecabezas, llegando a la conclusi\u00f3n de que \u201caprender Geometr\u00eda utilizando rompecabezas fue percibido por la mayor\u00eda de los estudiantes como una experiencia agradable que les permite descubrir nuevas cosas\u201d y que al docente le sirve \u201cno s\u00f3lo para estimular el pensamiento geom\u00e9trico, sino tambi\u00e9n fomentar el inter\u00e9s y motivaci\u00f3n hacia aprendizaje de la Geometr\u00eda\u201d. Adem\u00e1s, el uso de las nuevas tecnolog\u00edas en el aula tiene importantes implicaciones pedag\u00f3gicas, como pueden ser, seg\u00fan [14]: \u201cla creaci\u00f3n un entorno interactivo de ense\u00f1anza / aprendizaje en el cual los aprendices pueden ser indistintamente emisores y receptores de informaci\u00f3n, lo que provoca alta motivaci\u00f3n en el aprendiz\u201d, que repercutir\u00e1 directamente en el clima de la clase; \u201cla ense\u00f1anza se adapta a las necesidades espec\u00edficas del alumno\u201d, lo que favorece una de las obligaciones de todo docente, la atenci\u00f3n a la diversidad; \u201cse facilita la ense\u00f1anza cooperativa\u201d, favoreciendo as\u00ed las relaciones sociales y la empat\u00eda entre discentes; y por \u00faltimo \u201cse fomenta el autoaprendizaje\u201d, es decir, estamos repercutiendo positivamente en la adquisici\u00f3n de otra de las competencias b\u00e1sicas de especial importancia en la educaci\u00f3n integral de los alumnos, aprender a aprender. Una vez que hemos visto las dos competencias fundamentales que se buscan estudiar en este trabajo, cabe destacar que la Real Sociedad Matem\u00e1tica Espa\u00f1ola est\u00e1 haciendo importantes esfuerzos por estudiar c\u00f3mo aunar estas dos competencias durante todo el per\u00edodo de escolaridad. M\u00e1s concretamente, en [17] se establece que \u201cla educaci\u00f3n y, espec\u00edficamente, el aprendizaje de las matem\u00e1ticas, no pueden ser ajenas a los cambios que nos conducen hacia una sociedad m\u00e1s tecnificada y digitalizada\u201d. Analizaremos en la pr\u00f3xima secci\u00f3n, la necesidad de formaci\u00f3n del profesorado en el uso y utilidad de las herramientas digitales. Seg\u00fan Carioca et. al. [7], la necesidad de formaci\u00f3n del profesorado en el uso de las herramientas digitales es una necesidad prioritaria de nuestros d\u00edas, no tanto en el uso de las propias herramientas, sino en la utilidad did\u00e1ctica que tienen y en c\u00f3mo llevarlas al aula. Adem\u00e1s, Mart\u00edn destaca en [14, p. 44] que \u201cdebido a la rapidez de los avances tecnol\u00f3gicos se hace m\u00e1s patente que nunca la asunci\u00f3n del profesorado en general de la necesidad de un reciclaje en su formaci\u00f3n tecnol\u00f3gica y en el uso pedag\u00f3gico de la tecnolog\u00eda\u201d. Necesidad que se subraya en el Libro Blanco de las Matem\u00e1ticas [17, p.33] m\u00e1s de una d\u00e9cada despu\u00e9s: \u201cel uso de tecnolog\u00edas en las aulas requiere de un conocimiento did\u00e1ctico que va m\u00e1s all\u00e1 del conocimiento de su simple uso\u201d. Ya hemos se\u00f1alado en las secciones anteriores, el papel de las nuevas tecnolog\u00edas en la ense\u00f1anza de las matem\u00e1ticas. Sin embargo, a\u00fan hay docentes que se limitan al uso de las clases magistrales para la ense\u00f1anza de esta materia. El objetivo principal de este art\u00edculo es realizar un estudio en docentes para comprobar el uso que le dan a distintas herramientas digitales, as\u00ed como el grado de conocimiento que poseen de ellas. M\u00e1s a\u00fan, nos interesa ver c\u00f3mo percibe el alumnado la implementaci\u00f3n de las herramientas digitales en la ense\u00f1anza de las matem\u00e1ticas. Todo esto nos lleva a realizar una encuesta a docentes y alumnado, en la que se les pregunte por distintos aspectos relacionados con las herramientas digitales y, m\u00e1s espec\u00edficamente, por aquellas relacionadas con las matem\u00e1ticas. A ra\u00edz de estas encuestas, podremos establecer distintas comparativas en cuanto al uso de las herramientas digitales por parte de los docentes en el aula o por parte de los alumnos en sus casas, as\u00ed como intentar entender los beneficios y los perjuicios que declaran ambos colectivos en el uso de las herramientas digitales en la ense\u00f1anza de las matem\u00e1ticas. En esta secci\u00f3n veremos las principales respuestas a las encuestas realizadas a docentes y alumnos durante el curso 2020-2021. La muestra tomada para el estudio en los docentes ha sido el conjunto de profesores de Ciencias (Matem\u00e1ticas, F\u00edsica, Qu\u00edmica y Biolog\u00eda) del centro en el que el autor realiz\u00f3 las pr\u00e1cticas del M\u00e1ster de Formaci\u00f3n del Profesorado, durante el curso 2020-2021, el Colegio Santa Teresa de Jes\u00fas en Badajoz, cuya titularidad es privada\u2013concertada para los niveles de la ESO y privada\u2013no concertada para los niveles de Bachillerato. Adem\u00e1s, para obtener m\u00e1s informaci\u00f3n, se ha ampliado la muestra con el conjunto de los profesores de Ciencias del Instituto de Educaci\u00f3n Secundaria \u201cEl Sur\u201d, de la ciudad de Lepe, cuya titularidad es p\u00fablica. La muestra tomada en los alumnos ha sido exclusivamente del Colegio Santa Teresa de Badajoz, m\u00e1s concretamente los alumnos de los grupos donde mi tutora de pr\u00e1cticas imparte clases, es decir, 4.\u00ba de la ESO, 1.\u00ba y 2.\u00ba de Bachillerato, tanto la rama de Matem\u00e1ticas de Ciencias Sociales como de la de Matem\u00e1ticas para Ciencias. Por supuesto, la encuesta ha sido an\u00f3nima y voluntaria. Las preguntas que se hicieron a ambos colectivos pueden encontrarse en los siguientes enlaces: Docentes: \nhttps://drive.google.com/file/d/1r-_YReEOhFgaTqtXX2TqPu94N4EQoDFW/view?usp=share_link Alumnado: \nhttps://drive.google.com/file/d/1460CqUUTl63VheDltHetF_r2OuMZmJeC/view?usp=share_link Se pueden observar que las preguntas son parecidas, de forma que podamos establecer algunas relaciones. Analizaremos primero las respuestas de los docentes, despu\u00e9s la del alumnado, y finalmente comparemos ambos colectivos. Entre los docentes se han registrado un total de 12 respuestas. Empezando por la formaci\u00f3n, observamos que la mayor\u00eda (58,3%percent58.358{,}3\\leavevmode\\,\\%{}58,3 %) de docentes provienen de licenciaturas, por lo que han pasado al menos diez a\u00f1os desde que egregaron y, posiblemente, no tengan toda la formaci\u00f3n en el uso de las TIC con fines did\u00e1cticos como ser\u00eda deseable. Sin embargo, todos los docentes reconocen su utilidad y s\u00f3lo el 8,3%percent8.38{,}3\\leavevmode\\,\\%{}8,3 % admite no saber usarlas. Algunas de las respuestas m\u00e1s interesantes a la pregunta \u00bfC\u00f3mo crees que las herramientas digitales (en general) pueden ayudar a los alumnos en el aula o fuera de ella?, han sido: Pueden visualizar contenidos complejos de reproducir sin digitalizaci\u00f3n. La motivaci\u00f3n hacia la asignatura es mayor utilizando una herramienta digital. Pueden ayudar a comprender y aprender m\u00e1s y mejor que con el m\u00e9todo tradicional. Les ayuda a que los estudios sean m\u00e1s cercanos. Adem\u00e1s, dos tercios del profesorado encuestado afirma haber realizado cursos de formaci\u00f3n en herramientas digitales en el \u00faltimo a\u00f1o, quiz\u00e1 debido a que han tenido que actualizarse r\u00e1pidamente por los confinamientos y la situaci\u00f3n del COVID\u201319, mientras que un 16,7%percent16.716{,}7\\leavevmode\\,\\%{}16,7 % afirma haber realizado cursos en los \u00faltimos cinco a\u00f1os y el otro 16,7%percent16.716{,}7\\leavevmode\\,\\%{}16,7 % afirma no haber realizado cursos desde hace m\u00e1s de diez a\u00f1os. Muchos de los cursos ofertados por el Centro de Profesores y Recursos (CPR) son de manejo elemental y, precisamente por esto, algunos de los docentes que usan estas herramientas terminan no haciendo los cursos. Se pregunt\u00f3 tambi\u00e9n sobre el nivel de uso de distintas herramientas (ofim\u00e1tica, Kahoot!, generador de nubes de palabras, mapas conceptuales, Canva, Genially y Powtoon) para la elaboraci\u00f3n de material did\u00e1ctico. Las respuestas se recogen en la Figura 2. Cabe destacar el uso casi a diario de las herramientas de ofim\u00e1tica, y un uso algo menor para Kahoot! y herramientas de creaci\u00f3n de mapas conceptuales. El resto de aplicaciones tiene un uso pr\u00e1cticamente nulo. En el \u00e1mbito espec\u00edfico de las herramientas digitales relacionadas con las matem\u00e1ticas, sobre el conocimiento en general de ciertas herramientas se han obtenido las respuestas recogidas en la Figura 3. Donde apreciamos que todos los docentes conocen el editor de f\u00f3rmulas de Word, pero que la mayor\u00eda (siete de los doce encuestados) no conocen LaTeX para la edici\u00f3n de texto cient\u00edfico. Sobre las herramientas de c\u00e1lculo destaca que casi todos conocen Geogebra, pero la mayor\u00eda desconocen programas de c\u00e1lculo simb\u00f3lico como WxMaxima, Wolfram Alpha o Wolfram Mathematica. Centr\u00e1ndonos, por tanto, en el uso del editor de f\u00f3rmulas de Word, cinco docentes afirman usarlo con mucha frecuencia y dos de ellos a diario, indicando, en la siguiente pregunta, que han aprendido a usarlo, mayoritariamente de manera autodidacta. En cuanto a Geogebra, la mayor\u00eda de respuesta se ubica en que su uso es espor\u00e1dico (alguna vez) y que la mayor\u00eda, de nuevo, han sido autodidactas en su aprendizaje. Algunas opiniones de los docentes sobre c\u00f3mo ayudan estas herramientas espec\u00edficamente matem\u00e1ticas a los alumnos son: Permite obtener multitud de ejemplos y generalizar contenidos trabajados. Muy \u00fatil en geometr\u00eda, estad\u00edstica y an\u00e1lisis. Pueden hacer m\u00e1s atractiva la asignatura y les puede motivar m\u00e1s su estudio. Facilitar los c\u00e1lculos, comprobar sus resultados, visualizar. Les hacen desarrollar la \u2019imaginaci\u00f3n\u2019 y capacidad de deducci\u00f3n y resoluci\u00f3n de problemas y teor\u00edas. Esto se corresponde con la idea generalizada que ya puntualizamos en la secci\u00f3n anterior y que en [8] transmite el CEMAT, y es que es necesario \u201cusar utilidades inform\u00e1ticas para desarrollar estructuras conceptuales\u201d en detrimento del c\u00e1lculo con \u201cl\u00e1piz y papel\u201d ya que \u201csolucionar problemas con ayuda del ordenador es un ejercicio que permite adquirir la costumbre de enfrentarse a problemas predefinidos de una forma rigurosa y sistem\u00e1tica\u201d. Como \u00faltimo apunte, algunas de las respuestas m\u00e1s interesantes de los docentes a si les gustar\u00eda recibir alg\u00fan tipo de formaci\u00f3n sobre el uso de estas herramientas fueron: Geogebra, sobre la realizaci\u00f3n de recursos interactivos. Geogebra y WxMaxima. S\u00ed, ser\u00eda muy bueno aprender todas las funcionalidades de todas estas herramientas. S\u00ed, sobre Geogebra, con un curso pr\u00e1ctico. S\u00ed. Me gustar\u00eda saber emplear en mis clases m\u00e1s de las herramientas digitales que ya uso. De estas respuestas se deduce el inter\u00e9s del profesorado en la formaci\u00f3n en herramientas digitales espec\u00edficas de las matem\u00e1ticas para su utilizaci\u00f3n en el aula y que, adem\u00e1s opinan que pueden tener un importante beneficio en el alumnado. As\u00ed, en la secci\u00f3n 5 se propondr\u00e1 un curso formativo para docentes en las herramientas WxMaxima y Geogebra. En este caso, hemos obtenido 40 respuestas por parte del alumnado. Empezaremos localizando en los cursos a estos alumnos, el 20%percent2020\\leavevmode\\,\\%{}20 % corresponde a alumnos de 4.\u00ba de la ESO, el 52,5%percent52.552{,}5\\leavevmode\\,\\%{}52,5 % a alumnos de 1.\u00ba de Bachillerato y el 27,5%percent27.527{,}5\\leavevmode\\,\\%{}27,5 % de 2.\u00ba de Bachillerato. Para empezar, cabe destacar que todos afirmaron que las herramientas digitales son \u00fatiles, y s\u00f3lo el 5%percent55\\leavevmode\\,\\%{}5 % de ellos admiti\u00f3 no saber utilizarlas. Algunas de las respuestas m\u00e1s interesantes a la pregunta \u00bfC\u00f3mo crees que las herramientas digitales (en general) pueden ayudarte en el aula o fuera de ella?, han sido: Sobre todo en la din\u00e1mica que estableces con el profesor, teniendo en cuenta que es mucho m\u00e1s entretenida la clase y se te pasa mucho m\u00e1s r\u00e1pido. A la hora de poder hacer trabajos, estudiar o incluso informarme de cosas que no sab\u00eda antes que pueden ser interesantes. Creo que la comunicaci\u00f3n mejorar\u00eda mucho entre alumnos y profesores. Tambi\u00e9n har\u00eda que las clases fueran m\u00e1s din\u00e1micas. Ayudan a organizarte mejor, y a veces te hacen las cosas m\u00e1s f\u00e1ciles, m\u00e1s visuales. Adem\u00e1s te permite preguntar al profesor aunque no est\u00e9 en horario de clases. Cuando se pregunta al alumnado sobre el uso de distintas herramientas generales (ofim\u00e1tica, Kahoot!, generador de nubes de palabras, mapas conceptuales, Canva, Genially y Powtoon), se obtienen las respuestas recogidas en la Figura 4. Donde destaca especialmente el uso bastante extendido de las aplicaciones de ofim\u00e1tica y algo menor el uso de Kahoot!, adem\u00e1s de un uso pr\u00e1cticamente nulo del resto de herramientas. Centr\u00e1ndonos en las herramientas digitales matem\u00e1ticas, se pregunt\u00f3 a los alumnos por las mismas herramientas que a los docentes, obteniendo las respuestas recogidas en la Figura 5. Siguen destacando el editor de f\u00f3rmulas de Word y Geogebra, aunque sus usos sean pr\u00e1cticamente nulos tal y como se recoge en la Figura 6. As\u00ed, algunas de las respuestas m\u00e1s interesantes a la pregunta \u00bfTe gustar\u00eda recibir alg\u00fan tipo de formaci\u00f3n sobre alguna de las herramientas matem\u00e1ticas?, fueron: S\u00ed, sinceramente de todas. Porque recientemente he visto como era la de Geogebra y, me ha parecido que est\u00e1 muy avanzada y tiene muy buenas cosas. No tengo ninguna preferencia y la formaci\u00f3n deber\u00eda ser una breve introducci\u00f3n o algo por el estilo. S\u00ed, como WxMaxima u otra para saber m\u00e1s sobre ellas. A trav\u00e9s de alg\u00fan seminario o v\u00eddeos explicativos. No me interesa en este momento. Observamos que, a pesar de haber algunas respuestas negativas a recibir alg\u00fan tipo de formaci\u00f3n, la mayor\u00eda de alumnos reconoci\u00f3 querer formarse en este tipo de herramientas. Y, finalmente, sobre por qu\u00e9 creen que estas les pueden ayudar en casa o en el aula, algunas de las respuestas m\u00e1s representativas fueron: Una mayor precisi\u00f3n en casos de gr\u00e1ficas, exactitud en c\u00e1lculos y control y organizaci\u00f3n cuando se necesario manejar mucho c\u00e1lculos diferentes. A la hora de las correcciones son m\u00e1s precisas que a lo mejor hacer una representaci\u00f3n gr\u00e1fica en la pizarra. Haciendo ejercicios que no entiendo, para poder prepararme un examen y as\u00ed saber si hago bien los ejercicios. No s\u00e9 a los dem\u00e1s, pero a mi durante la cuarentena me salvaron la evaluaci\u00f3n, porque pon\u00eda los ejercicios y ya est\u00e1 ja ja (Pero era porque no me enteraba, lo prometo). Por tanto, a pesar de que en la respuesta anterior hubo alumnos que no quer\u00edan formarse, en esta pregunta se aprecia una opini\u00f3n generalizada en torno a que el uso de este tipo de herramientas puede ayudar en casa y en el aula. Incluso la \u00faltima respuesta la he incluido porque hay alumnos para los que el uso de las herramientas inform\u00e1ticas es circunstancial y anecd\u00f3tico, y no est\u00e1 relacionado con el trabajo o el aprendizaje matem\u00e1tico. Teniendo en cuenta lo expuesto en las secciones de an\u00e1lisis de las respuestas de docentes y alumnos, podemos destacar las siguientes conclusiones importantes: Ambos colectivos consideran \u00fatil el uso de las herramientas digitales. De manera general, docentes y discentes tienen conocimientos sobre herramientas poco creativas y efectivas, como pueden ser las de ofim\u00e1tica; empieza a haber discrepancias en herramientas que necesitan un mayor grado de creatividad como pueden ser Kahoot!, Canva o Genially. El uso de dichas herramientas ofim\u00e1ticas est\u00e1 muy extendido, pr\u00e1cticamente a diario por parte de docentes y alumnos, pero el resto de herramientas son usadas de manera espor\u00e1dica. Ambos grupos consideran que las redes sociales pueden ayudar a la comunicaci\u00f3n docente\u2013discente y por tanto resaltan la importancia de una conversaci\u00f3n fluida y, en cierto modo, distendida. Sobre las herramientas de car\u00e1cter matem\u00e1tico, el desconocimiento es pr\u00e1cticamente absoluto, salvando quiz\u00e1 los casos del editor de f\u00f3rmulas de Word y Geogebra. El conocimiento del primero de ellos quiz\u00e1 sea debido al amplio uso que han reconocido de las herramientas de ofim\u00e1tica. El conocimiento y uso de Geogebra quiz\u00e1 merezca un estudio m\u00e1s en profundidad, pero en cualquier caso es una de las herramientas m\u00e1s sencillas e intuitivas de utilizar y que tiene una dilatada experiencia en el sector educativo, por lo que muchos docentes, cada vez m\u00e1s, la utilizan en clase con distintos fines. Por ejemplo [11], estudia el uso de Geogebra como facilitador del aprendizaje en el An\u00e1lisis, concretamente establece que Geogebra favorece \u201cla utilizaci\u00f3n de las funciones de variable real como instrumento de modelizaci\u00f3n y herramienta de soluci\u00f3n de situaciones problem\u00e1ticas intra y extra matem\u00e1ticas\u201d, as\u00ed como \u201cla visualizaci\u00f3n din\u00e1mica de los comportamientos funcionales\u201d. Aunque algunas herramientas, tanto generales como matem\u00e1ticas, son conocidas, la gran mayor\u00eda de herramientas son, o bien desconocidas, o bien de poca utilizaci\u00f3n. Esto nos lleva a preguntarnos si quiz\u00e1 se deba a que no han recibido ning\u00fan tipo de formaci\u00f3n sobre sus diferentes usos. Ya que, en cierta medida no podemos utilizar algo que no conocemos. En esta l\u00ednea se investig\u00f3 en el art\u00edculo [7] la formaci\u00f3n continuada en herramientas inform\u00e1ticas del profesorado de Extremadura y del Alentejo portugu\u00e9s, determinando que \u201cen Extremadura [\u2026] la formaci\u00f3n permanente del profesorado no necesita incidir tanto en la preparaci\u00f3n t\u00e9cnica en el campo de la inform\u00e1tica cuanto en la utilizaci\u00f3n did\u00e1ctica del ordenador en el contexto escolar\u201d. Es decir, tenemos profesores que entienden el uso del ordenador y de herramientas inform\u00e1ticas, pero no saben c\u00f3mo implementarlas en el aula. As\u00ed, a modo de conclusi\u00f3n, observamos que hay consenso en que las nuevas tencnolog\u00edas est\u00e1n aqu\u00ed para quedarse, por lo que, en nuestro caso particular, docentes y discentes entienden la importancia y el amplio abanico que pueden ofrecer herramientas inform\u00e1ticas a la mejora de la calidad educativa. El software WxMaxima es un programa de software libre, esto es, gratuito, lo cu\u00e1l facilita su difusi\u00f3n y utilizaci\u00f3n, a diferencia de otros programas que requieren una licencia de pago. Puede descargarse para distintos sistemas operativos como Windows, Mac OS, Linux o Ubuntu, por lo que pr\u00e1cticamente podremos instalarlo en cualquier ordenador e incluso tiene su versi\u00f3n en Android, por lo que algunos alumnos podr\u00e1n incluso trabajar con sus dispositivos m\u00f3viles. Se trata de un programa que, m\u00e1s all\u00e1 del propio c\u00e1lculo, tiene grandes implicaciones pedag\u00f3gicas, como apunta Jorquera en [13, p.11-12]: Permite realizar c\u00e1lculos reales, de mayor dificultad matem\u00e1tica evitando perder tiempo en el c\u00e1lculo rutinario, con lo que se puede dedicar m\u00e1s tiempo a la explicaci\u00f3n de los conceptos que a las habilidades de c\u00e1lculo. Ser\u00e1 \u00fatil en algunos casos, e in\u00fatil en otros. No hay que forzar su uso en todas las ocasiones ya que esto ser\u00eda un error, pero hay contextos en los cuales el error ser\u00eda no usarlo. Se fomenta m\u00e1s el trabajo creativo en detrimento del rutinario. Por su parte, Geogebra tiene una versi\u00f3n de escritorio y una versi\u00f3n en l\u00ednea, ambas gratuitas. Adem\u00e1s, en la p\u00e1gina de inicio de Geogebra existen un gran abanico de actividades en l\u00ednea y descargables para realizar en el aula con esta aplicaci\u00f3n. Est\u00e1 en espa\u00f1ol, lo cual es una gran ventaja para muchos docentes y alumnos. Y tiene una interfaz sencilla e intuitiva, que cualquiera puede aprender a manejarla simplemente probando sus distintas herramientas. A pesar de ello, tiene un gran n\u00famero de funciones m\u00e1s complejas para crear actividades muy interesantes. En este sentido, \u201cGeogebra mejora significativamente el aprendizaje de la capacidad de razonamiento y demostraci\u00f3n, de comunicaci\u00f3n matem\u00e1tica as\u00ed como la capacidad de resoluci\u00f3n de problemas\u201d [12], as\u00ed como \u201ccontribuy\u00f3 a que mejorasen sus actitudes hacia las matem\u00e1ticas durante su uso, exhibiendo gusto, implicaci\u00f3n y autoconfianza en matem\u00e1ticas\u201d [12]. Veamos, mediante un ejercicio de la prueba de acceso a la Universidad de Extremadura correspondiente al bloque de Geometr\u00eda de la asignatura Matem\u00e1ticas II, c\u00f3mo WxMaxima y Geogebra se complementan para una resoluci\u00f3n sencilla. Para ello, resolveremos el ejercicio manualmente y con ambos programas, argumentando cu\u00e1l es m\u00e1s idoneo en cada situaci\u00f3n. Este ejercicio apareci\u00f3 en la convocatoria ordinaria del curso 2020\u20132021 y su encunciado fue el siguiente: Sea el plano \u03a0\u03a0\\Piroman_\u03a0 de ecuaci\u00f3n 2\u2062x+y\u2212z\u22122=02\ud835\udc65\ud835\udc66\ud835\udc67202x+y-z-2=02 italic_x + italic_y - italic_z - 2 = 0 y la recta r\ud835\udc5fritalic_r dada por x3=y\u22122\u22123=z\u221213\ud835\udc653\ud835\udc6623\ud835\udc6713\\frac{x}{3}=\\frac{y-2}{-3}=\\frac{z-1}{3}divide start_ARG italic_x end_ARG start_ARG 3 end_ARG = divide start_ARG italic_y - 2 end_ARG start_ARG - 3 end_ARG = divide start_ARG italic_z - 1 end_ARG start_ARG 3 end_ARG. Estudie la posici\u00f3n relativa de la recta respecto al plano. Calcule la distancia de la recta al plano. Debemos tener en cuenta que un punto de la recta es P=(0,2,1)\ud835\udc430.2.1P=(0,2,1)italic_P = ( 0,2,1 ) y su vector director es u\u2192=(3,\u22123,3)\u2192\ud835\udc6233.3\\vec{u}=(3,-3,3)over\u2192 start_ARG italic_u end_ARG = ( 3 , - 3,3 ). Por otro lado el vector normal del plano es n\u2192=(2,1,\u22121)\u2192\ud835\udc5b2.11\\vec{n}=(2,1,-1)over\u2192 start_ARG italic_n end_ARG = ( 2,1 , - 1 ). As\u00ed, como y comprobando si P\ud835\udc43Pitalic_P pertenece, o no, a \u03a0\u03a0\\Piroman_\u03a0, Luego el plano y la recta son paralelos. La distancia vendr\u00e1 dada por La idea que tenemos que seguir es la misma que la resoluci\u00f3n manual. En primer lugar, definimos los vectores director de la recta y normal del plano, y realizamos su producto escalar (Figura 7): Se define la funci\u00f3n que nos indica si un punto pertenece o no al plano \u03a0\u03a0\\Piroman_\u03a0 y sustituimos el punto P=(0,2,1)\ud835\udc430.2.1P=(0,2,1)italic_P = ( 0,2,1 ) (Figura 8): Como u\u2192\u22c5n\u2192=0\u22c5\u2192\ud835\udc62\u2192\ud835\udc5b0\\vec{u}\\cdot\\vec{n}=0over\u2192 start_ARG italic_u end_ARG \u22c5 over\u2192 start_ARG italic_n end_ARG = 0 y P\u2209\u03a0\ud835\udc43\u03a0P\\notin\\Piitalic_P \u2209 roman_\u03a0, se deduce que la recta r\ud835\udc5fritalic_r y el plano \u03a0\u03a0\\Piroman_\u03a0 son paralelos, por lo que su distancia puede ser calculada como sigue (Figura 9) Y el ejercicio quedar\u00eda resuelto. Primero definimos el plano y la recta dados, as\u00ed como el punto P=(0,2,1)\ud835\udc430.2.1P=(0,2,1)italic_P = ( 0,2,1 ) (Figura 10). A continuaci\u00f3n, trazamos la recta perpendicular al plano que pasa por P\ud835\udc43Pitalic_P y se\u00f1alamos como P\u2032superscript\ud835\udc43\u2032P^{\\prime}italic_P start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT el punto donde intersecta esta perpendicular con el plano \u03a0\u03a0\\Piroman_\u03a0, es decir, la proyecci\u00f3n de P\ud835\udc43Pitalic_P en \u03a0\u03a0\\Piroman_\u03a0 (Figura 11) Para finalizar, s\u00f3lo tendremos que utilizar la herramienta de distancia se\u00f1alando los puntos P\ud835\udc43Pitalic_P y P\u2032superscript\ud835\udc43\u2032P^{\\prime}italic_P start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT (Figura 12). Obteniendo el resultado aproximado de 0\u2032\u206241\u224816superscript0\u203241160^{\\prime}41\\approx\\frac{1}{\\sqrt{6}}0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT 41 \u2248 divide start_ARG 1 end_ARG start_ARG square-root start_ARG 6 end_ARG end_ARG, concluyendo as\u00ed el ejercicio. En este caso es clara la diferencia entre las tres resoluciones: La resoluci\u00f3n manual es tediosa y falta de visualizaci\u00f3n, algo clave en la parte de Geometr\u00eda, ya que es la parte de las matem\u00e1ticas m\u00e1s visual. La resoluci\u00f3n con WxMaxima hace sencillos los c\u00e1lculos, pero de nuevo carece de visualizaci\u00f3n. Bien es cierto que, adem\u00e1s, tiene un lenguaje particular y es necesario saber escribir las operaciones y funciones, ya que, de lo contrario, podemos tardar mucho en resolver un ejercicio. La resoluci\u00f3n con Geogebra es eminentemente visual, de hecho, para resolver el primer apartado basta con representar ambos objetos para darnos cuenta de su posici\u00f3n relativa. M\u00e1s complicado es, sin embargo, el segundo apartado, ya que debemos conocer que la distancia entre una recta y un plano paralelos es la distancia entre un punto cualquiera de la recta hasta su proyecci\u00f3n en el plano, lo cual no es tan sencillo de realizar en Geogebra ya que tendremos que calcular la perpendicular, la intersecci\u00f3n y despu\u00e9s la distancia. Adem\u00e1s, observamos que la distancia obtenida es una aproximaci\u00f3n y no el valor exacto. Por tanto, mi conclusi\u00f3n en este ejercicio es que la soluci\u00f3n \u00f3ptima vendr\u00eda dada por una mezcla de los dos programas, el primer apartado se resolver\u00eda f\u00e1cilmente con Geogebra mientras que para el segundo apartado emplear\u00eda WxMaxima. Teniendo en cuenta que a lo largo del trabajo se ha pretendido inculcar una visi\u00f3n de las herramientas digitales como facilitadoras del aprendizaje, pero que tanto docentes como alumnos no conocen su funcionamiento, el autor propone un curso/seminario formativo orientado a docentes. Estar\u00e1 compuesto por cuatro sesiones y se trabajar\u00e1n los aspectos y utilidades fundamentales de WxMaxima y Geogebra recogidos en las Tablas 1, 2, 3 y 4. En total, este curso/seminario consta de 21 v\u00eddeotutoriales con una duraci\u00f3n de dos horas y media aproximadamente. Trece de ellos est\u00e1n dedicados, entre las dos primeras sesiones, a WxMaxima, con una duraci\u00f3n de 1 hora y 25 minutos aproximadamente; y ocho v\u00eddeos, los correspondientes a las sesiones tercera y cuarta, dedicados a Geogebra, con una duraci\u00f3n aproximada de una hora y cinco minutos. Como hemos venido haciendo hincapi\u00e9, su objetivo es brindar a los docentes las herramientas y utilidades b\u00e1sicas de estos dos programas para que puedan adaptar los ejercicios del d\u00eda a d\u00eda en el aula e implementar el uso de las herramientas digitales para la resoluci\u00f3n y visualizaci\u00f3n de contenidos matem\u00e1ticos, as\u00ed como de la mejora de la asimilaci\u00f3n de los conceptos y una mejora de la predisposici\u00f3na a aprender matem\u00e1ticas. A modo de conclusi\u00f3n, podemos extraer algunas de las ideas fundamentales que se han desarrollado a lo largo del trabajo: En primer lugar, el aprendizaje del contenido matem\u00e1tico y de procesos de resoluci\u00f3n de problemas no est\u00e1 re\u00f1ido con el hecho de aprender el uso de herramientas digitales. Esto se debe a que ambos m\u00e9todos de resoluci\u00f3n se complementan. Hemos visto, dentro de los ejercicios resueltos, que un programa puede servir mejor que el otro para \u201chacer cuentas\u201d o para representar, pero en cualquiera de los dos programas, se ha de tener una visi\u00f3n general de la parte te\u00f3rica para poder seguir el hilo argumental del problema y obtener la soluci\u00f3n. Esto puede ayudar a la autocorrecci\u00f3n de los ejercicios que, habitualmente, los alumnos tienen como tarea para casa; tambi\u00e9n puede ayudar a que alumnos con altas capacidades indaguen e investiguen en mayor profundidad, buscando nuevos retos y problemas m\u00e1s complicados; e incluso, puede ayudar, al aprendizaje por descubrimiento o al just in time teaching, es decir, darle respuestas al alumno en el momento en que se haga las cuestiones, por lo que los programas pueden servir para dejarles probar y, como docentes, les ayudaremos en sus procesos de descubrimiento. En segundo lugar, creo que hay mucho camino por delante en cuanto a la implantaci\u00f3n de las nuevas tecnolog\u00edas en los centros educativos. Aunque es verdad que cada vez se invierte m\u00e1s en adaptar las aulas a las nuevas tecnolog\u00edas (pizarras digitales, proyectores o aulas virtuales), no podemos decir lo mismo sobre la inversi\u00f3n en la formaci\u00f3n de los docentes en el uso de estas herramientas. Esto implica que las nuevas tecnolog\u00edas pueden ser en ciertos casos, vistas como una fuente adicional de estr\u00e9s en el profesorado, por ejemplo ante la posibilidad de que el docente tenga preparada una clase y, el d\u00eda que pretenda impartirla, no funcione internet; o que las herramientas sean vistas m\u00e1s como un elemento extra\u00f1o que como un medio educativo. Tampoco los docentes conocen todas las funcionalidades que estas les ofrecen, por tanto, muchos de ellos seguir\u00e1n con sus rutinas sin saber los beneficios de dichas herramientas. Como hemos dicho, hay mucho camino por recorrer, lo cual es bueno, pr\u00e1cticamente cualquier iniciativa formativa ser\u00e1 bien acogida por la comunidad educativa, tanto de formaci\u00f3n al profesorado como de formaci\u00f3n al alumnado, ya que ambos colectivos observan que las herramientas digitales tienen un gran potencial, pero no saben c\u00f3mo aprovecharlo. Por \u00faltimo, teniendo en cuenta estas conclusiones, podemos proponer las siguientes l\u00edneas de investigaci\u00f3n para las que ser\u00e1 necesario un an\u00e1lisis m\u00e1s detallado de las diferencias en el uso y en la concepci\u00f3n de las herramientas digitales en la educaci\u00f3n secundaria: Lo primero en lo que deber\u00edamos pensar es en realizar una encuesta a un espacio muestral m\u00e1s amplio y elegido considerando ciertas variables (formaci\u00f3n inicial del profesorado, titulaci\u00f3n de acceso al cuerpo de profesores de secundaria, a\u00f1os de experiencia como docente, contexto socioecon\u00f3mico del centro, etc.), con el objetivo de poder obtener conclusiones m\u00e1s significativas para una poblaci\u00f3n mayor. Una vez realizado el curso introductorio de las herramientas digitales WxMaxima y Geogebra, realizar un seguimiento, por ejemplo, tomar dos grupos de alumnos que cursen la misma asignatura de matem\u00e1ticas en el mismo curso. A uno de estos grupos se le asignar\u00e1 un profesor que no haya realizado el curso introductorio y seguir\u00e1 una metodolog\u00eda sin TIC. Al otro grupo, se le asignar\u00e1 un profesor que s\u00ed haya realizado el curso, que haya intentado introducir estas herramientas a lo largo de las explicaciones. Finalmente, se comparar\u00e1 si el uso de las herramientas digitales ha influido no s\u00f3lo en los resultados, sino en la aceptaci\u00f3n de la asignatura de matem\u00e1ticas, en la motivaci\u00f3n con que van a clase y en la satisfacci\u00f3n y la percepci\u00f3n de aprendizaje de los alumnos. Por \u00faltimo, en caso de que lo anterior refleje un aumento significativo de los resultados acad\u00e9micos y la motivaci\u00f3n del alumno por la asignatura, cabr\u00eda plantear un curso de material m\u00e1s avanzado con el que puedan seguir profundizando en el uso de WxMaxima y Geogebra los docentes que hicieron el primer curso. As\u00ed, de nuevo, tras un dominio m\u00e1s avanzado de las herramientas podr\u00edamos hacer un estudio comparativo entre ambos grupos, uno con un docente que tenga un menor dominio, que solo haya realizado el primer curso, y otro con un profesor que haya realizado el curso avanzado. "
    },
    {
        "id": 20,
        "title": "Algorithms for constrained optimal transport",
        "corpus": "1 We derive iterative scaling algorithms of the Sinkhorn-Knopp (SK) type for constrained optimal transport. The constraints are in the form of prior-imposed zeroes in the transport plan. Based on classical Bregman arguments, we prove asymptotic convergence of our algorithms to a unique optimal solution. New insights obtained from the convergence proof are highlighted. An example from electrical vehicle charging in a smart city context is outlined, in which the prior zero-constraints prevent energy from being transported from some providers to some vehicles. Optimal Transport (OT) has emerged as a key enabling mathematical technology which is driving a growing number of contemporary engineering applications in fields such as machine learning, image processing, and in optimization and control [1], [2], [3]. The field is an old one, dating back to Monge in the 18th century.\nNevertheless, OT is now attracting accelerated attention from both theoreticians and practitioners alike, with widespread application in engineering practice. OT refers to a class of problems in which we seek to transport a finite resource (e.g.\u00a0mass) from a distributed source to a distributed target, in some optimal manner. For example, the classical problems of Monge and Kantorovitch relate to the transportation of a distributed pile of sand [4] from one location to another. The contemporary analogues of these formulations (for example, in economics) arise in resource (re)allocation problems, and in supply-demand matching problems\u00a0[5]. Closely related problems arise in key machine learning (ML) settings, such as domain adaptation. Here, source data are optimally adapted (i.e.\u00a0transported) for use in a related, but distinct, target domain\u00a0[6]. An example is \u201cdata repair\u201d, in which OT is used to de-bias ML tasks in order to improve their fairness properties. Classifiers and recommender systems\u2014trained on data with fairness deficiencies such as representation bias, dependence on protected attributes, etc.\u2014can be fairness-repaired using methods of OT [7]. In this paper, we confine ourselves to the discrete case, in which the resource (mass) is distributed across a finite (though typically large) number of states in both the source and target. For every pair of source-target states, the designer specifies a cost per unit mass of transporting the resource from this source state to this target state. The OT problem then involves the design of a transport plan that specifies the amount of resource to be transported for every one of these source-target state pairs, in a way that minimizes the total cost of transport. A feature of our setting of the OT problem in this paper is that we impose constraints in which some source states are not allowed to transport to some target states. These prior zero-transport constraints may arise for a variety of reasons. For example, in economics, certain producers may not be allowed to supply a product to certain consumers. In fairness-aware domain adaptation for ML (above), data for a particular demographic group may not be mapped to a different demographic group. These OT problems give rise to linear programs of very large scale\u00a0[8]. Linear programming solvers are known to scale poorly, and much of the current OT work focuses on regularizing the classical OT problem to ensure tractability at scale. The best known of these approaches is the entropic regularisation of the OT problem\u00a0[8]. In essence, this amounts to the addition of an extra term in the (total cost) objective, which penalizes a specified divergence of the transport plan from a prior-defined ideal plan [9]. The resulting optimization problem is then strongly convex on a compact convex set, and can be solved efficiently using a Sinkhorn-Knopp-type (SK) iterative scaling algorithm, with its favourable large-scale computational properties\u00a0[10], [11]. These computational OT results and guarantees\u2014based on the SK algorithm\u2014 have been central to the widespread adoption of the OT paradigm in applications, particularly in ML [4], [6], [12], [13]. In contrast to previous results in the literature, our purpose in this paper is to consider OT problems in which some elements of the transport plan are forced to be zero a priori,\nand to derive iterative scaling algorithms of the SK-type to solve these problems. We use Bregman-type arguments [14] to prove convergence of our algorithms to the (unique) solution of the OT problems under consideration. We outline an application of our results in a smart cities context, where prior zeroes in the transport plan are an important constraint. OT problems are often cast in the language of probability, where the resource (mass) to be transported is a probability measure, and so the net resource (mass) is normalized to one. The transport plan is thus a bivariate probability mass function (pmf), and the source and target distributions are its two marginals. We speak of a transport plan that moves the source distribution (marginal) to the target distribution (marginal). In this way, OT can be viewed as a mathematical framework for measuring the distance between (source and target marginal) probability distributions, this distance being the minimal expected cost associated with the optimal transport plan\u00a0[4]. This Kantorovich-Rubinstein (also called Wasserstein or earth-mover\u2019s) norm\u00a0[4] for classical entropy-regularized OT gives rise to a unique solution of a strongly convex optimization problem on a compact convex support\u00a0[15], [16], with linear convergence of the SK iterative scaling algorithm to this unique solution\u00a0[17]. If, as in this paper, we impose prior zero-constraints on some elements of the transport plan,\nthere may not exist a plan that satisfies exact marginal constraints at the source and target, as already noted. Another situation in which a transport plan satisfying exact marginal constraints does not exist is unbalanced OT (UOT) [16], in which the prescribed net masses of the source and target are not the same.\nEarlier, in\u00a0[18], an SK-type iterative scaling algorithm was derived for unconstrained UOT (i.e.\u00a0without prior zero-constraints on the transport plan), by relaxing the source and target marginal constraints via extra terms in the cost that penalize noncompliance with the marginal constraints. This was shown to converge linearly to a unique solution.\nIn [16], the authors study the UOT\ncase with prior zero-constraints on the transport plan.\nThey prove that the SK algorithm has two convergent subsequences in this case and they propose a transport plan which is the component-wise geometric mean of\nthe limits plans of the two convergent subsequences The paper is organized as follows: in Section\u00a0III, our OT problem is specified with prior constraints on the pattern of the transport plan. After developing background material, two iterative scaling algorithms are presented in Section IV for OT problems with prior zero-constraints.\nSection V presents some properties of the resulting OT plans.\nSection VI provides the proof of convergence or our algorithms.\nFinally, a use-case from the domain of smart mobility\nis outlined in Section VII, illustrating the efficacy of our new algorithms. Consider an OT problem in which we have a finite number, m\ud835\udc5amitalic_m, of source agents (i.e.\u00a0source states), i=1,2,\u2026,m\ud835\udc5612\u2026\ud835\udc5ai=1,2,\\dots,mitalic_i = 1 , 2 , \u2026 , italic_m, and a finite number, n\ud835\udc5bnitalic_n, of target agents (i.e.\u00a0target states), j=1,2,\u2026,n\ud835\udc5712\u2026\ud835\udc5bj=1,2,\\dots,nitalic_j = 1 , 2 , \u2026 , italic_n.\nSuppose each source agent, i\ud835\udc56iitalic_i, has capacity or mass, u~i>0subscript~\ud835\udc62\ud835\udc560\\tilde{u}_{i}>0over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT > 0, and each target agent, j\ud835\udc57jitalic_j, desires a capacity or mass, v~j>0subscript~\ud835\udc63\ud835\udc570\\tilde{v}_{j}>0over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT > 0.\nWe wish to transport the masses of the source agents to the target agents.\nFor the time being, we impose mass balance (conservation), i.e. that is, \ud835\udfcf\u2032\u2062u~=\ud835\udfcf\u2032\u2062v~superscript1\u2032~\ud835\udc62superscript1\u2032~\ud835\udc63{\\bm{1}}^{\\prime}\\tilde{u}={\\bm{1}}^{\\prime}\\tilde{v}bold_1 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT over~ start_ARG italic_u end_ARG = bold_1 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT over~ start_ARG italic_v end_ARG where \ud835\udfcf1{\\bm{1}}bold_1 is a vector of ones, of appropriate length. Let\nti\u2062j\u22650subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}\\geq 0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u2265 0\nbe the mass or capacity that source agent, i\ud835\udc56iitalic_i, transports to target agent, j\ud835\udc57jitalic_j.\nWe will refer to the m\u00d7n\ud835\udc5a\ud835\udc5bm\\times nitalic_m \u00d7 italic_n matrix, T={ti\u2062j}\ud835\udc47subscript\ud835\udc61\ud835\udc56\ud835\udc57T=\\left\\{t_{ij}\\right\\}italic_T = { italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT }, as the transport plan.\nAs a consequence of the capacity constraints of the source and target agents, we must have or, T\u2062\ud835\udfcf=u~\ud835\udc471~\ud835\udc62T{\\bm{1}}=\\tilde{u}italic_T bold_1 = over~ start_ARG italic_u end_ARG, and or, T\u2032\u2062\ud835\udfcf=v~superscript\ud835\udc47\u20321~\ud835\udc63T^{\\prime}{\\bm{1}}=\\tilde{v}italic_T start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT bold_1 = over~ start_ARG italic_v end_ARG.\nNote that constraints (1), (2) and (3) imply that Next, suppose that a specific source agent, i\ud835\udc56iitalic_i, never transports to a specific target agent, j\ud835\udc57jitalic_j, so that\nti\u2062j=0subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0.\nWe let \ud835\udcb5\ud835\udcb5\\mathcal{Z}caligraphic_Z be the set of these prior non-transporting index pairs: The set of allowable transport plans is given by We assume that for every i\ud835\udc56iitalic_i, that there is at least one (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z\nand for every j\ud835\udc57jitalic_j, there is also at least one (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z;\ni.e.\u00a0if\nti\u2062j>0subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}>0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z\nthen, T\ud835\udc47Titalic_T has no zero-rows or zero-columns.\nIf \ud835\udcb5\ud835\udcb5\\mathcal{Z}caligraphic_Z is empty, i.e.\u00a0if every source agent can transport to every target agent, then the marginal constraints (2) and (3) are feasible (i.e. there is at least one solution in \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T, for example,\nT\u2261u~\u2062v~\u2032/\ud835\udfcf\u2032\u2062v~\ud835\udc47~\ud835\udc62superscript~\ud835\udc63\u2032superscript1\u2032~\ud835\udc63T\\equiv\\tilde{u}\\tilde{v}^{\\prime}/{\\bm{1}}^{\\prime}\\tilde{v}italic_T \u2261 over~ start_ARG italic_u end_ARG over~ start_ARG italic_v end_ARG start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / bold_1 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT over~ start_ARG italic_v end_ARG).\nHowever, if \ud835\udcb5\ud835\udcb5\\mathcal{Z}caligraphic_Z is non-empty, then (2) and (3) may not be feasible (i.e.\u00a0there may not be any solution in \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic_T). An example is given by m=n=2\ud835\udc5a\ud835\udc5b2m=n=2italic_m = italic_n = 2 and \ud835\udcb5\u2261{(2,2)}\ud835\udcb522\\mathcal{Z}\\equiv\\{(2,2)\\}caligraphic_Z \u2261 { ( 2 , 2 ) }: Suppose that there is a cost, ci\u2062j\u2208\u211dsubscript\ud835\udc50\ud835\udc56\ud835\udc57\u211dc_{ij}\\in\\mathbb{R}italic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u2208 blackboard_R, of moving a unit mass from source, i\ud835\udc56iitalic_i, to\ntarget, j\ud835\udc57jitalic_j.\nThen, the total cost of transport is\n\u2211(i,j)\u2209\ud835\udcb5ci\u2062j\u2062ti\u2062jsubscript\ud835\udc56\ud835\udc57\ud835\udcb5subscript\ud835\udc50\ud835\udc56\ud835\udc57subscript\ud835\udc61\ud835\udc56\ud835\udc57\\sum_{(i,j)\\notin\\mathcal{Z}}c_{ij}t_{ij}\u2211 start_POSTSUBSCRIPT ( italic_i , italic_j ) \u2209 caligraphic_Z end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT\nThis gives rise to the constrained OT problem: Next, suppose that it is also desirable for T\ud835\udc47Titalic_T to be close to some ideal (desired) transport plan, T~\u2208\ud835\udcaf~\ud835\udc47\ud835\udcaf\\tilde{T}\\in\\mathcal{T}over~ start_ARG italic_T end_ARG \u2208 caligraphic_T (8) with\nt~i\u2062j>0subscript~\ud835\udc61\ud835\udc56\ud835\udc570\\tilde{t}_{ij}>0over~ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z.\nWe therefore modify\nthe cost to where \u03b30>0subscript\ud835\udefe00\\gamma_{0}>0italic_\u03b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0 is a pre-assigned regularization constant, and the Kullback-Leibler (K\u2062L\ud835\udc3e\ud835\udc3fKLitalic_K italic_L) divergence [9] of T\ud835\udc47Titalic_T from T~~\ud835\udc47\\tilde{T}over~ start_ARG italic_T end_ARG is defined as where, for any two scalar, t\u22650\ud835\udc610t\\geq 0italic_t \u2265 0 and t~>0~\ud835\udc610\\tilde{t}>0over~ start_ARG italic_t end_ARG > 0, we define One may readily show that, for all t\u22650\ud835\udc610t\\geq 0italic_t \u2265 0 and t~>0~\ud835\udc610\\tilde{t}>0over~ start_ARG italic_t end_ARG > 0, k\u2062l\u2062(t|t~)\u22650\ud835\udc58\ud835\udc59conditional\ud835\udc61~\ud835\udc610kl(t|\\tilde{t})\\geq 0italic_k italic_l ( italic_t | over~ start_ARG italic_t end_ARG ) \u2265 0; also k\u2062l\u2062(t|t~)=0\ud835\udc58\ud835\udc59conditional\ud835\udc61~\ud835\udc610kl(t|\\tilde{t})=0italic_k italic_l ( italic_t | over~ start_ARG italic_t end_ARG ) = 0 iff t=t~\ud835\udc61~\ud835\udc61t=\\tilde{t}italic_t = over~ start_ARG italic_t end_ARG. Hence, for all T\u2208\ud835\udcaf\ud835\udc47\ud835\udcafT\\in\\mathcal{T}italic_T \u2208 caligraphic_T, K\u2062L\u2062(T|T~)\u22650\ud835\udc3e\ud835\udc3fconditional\ud835\udc47~\ud835\udc470KL(T|\\tilde{T})\\geq 0italic_K italic_L ( italic_T | over~ start_ARG italic_T end_ARG ) \u2265 0 and K\u2062L\u2062(T|T~)=0\ud835\udc3e\ud835\udc3fconditional\ud835\udc47~\ud835\udc470KL(T|\\tilde{T})=0italic_K italic_L ( italic_T | over~ start_ARG italic_T end_ARG ) = 0 iff T=T~\ud835\udc47~\ud835\udc47T=\\tilde{T}italic_T = over~ start_ARG italic_T end_ARG. Note again that original optimization problem (9) is a linear programming problem and may be computationally burdensome to solve. So, a common solution approach\nis approximately to solve the original problem (9) by minimizing the regularized cost in (11) with \u03b30subscript\ud835\udefe0\\gamma_{0}italic_\u03b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT small but postive.\nThis problem can be solved more efficiently than the original problem. Next, note that\nci\u2062j\u2062ti\u2062j=\u03b30\u2062ti\u2062j\u2062log\u2061(1exp\u2061(\u2212ci\u2062j/\u03b30))subscript\ud835\udc50\ud835\udc56\ud835\udc57subscript\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udefe0subscript\ud835\udc61\ud835\udc56\ud835\udc571subscript\ud835\udc50\ud835\udc56\ud835\udc57subscript\ud835\udefe0c_{ij}t_{ij}=\\gamma_{0}t_{ij}\\log\\left(\\frac{1}{\\exp(-c_{ij}/\\gamma_{0})}\\right)italic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_\u03b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT roman_log ( divide start_ARG 1 end_ARG start_ARG roman_exp ( - italic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT / italic_\u03b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_ARG )\nand define Then, whenever ti\u2062j\u22600subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}\\neq 0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u2260 0, (16) also holds for ti\u2062j=0subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 , (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z.\nHence, cost (11) can be expressed as\n\u03b30\u2062K\u2062L\u2062(T|K)+\u2211(i,j)\u2209\ud835\udcb5\u03b30\u2062(t~i\u2062j\u2212ki\u2062j)subscript\ud835\udefe0\ud835\udc3e\ud835\udc3fconditional\ud835\udc47\ud835\udc3esubscript\ud835\udc56\ud835\udc57\ud835\udcb5subscript\ud835\udefe0subscript~\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udc58\ud835\udc56\ud835\udc57\\gamma_{0}KL(T|K)+\\sum_{(i,j)\\notin\\mathcal{Z}}\\gamma_{0}(\\tilde{t}_{ij}-k_{ij})italic_\u03b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_K italic_L ( italic_T | italic_K ) + \u2211 start_POSTSUBSCRIPT ( italic_i , italic_j ) \u2209 caligraphic_Z end_POSTSUBSCRIPT italic_\u03b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( over~ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT - italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ).\nTherefore, we consider the new optimization problem: where \ud835\udcb0\u2062(u~,v~)\ud835\udcb0~\ud835\udc62~\ud835\udc63\\mathcal{U}(\\tilde{u},\\tilde{v})caligraphic_U ( over~ start_ARG italic_u end_ARG , over~ start_ARG italic_v end_ARG ) is given by (10).\nWhen the optimization problem (17) is feasible (i.e.\u00a0\ud835\udcb0\u2062(u~,v~)\ud835\udcb0~\ud835\udc62~\ud835\udc63\\mathcal{U}(\\tilde{u},\\tilde{v})caligraphic_U ( over~ start_ARG italic_u end_ARG , over~ start_ARG italic_v end_ARG ) is non-empty),\nits solution can be obtained using the Sinkhorn-Knopp (SK) Algorithm [17]. Sinkhorn-Knopp (SK) Algorithm.\nInitialize\nd2\u2062j\u2062(0)=1subscript\ud835\udc512\ud835\udc5701d_{2j}(0)=1italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( 0 ) = 1. Iterate for l=0,1,\u2026\ud835\udc5901\u2026l=0,1,\\dotsitalic_l = 0 , 1 , \u2026 \u25a1\u25a1{\\hskip 220.50885pt}\\square\u25a1 If (17) is feasible, the sequence, {T\u2062(l)}\ud835\udc47\ud835\udc59\\{T(l)\\}{ italic_T ( italic_l ) } converges to a limit, T\u2217superscript\ud835\udc47T^{*}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT, which\nis the unique minimizer for (17) [16].\nIf ti\u2062j\u2217=0subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc570t^{*}_{ij}=0italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 for some (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z, then either\n{di\u2062i\u2062(l)}subscript\ud835\udc51\ud835\udc56\ud835\udc56\ud835\udc59\\{d_{ii}(l)\\}{ italic_d start_POSTSUBSCRIPT italic_i italic_i end_POSTSUBSCRIPT ( italic_l ) } or {d2\u2062j\u2062(l)}subscript\ud835\udc512\ud835\udc57\ud835\udc59\\{d_{2j}(l)\\}{ italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( italic_l ) } do not converge.\nIf (17) is not feasible,\nthe sequence, {T\u2062(l)}\ud835\udc47\ud835\udc59\\{T(l)\\}{ italic_T ( italic_l ) } has two convergent subsequences with different limits [16]. If \ud835\udcb5\ud835\udcb5\\mathcal{Z}caligraphic_Z is non-empty, it may not be possible to simultaneously satisfy the marginal constraints, (2) and (3).\nIf\u2014as already imposed in (8)\u2014T\ud835\udc47Titalic_T has no enforced rows of zeroes, the row constraints can always be achieved, as explained in Remark 2, below. Therefore, consider the situation in which row constraints (2) are satisfied but\ncolumn constraints (3) are not necessarily satisfied.\nInstead of requiring satisfaction of the column constraints, we add a KL-based penalty term to the cost function, which is a measure of non-compliance with the column constraints, v~~\ud835\udc63\\tilde{v}over~ start_ARG italic_v end_ARG.\nWe therefore consider a new optimization problem given by where K\u2062L\u2062(vT|v~)=\u2211j=1nk\u2062l\u2062(vTj|v~j)\ud835\udc3e\ud835\udc3fconditionalsubscript\ud835\udc63\ud835\udc47~\ud835\udc63superscriptsubscript\ud835\udc571\ud835\udc5b\ud835\udc58\ud835\udc59conditionalsubscript\ud835\udc63subscript\ud835\udc47\ud835\udc57subscript~\ud835\udc63\ud835\udc57KL(v_{T}|\\tilde{v})=\\sum_{j=1}^{n}kl(v_{T_{j}}|\\tilde{v}_{j})italic_K italic_L ( italic_v start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT | over~ start_ARG italic_v end_ARG ) = \u2211 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_k italic_l ( italic_v start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT | over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ),\nvTj\u2261\u2211i=1mti\u2062jsubscript\ud835\udc63subscript\ud835\udc47\ud835\udc57superscriptsubscript\ud835\udc561\ud835\udc5asubscript\ud835\udc61\ud835\udc56\ud835\udc57v_{T_{j}}{\\equiv}\\sum_{i=1}^{m}t_{ij}italic_v start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT \u2261 \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT, \u03b3>0\ud835\udefe0\\gamma>0italic_\u03b3 > 0, For any admissible u~~\ud835\udc62\\tilde{u}over~ start_ARG italic_u end_ARG, one can always obtain a T\ud835\udc47Titalic_T in \ud835\udcb1\u2062(u~)\ud835\udcb1~\ud835\udc62\\mathcal{V}(\\tilde{u})caligraphic_V ( over~ start_ARG italic_u end_ARG ) with ti\u2062j>0subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}>0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z. Simply choose any T\u2208\ud835\udcaf\ud835\udc47\ud835\udcafT\\in\\mathcal{T}italic_T \u2208 caligraphic_T\nwith ti\u2062j>0subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}>0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z, and scale each of its rows to yield a new matrix in \ud835\udcb1\u2062(u~)\ud835\udcb1~\ud835\udc62\\mathcal{V}(\\tilde{u})caligraphic_V ( over~ start_ARG italic_u end_ARG ).\nTherefore, \ud835\udcb1\u2062(u~)\ud835\udcb1~\ud835\udc62\\mathcal{V}(\\tilde{u})caligraphic_V ( over~ start_ARG italic_u end_ARG ) is non-empty, and since we are minimizing a continuous strictly convex function (21) over a compact convex set (22),\na unique minimizer exists. \u25a1\u25a1{\\hskip 220.50885pt}\\square\u25a1 [19] considers a generalization of the problem considered here. To highlight the novelty of our work we make the following comments. It is true that our problem is a special case of the initial general problem considered in [19] by, among other things, specializing to the bivariate (so, bi-marginal) case, and taking ci\u2062j=\u221esubscript\ud835\udc50\ud835\udc56\ud835\udc57c_{ij}=\\inftyitalic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = \u221e for all entries in the transport plan that are to be zero. However,\nour algorithms\u2014which have been designed, among other things, to be relevant in important applications of OT, such as the sharing economy application of our Section\u00a0VII\u2014are not presented in [19]. More substantially, we note the following difference. In order to prove convergence of their algorithm to solve their general problem, it is assumed that all the elements of their cost tensor \ud835\udc02\ud835\udc02\\mathbf{C}bold_C are finite (Assumption C on page 5, left column, of [19]). Under this assumption, our problem is not a special case of the problem solved by the algorithm in [19], because for our problem to be a special case, some of the elements of their cost tensor \ud835\udc02\ud835\udc02\\mathbf{C}bold_C must be infinite. This assumption is used in the proof of Lemma III.8 in [19]. Note also that prior zeros are not imposed on their transport tensor, M\ud835\udc40Mitalic_M (corresponding to our transport matrix, T\ud835\udc47Titalic_T). We now present the main results of the paper. These results yield iterative scaling algorithms that produce a sequence, {T(l}\\{T(l\\}{ italic_T ( italic_l }, converging to the optimal transport plan, T\u2217superscript\ud835\udc47T^{*}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT, for\n(21).\nIn particular, two algorithms are presented. Algorithm 1 is obtained using results in [14]. Algorithm 2 is equivalent to Algorithm I and is presented for comparison to other related algorithms such as the SK Algorithm.\nA third algorithm, the Chizat Algorithm is a related algorithm from the literature that is included to provide context for our contributions. Algorithm 1.\nInitialize\nT\u2062(0)=K,v\u2062(0)=v~formulae-sequence\ud835\udc470\ud835\udc3e\ud835\udc630~\ud835\udc63T(0)=K,v(0)=\\tilde{v}italic_T ( 0 ) = italic_K , italic_v ( 0 ) = over~ start_ARG italic_v end_ARG.\nIterate for l=0,1,\u2026\ud835\udc5901\u2026l=0,1,\\dotsitalic_l = 0 , 1 , \u2026 \u25a1\u25a1{\\hskip 220.50885pt}\\square\u25a1 The following theorem provides the main result of this paper. A proof is provided in Section VI. Consider the sequence, {T\u2062(l),v\u2062(l)}\ud835\udc47\ud835\udc59\ud835\udc63\ud835\udc59\\{T(l),v(l)\\}{ italic_T ( italic_l ) , italic_v ( italic_l ) }, generated by\nAlgorithm 1.\nThis sequence converges to the (unique) limit, (T\u2217,v\u2217)superscript\ud835\udc47superscript\ud835\udc63(T^{*},v^{*})( italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT , italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ),\nand T\u2217superscript\ud835\udc47T^{*}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT is the minimizer for the optimization problem given by (21). Since from (23),\nliml\u2192\u221ec1\u2062i\u2062(l)=1subscript\u2192\ud835\udc59subscript\ud835\udc501\ud835\udc56\ud835\udc591\\lim_{l\\rightarrow\\infty}c_{1i}(l)=1roman_lim start_POSTSUBSCRIPT italic_l \u2192 \u221e end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT ( italic_l ) = 1\nfor all i\ud835\udc56iitalic_i.\nIn Lemma 2 (see Section\u00a0V), it will be shown that ti\u2062j\u2217>0subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc570t^{*}_{ij}>0italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z.\nHence, T\u2217superscript\ud835\udc47T^{*}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT is guaranteed not to contain any row of zeroes, and it follows from (25) that\nliml\u2192\u221ec2\u2062j\u2062(l)=1subscript\u2192\ud835\udc59subscript\ud835\udc502\ud835\udc57\ud835\udc591\\lim_{l\\rightarrow\\infty}c_{2j}(l)=1roman_lim start_POSTSUBSCRIPT italic_l \u2192 \u221e end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( italic_l ) = 1\nfor all j\ud835\udc57jitalic_j.\nFrom (24), we see that and, since T\u2217superscript\ud835\udc47T^{*}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT does not contain any column of zeroes, we must have\nvj\u2217>0subscriptsuperscript\ud835\udc63\ud835\udc570v^{*}_{j}>0italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT > 0,\n\u2200jfor-all\ud835\udc57\\forall j\u2200 italic_j.\nIt now follows, from (27) and (28),\nthat\n\u2211j=1nvj\u2217=\u2211i=1mu~isuperscriptsubscript\ud835\udc571\ud835\udc5bsuperscriptsubscript\ud835\udc63\ud835\udc57superscriptsubscript\ud835\udc561\ud835\udc5asubscript~\ud835\udc62\ud835\udc56\\sum_{j=1}^{n}v_{j}^{*}=\\sum_{i=1}^{m}\\tilde{u}_{i}\u2211 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT = \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT\nand so v\u2217superscript\ud835\udc63v^{*}italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT and u~~\ud835\udc62\\tilde{u}over~ start_ARG italic_u end_ARG are balanced  (i.e. mass-conserving).\nThe above result holds even in the unbalanced (i.e.\u00a0non-mass-conserving) problem,\n\u2211i=1mu~i\u2260\u2211j=1nv~jsuperscriptsubscript\ud835\udc561\ud835\udc5asubscript~\ud835\udc62\ud835\udc56superscriptsubscript\ud835\udc571\ud835\udc5bsubscript~\ud835\udc63\ud835\udc57\\sum_{i=1}^{m}\\tilde{u}_{i}\\neq\\sum_{j=1}^{n}\\tilde{v}_{j}\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2260 \u2211 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT.\nIn this case, application of the SK algorithm\nproduces a\nsequence, {T\u2062(l)}\ud835\udc47\ud835\udc59\\{T(l)\\}{ italic_T ( italic_l ) }, which has two convergent subsequences with different limits [16]. \u25a1\u25a1{\\hskip 220.50885pt}\\square\u25a1 In order to obtain an algorithm for comparison with the SK algorithm, we introduce scaling parameters, d1\u2062i\u2062(l)subscript\ud835\udc511\ud835\udc56\ud835\udc59d_{1i}(l)italic_d start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT ( italic_l ) and d2\u2062j\u2062(l)subscript\ud835\udc512\ud835\udc57\ud835\udc59d_{2j}(l)italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( italic_l ), defined by Then The sequence, {T\u2062(l)}\ud835\udc47\ud835\udc59\\{T(l)\\}{ italic_T ( italic_l ) }, obtained from Algorithm\u00a01, can then also be obtained from the following algorithm. Algorithm 2.\nInitialize\nd2\u2062j\u2062(0)=1.subscript\ud835\udc512\ud835\udc5701d_{2j}(0)=1.italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( 0 ) = 1 .\nIterate for l=0,1,\u2026\ud835\udc5901\u2026l=0,1,\\dotsitalic_l = 0 , 1 , \u2026 \u25a1\u25a1{\\hskip 220.50885pt}\\square\u25a1 Since v~j,vj\u2217>0subscript~\ud835\udc63\ud835\udc57subscriptsuperscript\ud835\udc63\ud835\udc570\\tilde{v}_{j},v^{*}_{j}>0over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT > 0 for all j\ud835\udc57jitalic_j, it follows from (32)\nthat the sequence {d2\u2062j\u2062(l)}subscript\ud835\udc512\ud835\udc57\ud835\udc59\\{d_{2j}(l)\\}{ italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( italic_l ) } has a limit d2\u2062j\u2217subscriptsuperscript\ud835\udc512\ud835\udc57d^{*}_{2j}italic_d start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT which is non-zero\nfor all j\ud835\udc57jitalic_j. Now\n(31) implies that\nthat the sequence {d1\u2062i\u2062(l)}subscript\ud835\udc511\ud835\udc56\ud835\udc59\\{d_{1i}(l)\\}{ italic_d start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT ( italic_l ) } has a limit d1\u2062i\u2217subscriptsuperscript\ud835\udc511\ud835\udc56d^{*}_{1i}italic_d start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT\nfor all i\ud835\udc56iitalic_i.\nMoreover (33) and (34) show that these limits satisfy and (35) results in \u25a1\u25a1{\\hskip 220.50885pt}\\square\u25a1 If one considers the limit, as \u03b3\u2192\u221e\u2192\ud835\udefe\\gamma\\rightarrow\\inftyitalic_\u03b3 \u2192 \u221e, in Algorithm\u00a02, one obtains the SK algorithm [17], whose sequence, {T\u2062(l)}\ud835\udc47\ud835\udc59\\{T(l)\\}{ italic_T ( italic_l ) },\nconverges to the minimizer for optimization problem (17),\nprovided this problem is feasible. \u25a1\u25a1{\\hskip 220.50885pt}\\square\u25a1 Before proceeding we note that [18] considers a problem which is related (but different from) to the problem considered here. Namely, to solve where\nuTi=\u2211j=1nti\u2062jsubscript\ud835\udc62subscript\ud835\udc47\ud835\udc56superscriptsubscript\ud835\udc571\ud835\udc5bsubscript\ud835\udc61\ud835\udc56\ud835\udc57u_{T_{i}}=\\sum_{j=1}^{n}t_{ij}italic_u start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT = \u2211 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT for all i\ud835\udc56iitalic_i,\nki\u2062j=exp\u2061(\u2212ci\u2062j/\u03b30)\u2062\u00a0for all\u00a0\u2062(i,j)subscript\ud835\udc58\ud835\udc56\ud835\udc57subscript\ud835\udc50\ud835\udc56\ud835\udc57subscript\ud835\udefe0\u00a0for all\u00a0\ud835\udc56\ud835\udc57k_{ij}=\\exp(-c_{ij}/\\gamma_{0})\\text{ for all }(i,j)italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = roman_exp ( - italic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT / italic_\u03b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) for all ( italic_i , italic_j )\nand \u03b31,\u03b32>0subscript\ud835\udefe1subscript\ud835\udefe20\\gamma_{1},\\gamma_{2}>0italic_\u03b3 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u03b3 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > 0.\nIn [18], neither marginal constraint is enforced and\nnone of the elements of T\ud835\udc47Titalic_T are constrained to be zero.\nThis is in contrast to the current paper, in which the source marginal is constrained to be u~~\ud835\udc62\\tilde{u}over~ start_ARG italic_u end_ARG, and some of the elements of T\ud835\udc47Titalic_T\nare enforced to be zero, specifically\nti\u2062j=0subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 for (i,j)\u2208\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\in\\mathcal{Z}( italic_i , italic_j ) \u2208 caligraphic_Z.\n[18] shows that the sequence, {T\u2062(l)}\ud835\udc47\ud835\udc59\\{T(l)\\}{ italic_T ( italic_l ) }, generated by the following algorithm converges to a limit which is the minimizer for optimization\nproblem (38). Chizat Algorithm.\nInitialize\nd2\u2062j\u2062(0)=1.subscript\ud835\udc512\ud835\udc5701d_{2j}(0)=1.italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( 0 ) = 1 .\nIterate for l=0,1,\u2026\ud835\udc5901\u2026l=0,1,\\dotsitalic_l = 0 , 1 , \u2026 \u25a1\u25a1{\\hskip 220.50885pt}\\square\u25a1 Remarkably, if one considers the limit as \u03b31\u2192\u221e\u2192subscript\ud835\udefe1\\gamma_{1}\\rightarrow\\inftyitalic_\u03b3 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2192 \u221e,\nthen the Chizat algorithm reduces to our Algorithm 2 in the case where there are no constraints on T\ud835\udc47Titalic_T and all the elements\nof T~~\ud835\udc47\\tilde{T}over~ start_ARG italic_T end_ARG equal one. If\nT\u2217superscript\ud835\udc47T^{*}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT is a minimizer for (21), then ti\u2062j\u2217>0subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc570t^{*}_{ij}>0italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z. Suppose that T\u2217superscript\ud835\udc47T^{*}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT is a minimizer for (21).\nFrom Remark 2, there is a T^\u2208\ud835\udcb1\u2062(u~)^\ud835\udc47\ud835\udcb1~\ud835\udc62\\hat{T}\\in\\mathcal{V}(\\tilde{u})over^ start_ARG italic_T end_ARG \u2208 caligraphic_V ( over~ start_ARG italic_u end_ARG )\nwith t^i\u2062j>0subscript^\ud835\udc61\ud835\udc56\ud835\udc570\\hat{t}_{ij}>0over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z.\nSince \ud835\udcb1\u2062(u~)\ud835\udcb1~\ud835\udc62\\mathcal{V}(\\tilde{u})caligraphic_V ( over~ start_ARG italic_u end_ARG ) is convex, (1\u2212\u03bb)\u2062T\u2217+\u03bb\u2062T^1\ud835\udf06superscript\ud835\udc47\ud835\udf06^\ud835\udc47(1-\\lambda)T^{*}+\\lambda\\hat{T}( 1 - italic_\u03bb ) italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT + italic_\u03bb over^ start_ARG italic_T end_ARG is in \ud835\udcb1\u2062(u~)\ud835\udcb1~\ud835\udc62\\mathcal{V}(\\tilde{u})caligraphic_V ( over~ start_ARG italic_u end_ARG ) for all \u03bb\u2208[0,1]\ud835\udf0601\\lambda\\in[0,1]italic_\u03bb \u2208 [ 0 , 1 ].\nAlso,\nthere are bounds, \u03b21subscript\ud835\udefd1\\beta_{1}italic_\u03b2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \u03b22subscript\ud835\udefd2\\beta_{2}italic_\u03b2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, such that, if ti\u2062j\u2217>0subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc570t^{*}_{ij}>0italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 then for any (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z,\n0<\u03b21\u2264ti\u2062j\u2264\u03b220subscript\ud835\udefd1subscript\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udefd20<\\beta_{1}\\leq t_{ij}\\leq\\beta_{2}0 < italic_\u03b2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2264 italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u2264 italic_\u03b2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT\nfor T=(1\u2212\u03bb)\u2062T\u2217+\u03bb\u2062T^\u2062\u00a0and\u00a0\u2062\u03bb\u2208[0,1]\ud835\udc471\ud835\udf06superscript\ud835\udc47\ud835\udf06^\ud835\udc47\u00a0and\u00a0\ud835\udf0601T=(1-\\lambda)T^{*}+\\lambda\\hat{T}\\text{ and }\\lambda\\in[0,1]italic_T = ( 1 - italic_\u03bb ) italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT + italic_\u03bb over^ start_ARG italic_T end_ARG and italic_\u03bb \u2208 [ 0 , 1 ].\nThe function to be minimized in (21) can be expressed as Consider any \u03bb\u2208(0,1]\ud835\udf0601\\lambda\\in(0,1]italic_\u03bb \u2208 ( 0 , 1 ] and T=(1\u2212\u03bb)\u2062T\u2217+\u03bb\u2062T^\ud835\udc471\ud835\udf06superscript\ud835\udc47\ud835\udf06^\ud835\udc47T=(1-\\lambda)T^{*}+\\lambda\\hat{T}italic_T = ( 1 - italic_\u03bb ) italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT + italic_\u03bb over^ start_ARG italic_T end_ARG.\nBy the mean value theorem, \u2203\\exists\u2203 \u03bb\u00af\u2208(0,\u03bb)\u00af\ud835\udf060\ud835\udf06\\underline{\\lambda}\\in(0,\\lambda)under\u00af start_ARG italic_\u03bb end_ARG \u2208 ( 0 , italic_\u03bb ) such that where T\u00af=(1\u2212\u03bb\u00af)\u2062T\u2217+\u03bb\u00af\u2062T^\u00af\ud835\udc471\u00af\ud835\udf06superscript\ud835\udc47\u00af\ud835\udf06^\ud835\udc47\\underline{T}=(1-\\underline{\\lambda})T^{*}+\\underline{\\lambda}\\hat{T}under\u00af start_ARG italic_T end_ARG = ( 1 - under\u00af start_ARG italic_\u03bb end_ARG ) italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT + under\u00af start_ARG italic_\u03bb end_ARG over^ start_ARG italic_T end_ARG and If ti\u2062j\u2217>0subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc570t^{*}_{ij}>0italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 then, for all \u03bb\u2208(0,1]\ud835\udf0601\\lambda\\in(0,1]italic_\u03bb \u2208 ( 0 , 1 ], we have 0<\u03b21\u2264t\u00afi\u2062j\u2264\u03b220subscript\ud835\udefd1subscript\u00af\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udefd20<\\beta_{1}\\leq\\underline{t}_{ij}\\leq\\beta_{2}0 < italic_\u03b2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2264 under\u00af start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u2264 italic_\u03b2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT,\nand 0<\u03b21\u2264\u2211l=1mt\u00afl\u2062j\u2264\u03b230subscript\ud835\udefd1superscriptsubscript\ud835\udc591\ud835\udc5asubscript\u00af\ud835\udc61\ud835\udc59\ud835\udc57subscript\ud835\udefd30<\\beta_{1}\\leq\\sum_{l=1}^{m}\\underline{t}_{lj}\\leq\\beta_{3}0 < italic_\u03b2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2264 \u2211 start_POSTSUBSCRIPT italic_l = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT under\u00af start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_l italic_j end_POSTSUBSCRIPT \u2264 italic_\u03b2 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT for some \u03b23subscript\ud835\udefd3\\beta_{3}italic_\u03b2 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT.\nHence\n\u2202f\u2202ti\u2062j\u2062(T\u00af)\u2062(t^i\u2062j\u2212ti\u2062j\u2217)\u2264\u03b3i\u2062j\ud835\udc53subscript\ud835\udc61\ud835\udc56\ud835\udc57\u00af\ud835\udc47subscript^\ud835\udc61\ud835\udc56\ud835\udc57subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udefe\ud835\udc56\ud835\udc57\\frac{\\partial f}{\\partial t_{ij}}(\\underline{T})(\\hat{t}_{ij}-t^{*}_{ij})\\leq%\n\\gamma_{ij}divide start_ARG \u2202 italic_f end_ARG start_ARG \u2202 italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ( under\u00af start_ARG italic_T end_ARG ) ( over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT - italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) \u2264 italic_\u03b3 start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT\nfor some \u03b3i\u2062jsubscript\ud835\udefe\ud835\udc56\ud835\udc57\\gamma_{ij}italic_\u03b3 start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT.\nSuppose that ti\u2062j\u2217=0subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc570t^{*}_{ij}=0italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 for some (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z. Then lim\u03bb\u21920t\u00afi\u2062j=ti\u2062j\u2217=0subscript\u2192\ud835\udf060subscript\u00af\ud835\udc61\ud835\udc56\ud835\udc57subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc570\\lim_{\\lambda\\rightarrow 0}\\underline{t}_{ij}=t^{*}_{ij}=0roman_lim start_POSTSUBSCRIPT italic_\u03bb \u2192 0 end_POSTSUBSCRIPT under\u00af start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0; and\nlim\u03bb\u21920\u2202f\u2202ti\u2062j\u2062(T\u00af)\u2062(t^i\u2062j\u2212ti\u2062j\u2217)=\u2212\u221esubscript\u2192\ud835\udf060\ud835\udc53subscript\ud835\udc61\ud835\udc56\ud835\udc57\u00af\ud835\udc47subscript^\ud835\udc61\ud835\udc56\ud835\udc57subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57\\lim_{\\lambda\\rightarrow 0}\\frac{\\partial f}{\\partial t_{ij}}(\\underline{T})(%\n\\hat{t}_{ij}-t^{*}_{ij})=-\\inftyroman_lim start_POSTSUBSCRIPT italic_\u03bb \u2192 0 end_POSTSUBSCRIPT divide start_ARG \u2202 italic_f end_ARG start_ARG \u2202 italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ( under\u00af start_ARG italic_T end_ARG ) ( over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT - italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) = - \u221e.\nThis implies that, for \u03bb>0\ud835\udf060\\lambda>0italic_\u03bb > 0 sufficiently small,\n\u2211(i,j)\u2209\ud835\udcb5\u2202f\u2202ti\u2062j\u2062(T\u00af)\u2062(t^i\u2062j\u2212ti\u2062j\u2217)<0subscript\ud835\udc56\ud835\udc57\ud835\udcb5\ud835\udc53subscript\ud835\udc61\ud835\udc56\ud835\udc57\u00af\ud835\udc47subscript^\ud835\udc61\ud835\udc56\ud835\udc57subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc570\\sum_{(i,j)\\notin\\mathcal{Z}}\\frac{\\partial f}{\\partial t_{ij}}(\\underline{T})%\n(\\hat{t}_{ij}-t^{*}_{ij})<0\u2211 start_POSTSUBSCRIPT ( italic_i , italic_j ) \u2209 caligraphic_Z end_POSTSUBSCRIPT divide start_ARG \u2202 italic_f end_ARG start_ARG \u2202 italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ( under\u00af start_ARG italic_T end_ARG ) ( over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT - italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) < 0\nwhich along with (42) yields the contradiction,\nf\u2062(T)<f\u2062(T\u2217).\ud835\udc53\ud835\udc47\ud835\udc53superscript\ud835\udc47f(T)<f(T^{*}).italic_f ( italic_T ) < italic_f ( italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) .  The following result can be obtained from the discussion of Algorithm 2; see Remark 5.\nHowever we wish to provide a proof which is independent of any algorithm. A matrix, T\u2217superscript\ud835\udc47T^{*}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT, solves the OT problem given by (21) iff\n\u2203\\exists\u2203 positive scalars, d11,\u2026,d1\u2062msubscript\ud835\udc5111\u2026subscript\ud835\udc511\ud835\udc5ad_{11},\\dots,d_{1m}italic_d start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , \u2026 , italic_d start_POSTSUBSCRIPT 1 italic_m end_POSTSUBSCRIPT and d21,\u2026,d2\u2062nsubscript\ud835\udc5121\u2026subscript\ud835\udc512\ud835\udc5bd_{21},\\dots,d_{2n}italic_d start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT , \u2026 , italic_d start_POSTSUBSCRIPT 2 italic_n end_POSTSUBSCRIPT, such that,\nfor all (i,j)\ud835\udc56\ud835\udc57(i,j)( italic_i , italic_j )\n\n(37) and (36) hold. If\n(i,j)\u2208\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\in\\mathcal{Z}( italic_i , italic_j ) \u2208 caligraphic_Z, we have ti\u2062j\u2217=ki\u2062j=0subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udc58\ud835\udc56\ud835\udc570t^{*}_{ij}=k_{ij}=0italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 and the expression for ti\u2062j\u2217subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57t^{*}_{ij}italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT in (37) holds.\nThe Lagrangian associated with this optimization problem is For (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z and ti\u2062j\u22600subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}\\neq 0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u2260 0, From Lemma 1, we know that ti\u2062j\u2217>0subscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc570t^{*}_{ij}>0italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z.\nHence T\u2217superscript\ud835\udc47T^{*}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT is a minimizer iff \u2203\\exists\u2203 scalars, \u03b11,\u2026,\u03b1msubscript\ud835\udefc1\u2026subscript\ud835\udefc\ud835\udc5a\\alpha_{1},\\dots,\\alpha_{m}italic_\u03b1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_\u03b1 start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT, such that\n\u2202L\u2202ti\u2062j\u2062(T\u2217,\u03b1)=0\ud835\udc3fsubscript\ud835\udc61\ud835\udc56\ud835\udc57superscript\ud835\udc47\ud835\udefc0\\frac{\\partial L}{\\partial t_{ij}}(T^{*},\\alpha)=0divide start_ARG \u2202 italic_L end_ARG start_ARG \u2202 italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ( italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT , italic_\u03b1 ) = 0 for all (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z, that is,\nlog\u2061(ti\u2062j\u2217ki\u2062j)=\u2212\u03b1i\u2212\u03b2jsubscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udc58\ud835\udc56\ud835\udc57subscript\ud835\udefc\ud835\udc56subscript\ud835\udefd\ud835\udc57\\log\\left(\\frac{t^{*}_{ij}}{k_{ij}}\\right)=-\\alpha_{i}-\\beta_{j}roman_log ( divide start_ARG italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG start_ARG italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ) = - italic_\u03b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_\u03b2 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, where Hence where\nd1\u2062i\u2261exp\u2061(\u2212\u03b1i)subscript\ud835\udc511\ud835\udc56subscript\ud835\udefc\ud835\udc56d_{1i}\\equiv\\exp(-\\alpha_{i})italic_d start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT \u2261 roman_exp ( - italic_\u03b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and\nd2\u2062j\u2261exp\u2061(\u2212\u03b2j)subscript\ud835\udc512\ud835\udc57subscript\ud835\udefd\ud835\udc57d_{2j}\\equiv\\exp(-\\beta_{j})italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT \u2261 roman_exp ( - italic_\u03b2 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ).\nUsing the row constraints, we have\nu~i=\u2211j=1mti\u2062j\u2217=\u2211j=1md1\u2062i\u2062ki\u2062j\u2062d2\u2062jsubscript~\ud835\udc62\ud835\udc56superscriptsubscript\ud835\udc571\ud835\udc5asubscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57superscriptsubscript\ud835\udc571\ud835\udc5asubscript\ud835\udc511\ud835\udc56subscript\ud835\udc58\ud835\udc56\ud835\udc57subscript\ud835\udc512\ud835\udc57\\tilde{u}_{i}=\\sum_{j=1}^{m}t^{*}_{ij}=\\sum_{j=1}^{m}d_{1i}k_{ij}d_{2j}over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = \u2211 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = \u2211 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT.\nHence,\nd1\u2062i=u~i\u2211j=1mki\u2062j\u2062d2\u2062jsubscript\ud835\udc511\ud835\udc56subscript~\ud835\udc62\ud835\udc56superscriptsubscript\ud835\udc571\ud835\udc5asubscript\ud835\udc58\ud835\udc56\ud835\udc57subscript\ud835\udc512\ud835\udc57d_{1i}=\\frac{\\tilde{u}_{i}}{\\sum_{j=1}^{m}k_{ij}d_{2j}}italic_d start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT = divide start_ARG over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG \u2211 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT end_ARG.\nIt follows, from (44) and (45), that that is,\nd2\u2062j1+\u03b3\u03b3\u2062\u2211i=1md1\u2062i\u2062ki\u2062j=v~jsuperscriptsubscript\ud835\udc512\ud835\udc571\ud835\udefe\ud835\udefesuperscriptsubscript\ud835\udc561\ud835\udc5asubscript\ud835\udc511\ud835\udc56subscript\ud835\udc58\ud835\udc56\ud835\udc57subscript~\ud835\udc63\ud835\udc57d_{2j}^{\\frac{1+\\gamma}{\\gamma}}\\sum_{i=1}^{m}d_{1i}k_{ij}=\\tilde{v}_{j}italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT divide start_ARG 1 + italic_\u03b3 end_ARG start_ARG italic_\u03b3 end_ARG end_POSTSUPERSCRIPT \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT,\nor  To prove Theorem 1, we need a result from [14].\nLet and, for a fixed x~\u2208\ud835\udcb3~\ud835\udc65\ud835\udcb3\\tilde{x}\\in\\mathcal{X}over~ start_ARG italic_x end_ARG \u2208 caligraphic_X, consider the strictly convex function, f:\ud835\udcb3\u00af\u2192\u211d:\ud835\udc53\u2192\u00af\ud835\udcb3\u211df:\\bar{\\mathcal{X}}\\rightarrow\\mathbb{R}italic_f : over\u00af start_ARG caligraphic_X end_ARG \u2192 blackboard_R, given by where \ud835\udcb3\u00af\u00af\ud835\udcb3\\overline{\\mathcal{X}}over\u00af start_ARG caligraphic_X end_ARG is the closure of \ud835\udcb3\ud835\udcb3\\mathcal{X}caligraphic_X,\nthat is Also, let\nAi\u2208\u211dmi\u00d7qsubscript\ud835\udc34\ud835\udc56superscript\u211dsubscript\ud835\udc5a\ud835\udc56\ud835\udc5eA_{i}\\in\\mathbb{R}^{m_{i}\\times q}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00d7 italic_q end_POSTSUPERSCRIPT and bi\u2208\u211dmisubscript\ud835\udc4f\ud835\udc56superscript\u211dsubscript\ud835\udc5a\ud835\udc56b_{i}\\in\\mathbb{R}^{m_{i}}italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, for i=1,2,\u2026,N\ud835\udc5612\u2026\ud835\udc41i=1,2,\\dots,Nitalic_i = 1 , 2 , \u2026 , italic_N, for some positive integers, N\ud835\udc41Nitalic_N and misubscript\ud835\udc5a\ud835\udc56m_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and consider the following optimization problem: Let \ud835\udc9eisubscript\ud835\udc9e\ud835\udc56\\mathcal{C}_{i}caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be the closed convex set, {x\u2208\u211dq:Ai\u2062x=bi}conditional-set\ud835\udc65superscript\u211d\ud835\udc5esubscript\ud835\udc34\ud835\udc56\ud835\udc65subscript\ud835\udc4f\ud835\udc56\\{x\\in\\mathbb{R}^{q}:A_{i}x=b_{i}\\}{ italic_x \u2208 blackboard_R start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT : italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x = italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT }, and assume that\n\ud835\udc9e\u2261\u22c2i=1N\ud835\udc9ei\ud835\udc9esuperscriptsubscript\ud835\udc561\ud835\udc41subscript\ud835\udc9e\ud835\udc56\\mathcal{C}\\equiv\\bigcap_{i=1}^{N}\\mathcal{C}_{i}caligraphic_C \u2261 \u22c2 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is non-empty.\nWe also require the following assumption. For each\ni=1,2,\u2026,N\ud835\udc5612\u2026\ud835\udc41i=1,2,\\dots,Nitalic_i = 1 , 2 , \u2026 , italic_N and x\u2208\ud835\udcb3\ud835\udc65\ud835\udcb3x\\in\\mathcal{X}italic_x \u2208 caligraphic_X, \u2203\\exists\u2203 y\u2217\u2208\ud835\udcb3\u2229\ud835\udc9eisuperscript\ud835\udc66\ud835\udcb3subscript\ud835\udc9e\ud835\udc56y^{*}\\in\\mathcal{X}\\cap\\mathcal{C}_{i}italic_y start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT \u2208 caligraphic_X \u2229 caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT such that Note that, in this assumption, optimization is over \ud835\udcb3\u2229\ud835\udc9ei\ud835\udcb3subscript\ud835\udc9e\ud835\udc56\\mathcal{X}\\cap\\mathcal{C}_{i}caligraphic_X \u2229 caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and not over \ud835\udcb3\u00af\u2229\ud835\udc9ei\u00af\ud835\udcb3subscript\ud835\udc9e\ud835\udc56\\overline{\\mathcal{X}}\\cap\\mathcal{C}_{i}over\u00af start_ARG caligraphic_X end_ARG \u2229 caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.\nWe will denote the point y\u2217superscript\ud835\udc66y^{*}italic_y start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT above by Pi\u2062(x)subscript\ud835\udc43\ud835\udc56\ud835\udc65P_{i}(x)italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) and refer to it as the K\u2062L\ud835\udc3e\ud835\udc3fKLitalic_K italic_L-projection of x\ud835\udc65xitalic_x onto \ud835\udc9eisubscript\ud835\udc9e\ud835\udc56\\mathcal{C}_{i}caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Let p\ud835\udc5dpitalic_p\nbe a permutation on {1,2,\u2026,N}12\u2026\ud835\udc41\\{1,2,\\dots,N\\}{ 1 , 2 , \u2026 , italic_N }, that is where pksuperscript\ud835\udc5d\ud835\udc58p^{k}italic_p start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT is the application of p\ud835\udc5dpitalic_p, k\ud835\udc58kitalic_k times. The following result may be gleaned from [14]. Suppose \ud835\udc9e\u2229\ud835\udcb3\u00af\ud835\udc9e\u00af\ud835\udcb3\\mathcal{C}\\cap\\overline{\\mathcal{X}}caligraphic_C \u2229 over\u00af start_ARG caligraphic_X end_ARG is non-empty, that Assumption 1 holds, and where il+1=p\u2062(il)subscript\ud835\udc56\ud835\udc591\ud835\udc5dsubscript\ud835\udc56\ud835\udc59i_{l+1}=p(i_{l})italic_i start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT = italic_p ( italic_i start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ).\nThen,\nliml\u2192\u221ex\u2062(l)=x\u2217\u2208\ud835\udc9e\u2229\ud835\udcb3\u00afsubscript\u2192\ud835\udc59\ud835\udc65\ud835\udc59superscript\ud835\udc65\ud835\udc9e\u00af\ud835\udcb3\\lim_{l\\rightarrow\\infty}x(l)=x^{*}\\in{\\mathcal{C}}\\cap\\overline{\\mathcal{X}}roman_lim start_POSTSUBSCRIPT italic_l \u2192 \u221e end_POSTSUBSCRIPT italic_x ( italic_l ) = italic_x start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT \u2208 caligraphic_C \u2229 over\u00af start_ARG caligraphic_X end_ARG.\nMoreover, if where \u2032 denotes transpose,\nthen The algorithm in Theorem\u00a02 initially chooses some point, x\u2062(0)\u2208\ud835\udcb3\ud835\udc650\ud835\udcb3x(0)\\in\\mathcal{X}italic_x ( 0 ) \u2208 caligraphic_X.\nIt then cycles indefinitely through each index, i\ud835\udc56iitalic_i, and projects onto \ud835\udc9eisubscript\ud835\udc9e\ud835\udc56\\mathcal{C}_{i}caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.\nIt can be viewed as an alternating projection algorithm.\nThe resulting sequence, {x\u2062(l)}l=0\u221esuperscriptsubscript\ud835\udc65\ud835\udc59\ud835\udc590\\{x(l)\\}_{l=0}^{\\infty}{ italic_x ( italic_l ) } start_POSTSUBSCRIPT italic_l = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u221e end_POSTSUPERSCRIPT, converges to a point which is common to all of the sets, \ud835\udc9eisubscript\ud835\udc9e\ud835\udc56\\mathcal{C}_{i}caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT\nand \ud835\udcb3\u00af\u00af\ud835\udcb3\\overline{\\mathcal{X}}over\u00af start_ARG caligraphic_X end_ARG.\nIn addition, if \u2207f\u2062(x\u2062(0))\u2207\ud835\udc53\ud835\udc650\\nabla f(x(0))\u2207 italic_f ( italic_x ( 0 ) ) satisfies (50), then x\u2217superscript\ud835\udc65x^{*}italic_x start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT is a minimizer for optimization problem (47).\nThis algorithm is very useful when one can readily solve the optimization problems in (48). The optimization problem of this paper (21) can be rewritten as\nmin(T,v)\u2208\ud835\udcaf\u2062\ud835\udcb1\u00af\u2061J\u2062(T,v)subscript\ud835\udc47\ud835\udc63\u00af\ud835\udcaf\ud835\udcb1\ud835\udc3d\ud835\udc47\ud835\udc63\\min_{(T,v)\\in\\overline{\\mathcal{TV}}}J(T,v)roman_min start_POSTSUBSCRIPT ( italic_T , italic_v ) \u2208 over\u00af start_ARG caligraphic_T caligraphic_V end_ARG end_POSTSUBSCRIPT italic_J ( italic_T , italic_v ),\nsubject to where \u03b3>0\ud835\udefe0\\gamma>0italic_\u03b3 > 0 and Let q=nT+n\ud835\udc5esubscript\ud835\udc5b\ud835\udc47\ud835\udc5bq=n_{T}+nitalic_q = italic_n start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT + italic_n, where\nnTsubscript\ud835\udc5b\ud835\udc47n_{T}italic_n start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT is the number of index pairs (i,j)\ud835\udc56\ud835\udc57(i,j)( italic_i , italic_j ) not in \ud835\udcb5\ud835\udcb5\\mathcal{Z}caligraphic_Z.\nThen, by appropriate definition of x\ud835\udc65xitalic_x in \u211dqsuperscript\u211d\ud835\udc5e\\mathbb{R}^{q}blackboard_R start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT,\none can associate each element of x\ud835\udc65xitalic_x to an element of T\ud835\udc47Titalic_T or \u03b3\u2062v\ud835\udefe\ud835\udc63\\gamma vitalic_\u03b3 italic_v.\nWe denote this by x=vec\u2062(T,\u03b3\u2062v)\ud835\udc65vec\ud835\udc47\ud835\udefe\ud835\udc63x=\\text{vec}(T,\\gamma v)italic_x = vec ( italic_T , italic_\u03b3 italic_v )\nand the objective function in (53) can be written as\nf\u2062(x)=K\u2062L\u2062(x|x~)\ud835\udc53\ud835\udc65\ud835\udc3e\ud835\udc3fconditional\ud835\udc65~\ud835\udc65f(x)=KL(x|\\tilde{x})italic_f ( italic_x ) = italic_K italic_L ( italic_x | over~ start_ARG italic_x end_ARG ),\nwhere x~=vec\u2062(K,\u03b3\u2062v~)~\ud835\udc65vec\ud835\udc3e\ud835\udefe~\ud835\udc63\\tilde{x}=\\text{vec}(K,\\gamma\\tilde{v})over~ start_ARG italic_x end_ARG = vec ( italic_K , italic_\u03b3 over~ start_ARG italic_v end_ARG ).\nAlso, the constraints in (52) can be expressed as\nA1\u2062x=b1,A2\u2062x=b2formulae-sequencesubscript\ud835\udc341\ud835\udc65subscript\ud835\udc4f1subscript\ud835\udc342\ud835\udc65subscript\ud835\udc4f2A_{1}x=b_{1},\\;\\;A_{2}x=b_{2}italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x = italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_x = italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT,\nwhere If (T,v),(S,w)\u2208\ud835\udcaf\u2062\ud835\udcb1\ud835\udc47\ud835\udc63\ud835\udc46\ud835\udc64\ud835\udcaf\ud835\udcb1(T,v),(S,w)\\in\\mathcal{TV}( italic_T , italic_v ) , ( italic_S , italic_w ) \u2208 caligraphic_T caligraphic_V, y=vec\u2062(T,\u03b3\u2062v)\ud835\udc66vec\ud835\udc47\ud835\udefe\ud835\udc63y=\\text{vec}(T,\\gamma v)italic_y = vec ( italic_T , italic_\u03b3 italic_v ), x=vec\u2062(S,\u03b3\u2062w)\ud835\udc65vec\ud835\udc46\ud835\udefe\ud835\udc64x=\\text{vec}(S,\\gamma w)italic_x = vec ( italic_S , italic_\u03b3 italic_w ): If (S,w)\u2208\ud835\udcaf\u2062\ud835\udcb1\ud835\udc46\ud835\udc64\ud835\udcaf\ud835\udcb1(S,w)\\in\\mathcal{TV}( italic_S , italic_w ) \u2208 caligraphic_T caligraphic_V then iff\nti\u2062j\u2217=c1\u2062i\u2062si\u2062j,vj\u2217=wjformulae-sequencesubscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udc501\ud835\udc56subscript\ud835\udc60\ud835\udc56\ud835\udc57subscriptsuperscript\ud835\udc63\ud835\udc57subscript\ud835\udc64\ud835\udc57t^{*}_{ij}=c_{1i}s_{ij},\\;\\;v^{*}_{j}=w_{j}italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT , italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT,\nwhere Since ti\u2062j=0subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 for (i,j)\u2208\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\in\\mathcal{Z}( italic_i , italic_j ) \u2208 caligraphic_Z, the Lagrangian associated with this optimization problem is When (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin\\mathcal{Z}( italic_i , italic_j ) \u2209 caligraphic_Z, Setting these to zero yields Hence,\nti\u2062j\u2217=si\u2062j\u2062exp\u2061(\u2212\u03b1i)=c1\u2062i\u2062si\u2062jsubscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udc60\ud835\udc56\ud835\udc57subscript\ud835\udefc\ud835\udc56subscript\ud835\udc501\ud835\udc56subscript\ud835\udc60\ud835\udc56\ud835\udc57t^{*}_{ij}=s_{ij}\\exp\\left(-\\alpha_{i}\\right)=c_{1i}s_{ij}italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT roman_exp ( - italic_\u03b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_c start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT,\nwhere\nc1\u2062i=exp\u2061(\u2212\u03b1i)subscript\ud835\udc501\ud835\udc56subscript\ud835\udefc\ud835\udc56c_{1i}=\\exp(-\\alpha_{i})italic_c start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT = roman_exp ( - italic_\u03b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )\nand\nvj\u2217=wjsubscriptsuperscript\ud835\udc63\ud835\udc57subscript\ud835\udc64\ud835\udc57v^{*}_{j}=w_{j}italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT.\nAlso, \u2211j=1nti\u2062j\u2217=u~isuperscriptsubscript\ud835\udc571\ud835\udc5bsubscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57subscript~\ud835\udc62\ud835\udc56\\sum_{j=1}^{n}t^{*}_{ij}=\\tilde{u}_{i}\u2211 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT implies (54). If (S,w)\u2208\ud835\udcaf\u2062\ud835\udcb1\ud835\udc46\ud835\udc64\ud835\udcaf\ud835\udcb1(S,w)\\in\\mathcal{TV}( italic_S , italic_w ) \u2208 caligraphic_T caligraphic_V then iff\nti\u2062j\u2217=c2\u2062j\u2062si\u2062j,vj\u2217=c2\u2062j\u22121\u03b3\u2062wjformulae-sequencesubscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udc502\ud835\udc57subscript\ud835\udc60\ud835\udc56\ud835\udc57subscriptsuperscript\ud835\udc63\ud835\udc57superscriptsubscript\ud835\udc502\ud835\udc571\ud835\udefesubscript\ud835\udc64\ud835\udc57t^{*}_{ij}=c_{2j}s_{ij},\\;\\;v^{*}_{j}=c_{2j}^{-\\frac{1}{\\gamma}}w_{j}italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT , italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - divide start_ARG 1 end_ARG start_ARG italic_\u03b3 end_ARG end_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT,\nwhere Since ti\u2062j=0subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 for (i,j)\u2208\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\in\\mathcal{Z}( italic_i , italic_j ) \u2208 caligraphic_Z, the\nLagrangian associated with this optimization problem is given by When (i,j)\u2209\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\notin{\\mathcal{Z}}( italic_i , italic_j ) \u2209 caligraphic_Z, Setting these to zero results in Hence,\nti\u2062j\u2217=si\u2062j\u2062c2\u2062jsubscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57subscript\ud835\udc60\ud835\udc56\ud835\udc57subscript\ud835\udc502\ud835\udc57t^{*}_{ij}=s_{ij}c_{2j}italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT\nwhere\nc2\u2062j=exp\u2061(\u2212\u03b2j)subscript\ud835\udc502\ud835\udc57subscript\ud835\udefd\ud835\udc57c_{2j}=\\exp(-\\beta_{j})italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT = roman_exp ( - italic_\u03b2 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ).\nAlso,\nvj\u2217=wj\u2062exp\u2061(\u03b2j/\u03b3)=c2\u2062j\u22121/\u03b3\u2062wjsubscriptsuperscript\ud835\udc63\ud835\udc57subscript\ud835\udc64\ud835\udc57subscript\ud835\udefd\ud835\udc57\ud835\udefesuperscriptsubscript\ud835\udc502\ud835\udc571\ud835\udefesubscript\ud835\udc64\ud835\udc57v^{*}_{j}=w_{j}\\exp(\\beta_{j}/\\gamma)=c_{2j}^{-1/\\gamma}w_{j}italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT roman_exp ( italic_\u03b2 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT / italic_\u03b3 ) = italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / italic_\u03b3 end_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT.\nDue to the column sum constraints, we must have\nc2\u2062j\u2062\u2211i=1msi\u2062j=\u2211i=1mti\u2062j\u2217=vj\u2217=c2\u2062j\u22121/\u03b3\u2062wjsubscript\ud835\udc502\ud835\udc57superscriptsubscript\ud835\udc561\ud835\udc5asubscript\ud835\udc60\ud835\udc56\ud835\udc57superscriptsubscript\ud835\udc561\ud835\udc5asubscriptsuperscript\ud835\udc61\ud835\udc56\ud835\udc57subscriptsuperscript\ud835\udc63\ud835\udc57superscriptsubscript\ud835\udc502\ud835\udc571\ud835\udefesubscript\ud835\udc64\ud835\udc57c_{2j}\\sum_{i=1}^{m}s_{ij}=\\sum_{i=1}^{m}t^{*}_{ij}=v^{*}_{j}=c_{2j}^{-1/%\n\\gamma}w_{j}italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / italic_\u03b3 end_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT,\nthat is,\nc2\u2062j1+\u03b3\u03b3\u2062\u2211i=1msi\u2062j=wjsuperscriptsubscript\ud835\udc502\ud835\udc571\ud835\udefe\ud835\udefesuperscriptsubscript\ud835\udc561\ud835\udc5asubscript\ud835\udc60\ud835\udc56\ud835\udc57subscript\ud835\udc64\ud835\udc57c_{2j}^{\\frac{1+\\gamma}{\\gamma}}\\sum_{i=1}^{m}s_{ij}=w_{j}italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT divide start_ARG 1 + italic_\u03b3 end_ARG start_ARG italic_\u03b3 end_ARG end_POSTSUPERSCRIPT \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT,\nwhich implies (55).  It follows, from Theorem 2 and Lemmas 3 and 4, that the sequence, {(T(l),v(l)}\\{(T(l),v(l)\\}{ ( italic_T ( italic_l ) , italic_v ( italic_l ) }, converges to a limit, (T\u2217,v\u2217)superscript\ud835\udc47superscript\ud835\udc63(T^{*},v^{*})( italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT , italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ), with T\u2217\u2208\ud835\udcafsuperscript\ud835\udc47\ud835\udcafT^{*}\\in{\\mathcal{T}}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT \u2208 caligraphic_T, v\u2217\u2208\u211d+nsuperscript\ud835\udc63subscriptsuperscript\u211d\ud835\udc5bv^{*}\\in\\mathbb{R}^{n}_{+}italic_v start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT,\nand this limit satisfies the constraints\nin (52). We now only need to prove\nthat \u2207f\u2062(x\u2062(0))\u2207\ud835\udc53\ud835\udc650\\nabla f(x(0))\u2207 italic_f ( italic_x ( 0 ) ) satisfies (50), where x\u2062(0)=vec\u2062(K,\u03b3\u2062v~)\ud835\udc650vec\ud835\udc3e\ud835\udefe~\ud835\udc63x(0)=\\text{vec}(K,\\gamma\\tilde{v})italic_x ( 0 ) = vec ( italic_K , italic_\u03b3 over~ start_ARG italic_v end_ARG ).\nWith J\ud835\udc3dJitalic_J given by (53), we have, for ti\u2062j>0subscript\ud835\udc61\ud835\udc56\ud835\udc570t_{ij}>0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 and vj>0subscript\ud835\udc63\ud835\udc570v_{j}>0italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT > 0, Hence,\n\u2202J\u2202ti\u2062j\u2062(K,v~)=0,\u2202J\u2202\u03b3\u2062vj\u2062(K,v~)=0formulae-sequence\ud835\udc3dsubscript\ud835\udc61\ud835\udc56\ud835\udc57\ud835\udc3e~\ud835\udc630\ud835\udc3d\ud835\udefesubscript\ud835\udc63\ud835\udc57\ud835\udc3e~\ud835\udc630\\frac{\\partial J}{\\partial t_{ij}}(K,\\tilde{v})=0,\\;\\;\\frac{\\partial J}{%\n\\partial\\gamma v_{j}}(K,\\tilde{v})=0divide start_ARG \u2202 italic_J end_ARG start_ARG \u2202 italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ( italic_K , over~ start_ARG italic_v end_ARG ) = 0 , divide start_ARG \u2202 italic_J end_ARG start_ARG \u2202 italic_\u03b3 italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_ARG ( italic_K , over~ start_ARG italic_v end_ARG ) = 0,\nand\n\u2207f\u2062(x\u2062(0))i=0\u2207\ud835\udc53subscript\ud835\udc650\ud835\udc560\\nabla f(x(0))_{i}=0\u2207 italic_f ( italic_x ( 0 ) ) start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0 for i=1,2,\u2026,q\ud835\udc5612\u2026\ud835\udc5ei=1,2,\\dots,qitalic_i = 1 , 2 , \u2026 , italic_q. Therefore, \u2207f\u2062(x\u2062(0))\u2207\ud835\udc53\ud835\udc650\\nabla f(x(0))\u2207 italic_f ( italic_x ( 0 ) ) satisfies (50). \u25a0\u25a0{\\hskip 220.50885pt}\\blacksquare\u25a0 SK-type iterations make sense for large-scale problems. Smart cities are a natural place to look for such problems, and, in particular, sharing economy [20] applications, since these are precisely the problem domains where allocation of resources at scale emerge, and where the scale of the problem is subject to temporal variations. One such problem arises in the context of charging m\ud835\udc5amitalic_m electric vehicles (EVs) overnight in a city such as London. With the advent of vehicle-to-grid (V2G), vehicle-to-vehicle (V2V) and widespread availability of solar, it is likely that many entities that currently consume energy will become prosumers in the near future; i.e.\u00a0most homes, and even cars, will consume energy and also make energy available, depending on the circumstance. Such a scenario is clearly very large scale, with a potentially very large number, m\ud835\udc5amitalic_m, of EVs (there are currently more than 2.5M cars registered in London), and a large number, n\ud835\udc5bnitalic_n, of energy providers (consisting of conventional utilities, energy brokerages, households and even other cars, and constituting the target agents of our OT setup in Section\u00a0III). In the setting of this paper (Section\u00a0III), each EV specifies the energy it requires in KWhrs, and then this demand for energy is communicated (i.e.\u00a0\u2018transported\u2019) to a set of providers. Each provider may set a cost based on their type of energy generation, their proximity to the car being charged, and the type of vehicle being charged. In addition, some providers may prohibit certain types of vehicles, for example plug-in hybrid vehicles (PHEVs), or vehicles that are very large in size. Our OT formulation (21) captures the realistic scenario in which the n\ud835\udc5bnitalic_n energy providers make available flexible amounts of energy, nominally v~~\ud835\udc63\\tilde{v}over~ start_ARG italic_v end_ARG, to m\ud835\udc5amitalic_m EVs whose demands are exactly u~~\ud835\udc62\\tilde{u}over~ start_ARG italic_u end_ARG. Furthermore, energy transfer between specified provider-EV pairs, (i,j)\u2208\ud835\udcb5\ud835\udc56\ud835\udc57\ud835\udcb5(i,j)\\in{\\mathcal{Z}}( italic_i , italic_j ) \u2208 caligraphic_Z (5), are not allowed a priori. To simulate this scenario, consider m=10,000\ud835\udc5a10000m=10,000italic_m = 10 , 000 EVs requiring charging and n=10\ud835\udc5b10n=10italic_n = 10 energy providers. We simulate the specified energy charging requirement, u~isubscript~\ud835\udc62\ud835\udc56\\tilde{u}_{i}over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, i=1,\u2026,m\ud835\udc561\u2026\ud835\udc5ai=1,\\ldots,mitalic_i = 1 , \u2026 , italic_m, of each EV via independent and uniform draws in the range (0,1)01(0,1)( 0 , 1 ) KWhrs. We simulate the nominal available energy of each supplier, v~jsubscript~\ud835\udc63\ud835\udc57\\tilde{v}_{j}over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, j=1,\u2026,n\ud835\udc571\u2026\ud835\udc5bj=1,\\ldots,nitalic_j = 1 , \u2026 , italic_n, in the same way. Therefore, (1) may not hold, i.e.\u00a0the transport problem may be unbalanced, in that the total energy required by the EVs may differ from the total nominal energy made available by the providers. This UOT problem is also solved by our algorithms. To effect prior zero constraints, we assume that even-indexed cars are PHEVs, and that even-indexed providers will not supply these PHEVs. This defines a transport plan with m\u2062n4\ud835\udc5a\ud835\udc5b4\\frac{mn}{4}divide start_ARG italic_m italic_n end_ARG start_ARG 4 end_ARG pre-specified zeroes. The non-zero elements of K\ud835\udc3eKitalic_K in (15) are obtained with t~i\u2062j=1subscript~\ud835\udc61\ud835\udc56\ud835\udc571\\tilde{t}_{ij}=1over~ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 1 and \u03b30=1.99subscript\ud835\udefe01.99\\gamma_{0}=1.99italic_\u03b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 1.99,\nand the transport cost, ci\u2062jsubscript\ud835\udc50\ud835\udc56\ud835\udc57c_{ij}italic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT, \u2200(i,j)\u2209\ud835\udcb5for-all\ud835\udc56\ud835\udc57\ud835\udcb5\\forall(i,j)\\notin\\mathcal{Z}\u2200 ( italic_i , italic_j ) \u2209 caligraphic_Z are again iid uniformly drawn from (0,1)01(0,1)( 0 , 1 ). We use Algorithm 1, with \u03b3=1.005\ud835\udefe1.005\\gamma=1.005italic_\u03b3 = 1.005 (21), to obtain the OT plan, T\u2217superscript\ud835\udc47T^{*}italic_T start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT.\nFigure 1 illustrates the convergence of the algorithm for 10 simulation runs.\nLet T\u2062(l\u22121)\ud835\udc47\ud835\udc591T(l-1)italic_T ( italic_l - 1 ) and T\u2062(l)\ud835\udc47\ud835\udc59T(l)italic_T ( italic_l ) be the transport plans obtained from two consecutive iterations of the algorithm in any one simulation, and let \u0394\u2062(l)\u0394\ud835\udc59\\Delta(l)roman_\u0394 ( italic_l ) be the matrix with (i,j)\ud835\udc56\ud835\udc57(i,j)( italic_i , italic_j )th entry defined as \u03b4i\u2062j\u2062(l)=|ti\u2062j\u2062(l)\u2212ti\u2062j\u2062(l\u22121)|subscript\ud835\udeff\ud835\udc56\ud835\udc57\ud835\udc59subscript\ud835\udc61\ud835\udc56\ud835\udc57\ud835\udc59subscript\ud835\udc61\ud835\udc56\ud835\udc57\ud835\udc591\\delta_{ij}(l)=|t_{ij}(l)-t_{ij}(l-1)|italic_\u03b4 start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_l ) = | italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_l ) - italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_l - 1 ) |.\nFigure 1 plots the log of the sum of the \u03b4i\u2062jsubscript\ud835\udeff\ud835\udc56\ud835\udc57\\delta_{ij}italic_\u03b4 start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPTs, normalised by the first log-sum, for each of the 10 simulations,\n i.e.\nlog\u2061(\u2211(i,j)\u2209\ud835\udcb5|ti\u2062j\u2062(l)\u2212ti\u2062j\u2062(l\u22121)|)log\u2061(\u2211(i,j)\u2209\ud835\udcb5|ti\u2062j\u2062(1)\u2212ti\u2062j\u2062(0)|)subscript\ud835\udc56\ud835\udc57\ud835\udcb5subscript\ud835\udc61\ud835\udc56\ud835\udc57\ud835\udc59subscript\ud835\udc61\ud835\udc56\ud835\udc57\ud835\udc591subscript\ud835\udc56\ud835\udc57\ud835\udcb5subscript\ud835\udc61\ud835\udc56\ud835\udc571subscript\ud835\udc61\ud835\udc56\ud835\udc570\\frac{\\log\\left(\\sum_{(i,j)\\notin{\\mathcal{Z}}}|t_{ij}(l)-t_{ij}(l-1)|\\right)}%\n{\\log\\left(\\sum_{(i,j)\\notin{\\mathcal{Z}}}|t_{ij}(1)-t_{ij}(0)|\\right)}divide start_ARG roman_log ( \u2211 start_POSTSUBSCRIPT ( italic_i , italic_j ) \u2209 caligraphic_Z end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_l ) - italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_l - 1 ) | ) end_ARG start_ARG roman_log ( \u2211 start_POSTSUBSCRIPT ( italic_i , italic_j ) \u2209 caligraphic_Z end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( 1 ) - italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( 0 ) | ) end_ARG.\nWe have normalized in order to facilitate comparison of the different simulations. In this paper, we have presented SK-type algorithms for constrained optimal transport. Specifically, our algorithms allow for transport plans that force some entries to be zero a priori. The convergence proof is based on Bregman-type ideas. An example in resource allocation for the sharing economy is provided, pointing to situations in which our algorithm is relevant. Future work will investigate extension of this work to problems that incorporate other forms of regularisation terms [21], and other potential use-cases."
    },
    {
        "id": 21,
        "title": "A contribution to the theory of \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-properties of a finite group\u2020\u2020thanks: Research was supported by the National\nNatural Science Foundation of China\n(No. 12171126, 12101165).\nResearch of the third author and the fourth author was\nsupported by the Ministry of Education of the\nRepublic of Belarus (No.\u00a020211328, 20211778).\n\nIn memory of Professor Francesco de Giovanni",
        "corpus": "Let \u03c3={\u03c3i\u2223i\u2208I}\ud835\udf0econditional-setsubscript\ud835\udf0e\ud835\udc56\ud835\udc56\ud835\udc3c\\sigma=\\{\\sigma_{i}\\mid i\\in I\\}italic_\u03c3 = { italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2223 italic_i \u2208 italic_I } be some\npartition of the set of all primes.\nA subgroup A\ud835\udc34Aitalic_A of a finite group G\ud835\udc3aGitalic_G is said to be: (i)\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal in G\ud835\udc3aGitalic_G if\nthere is a subgroup chain A=A0\u2264A1\u2264\u22ef\u2264An=G\ud835\udc34subscript\ud835\udc340subscript\ud835\udc341\u22efsubscript\ud835\udc34\ud835\udc5b\ud835\udc3aA=A_{0}\\leq A_{1}\\leq\\cdots\\leq A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2264 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2264 \u22ef \u2264 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that either Ai\u22121\u2062\u22b4\u2062Aisubscript\ud835\udc34\ud835\udc561\u22b4subscript\ud835\udc34\ud835\udc56A_{i-1}\\trianglelefteq A_{i}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT \u22b4 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT or\nAi/(Ai\u22121)Aisubscript\ud835\udc34\ud835\udc56subscriptsubscript\ud835\udc34\ud835\udc561subscript\ud835\udc34\ud835\udc56A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT is a \u03c3jsubscript\ud835\udf0e\ud835\udc57{\\sigma}_{j}italic_\u03c3 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT-group, j=j\u2062(i)\ud835\udc57\ud835\udc57\ud835\udc56j=j(i)italic_j = italic_j ( italic_i ), for all i=1,\u2026,n\ud835\udc561\u2026\ud835\udc5bi=1,\\ldots,nitalic_i = 1 , \u2026 , italic_n;\n(ii) modular in G\ud835\udc3aGitalic_G\nif the following conditions are held:\n(1) \u27e8X,A\u2229Z\u27e9=\u27e8X,A\u27e9\u2229Z\ud835\udc4b\ud835\udc34\ud835\udc4d\ud835\udc4b\ud835\udc34\ud835\udc4d\\langle X,A\\cap Z\\rangle=\\langle X,A\\rangle\\cap Z\u27e8 italic_X , italic_A \u2229 italic_Z \u27e9 = \u27e8 italic_X , italic_A \u27e9 \u2229 italic_Z for all X\u2264G,Z\u2264Gformulae-sequence\ud835\udc4b\ud835\udc3a\ud835\udc4d\ud835\udc3aX\\leq G,Z\\leq Gitalic_X \u2264 italic_G , italic_Z \u2264 italic_G such that\nX\u2264Z\ud835\udc4b\ud835\udc4dX\\leq Zitalic_X \u2264 italic_Z, and\n(2) \u27e8A,Y\u2229Z\u27e9=\u27e8A,Y\u27e9\u2229Z\ud835\udc34\ud835\udc4c\ud835\udc4d\ud835\udc34\ud835\udc4c\ud835\udc4d\\langle A,Y\\cap Z\\rangle=\\langle A,Y\\rangle\\cap Z\u27e8 italic_A , italic_Y \u2229 italic_Z \u27e9 = \u27e8 italic_A , italic_Y \u27e9 \u2229 italic_Z for all Y\u2264G,Z\u2264Gformulae-sequence\ud835\udc4c\ud835\udc3a\ud835\udc4d\ud835\udc3aY\\leq G,Z\\leq Gitalic_Y \u2264 italic_G , italic_Z \u2264 italic_G such that A\u2264Z\ud835\udc34\ud835\udc4dA\\leq Zitalic_A \u2264 italic_Z; (iii) \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G if A\ud835\udc34Aitalic_A is\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal and modular in G\ud835\udc3aGitalic_G. We obtain a description of finite groups in which\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormality (respectively, modularity) is a\ntransitive relation. Some known results are extended. Throughout this paper, all groups are finite and G\ud835\udc3aGitalic_G always denotes\na finite group; \u2112\u2062(G)\u2112\ud835\udc3a{\\cal L}(G)caligraphic_L ( italic_G ) is the lattice of all subgroups of G\ud835\udc3aGitalic_G;\nG\ud835\udc3aGitalic_G is said to be an M\ud835\udc40Mitalic_M-group [1]\nif the lattice \u2112\u2062(G)\u2112\ud835\udc3a{\\cal L}(G)caligraphic_L ( italic_G ) is modular.\nMoreover, \u2119\u2119\\mathbb{P}blackboard_P is the set of all primes, \u03c0\u2286\u2119\ud835\udf0b\u2119\\pi\\subseteq\\mathbb{P}italic_\u03c0 \u2286 blackboard_P,\n\u03c0\u2032=\u2119\u2216\u03c0superscript\ud835\udf0b\u2032\u2119\ud835\udf0b\\pi^{\\prime}=\\mathbb{P}\\setminus\\piitalic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = blackboard_P \u2216 italic_\u03c0, and \u03c3={\u03c3i\u2223i\u2208I}\ud835\udf0econditional-setsubscript\ud835\udf0e\ud835\udc56\ud835\udc56\ud835\udc3c\\sigma=\\{\\sigma_{i}\\mid i\\in I\\}italic_\u03c3 = { italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2223 italic_i \u2208 italic_I } is some partition of \u2119\u2119\\mathbb{P}blackboard_P.\nIf\nn\ud835\udc5bnitalic_n is an integer, the symbol \u03c0\u2062(n)\ud835\udf0b\ud835\udc5b\\pi(n)italic_\u03c0 ( italic_n ) denotes\nthe set of all primes dividing n\ud835\udc5bnitalic_n; as usual, \u03c0\u2062(G)=\u03c0\u2062(|G|)\ud835\udf0b\ud835\udc3a\ud835\udf0b\ud835\udc3a\\pi(G)=\\pi(|G|)italic_\u03c0 ( italic_G ) = italic_\u03c0 ( | italic_G | ), the set of all\nprimes dividing the order of G\ud835\udc3aGitalic_G; \u03c3\u2062(n)={\u03c3i\u2223\u03c3i\u2229\u03c0\u2062(n)\u2260\u2205}\ud835\udf0e\ud835\udc5bconditional-setsubscript\ud835\udf0e\ud835\udc56subscript\ud835\udf0e\ud835\udc56\ud835\udf0b\ud835\udc5b\\sigma(n)=\\{\\sigma_{i}\\mid\\sigma_{i}\\cap\\pi(n)\\neq\\emptyset\\}italic_\u03c3 ( italic_n ) = { italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2223 italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2229 italic_\u03c0 ( italic_n ) \u2260 \u2205 } and\n\u03c3\u2062(G)=\u03c3\u2062(|G|)\ud835\udf0e\ud835\udc3a\ud835\udf0e\ud835\udc3a\\sigma(G)=\\sigma(|G|)italic_\u03c3 ( italic_G ) = italic_\u03c3 ( | italic_G | ) [2, 3].\nA group G\ud835\udc3aGitalic_G is said to be [2, 3]: \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-primary if G\ud835\udc3aGitalic_G is a \u03c3isubscript\ud835\udf0e\ud835\udc56\\sigma_{i}italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-group\nfor some i\ud835\udc56iitalic_i; \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-nilpotent if G\ud835\udc3aGitalic_G is a direct product\nof \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-primary groups. A subgroup A\ud835\udc34Aitalic_A of G\ud835\udc3aGitalic_G is said to be quasinormal (Ore)\nor permutable (Stonehewer)\nin G\ud835\udc3aGitalic_G\nif A\ud835\udc34Aitalic_A permutes with every subgroup H\ud835\udc3bHitalic_H of G\ud835\udc3aGitalic_G, that is, A\u2062H=H\u2062A\ud835\udc34\ud835\udc3b\ud835\udc3b\ud835\udc34AH=HAitalic_A italic_H = italic_H italic_A. The quasinormal subgroups have many interesting and\nuseful for applications properties.\nFor instance, if A\ud835\udc34Aitalic_A is quasinormal in G\ud835\udc3aGitalic_G, then: A\ud835\udc34Aitalic_A is subnormal in G\ud835\udc3aGitalic_G\n(Ore [4]), A/AG\ud835\udc34subscript\ud835\udc34\ud835\udc3aA/A_{G}italic_A / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is nilpotent (Ito and Szep [5]),\nevery chief factor\nH/K\ud835\udc3b\ud835\udc3eH/Kitalic_H / italic_K of G\ud835\udc3aGitalic_G between AGsubscript\ud835\udc34\ud835\udc3aA_{G}italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT and AGsuperscript\ud835\udc34\ud835\udc3aA^{G}italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is central, that is, CG\u2062(H/K)=Gsubscript\ud835\udc36\ud835\udc3a\ud835\udc3b\ud835\udc3e\ud835\udc3aC_{G}(H/K)=Gitalic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_H / italic_K ) = italic_G (Maier and Schmid [6]),\nand,\nin general, the section A/AG\ud835\udc34subscript\ud835\udc34\ud835\udc3aA/A_{G}italic_A / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is not necessarily abelian\n(Thomson [7]). Quasinormal subgroups have a\nclose connection with the so-called modular subgroups. Recall that a subgroup M\ud835\udc40Mitalic_M of G\ud835\udc3aGitalic_G is said to be: (i)  modular in G\ud835\udc3aGitalic_G [1]\nif M\ud835\udc40Mitalic_M is a modular element (in the sense of\nKurosh [1, p. 43]) of the lattice \u2112\u2062(G)\u2112\ud835\udc3a{\\cal L}(G)caligraphic_L ( italic_G ), that is,\n(1) \u27e8X,M\u2229Z\u27e9=\u27e8X,M\u27e9\u2229Z\ud835\udc4b\ud835\udc40\ud835\udc4d\ud835\udc4b\ud835\udc40\ud835\udc4d\\langle X,M\\cap Z\\rangle=\\langle X,M\\rangle\\cap Z\u27e8 italic_X , italic_M \u2229 italic_Z \u27e9 = \u27e8 italic_X , italic_M \u27e9 \u2229 italic_Z for all X\u2264G,Z\u2264Gformulae-sequence\ud835\udc4b\ud835\udc3a\ud835\udc4d\ud835\udc3aX\\leq G,Z\\leq Gitalic_X \u2264 italic_G , italic_Z \u2264 italic_G such that X\u2264Z\ud835\udc4b\ud835\udc4dX\\leq Zitalic_X \u2264 italic_Z, and\n(2) \u27e8M,Y\u2229Z\u27e9=\u27e8M,Y\u27e9\u2229Z\ud835\udc40\ud835\udc4c\ud835\udc4d\ud835\udc40\ud835\udc4c\ud835\udc4d\\langle M,Y\\cap Z\\rangle=\\langle M,Y\\rangle\\cap Z\u27e8 italic_M , italic_Y \u2229 italic_Z \u27e9 = \u27e8 italic_M , italic_Y \u27e9 \u2229 italic_Z for all Y\u2264G,Z\u2264Gformulae-sequence\ud835\udc4c\ud835\udc3a\ud835\udc4d\ud835\udc3aY\\leq G,Z\\leq Gitalic_Y \u2264 italic_G , italic_Z \u2264 italic_G such that M\u2264Z\ud835\udc40\ud835\udc4dM\\leq Zitalic_M \u2264 italic_Z; (ii) submodular in G\ud835\udc3aGitalic_G if\nthere is a subgroup chain A=A0\u2264A1\u2264\u22ef\u2264An=G\ud835\udc34subscript\ud835\udc340subscript\ud835\udc341\u22efsubscript\ud835\udc34\ud835\udc5b\ud835\udc3aA=A_{0}\\leq A_{1}\\leq\\cdots\\leq A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2264 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2264 \u22ef \u2264 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that Ai\u22121subscript\ud835\udc34\ud835\udc561A_{i-1}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT is modular in Aisubscript\ud835\udc34\ud835\udc56A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for all i=1,\u2026,n\ud835\udc561\u2026\ud835\udc5bi=1,\\ldots,nitalic_i = 1 , \u2026 , italic_n. Every quasinormal is clearly modular in the group. Moreover,\nthe following remarkable result is well-known. Theorem A (Schmidt [1, Theorem 5.1.1]) A subgroup A\ud835\udc34Aitalic_A of G\ud835\udc3aGitalic_G is\nquasinormal in G\ud835\udc3aGitalic_G if and only if A\ud835\udc34Aitalic_A is subnormal and modular in G\ud835\udc3aGitalic_G. This result made\nit possible to find an analogue of quasinormality in the theory of the\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-properties of a group [8]. A subgroup A\ud835\udc34Aitalic_A of G\ud835\udc3aGitalic_G is said to\nbe \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal\nin G\ud835\udc3aGitalic_G [2, 3] if there is a subgroup chain\nA=A0\u2264A1\u2264\u22ef\u2264An=G\ud835\udc34subscript\ud835\udc340subscript\ud835\udc341\u22efsubscript\ud835\udc34\ud835\udc5b\ud835\udc3aA=A_{0}\\leq A_{1}\\leq\\cdots\\leq A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2264 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2264 \u22ef \u2264 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that either Ai\u22121\u2062\u22b4\u2062Aisubscript\ud835\udc34\ud835\udc561\u22b4subscript\ud835\udc34\ud835\udc56A_{i-1}\\trianglelefteq A_{i}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT \u22b4 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT or\nAi/(Ai\u22121)Aisubscript\ud835\udc34\ud835\udc56subscriptsubscript\ud835\udc34\ud835\udc561subscript\ud835\udc34\ud835\udc56A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT is \u03c3\ud835\udf0e{\\sigma}italic_\u03c3-primary\nfor all i=1,\u2026,n\ud835\udc561\u2026\ud835\udc5bi=1,\\ldots,nitalic_i = 1 , \u2026 , italic_n; \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-seminormal\nin G\ud835\udc3aGitalic_G (J.C. Beidleman) if x\u2208NG\u2062(A)\ud835\udc65subscript\ud835\udc41\ud835\udc3a\ud835\udc34x\\in N_{G}(A)italic_x \u2208 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A ) for all x\u2208G\ud835\udc65\ud835\udc3ax\\in Gitalic_x \u2208 italic_G such that\n\u03c3\u2062(|x|)\u2229\u03c3\u2062(A)=\u2205\ud835\udf0e\ud835\udc65\ud835\udf0e\ud835\udc34\\sigma(|x|)\\cap\\sigma(A)=\\emptysetitalic_\u03c3 ( | italic_x | ) \u2229 italic_\u03c3 ( italic_A ) = \u2205. Definition 1.1. We say that a subgroup A\ud835\udc34Aitalic_A of G\ud835\udc3aGitalic_G\nis \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G if A\ud835\udc34Aitalic_A is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal and modular\nin G\ud835\udc3aGitalic_G. Before continuing, consider some examples. Example 1.2. (i)\nIn the first limiting case, when\n\u03c3={\u2119}\ud835\udf0e\u2119\\sigma=\\{\\mathbb{P}\\}italic_\u03c3 = { blackboard_P }, every group is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-nilpotent and every\nsubgroup of any group is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal. Therefore in this case\na subgroup A\ud835\udc34Aitalic_A of G\ud835\udc3aGitalic_G is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal if and only if it is modular in G\ud835\udc3aGitalic_G. (ii) In the second limiting case, when \u03c3=\u03c31={{2},{3},{5}\u2062\u2026}\ud835\udf0esuperscript\ud835\udf0e1235\u2026\\sigma=\\sigma^{1}=\\{\\{2\\},\\{3\\},\\{5\\}\\ldots\\}italic_\u03c3 = italic_\u03c3 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT = { { 2 } , { 3 } , { 5 } \u2026 }, a subgroup A\ud835\udc34Aitalic_A of G\ud835\udc3aGitalic_G\nis \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal in G\ud835\udc3aGitalic_G if and only if it is subnormal in G\ud835\udc3aGitalic_G.\nTherefore in this case, in view of Theorem A,\na subgroup A\ud835\udc34Aitalic_A of G\ud835\udc3aGitalic_G is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal if and only if it is quasinormal\nin G\ud835\udc3aGitalic_G. (iii) In the case\n\u03c3=\u03c31\u2062\u03c0={{p1},\u2026,{pn},\u03c0\u2032}\ud835\udf0esuperscript\ud835\udf0e1\ud835\udf0bsubscript\ud835\udc5d1\u2026subscript\ud835\udc5d\ud835\udc5bsuperscript\ud835\udf0b\u2032\\sigma=\\sigma^{1\\pi}=\\{\\{p_{1}\\},\\ldots,\\{p_{n}\\},\\pi^{\\prime}\\}italic_\u03c3 = italic_\u03c3 start_POSTSUPERSCRIPT 1 italic_\u03c0 end_POSTSUPERSCRIPT = { { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } , \u2026 , { italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT }, where\n\u03c0={p1,\u2026,pn}\ud835\udf0bsubscript\ud835\udc5d1\u2026subscript\ud835\udc5d\ud835\udc5b\\pi=\\{p_{1},\\ldots,p_{n}\\}italic_\u03c0 = { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }, a subgroup A\ud835\udc34Aitalic_A of\nG\ud835\udc3aGitalic_G is \u03c31\u2062\u03c0superscript\ud835\udf0e1\ud835\udf0b\\sigma^{1\\pi}italic_\u03c3 start_POSTSUPERSCRIPT 1 italic_\u03c0 end_POSTSUPERSCRIPT-subnormal in G\ud835\udc3aGitalic_G if and only if G\ud835\udc3aGitalic_G has\na subgroup chain\nA=A0\u2264A1\u2264\u22ef\u2264An=G\ud835\udc34subscript\ud835\udc340subscript\ud835\udc341\u22efsubscript\ud835\udc34\ud835\udc5b\ud835\udc3aA=A_{0}\\leq A_{1}\\leq\\cdots\\leq A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2264 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2264 \u22ef \u2264 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that either Ai\u22121\u2062\u22b4\u2062Aisubscript\ud835\udc34\ud835\udc561\u22b4subscript\ud835\udc34\ud835\udc56A_{i-1}\\trianglelefteq A_{i}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT \u22b4 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT or\nAi/(Ai\u22121)Aisubscript\ud835\udc34\ud835\udc56subscriptsubscript\ud835\udc34\ud835\udc561subscript\ud835\udc34\ud835\udc56A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT is a \u03c0\u2032superscript\ud835\udf0b\u2032{\\pi}^{\\prime}italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT-group for all i=1,\u2026,n\ud835\udc561\u2026\ud835\udc5bi=1,\\ldots,nitalic_i = 1 , \u2026 , italic_n. In this case we say, following\n[9, 10, 11], that A\ud835\udc34Aitalic_A is 1\u2062\u03c01\ud835\udf0b1\\pi1 italic_\u03c0-subnormal in G\ud835\udc3aGitalic_G, and we say that\nA\ud835\udc34Aitalic_A is 1\u2062\u03c01\ud835\udf0b1\\pi1 italic_\u03c0-quasinormal in G\ud835\udc3aGitalic_G if A\ud835\udc34Aitalic_A is\n1\u2062\u03c01\ud835\udf0b1\\pi1 italic_\u03c0-subnormal and modular in G\ud835\udc3aGitalic_G. Note, in passing, that A\ud835\udc34Aitalic_A is 1\u2062\u03c01\ud835\udf0b1\\pi1 italic_\u03c0-subnormal\nin G\ud835\udc3aGitalic_G if and only if A\ud835\udc34Aitalic_A is \ud835\udd09\ud835\udd09\\mathfrak{F}fraktur_F-subnormal in G\ud835\udc3aGitalic_G in\nthe sence of Kegel\n[12], where \ud835\udd09\ud835\udd09\\mathfrak{F}fraktur_F is the class of all \u03c0\u2032superscript\ud835\udf0b\u2032\\pi^{\\prime}italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT-groups. (iv) In the other classical case \u03c3=\u03c3\u03c0={\u03c0,\u03c0\u2032}\ud835\udf0esuperscript\ud835\udf0e\ud835\udf0b\ud835\udf0bsuperscript\ud835\udf0b\u2032\\sigma=\\sigma^{\\pi}=\\{\\pi,\\pi^{\\prime}\\}italic_\u03c3 = italic_\u03c3 start_POSTSUPERSCRIPT italic_\u03c0 end_POSTSUPERSCRIPT = { italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT } a\nsubgroup A\ud835\udc34Aitalic_A of G\ud835\udc3aGitalic_G is\n\u03c3\u03c0superscript\ud835\udf0e\ud835\udf0b{\\sigma}^{\\pi}italic_\u03c3 start_POSTSUPERSCRIPT italic_\u03c0 end_POSTSUPERSCRIPT-subnormal in G\ud835\udc3aGitalic_G if and only\nif G\ud835\udc3aGitalic_G has a subgroup chain\nA=A0\u2264A1\u2264\u22ef\u2264An=G\ud835\udc34subscript\ud835\udc340subscript\ud835\udc341\u22efsubscript\ud835\udc34\ud835\udc5b\ud835\udc3aA=A_{0}\\leq A_{1}\\leq\\cdots\\leq A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2264 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2264 \u22ef \u2264 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that either Ai\u22121\u2062\u22b4\u2062Aisubscript\ud835\udc34\ud835\udc561\u22b4subscript\ud835\udc34\ud835\udc56A_{i-1}\\trianglelefteq A_{i}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT \u22b4 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, or\nAi/(Ai\u22121)Aisubscript\ud835\udc34\ud835\udc56subscriptsubscript\ud835\udc34\ud835\udc561subscript\ud835\udc34\ud835\udc56A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT is a \u03c0\ud835\udf0b{\\pi}italic_\u03c0-group, or\nAi/(Ai\u22121)Aisubscript\ud835\udc34\ud835\udc56subscriptsubscript\ud835\udc34\ud835\udc561subscript\ud835\udc34\ud835\udc56A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT is a \u03c0\u2032superscript\ud835\udf0b\u2032{\\pi}^{\\prime}italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT-group for all i=1,\u2026,n\ud835\udc561\u2026\ud835\udc5bi=1,\\ldots,nitalic_i = 1 , \u2026 , italic_n. In this case we say that A\ud835\udc34Aitalic_A is\n\u03c0,\u03c0\u2032\ud835\udf0bsuperscript\ud835\udf0b\u2032\\pi,\\pi^{\\prime}italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT-subnormal in G\ud835\udc3aGitalic_G [9, 10, 11], and we say that\nA\ud835\udc34Aitalic_A is \u03c0,\u03c0\u2032\ud835\udf0bsuperscript\ud835\udf0b\u2032\\pi,\\pi^{\\prime}italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT-quasinormal in G\ud835\udc3aGitalic_G if A\ud835\udc34Aitalic_A is\n\u03c0,\u03c0\u2032\ud835\udf0bsuperscript\ud835\udf0b\u2032\\pi,\\pi^{\\prime}italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT-subnormal and modular in G\ud835\udc3aGitalic_G. The\ntheory of \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroups was constructed in the paper [13].\nIn particular, it was proven the following result covering in the\ncase \u03c3=\u03c31={{2},{3},{5}\u2062\u2026}\ud835\udf0esuperscript\ud835\udf0e1235\u2026\\sigma=\\sigma^{1}=\\{\\{2\\},\\{3\\},\\{5\\}\\ldots\\}italic_\u03c3 = italic_\u03c3 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT = { { 2 } , { 3 } , { 5 } \u2026 } the above mentioned results in\n[4, 5, 6]. Theorem B (See Theorem C in [13]). Let A\ud835\udc34Aitalic_A be a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup of G\ud835\udc3aGitalic_G.\nThen the following statements hold: (i) A\ud835\udc34Aitalic_A permutes with all Hall \u03c3isubscript\ud835\udf0e\ud835\udc56\\sigma_{i}italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-subgroups of G\ud835\udc3aGitalic_G for all i\ud835\udc56iitalic_i. (ii) The quotients\nAG/AGsuperscript\ud835\udc34\ud835\udc3asubscript\ud835\udc34\ud835\udc3aA^{G}/A_{G}italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT and G/CG\u2062(AG/AG)\ud835\udc3asubscript\ud835\udc36\ud835\udc3asuperscript\ud835\udc34\ud835\udc3asubscript\ud835\udc34\ud835\udc3aG/C_{G}(A^{G}/A_{G})italic_G / italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) are \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-nilpotent, and (iii) Every chief factor H/K\ud835\udc3b\ud835\udc3eH/Kitalic_H / italic_K of G\ud835\udc3aGitalic_G between\nAGsuperscript\ud835\udc34\ud835\udc3aA^{G}italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT and AGsubscript\ud835\udc34\ud835\udc3aA_{G}italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-central in G\ud835\udc3aGitalic_G , that is,\n(H/K)\u22ca(G/CG\u2062(H/K))right-normal-factor-semidirect-product\ud835\udc3b\ud835\udc3e\ud835\udc3asubscript\ud835\udc36\ud835\udc3a\ud835\udc3b\ud835\udc3e(H/K)\\rtimes(G/C_{G}(H/K))( italic_H / italic_K ) \u22ca ( italic_G / italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_H / italic_K ) ) is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-primary. (iv) For every i\ud835\udc56iitalic_i such that \u03c3i\u2208\u03c3\u2062(G/CG\u2062(AG/AG))subscript\ud835\udf0e\ud835\udc56\ud835\udf0e\ud835\udc3asubscript\ud835\udc36\ud835\udc3asuperscript\ud835\udc34\ud835\udc3asubscript\ud835\udc34\ud835\udc3a\\sigma_{i}\\in\\sigma(G/C_{G}(A^{G}/A_{G}))italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2208 italic_\u03c3 ( italic_G / italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) ) we have\n\u03c3i\u2208\u03c3\u2062(AG/AG).subscript\ud835\udf0e\ud835\udc56\ud835\udf0esuperscript\ud835\udc34\ud835\udc3asubscript\ud835\udc34\ud835\udc3a\\sigma_{i}\\in\\sigma(A^{G}/A_{G}).italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2208 italic_\u03c3 ( italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) . (v) A\ud835\udc34Aitalic_A is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-seminormal in G\ud835\udc3aGitalic_G. A group G\ud835\udc3aGitalic_G is said to be a\nP\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group [14, 2.0.2]\nif quasinormality is\na transitive relation on G\ud835\udc3aGitalic_G, that is, if H\ud835\udc3bHitalic_H is a quasinormal subgroup\nof K\ud835\udc3eKitalic_K and K\ud835\udc3eKitalic_K is a quasinormal subgroup\nof G\ud835\udc3aGitalic_G, then H\ud835\udc3bHitalic_H is a quasinormal subgroup of G\ud835\udc3aGitalic_G. The description of P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-groups was first obtained by Zacher [15],\nfor the soluble case, and by Robinson in [16], for the general case. Bearing in mind the results in\n[15, 16] and many other known results on P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-groups (see, in particular,\nChapter 2 in [14]), it seems to be natural to ask: Question 1.3. What is the structure of G\ud835\udc3aGitalic_G\nprovided \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormality is a transitive relation in G\ud835\udc3aGitalic_G? Question 1.4. What is the structure of G\ud835\udc3aGitalic_G\nprovided modularity is a transitive relation in G\ud835\udc3aGitalic_G? Note that in view of Example 1.2(i), Question 1.4\nis a special case of Question 1.3, where \u03c3={\u2119}\ud835\udf0e\u2119\\sigma=\\{\\mathbb{P}\\}italic_\u03c3 = { blackboard_P }. Note also that\nfor the case when G\ud835\udc3aGitalic_G is a soluble group,\nthe answers to both of these questions are known. Frigerio proved [18] (see also [19]) that modularity\nis a transitive relation in a soluble group G\ud835\udc3aGitalic_G if and only if G\ud835\udc3aGitalic_G is an M\ud835\udc40Mitalic_M-group. An important step in solving the general Problem 1.3\nwas made in the paper [17], where it was proven the following theorem\nturn into Frigerion result in the case where \u03c3={\u2119}\ud835\udf0e\u2119\\sigma=\\{\\mathbb{P}\\}italic_\u03c3 = { blackboard_P }. Theorem C  (X.-F. Zhang, W. Guo, I.N. Safonova,\nA.N. Skiba [17]). Let G\ud835\udc3aGitalic_G be a soluble\ngroup and D=G\ud835\udd11\u03c3\ud835\udc37superscript\ud835\udc3asubscript\ud835\udd11\ud835\udf0eD=G^{\\mathfrak{N_{\\sigma}}}italic_D = italic_G start_POSTSUPERSCRIPT fraktur_N start_POSTSUBSCRIPT italic_\u03c3 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT. Then \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormality\nis a transitive relation in G\ud835\udc3aGitalic_G if and only if\nthe following conditions hold: (i) G=D\u22caM\ud835\udc3aright-normal-factor-semidirect-product\ud835\udc37\ud835\udc40G=D\\rtimes Mitalic_G = italic_D \u22ca italic_M, where D\ud835\udc37Ditalic_D is an abelian Hall\nsubgroup of G\ud835\udc3aGitalic_G of odd order, M\ud835\udc40Mitalic_M is a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-nilpotent M\ud835\udc40Mitalic_M-group. (ii) every element of G\ud835\udc3aGitalic_G induces a\npower automorphism on D\ud835\udc37Ditalic_D, (iii) O\u03c3i\u2062(D)subscript\ud835\udc42subscript\ud835\udf0e\ud835\udc56\ud835\udc37O_{\\sigma_{i}}(D)italic_O start_POSTSUBSCRIPT italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) has\na normal complement in a Hall \u03c3isubscript\ud835\udf0e\ud835\udc56\\sigma_{i}italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-subgroup of G\ud835\udc3aGitalic_G for all i\ud835\udc56iitalic_i. Conversely, if Conditions (i), (ii)\nand (iii) hold for some subgroups D\ud835\udc37Ditalic_D and M\ud835\udc40Mitalic_M of\nG\ud835\udc3aGitalic_G, then \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormality\nis a transitive relation in G\ud835\udc3aGitalic_G. In this theorem, G\ud835\udd11\u03c3superscript\ud835\udc3asubscript\ud835\udd11\ud835\udf0eG^{\\mathfrak{N_{\\sigma}}}italic_G start_POSTSUPERSCRIPT fraktur_N start_POSTSUBSCRIPT italic_\u03c3 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT denotes the \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-nilpotent\nresidual of G\ud835\udc3aGitalic_G,\nthat is, the intersection of all normal subgroups N\ud835\udc41Nitalic_N of G\ud835\udc3aGitalic_G with\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-nilpotent quotient G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N. Definition 1.5. We say that G\ud835\udc3aGitalic_G is: (i) a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group if the\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormality is\na transitive relation on G\ud835\udc3aGitalic_G, that is, if H\ud835\udc3bHitalic_H is a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup\nof K\ud835\udc3eKitalic_K and K\ud835\udc3eKitalic_K is a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup\nof G\ud835\udc3aGitalic_G, then H\ud835\udc3bHitalic_H is a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup of G\ud835\udc3aGitalic_G;\n(ii) an M\u2062T\ud835\udc40\ud835\udc47MTitalic_M italic_T-group\nif the modularity is a transitive relation in G\ud835\udc3aGitalic_G. It is clear that an M\u2062T\ud835\udc40\ud835\udc47MTitalic_M italic_T-group is exactly a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group\nwhere \u03c3={\u2119}\ud835\udf0e\u2119\\sigma=\\{\\mathbb{P}\\}italic_\u03c3 = { blackboard_P }. In this article, expanding the corresponding results of the papers\n[16, 17, 21], we answer Questions 1.3 and 1.4 in the general case. Definition 1.6. We say that\n(D,Z\u2062(D);U1,\u2026,Uk)\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\u2026subscript\ud835\udc48\ud835\udc58(D,Z(D);U_{1},\\ldots,U_{k})( italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) is a Robinson complex\nif the following fold: (i) D\u22601\ud835\udc371D\\neq 1italic_D \u2260 1 is a perfect normal subgroup of G\ud835\udc3aGitalic_G, (ii) D/Z\u2062(D)=U1/Z\u2062(D)\u00d7\u22ef\u00d7Uk/Z\u2062(D)\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\ud835\udc4d\ud835\udc37\u22efsubscript\ud835\udc48\ud835\udc58\ud835\udc4d\ud835\udc37D/Z(D)=U_{1}/Z(D)\\times\\cdots\\times U_{k}/Z(D)italic_D / italic_Z ( italic_D ) = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT / italic_Z ( italic_D ) \u00d7 \u22ef \u00d7 italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_Z ( italic_D ), where Ui/Z\u2062(D)subscript\ud835\udc48\ud835\udc56\ud835\udc4d\ud835\udc37U_{i}/Z(D)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z ( italic_D ) is a\nsimple non-abelian chief factor of G\ud835\udc3aGitalic_G, Z\u2062(D)=\u03a6\u2062(D)\ud835\udc4d\ud835\udc37\u03a6\ud835\udc37Z(D)=\\Phi(D)italic_Z ( italic_D ) = roman_\u03a6 ( italic_D ), and (iii) every chief factor of G\ud835\udc3aGitalic_G below Z\u2062(D)\ud835\udc4d\ud835\udc37Z(D)italic_Z ( italic_D ) is cyclic. Example 1.7. Let G=S\u2062L\u2062(2,7)\u00d7A7\u00d7A5\u00d7B\ud835\udc3a\ud835\udc46\ud835\udc3f27subscript\ud835\udc347subscript\ud835\udc345\ud835\udc35G=SL(2,7)\\times A_{7}\\times A_{5}\\times Bitalic_G = italic_S italic_L ( 2 , 7 ) \u00d7 italic_A start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT \u00d7 italic_A start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT \u00d7 italic_B,\nwhere B=C43\u22caC7\ud835\udc35right-normal-factor-semidirect-productsubscript\ud835\udc3643subscript\ud835\udc367B=C_{43}\\rtimes C_{7}italic_B = italic_C start_POSTSUBSCRIPT 43 end_POSTSUBSCRIPT \u22ca italic_C start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT\nis a non-abelian group of order 301.\nThen is a Robinson complex of G\ud835\udc3aGitalic_G. Now let G=An\u2240Cp=K\u22caCp\ud835\udc3a\u2240subscript\ud835\udc34\ud835\udc5bsubscript\ud835\udc36\ud835\udc5dright-normal-factor-semidirect-product\ud835\udc3esubscript\ud835\udc36\ud835\udc5dG=A_{n}\\wr C_{p}=K\\rtimes C_{p}italic_G = italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \u2240 italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT = italic_K \u22ca italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT, where K\ud835\udc3eKitalic_K is the base group of the regular\nwreath product of the alternating group Ansubscript\ud835\udc34\ud835\udc5bA_{n}italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT of degree n>4\ud835\udc5b4n>4italic_n > 4\nwith a group Cpsubscript\ud835\udc36\ud835\udc5dC_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT of prime order p\ud835\udc5dpitalic_p. Then K\ud835\udc3eKitalic_K is a minimal normal subgroup of G\ud835\udc3aGitalic_G\nby [20, Chapter A, 18.5(a) ]. Hence G\ud835\udc3aGitalic_G has no a Robinson complex. We say, following Robinson [16], that G\ud835\udc3aGitalic_G satisfies: (1) \ud835\udc0dpsubscript\ud835\udc0d\ud835\udc5d{\\bf N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT if whenever N\ud835\udc41Nitalic_N is a soluble normal\nsubgroup of G\ud835\udc3aGitalic_G, p\u2032superscript\ud835\udc5d\u2032p^{\\prime}italic_p start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT-elements of G\ud835\udc3aGitalic_G induce power automorphism in\nOp\u2062(G/N)subscript\ud835\udc42\ud835\udc5d\ud835\udc3a\ud835\udc41O_{p}(G/N)italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_G / italic_N ); (2) \ud835\udc0fpsubscript\ud835\udc0f\ud835\udc5d{\\bf P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT if whenever N\ud835\udc41Nitalic_N is a soluble normal\nsubgroup of G\ud835\udc3aGitalic_G, every subgroup of Op\u2062(G/N)subscript\ud835\udc42\ud835\udc5d\ud835\udc3a\ud835\udc41O_{p}(G/N)italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_G / italic_N ) is quasinormal\nin every Sylow p\ud835\udc5dpitalic_p-subgroup of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N. Every subnormal subgroup is both submodular and \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal in the group.\nThus the following well-known\nresult partially describes the structure of insoluble Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-groups. Theorem D (Robinson [16]). G\ud835\udc3aGitalic_G is a P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group if\nand only if G\ud835\udc3aGitalic_G has a normal perfect subgroup D\ud835\udc37Ditalic_D such that: (i) G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is a soluble P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group, and (i) if D\u22601\ud835\udc371D\\neq 1italic_D \u2260 1, G\ud835\udc3aGitalic_G has a Robinson complex\n(D,Z\u2062(D);U1,\u2026,Uk)\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\u2026subscript\ud835\udc48\ud835\udc58(D,Z(D);U_{1},\\ldots,U_{k})( italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u2026,ir}\u2286{1,\u2026,k}subscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc5f1\u2026\ud835\udc58\\{i_{1},\\ldots,i_{r}\\}\\subseteq\\{1,\\ldots,k\\}{ italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u2286 { 1 , \u2026 , italic_k }, where\n1\u2264r<k1\ud835\udc5f\ud835\udc581\\leq r<k1 \u2264 italic_r < italic_k, G\ud835\udc3aGitalic_G and G/Ui1\u2032\u2062\u22ef\u2062Uir\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48subscript\ud835\udc561\u2032\u22efsuperscriptsubscript\ud835\udc48subscript\ud835\udc56\ud835\udc5f\u2032G/U_{i_{1}}^{\\prime}\\cdots U_{i_{r}}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT satisfy\n\ud835\udc0dpsubscript\ud835\udc0d\ud835\udc5d{\\bf N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u2208\u03c0\u2062(Z\u2062(D))\ud835\udc5d\ud835\udf0b\ud835\udc4d\ud835\udc37p\\in\\pi(Z(D))italic_p \u2208 italic_\u03c0 ( italic_Z ( italic_D ) ) and\n\ud835\udc0fpsubscript\ud835\udc0f\ud835\udc5d{\\bf P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT\nfor all p\u2208\u03c0\u2062(D)\ud835\udc5d\ud835\udf0b\ud835\udc37p\\in\\pi(D)italic_p \u2208 italic_\u03c0 ( italic_D ). Now, recall that G\ud835\udc3aGitalic_G is a non-abelian P\ud835\udc43Pitalic_P-group (see [1, p. 49]) if\nG=A\u22ca\u27e8t\u27e9\ud835\udc3aright-normal-factor-semidirect-product\ud835\udc34delimited-\u27e8\u27e9\ud835\udc61G=A\\rtimes\\langle t\\rangleitalic_G = italic_A \u22ca \u27e8 italic_t \u27e9, where A\ud835\udc34Aitalic_A is an elementary abelian\np\ud835\udc5dpitalic_p-group and an element t\ud835\udc61titalic_t of\nprime order q\u2260p\ud835\udc5e\ud835\udc5dq\\neq pitalic_q \u2260 italic_p induces a non-trivial power\nautomorphism on A\ud835\udc34Aitalic_A. In this case we say that G\ud835\udc3aGitalic_G is a P\ud835\udc43Pitalic_P-group\nof type (p,q)\ud835\udc5d\ud835\udc5e(p,q)( italic_p , italic_q ). Definition 1.8. We say that: (i) G\ud835\udc3aGitalic_G satisfies\n\ud835\udc10\u03c3\u2062(p,q)subscript\ud835\udc10\ud835\udf0e\ud835\udc5d\ud835\udc5e{\\bf Q}_{\\sigma(p,q)}bold_Q start_POSTSUBSCRIPT italic_\u03c3 ( italic_p , italic_q ) end_POSTSUBSCRIPT if\nwhenever N\ud835\udc41Nitalic_N is a soluble normal\nsubgroup of G\ud835\udc3aGitalic_G and P/N\ud835\udc43\ud835\udc41P/Nitalic_P / italic_N is a normal \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-primary\nP\ud835\udc43Pitalic_P-subgroup of type (p,q)\ud835\udc5d\ud835\udc5e(p,q)( italic_p , italic_q ) of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N,\nevery subgroup of P/N\ud835\udc43\ud835\udc41P/Nitalic_P / italic_N is modular in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N. If G\ud835\udc3aGitalic_G satisfies\n\ud835\udc10\u03c3\u2062(p,q)subscript\ud835\udc10\ud835\udf0e\ud835\udc5d\ud835\udc5e{\\bf Q}_{\\sigma(p,q)}bold_Q start_POSTSUBSCRIPT italic_\u03c3 ( italic_p , italic_q ) end_POSTSUBSCRIPT and \u03c3={\u2119}\ud835\udf0e\u2119\\sigma=\\{\\mathbb{P}\\}italic_\u03c3 = { blackboard_P },\nthen say, following [21], that G\ud835\udc3aGitalic_G satisfies\n\ud835\udc0cp,qsubscript\ud835\udc0c\ud835\udc5d\ud835\udc5e{\\bf M}_{p,q}bold_M start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT. (ii) G\ud835\udc3aGitalic_G satisfies\n\ud835\udc10\u03c3\u2062Psubscript\ud835\udc10\ud835\udf0e\ud835\udc43{\\bf Q}_{\\sigma P}bold_Q start_POSTSUBSCRIPT italic_\u03c3 italic_P end_POSTSUBSCRIPT if G\ud835\udc3aGitalic_G satisfies\n\ud835\udc10\u03c3\u2062(p,q)subscript\ud835\udc10\ud835\udf0e\ud835\udc5d\ud835\udc5e{\\bf Q}_{\\sigma(p,q)}bold_Q start_POSTSUBSCRIPT italic_\u03c3 ( italic_p , italic_q ) end_POSTSUBSCRIPT for each pair p,q\ud835\udc5d\ud835\udc5ep,qitalic_p , italic_q\nsuch that there is a P\ud835\udc43Pitalic_P-group of type (p,q)\ud835\udc5d\ud835\udc5e(p,q)( italic_p , italic_q ). In this paper, based on Theorems C and D,\nwe prove the following result. Theorem E. A group G\ud835\udc3aGitalic_G is a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group if\nand only if G\ud835\udc3aGitalic_G has a perfect normal subgroup D\ud835\udc37Ditalic_D such that: (i) G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is a soluble Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group, (ii) if D\u22601\ud835\udc371D\\neq 1italic_D \u2260 1, G\ud835\udc3aGitalic_G has a Robinson complex\n(D,Z\u2062(D);U1,\u2026,Uk)\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\u2026subscript\ud835\udc48\ud835\udc58(D,Z(D);U_{1},\\ldots,U_{k})( italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u2026,ir}\u2286{1,\u2026,k}subscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc5f1\u2026\ud835\udc58\\{i_{1},\\ldots,i_{r}\\}\\subseteq\\{1,\\ldots,k\\}{ italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u2286 { 1 , \u2026 , italic_k }, where\n1\u2264r<k1\ud835\udc5f\ud835\udc581\\leq r<k1 \u2264 italic_r < italic_k, the groups G\ud835\udc3aGitalic_G and G/Ui1\u2032\u2062\u22ef\u2062Uir\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48subscript\ud835\udc561\u2032\u22efsuperscriptsubscript\ud835\udc48subscript\ud835\udc56\ud835\udc5f\u2032G/U_{i_{1}}^{\\prime}\\cdots U_{i_{r}}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT satisfy\n\ud835\udc0dpsubscript\ud835\udc0d\ud835\udc5d{\\bf N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u2208{2,3}\u2229\u03c0\u2062(Z\u2062(D))\ud835\udc5d23\ud835\udf0b\ud835\udc4d\ud835\udc37p\\in\\{2,3\\}\\cap\\pi(Z(D))italic_p \u2208 { 2 , 3 } \u2229 italic_\u03c0 ( italic_Z ( italic_D ) ),\n\ud835\udc0fpsubscript\ud835\udc0f\ud835\udc5d{\\bf P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT\nfor all p\u2208\u03c0\u2062(D)\ud835\udc5d\ud835\udf0b\ud835\udc37p\\in\\pi(D)italic_p \u2208 italic_\u03c0 ( italic_D ), and \ud835\udc10\u03c3(p,q){\\bf Q}_{\\sigma(p,q})bold_Q start_POSTSUBSCRIPT italic_\u03c3 ( italic_p , italic_q end_POSTSUBSCRIPT )\nfor all\n{p,q}\u2229\u03c0\u2062(D)\u2260\u2205\ud835\udc5d\ud835\udc5e\ud835\udf0b\ud835\udc37\\{p,q\\}\\cap\\pi(D)\\neq\\emptyset{ italic_p , italic_q } \u2229 italic_\u03c0 ( italic_D ) \u2260 \u2205. Theorem E gives a solution to Question 1.3. The following special case\nof Theorem E gives a solution to Question 1.4. Theorem F.  A group G\ud835\udc3aGitalic_G is an M\u2062T\ud835\udc40\ud835\udc47MTitalic_M italic_T-group if\nand only if G\ud835\udc3aGitalic_G has a perfect normal subgroup D\ud835\udc37Ditalic_D such that: (i) G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is an M\ud835\udc40Mitalic_M-group, (ii) if D\u22601\ud835\udc371D\\neq 1italic_D \u2260 1, G\ud835\udc3aGitalic_G has a Robinson complex\n(D,Z\u2062(D);U1,\u2026,Uk)\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\u2026subscript\ud835\udc48\ud835\udc58(D,Z(D);U_{1},\\ldots,U_{k})( italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u2026,ir}\u2286{1,\u2026,k}subscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc5f1\u2026\ud835\udc58\\{i_{1},\\ldots,i_{r}\\}\\subseteq\\{1,\\ldots,k\\}{ italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u2286 { 1 , \u2026 , italic_k }, where\n1\u2264r<k1\ud835\udc5f\ud835\udc581\\leq r<k1 \u2264 italic_r < italic_k, G\ud835\udc3aGitalic_G and G/Ui1\u2032\u2062\u22ef\u2062Uir\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48subscript\ud835\udc561\u2032\u22efsuperscriptsubscript\ud835\udc48subscript\ud835\udc56\ud835\udc5f\u2032G/U_{i_{1}}^{\\prime}\\cdots U_{i_{r}}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT satisfy\n\ud835\udc0dpsubscript\ud835\udc0d\ud835\udc5d{\\bf N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u2208{2,3}\u2229\u03c0\u2062(Z\u2062(D))\ud835\udc5d23\ud835\udf0b\ud835\udc4d\ud835\udc37p\\in\\{2,3\\}\\cap\\pi(Z(D))italic_p \u2208 { 2 , 3 } \u2229 italic_\u03c0 ( italic_Z ( italic_D ) ),\n\ud835\udc0fpsubscript\ud835\udc0f\ud835\udc5d{\\bf P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT\nfor all p\u2208\u03c0\u2062(D)\ud835\udc5d\ud835\udf0b\ud835\udc37p\\in\\pi(D)italic_p \u2208 italic_\u03c0 ( italic_D ), and \ud835\udc0cp,qsubscript\ud835\udc0c\ud835\udc5d\ud835\udc5e{\\bf M}_{p,q}bold_M start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT for all pairs\n{p,q}\u2229\u03c0\u2062(D)\u2260\u2205.\ud835\udc5d\ud835\udc5e\ud835\udf0b\ud835\udc37\\{p,q\\}\\cap\\pi(D)\\neq\\emptyset.{ italic_p , italic_q } \u2229 italic_\u03c0 ( italic_D ) \u2260 \u2205 . We prove Theorem E (and so Theorem F, as well) in Section 3. In Section 4\nwe discuss some other applications of these results. The first lemma is a corollary of general properties of modular\nsubgroups [1, p. 201] and \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal subgroups [3, Lemma 2.6]. Lemma 2.1. Let A\ud835\udc34Aitalic_A, B\ud835\udc35Bitalic_B and\nN\ud835\udc41Nitalic_N be subgroups of G\ud835\udc3aGitalic_G, where A\ud835\udc34Aitalic_A is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal and N\ud835\udc41Nitalic_N is\nnormal in G\ud835\udc3aGitalic_G. (1) The subgroup A\u2229B\ud835\udc34\ud835\udc35A\\cap Bitalic_A \u2229 italic_B is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in B\ud835\udc35Bitalic_B. (2) The subgroup A\u2062N/N\ud835\udc34\ud835\udc41\ud835\udc41AN/Nitalic_A italic_N / italic_N\nis \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N. (3) If N\u2264B\ud835\udc41\ud835\udc35N\\leq Bitalic_N \u2264 italic_B and B/N\ud835\udc35\ud835\udc41B/Nitalic_B / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N, then\nB\ud835\udc35Bitalic_B is\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G. (4) B\ud835\udc35Bitalic_B is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G, then \u27e8A,B\u27e9\ud835\udc34\ud835\udc35\\langle A,B\\rangle\u27e8 italic_A , italic_B \u27e9\nis \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G. Lemma 2.2 A subgroup A\ud835\udc34Aitalic_A of G\ud835\udc3aGitalic_G is a\nmaximal \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup of\nG\ud835\udc3aGitalic_G\nif and only if either A\ud835\udc34Aitalic_A is normal in G\ud835\udc3aGitalic_G and G/A\ud835\udc3a\ud835\udc34G/Aitalic_G / italic_A is a\nsimple gropup or AG<Asubscript\ud835\udc34\ud835\udc3a\ud835\udc34A_{G}<Aitalic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT < italic_A and\nG/AG\ud835\udc3asubscript\ud835\udc34\ud835\udc3aG/A_{G}italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-primary non-abelian group of order p\u2062q\ud835\udc5d\ud835\udc5epqitalic_p italic_q for primes\np\ud835\udc5dpitalic_p and q\ud835\udc5eqitalic_q. Proof.  First assume that A\ud835\udc34Aitalic_A is a maximal \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup of\nG\ud835\udc3aGitalic_G. If A\ud835\udc34Aitalic_A is normal in G\ud835\udc3aGitalic_G, then G/A=G/AG\ud835\udc3a\ud835\udc34\ud835\udc3asubscript\ud835\udc34\ud835\udc3aG/A=G/A_{G}italic_G / italic_A = italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is\nsimple. Now assume that A\ud835\udc34Aitalic_A is not normal in G\ud835\udc3aGitalic_G, so AG=Gsuperscript\ud835\udc34\ud835\udc3a\ud835\udc3aA^{G}=Gitalic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_G and, in view of\nTheorem B(ii),\nG/AG\ud835\udc3asubscript\ud835\udc34\ud835\udc3aG/A_{G}italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a \u03c3isubscript\ud835\udf0e\ud835\udc56\\sigma_{i}italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-group for some i\ud835\udc56iitalic_i. Hence every subgroup of G\ud835\udc3aGitalic_G\ncontaining AGsubscript\ud835\udc34\ud835\udc3aA_{G}italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal in G\ud835\udc3aGitalic_G by [3, Lemma 2.6(5)].\nOn the other hand, U/AG\ud835\udc48subscript\ud835\udc34\ud835\udc3aU/A_{G}italic_U / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is modular in G\ud835\udc3aGitalic_G if and only if U\ud835\udc48Uitalic_U is modular in G\ud835\udc3aGitalic_G\nby [1, Page 201, Properties (3)(4)]. Therefore, in fact, A\ud835\udc34Aitalic_A is a\nmaximal modular subgroup of G\ud835\udc3aGitalic_G.\nHence G/AG\ud835\udc3asubscript\ud835\udc34\ud835\udc3aG/A_{G}italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a non-abelian group of order p\u2062q\ud835\udc5d\ud835\udc5epqitalic_p italic_q for\nprimes p,q\u2208\u03c3i\ud835\udc5d\ud835\udc5esubscript\ud835\udf0e\ud835\udc56p,q\\in\\sigma_{i}italic_p , italic_q \u2208 italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT by [1, Lemma 5.1.2]. Now assume that AG<A<Gsubscript\ud835\udc34\ud835\udc3a\ud835\udc34\ud835\udc3aA_{G}<A<Gitalic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT < italic_A < italic_G and G/AG\ud835\udc3asubscript\ud835\udc34\ud835\udc3aG/A_{G}italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-primary non-abelian group\nof order p\u2062q\ud835\udc5d\ud835\udc5epqitalic_p italic_q for primes\np\ud835\udc5dpitalic_p and q\ud835\udc5eqitalic_q. Then A\ud835\udc34Aitalic_A is a maximal subgroup of G\ud835\udc3aGitalic_G and A\ud835\udc34Aitalic_A is a\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal subgroup of G\ud835\udc3aGitalic_G. Moreover, A/AG\ud835\udc34subscript\ud835\udc34\ud835\udc3aA/A_{G}italic_A / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is modular\nin G/AG\ud835\udc3asubscript\ud835\udc34\ud835\udc3aG/A_{G}italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT by [1, Lemma 5.1.2],\nso A\ud835\udc34Aitalic_A is a maximal modular subgroup of G\ud835\udc3aGitalic_G\nby [1, Page 201, Property (4)]. Hence A\ud835\udc34Aitalic_A is a maximal \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup of\nG\ud835\udc3aGitalic_G. Finally, assume that A\ud835\udc34Aitalic_A is normal in G\ud835\udc3aGitalic_G and\nG/A\ud835\udc3a\ud835\udc34G/Aitalic_G / italic_A is a\nsimple non-abelian group, then A\ud835\udc34Aitalic_A is a maximal modular\nsubgroup of G\ud835\udc3aGitalic_G by [1, Lemma 5.1.2] and A\ud835\udc34Aitalic_A\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal in G\ud835\udc3aGitalic_G. Hence A\ud835\udc34Aitalic_A is a maximal \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup of\nG\ud835\udc3aGitalic_G.\nThe lemma is proved. We say that a subgroup A\ud835\udc34Aitalic_A of G\ud835\udc3aGitalic_G is said to be \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal in G\ud835\udc3aGitalic_G\nif\nthere is a subgroup chain A=A0\u2264A1\u2264\u22ef\u2264An=G\ud835\udc34subscript\ud835\udc340subscript\ud835\udc341\u22efsubscript\ud835\udc34\ud835\udc5b\ud835\udc3aA=A_{0}\\leq A_{1}\\leq\\cdots\\leq A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2264 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2264 \u22ef \u2264 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that Ai\u22121subscript\ud835\udc34\ud835\udc561A_{i-1}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in Aisubscript\ud835\udc34\ud835\udc56A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT\nfor all i=1,\u2026,n\ud835\udc561\u2026\ud835\udc5bi=1,\\ldots,nitalic_i = 1 , \u2026 , italic_n. It is clear that G\ud835\udc3aGitalic_G is a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group if and only if every of its\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal subgroups is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G. The class of groups \ud835\udd09\ud835\udd09\\mathfrak{F}fraktur_F is a hereditary formation if\n\ud835\udd09\ud835\udd09\\mathfrak{F}fraktur_F is closed under\ntaking derect products, homomorphic images and subgroups.\nIf \ud835\udd09\u2260\u2205\ud835\udd09\\mathfrak{F}\\neq\\emptysetfraktur_F \u2260 \u2205 is a hereditary formation,\nthen the symbol G\ud835\udd09superscript\ud835\udc3a\ud835\udd09G^{\\mathfrak{F}}italic_G start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT denotes the \ud835\udd09\ud835\udd09\\mathfrak{F}fraktur_F-residual\nof G\ud835\udc3aGitalic_G, that is, the intersection of all normal subgroups N\ud835\udc41Nitalic_N of G\ud835\udc3aGitalic_G with\nG/N\u2208\ud835\udd09\ud835\udc3a\ud835\udc41\ud835\udd09G/N\\in\\mathfrak{F}italic_G / italic_N \u2208 fraktur_F. We use \ud835\udd04\u2217superscript\ud835\udd04\\mathfrak{A}^{*}fraktur_A start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT to denote the class of all abelian groups of squarefree exponent.\nIt is clear that \ud835\udd04\u2217superscript\ud835\udd04\\mathfrak{A}^{*}fraktur_A start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT is a hereditary formation. Lemma 2.3. Let A\ud835\udc34Aitalic_A, B\ud835\udc35Bitalic_B and N\ud835\udc41Nitalic_N be subgroups of G\ud835\udc3aGitalic_G, where\nA\ud835\udc34Aitalic_A\nis \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal G\ud835\udc3aGitalic_G and N\ud835\udc41Nitalic_N is normal G\ud835\udc3aGitalic_G in G\ud835\udc3aGitalic_G. (1) A\u2229B\ud835\udc34\ud835\udc35A\\cap Bitalic_A \u2229 italic_B is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal G\ud835\udc3aGitalic_G in B\ud835\udc35Bitalic_B. (2) A\u2062N/N\ud835\udc34\ud835\udc41\ud835\udc41AN/Nitalic_A italic_N / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal G\ud835\udc3aGitalic_G in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N. (3) If N\u2264K\ud835\udc41\ud835\udc3eN\\leq Kitalic_N \u2264 italic_K and K/N\ud835\udc3e\ud835\udc41K/Nitalic_K / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal G\ud835\udc3aGitalic_G\nin G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N, then K\ud835\udc3eKitalic_K is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal G\ud835\udc3aGitalic_G in G.\ud835\udc3aG.italic_G . (4) A\ud835\udd04\u2217superscript\ud835\udc34superscript\ud835\udd04A^{{\\mathfrak{A}^{*}}}italic_A start_POSTSUPERSCRIPT fraktur_A start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT is subnormal in G\ud835\udc3aGitalic_G. (5) If G=U1\u00d7\u22ef\u00d7Uk\ud835\udc3asubscript\ud835\udc481\u22efsubscript\ud835\udc48\ud835\udc58G=U_{1}\\times\\cdots\\times U_{k}italic_G = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00d7 \u22ef \u00d7 italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, where Uisubscript\ud835\udc48\ud835\udc56U_{i}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a simple\nnon-abelian group, then A\ud835\udc34Aitalic_A is normal in G\ud835\udc3aGitalic_G. Proof. (1)\u2013(4). These assertions follow from Lemma 2.6 in [3] and\ncorresponding lemmas in [19]. (5) Let E=Ui\u2062A\ud835\udc38subscript\ud835\udc48\ud835\udc56\ud835\udc34E=U_{i}Aitalic_E = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_A, where Ui\u2270Anot-less-than-nor-greater-thansubscript\ud835\udc48\ud835\udc56\ud835\udc34U_{i}\\nleq Aitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2270 italic_A. We show that A\u2062\u22b4\u2062E\ud835\udc34\u22b4\ud835\udc38A\\trianglelefteq Eitalic_A \u22b4 italic_E. The subgroup A\ud835\udc34Aitalic_A is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal G\ud835\udc3aGitalic_G in E\ud835\udc38Eitalic_E by Part (1) and A<E\ud835\udc34\ud835\udc38A<Eitalic_A < italic_E, so\nthere is a subgroup chain\nA=E0<E1<\u22ef<Et\u22121<Et=E\ud835\udc34subscript\ud835\udc380subscript\ud835\udc381\u22efsubscript\ud835\udc38\ud835\udc611subscript\ud835\udc38\ud835\udc61\ud835\udc38A=E_{0}<E_{1}<\\cdots<E_{t-1}<E_{t}=Eitalic_A = italic_E start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < \u22ef < italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_E such that Ei\u22121subscript\ud835\udc38\ud835\udc561E_{i-1}italic_E start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT is a maximal\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup of Eisubscript\ud835\udc38\ud835\udc56E_{i}italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for all i=1,\u2026,t\ud835\udc561\u2026\ud835\udc61i=1,\\ldots,titalic_i = 1 , \u2026 , italic_t and for M=Et\u22121\ud835\udc40subscript\ud835\udc38\ud835\udc611M=E_{t-1}italic_M = italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT\nwe have M=A\u2062(M\u2229Ui)\ud835\udc40\ud835\udc34\ud835\udc40subscript\ud835\udc48\ud835\udc56M=A(M\\cap U_{i})italic_M = italic_A ( italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), where M\u2229Ui\ud835\udc40subscript\ud835\udc48\ud835\udc56M\\cap U_{i}italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal in Uisubscript\ud835\udc48\ud835\udc56U_{i}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Then M\u2229Ui<Ui\ud835\udc40subscript\ud835\udc48\ud835\udc56subscript\ud835\udc48\ud835\udc56M\\cap U_{i}<U_{i}italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT\nsince M<E\ud835\udc40\ud835\udc38M<Eitalic_M < italic_E. Therefore M\u2229Ui=1=A\u2229Ui\ud835\udc40subscript\ud835\udc48\ud835\udc561\ud835\udc34subscript\ud835\udc48\ud835\udc56M\\cap U_{i}=1=A\\cap U_{i}italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1 = italic_A \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT by Lemma 2.2 since Uisubscript\ud835\udc48\ud835\udc56U_{i}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a simple\nnon-abelian group, so A\ud835\udc34Aitalic_A is a maximal \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup of E\ud835\udc38Eitalic_E.\nAssume that A\ud835\udc34Aitalic_A is not normal in E\ud835\udc38Eitalic_E. Then E/AE=Ui\u2062A/AE\ud835\udc38subscript\ud835\udc34\ud835\udc38subscript\ud835\udc48\ud835\udc56\ud835\udc34subscript\ud835\udc34\ud835\udc38E/A_{E}=U_{i}A/A_{E}italic_E / italic_A start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_A / italic_A start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a\ngroup of order q\u2062r\ud835\udc5e\ud835\udc5fqritalic_q italic_r for primes q\ud835\udc5eqitalic_q and r\ud835\udc5fritalic_r by Lemma 2.2, where\nUi\u2243Ui\u2062AE/AE\u2264E/AEsimilar-to-or-equalssubscript\ud835\udc48\ud835\udc56subscript\ud835\udc48\ud835\udc56subscript\ud835\udc34\ud835\udc38subscript\ud835\udc34\ud835\udc38\ud835\udc38subscript\ud835\udc34\ud835\udc38U_{i}\\simeq U_{i}A_{E}/A_{E}\\leq E/A_{E}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2243 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT / italic_A start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT \u2264 italic_E / italic_A start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT. This contradiction show that\nUi\u2264NE\u2062(A)subscript\ud835\udc48\ud835\udc56subscript\ud835\udc41\ud835\udc38\ud835\udc34U_{i}\\leq N_{E}(A)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2264 italic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_A ), so G\u2264NG\u2062(A)\ud835\udc3asubscript\ud835\udc41\ud835\udc3a\ud835\udc34G\\leq N_{G}(A)italic_G \u2264 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A ). Hence we have (5).\nThe lemma is proved. Lemma 2.4. If G\ud835\udc3aGitalic_G is a\nQ\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group, then every quotient G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N of G\ud835\udc3aGitalic_G is also a\nQ\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group. Proof.\nLet L/N\ud835\udc3f\ud835\udc41L/Nitalic_L / italic_N be a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal subgroup of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N. Then L\ud835\udc3fLitalic_L is a\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal subgroup in G\ud835\udc3aGitalic_G by Lemma 2.3(3), so L\ud835\udc3fLitalic_L\nis \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G by hypothesis\nand\nthen L/N\ud835\udc3f\ud835\udc41L/Nitalic_L / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N by\nLemma 2.1(2). Hence\nG/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N is a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group.\nThe lemma is proved. Lemma 2.5. If G\ud835\udc3aGitalic_G is a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group, then G/R\ud835\udc3a\ud835\udc45G/Ritalic_G / italic_R satisfies\n\ud835\udc10\u03c3\u2062Psubscript\ud835\udc10\ud835\udf0e\ud835\udc43{\\bf Q}_{\\sigma P}bold_Q start_POSTSUBSCRIPT italic_\u03c3 italic_P end_POSTSUBSCRIPT for every normal subgroup R\ud835\udc45Ritalic_R of G\ud835\udc3aGitalic_G. Proof.\nIn view of Lemma 2.4, we can assume without loss of\ngenerality that R=1\ud835\udc451R=1italic_R = 1. Let P/N\ud835\udc43\ud835\udc41P/Nitalic_P / italic_N be any normal \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-primary non-abelian P\ud835\udc43Pitalic_P-subgroup\nof type (p,q)\ud835\udc5d\ud835\udc5e(p,q)( italic_p , italic_q ) of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N\nand let L/N\u2264P/N\ud835\udc3f\ud835\udc41\ud835\udc43\ud835\udc41L/N\\leq P/Nitalic_L / italic_N \u2264 italic_P / italic_N.\nThen L/N\ud835\udc3f\ud835\udc41L/Nitalic_L / italic_N is modular in P/N\ud835\udc43\ud835\udc41P/Nitalic_P / italic_N by [1, Lemma 2.4.1], so\nL/N\ud835\udc3f\ud835\udc41L/Nitalic_L / italic_N is submodular in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N. On the other hand, L/N\ud835\udc3f\ud835\udc41L/Nitalic_L / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N\nsince P/N\u2264O\u03c3i\u2062(G/N)\ud835\udc43\ud835\udc41subscript\ud835\udc42subscript\ud835\udf0e\ud835\udc56\ud835\udc3a\ud835\udc41P/N\\leq O_{\\sigma_{i}}(G/N)italic_P / italic_N \u2264 italic_O start_POSTSUBSCRIPT italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_G / italic_N ) for some i\ud835\udc56iitalic_i.\nTherefore L/N\ud835\udc3f\ud835\udc41L/Nitalic_L / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N and so\nL\ud835\udc3fLitalic_L is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal in G\ud835\udc3aGitalic_G by Lemma 2.3(3).\nHence L\ud835\udc3fLitalic_L is\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G by hypothesis, so L/N\ud835\udc3f\ud835\udc41L/Nitalic_L / italic_N is modular in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N by\n[1, Page 201, Property (3)].\nTherefore G\ud835\udc3aGitalic_G satisfies \ud835\udc10\u03c3\u2062Psubscript\ud835\udc10\ud835\udf0e\ud835\udc43{\\bf Q}_{\\sigma P}bold_Q start_POSTSUBSCRIPT italic_\u03c3 italic_P end_POSTSUBSCRIPT. The\nlemma is proved. We use G\ud835\udd16superscript\ud835\udc3a\ud835\udd16G^{\\mathfrak{S}}italic_G start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT (respectively, G\ud835\udd18superscript\ud835\udc3a\ud835\udd18G^{\\mathfrak{U}}italic_G start_POSTSUPERSCRIPT fraktur_U end_POSTSUPERSCRIPT) to denote the soluble\n(respectively, the supersoluble) residual of G\ud835\udc3aGitalic_G. Lemma 2.6. Let G\ud835\udc3aGitalic_G be a non-soluble group\nand suppose that G\ud835\udc3aGitalic_G has a\nRobinson complex\n(D,Z\u2062(D);U1,\u2026,Uk),\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\u2026subscript\ud835\udc48\ud835\udc58(D,Z(D);U_{1},\\ldots,U_{k}),( italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) , where D=G\ud835\udd16=G\ud835\udd18\ud835\udc37superscript\ud835\udc3a\ud835\udd16superscript\ud835\udc3a\ud835\udd18D=G^{\\mathfrak{S}}=G^{\\mathfrak{U}}italic_D = italic_G start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT = italic_G start_POSTSUPERSCRIPT fraktur_U end_POSTSUPERSCRIPT.\nLet U\ud835\udc48Uitalic_U be a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal non-\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal\nsubgroup of G\ud835\udc3aGitalic_G of minimal order. Then: (1) If U\u2062Ui\u2032/Ui\u2032\ud835\udc48superscriptsubscript\ud835\udc48\ud835\udc56\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032UU_{i}^{\\prime}/U_{i}^{\\prime}italic_U italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal\nin G/Ui\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48\ud835\udc56\u2032G/U_{i}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT for\nall i=1,\u2026,k\ud835\udc561\u2026\ud835\udc58i=1,\\ldots,kitalic_i = 1 , \u2026 , italic_k, then U\ud835\udc48Uitalic_U is supersoluble. (2) If U\ud835\udc48Uitalic_U is supersoluble and U\u2062L/L\ud835\udc48\ud835\udc3f\ud835\udc3fUL/Litalic_U italic_L / italic_L is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal\nin G/L\ud835\udc3a\ud835\udc3fG/Litalic_G / italic_L for\nall non-trivial nilpotent normal subgroups L\ud835\udc3fLitalic_L of G\ud835\udc3aGitalic_G, then\nU\ud835\udc48Uitalic_U is a cyclic p\ud835\udc5dpitalic_p-group for some prime p\ud835\udc5dpitalic_p. Proof.  Suppose that this lemma is false and let G\ud835\udc3aGitalic_G be a\ncounterexample of minimal order. (1) Assume this is false. Suppose that\nU\u2229D\u2264Z\u2062(D)\ud835\udc48\ud835\udc37\ud835\udc4d\ud835\udc37U\\cap D\\leq Z(D)italic_U \u2229 italic_D \u2264 italic_Z ( italic_D ). Then every chief factor of U\ud835\udc48Uitalic_U below\nU\u2229Z\u2062(D)=U\u2229D\ud835\udc48\ud835\udc4d\ud835\udc37\ud835\udc48\ud835\udc37U\\cap Z(D)=U\\cap Ditalic_U \u2229 italic_Z ( italic_D ) = italic_U \u2229 italic_D is cyclic and, also, U\u2062D/D\u2243U/(U\u2229D)similar-to-or-equals\ud835\udc48\ud835\udc37\ud835\udc37\ud835\udc48\ud835\udc48\ud835\udc37UD/D\\simeq U/(U\\cap D)italic_U italic_D / italic_D \u2243 italic_U / ( italic_U \u2229 italic_D ) is\nsupersoluble.\nHence U\ud835\udc48Uitalic_U is supersoluble, a contradiction. Therefore\nU\u2229D\u2270Z\u2062(D)not-less-than-nor-greater-than\ud835\udc48\ud835\udc37\ud835\udc4d\ud835\udc37U\\cap D\\nleq Z(D)italic_U \u2229 italic_D \u2270 italic_Z ( italic_D ). Moreover, Lemma 2.3(1)(2)\nimplies that (U\u2229D)\u2062Z\u2062(D)/Z\u2062(D)\ud835\udc48\ud835\udc37\ud835\udc4d\ud835\udc37\ud835\udc4d\ud835\udc37(U\\cap D)Z(D)/Z(D)( italic_U \u2229 italic_D ) italic_Z ( italic_D ) / italic_Z ( italic_D ) is\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal in D/Z\u2062(D)\ud835\udc37\ud835\udc4d\ud835\udc37D/Z(D)italic_D / italic_Z ( italic_D ) and so (U\u2229D)\u2062Z\u2062(D)/Z\u2062(D)\ud835\udc48\ud835\udc37\ud835\udc4d\ud835\udc37\ud835\udc4d\ud835\udc37(U\\cap D)Z(D)/Z(D)( italic_U \u2229 italic_D ) italic_Z ( italic_D ) / italic_Z ( italic_D ) is a non-trivial\nnormal subgroup of D/Z\u2062(D)\ud835\udc37\ud835\udc4d\ud835\udc37D/Z(D)italic_D / italic_Z ( italic_D ) by Lemma 2.3(5). Hence for some i\ud835\udc56iitalic_i we\nhave Ui/Z\u2062(D)\u2264(U\u2229D)\u2062Z\u2062(D)/Z\u2062(D),subscript\ud835\udc48\ud835\udc56\ud835\udc4d\ud835\udc37\ud835\udc48\ud835\udc37\ud835\udc4d\ud835\udc37\ud835\udc4d\ud835\udc37U_{i}/Z(D)\\leq(U\\cap D)Z(D)/Z(D),italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z ( italic_D ) \u2264 ( italic_U \u2229 italic_D ) italic_Z ( italic_D ) / italic_Z ( italic_D ) , so Ui\u2264(U\u2229D)\u2062Z\u2062(D).subscript\ud835\udc48\ud835\udc56\ud835\udc48\ud835\udc37\ud835\udc4d\ud835\udc37U_{i}\\leq(U\\cap D)Z(D).italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2264 ( italic_U \u2229 italic_D ) italic_Z ( italic_D ) . But then Ui\u2032\u2264((U\u2229D)\u2062Z\u2062(D))\u2032\u2264U\u2229D.superscriptsubscript\ud835\udc48\ud835\udc56\u2032superscript\ud835\udc48\ud835\udc37\ud835\udc4d\ud835\udc37\u2032\ud835\udc48\ud835\udc37U_{i}^{\\prime}\\leq((U\\cap D)Z(D))^{\\prime}\\leq U\\cap D.italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2264 ( ( italic_U \u2229 italic_D ) italic_Z ( italic_D ) ) start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2264 italic_U \u2229 italic_D . By hypothesis, U\u2062Ui\u2032/Ui\u2032=U/Ui\u2032\ud835\udc48superscriptsubscript\ud835\udc48\ud835\udc56\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc48superscriptsubscript\ud835\udc48\ud835\udc56\u2032UU_{i}^{\\prime}/U_{i}^{\\prime}=U/U_{i}^{\\prime}italic_U italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = italic_U / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in\nG/Ui\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48\ud835\udc56\u2032G/U_{i}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT and so U\ud835\udc48Uitalic_U is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G by Lemma 2.1(3), a\ncontradiction.\nTherefore Statement (1) holds. (2) Assume that this is false. Let N=U\ud835\udd11\ud835\udc41superscript\ud835\udc48\ud835\udd11N=U^{{\\mathfrak{N}}}italic_N = italic_U start_POSTSUPERSCRIPT fraktur_N end_POSTSUPERSCRIPT be the nilpotent residual of U\ud835\udc48Uitalic_U.\nThen N<U\ud835\udc41\ud835\udc48N<Uitalic_N < italic_U since U\ud835\udc48Uitalic_U supersoluble, so N\ud835\udc41Nitalic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G by\nthe minimality of U\ud835\udc48Uitalic_U.\nIt is also clear that\nevery proper subgroup S\ud835\udc46Sitalic_S of U\ud835\udc48Uitalic_U with\nN\u2264S\ud835\udc41\ud835\udc46N\\leq Sitalic_N \u2264 italic_S is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal in G\ud835\udc3aGitalic_G, so S\ud835\udc46Sitalic_S is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G.\nTherefore, if U\ud835\udc48Uitalic_U has at least two distinct\nmaximal subgroups S\ud835\udc46Sitalic_S and W\ud835\udc4aWitalic_W\nsuch that N\u2264S\u2229W\ud835\udc41\ud835\udc46\ud835\udc4aN\\leq S\\cap Witalic_N \u2264 italic_S \u2229 italic_W, then U=\u27e8S,W\u27e9\ud835\udc48\ud835\udc46\ud835\udc4aU=\\langle S,W\\rangleitalic_U = \u27e8 italic_S , italic_W \u27e9 is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in\nG\ud835\udc3aGitalic_G by Lemma 2.1(4),\ncontrary to the choice of U\ud835\udc48Uitalic_U.\nHence U/N\ud835\udc48\ud835\udc41U/Nitalic_U / italic_N\nis a cyclic p\ud835\udc5dpitalic_p-group for some prime p\ud835\udc5dpitalic_p and N\u22601\ud835\udc411N\\neq 1italic_N \u2260 1 since U\ud835\udc48Uitalic_U is not cyclic. Now we show that U\ud835\udc48Uitalic_U is a P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group. Let S\ud835\udc46Sitalic_S be a proper\nsubnormal subgroup of U\ud835\udc48Uitalic_U. Then S\ud835\udc46Sitalic_S is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal in G\ud835\udc3aGitalic_G, so\nS\ud835\udc46Sitalic_S is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G and hence S\ud835\udc46Sitalic_S is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in U\ud835\udc48Uitalic_U by\nLemma 2.1(1). Therefore S\ud835\udc46Sitalic_S is\nquasinormal in U\ud835\udc48Uitalic_U by Theorem\u00a0A. Therefore\nU\ud835\udc48Uitalic_U is a soluble P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group, so N=U\ud835\udd11\ud835\udc41superscript\ud835\udc48\ud835\udd11N=U^{{\\mathfrak{N}}}italic_N = italic_U start_POSTSUPERSCRIPT fraktur_N end_POSTSUPERSCRIPT is a\nHall abelian subgroup of U\ud835\udc48Uitalic_U by[14, Theorem 2.1.11]. It follows that N\u2264U\ud835\udd04\u2217\ud835\udc41superscript\ud835\udc48superscript\ud835\udd04N\\leq U^{{\\mathfrak{A}^{*}}}italic_N \u2264 italic_U start_POSTSUPERSCRIPT fraktur_A start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT and so U\ud835\udd04\u2217=N\u2062V,superscript\ud835\udc48superscript\ud835\udd04\ud835\udc41\ud835\udc49U^{{\\mathfrak{A}^{*}}}=NV,italic_U start_POSTSUPERSCRIPT fraktur_A start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT = italic_N italic_V , where\nV\ud835\udc49Vitalic_V is a maximal\nsubgroup of a cyclic Sylow p\ud835\udc5dpitalic_p-subgroup P\u2243U/Nsimilar-to-or-equals\ud835\udc43\ud835\udc48\ud835\udc41P\\simeq U/Nitalic_P \u2243 italic_U / italic_N of U\ud835\udc48Uitalic_U.\nHence\nN\u2062V\ud835\udc41\ud835\udc49NVitalic_N italic_V is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G and N\u2062V\ud835\udc41\ud835\udc49NVitalic_N italic_V is subnormal in G\ud835\udc3aGitalic_G by Lemma 2.3(4).\nTherefore\nN\u2062V\ud835\udc41\ud835\udc49NVitalic_N italic_V is quasinormal in G\ud835\udc3aGitalic_G by Theorem\u00a0A. Assume that for some minimal normal\nsubgroup R\ud835\udc45Ritalic_R of G\ud835\udc3aGitalic_G we have R\u2264(N\u2062V)G\ud835\udc45subscript\ud835\udc41\ud835\udc49\ud835\udc3aR\\leq(NV)_{G}italic_R \u2264 ( italic_N italic_V ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT. Then U/R\ud835\udc48\ud835\udc45U/Ritalic_U / italic_R is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal\nin G/R\ud835\udc3a\ud835\udc45G/Ritalic_G / italic_R\nby hypothesis, so U\ud835\udc48Uitalic_U is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G, a contradiction.\nTherefore\n(N\u2062V)G=1subscript\ud835\udc41\ud835\udc49\ud835\udc3a1(NV)_{G}=1( italic_N italic_V ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = 1, so N\u2062V\ud835\udc41\ud835\udc49NVitalic_N italic_V is nilpotent and N\u2062V\u2264Z\u221e\u2062(G)\ud835\udc41\ud835\udc49subscript\ud835\udc4d\ud835\udc3aNV\\leq Z_{\\infty}(G)italic_N italic_V \u2264 italic_Z start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT ( italic_G )\nby [14, Corollary 1.5.6] and then U=N\u2062P\ud835\udc48\ud835\udc41\ud835\udc43U=NPitalic_U = italic_N italic_P is nilpotent, so N=1\ud835\udc411N=1italic_N = 1, a contradcition.\nTherefore Statement (2) holds.\nThe lemma is proved. Lemma 2.7. Suppose that a soluble group G=D\u22caM\ud835\udc3aright-normal-factor-semidirect-product\ud835\udc37\ud835\udc40G=D\\rtimes Mitalic_G = italic_D \u22ca italic_M satisfies\nConditions (i), (ii) and (iii) in Theorem C. If A\ud835\udc34Aitalic_A\nis a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-primary \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal subgroup of G\ud835\udc3aGitalic_G such that\nA\u2264M\ud835\udc34\ud835\udc40A\\leq Mitalic_A \u2264 italic_M, then D\u2264CG\u2062(A)\ud835\udc37subscript\ud835\udc36\ud835\udc3a\ud835\udc34D\\leq C_{G}(A)italic_D \u2264 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A ). Proof. Let A\ud835\udc34Aitalic_A be a \u03c3isubscript\ud835\udf0e\ud835\udc56\\sigma_{i}italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-group and x\ud835\udc65xitalic_x an element\nof prime power order pnsuperscript\ud835\udc5d\ud835\udc5bp^{n}italic_p start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT of D\ud835\udc37Ditalic_D. Let Hksubscript\ud835\udc3b\ud835\udc58H_{k}italic_H start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT be a Hall\n\u03c3ksubscript\ud835\udf0e\ud835\udc58\\sigma_{k}italic_\u03c3 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT-subgroup of G\ud835\udc3aGitalic_G. Then, by hypothesis,\nHk=O\u03c3k\u2062(D)\u00d7Sksubscript\ud835\udc3b\ud835\udc58subscript\ud835\udc42subscript\ud835\udf0e\ud835\udc58\ud835\udc37subscript\ud835\udc46\ud835\udc58H_{k}=O_{\\sigma_{k}}(D)\\times S_{k}italic_H start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_O start_POSTSUBSCRIPT italic_\u03c3 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) \u00d7 italic_S start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, where O\u03c3k\u2062(D)subscript\ud835\udc42subscript\ud835\udf0e\ud835\udc58\ud835\udc37O_{\\sigma_{k}}(D)italic_O start_POSTSUBSCRIPT italic_\u03c3 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) and Sksubscript\ud835\udc46\ud835\udc58S_{k}italic_S start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT are\nHall subgroups of G\ud835\udc3aGitalic_G. Since A\ud835\udc34Aitalic_A is\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal in G\ud835\udc3aGitalic_G, A\u2264Hi\ud835\udc34subscript\ud835\udc3b\ud835\udc56A\\leq H_{i}italic_A \u2264 italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT by Lemma 2.6(7) in [3]. On the other\nhand, since\nA\u2264M\ud835\udc34\ud835\udc40A\\leq Mitalic_A \u2264 italic_M, A\u2229D=1\ud835\udc34\ud835\udc371A\\cap D=1italic_A \u2229 italic_D = 1. Therefore\nA=(A\u2229O\u03c3i\u2062(D))\u00d7(A\u2229Si)=A\u2229Si\ud835\udc34\ud835\udc34subscript\ud835\udc42subscript\ud835\udf0e\ud835\udc56\ud835\udc37\ud835\udc34subscript\ud835\udc46\ud835\udc56\ud835\udc34subscript\ud835\udc46\ud835\udc56A=(A\\cap O_{\\sigma_{i}}(D))\\times(A\\cap S_{i})=A\\cap S_{i}italic_A = ( italic_A \u2229 italic_O start_POSTSUBSCRIPT italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) ) \u00d7 ( italic_A \u2229 italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_A \u2229 italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT,\nso A\u2264Si\ud835\udc34subscript\ud835\udc46\ud835\udc56A\\leq S_{i}italic_A \u2264 italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and hence O\u03c3i\u2062(D)\u2264CG\u2062(A)subscript\ud835\udc42subscript\ud835\udf0e\ud835\udc56\ud835\udc37subscript\ud835\udc36\ud835\udc3a\ud835\udc34O_{\\sigma_{i}}(D)\\leq C_{G}(A)italic_O start_POSTSUBSCRIPT italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) \u2264 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A ). Now, let k\u2260i\ud835\udc58\ud835\udc56k\\neq iitalic_k \u2260 italic_i.\nThen\nA\ud835\udc34Aitalic_A is a Hall \u03c3isubscript\ud835\udf0e\ud835\udc56\\sigma_{i}italic_\u03c3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-subgroup of V:=O\u03c3k\u2062(D)\u2062Aassign\ud835\udc49subscript\ud835\udc42subscript\ud835\udf0e\ud835\udc58\ud835\udc37\ud835\udc34V:=O_{\\sigma_{k}}(D)Aitalic_V := italic_O start_POSTSUBSCRIPT italic_\u03c3 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) italic_A and A\ud835\udc34Aitalic_A is\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subnormal\nin V\ud835\udc49Vitalic_V by Lemma 2.6(1) in [3], so V=O\u03c3k\u2062(D)\u00d7A\ud835\udc49subscript\ud835\udc42subscript\ud835\udf0e\ud835\udc58\ud835\udc37\ud835\udc34V=O_{\\sigma_{k}}(D)\\times Aitalic_V = italic_O start_POSTSUBSCRIPT italic_\u03c3 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) \u00d7 italic_A by\nLemma 2.6(10) in [3] and hence D\u2264CG\u2062(A)\ud835\udc37subscript\ud835\udc36\ud835\udc3a\ud835\udc34D\\leq C_{G}(A)italic_D \u2264 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A ).\nThe lemma is proved. Lemma 2.8 (See Lemma 5.1.9 in [1]).\nLet A\ud835\udc34Aitalic_A be a subgroup of prime power order of G\ud835\udc3aGitalic_G. (1) If A\ud835\udc34Aitalic_A is modular but not subnormal in G\ud835\udc3aGitalic_G, then where AG/AGsuperscript\ud835\udc34\ud835\udc3asubscript\ud835\udc34\ud835\udc3aA^{G}/A_{G}italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a non-abelian\nP\ud835\udc43Pitalic_P-group of order prime to |K/AG|\ud835\udc3esubscript\ud835\udc34\ud835\udc3a|K/A_{G}|| italic_K / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT |. (2) A\ud835\udc34Aitalic_A is modular\nin G\ud835\udc3aGitalic_G if and only if A\ud835\udc34Aitalic_A is modular in \u27e8x,A\u27e9\ud835\udc65\ud835\udc34\\langle x,A\\rangle\u27e8 italic_x , italic_A \u27e9 for all x\u2208G\ud835\udc65\ud835\udc3ax\\in Gitalic_x \u2208 italic_G\nof prime power order. Lemma 2.9. If G/Z\ud835\udc3a\ud835\udc4dG/Zitalic_G / italic_Z is p\ud835\udc5dpitalic_p-closed for some prime p\ud835\udc5dpitalic_p and\nZ\u2264Z\u221e\u2062(G)\ud835\udc4dsubscript\ud835\udc4d\ud835\udc3aZ\\leq Z_{\\infty}(G)italic_Z \u2264 italic_Z start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT ( italic_G ), then G\ud835\udc3aGitalic_G is p\ud835\udc5dpitalic_p-closed. Proof.  Since Z\u2264Z\u221e\u2062(G)\ud835\udc4dsubscript\ud835\udc4d\ud835\udc3aZ\\leq Z_{\\infty}(G)italic_Z \u2264 italic_Z start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT ( italic_G ), for a\nSylow p\ud835\udc5dpitalic_p-subgroup Zpsubscript\ud835\udc4d\ud835\udc5dZ_{p}italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT of Z\ud835\udc4dZitalic_Z we have\nZ=Zp\u00d7W\ud835\udc4dsubscript\ud835\udc4d\ud835\udc5d\ud835\udc4aZ=Z_{p}\\times Witalic_Z = italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00d7 italic_W, where Zpsubscript\ud835\udc4d\ud835\udc5dZ_{p}italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT and W\ud835\udc4aWitalic_W\nare characteristic in Z\ud835\udc4dZitalic_Z and so normal in G\ud835\udc3aGitalic_G. Let P/Z\ud835\udc43\ud835\udc4dP/Zitalic_P / italic_Z be a normal Sylow p\ud835\udc5dpitalic_p-subgroup of G/Z\ud835\udc3a\ud835\udc4dG/Zitalic_G / italic_Z and V\ud835\udc49Vitalic_V a Sylow\np\ud835\udc5dpitalic_p-subgroup of P\ud835\udc43Pitalic_P. Then Zp\u2264Vsubscript\ud835\udc4d\ud835\udc5d\ud835\udc49Z_{p}\\leq Vitalic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u2264 italic_V and P=V\u2062Z=V\u00d7W\ud835\udc43\ud835\udc49\ud835\udc4d\ud835\udc49\ud835\udc4aP=VZ=V\\times Witalic_P = italic_V italic_Z = italic_V \u00d7 italic_W since\nW\u2264Z\u221e\u2062(G)\u2229P\u2264Z\u221e\u2062(P)\ud835\udc4asubscript\ud835\udc4d\ud835\udc3a\ud835\udc43subscript\ud835\udc4d\ud835\udc43W\\leq Z_{\\infty}(G)\\cap P\\leq Z_{\\infty}(P)italic_W \u2264 italic_Z start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT ( italic_G ) \u2229 italic_P \u2264 italic_Z start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT ( italic_P ). Therefore V\ud835\udc49Vitalic_V is characteristic in P\ud835\udc43Pitalic_P and\nso normal in G\ud835\udc3aGitalic_G. The lemma is proved. Lemma 2.10. Let G=Q\u22caP\ud835\udc3aright-normal-factor-semidirect-product\ud835\udc44\ud835\udc43G=Q\\rtimes Pitalic_G = italic_Q \u22ca italic_P be\na non-abelian P\ud835\udc43Pitalic_P-group of type (q,p)\ud835\udc5e\ud835\udc5d(q,p)( italic_q , italic_p ). (1) PG=Gsuperscript\ud835\udc43\ud835\udc3a\ud835\udc3aP^{G}=Gitalic_P start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_G. (2) G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N is a non-abelian P\ud835\udc43Pitalic_P-group of type (q,p)\ud835\udc5e\ud835\udc5d(q,p)( italic_q , italic_p ) for\nevery proper normal subgroup N\ud835\udc41Nitalic_N of G\ud835\udc3aGitalic_G. Proof. See Lemma 2.2.2 in [1]. Lemma 2.11. If A\ud835\udc34Aitalic_A and B\ud835\udc35Bitalic_B are normal subgroups of G\ud835\udc3aGitalic_G, then every chief\nfactor H/K\ud835\udc3b\ud835\udc3eH/Kitalic_H / italic_K of G\ud835\udc3aGitalic_G below A\u2062B\ud835\udc34\ud835\udc35ABitalic_A italic_B is G\ud835\udc3aGitalic_G-isomorphic to either a chiew factor of\nG\ud835\udc3aGitalic_G below A\ud835\udc34Aitalic_A or a chief factor of G\ud835\udc3aGitalic_G between B\u2229A\ud835\udc35\ud835\udc34B\\cap Aitalic_B \u2229 italic_A and B\ud835\udc35Bitalic_B. Proof. This assertion follows from the G\ud835\udc3aGitalic_G-isomorphism A\u2062B/A\u2243B/(B\u2229A)similar-to-or-equals\ud835\udc34\ud835\udc35\ud835\udc34\ud835\udc35\ud835\udc35\ud835\udc34AB/A\\simeq B/(B\\cap A)italic_A italic_B / italic_A \u2243 italic_B / ( italic_B \u2229 italic_A ) and\nthe Jordan-H\u00f6lder theorem for the \u03a9\u03a9\\Omegaroman_\u03a9-composition seties of\na group (see [20, Chapter A, 3.2]). From Proposition 2.2.8 in [14] we get the following useful lemma. Lemma 2.12. Let \ud835\udd09\ud835\udd09\\mathfrak{F}fraktur_F be a non-empty hereditary formation. (1) If\nN\ud835\udc41Nitalic_N is a normal subgroup of G\ud835\udc3aGitalic_G, then\n(G/N)\ud835\udd09=G\ud835\udd09\u2062N/N.superscript\ud835\udc3a\ud835\udc41\ud835\udd09superscript\ud835\udc3a\ud835\udd09\ud835\udc41\ud835\udc41(G/N)^{\\mathfrak{F}}=G^{\\mathfrak{F}}N/N.( italic_G / italic_N ) start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT = italic_G start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT italic_N / italic_N . (2) If\nE\ud835\udc38Eitalic_E is a subgroup of G\ud835\udc3aGitalic_G, then\nE\ud835\udd09\u2264G\ud835\udd09superscript\ud835\udc38\ud835\udd09superscript\ud835\udc3a\ud835\udd09E^{\\mathfrak{F}}\\leq G^{\\mathfrak{F}}italic_E start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT \u2264 italic_G start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT and N\u2062(N\u2062E)\ud835\udd09=N\u2062E\ud835\udd09\ud835\udc41superscript\ud835\udc41\ud835\udc38\ud835\udd09\ud835\udc41superscript\ud835\udc38\ud835\udd09N(NE)^{\\mathfrak{F}}=NE^{\\mathfrak{F}}italic_N ( italic_N italic_E ) start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT = italic_N italic_E start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT. Lemma 2.13. Let (D,Z\u2062(D);U1,\u2026,Uk)\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\u2026subscript\ud835\udc48\ud835\udc58(D,Z(D);U_{1},\\ldots,U_{k})( italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) be\na Robinson complex of G\ud835\udc3aGitalic_G\nand N\ud835\udc41Nitalic_N a normal subgroup of G\ud835\udc3aGitalic_G. (1) Ui\u2032/(Ui\u2032\u2229Z\u2062(D))superscriptsubscript\ud835\udc48\ud835\udc56\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4d\ud835\udc37U_{i}^{\\prime}/(U_{i}^{\\prime}\\cap Z(D))italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2229 italic_Z ( italic_D ) ) is a simple non-abelian group and\nUi\u2032\u2229Z\u2062(D)=\u03a6\u2062(Ui\u2032)=Z\u2062(Ui\u2032)superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4d\ud835\udc37\u03a6superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}\\cap Z(D)=\\Phi(U_{i}^{\\prime})=Z(U_{i}^{\\prime})italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2229 italic_Z ( italic_D ) = roman_\u03a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) = italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ). In particular, Ui\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is a\nquasi-simple group. (2) If N=Ui\u2032\ud835\udc41superscriptsubscript\ud835\udc48\ud835\udc56\u2032N=U_{i}^{\\prime}italic_N = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT and k\u22601\ud835\udc581k\\neq 1italic_k \u2260 1, then (D/N,Z\u2062(D/N);U1\u2062N/N,\u2026,Ui\u22121\u2062N/N,Ui+1\u2062N/N,\u22ef,N\u2062Uk/N)\ud835\udc37\ud835\udc41\ud835\udc4d\ud835\udc37\ud835\udc41subscript\ud835\udc481\ud835\udc41\ud835\udc41\u2026subscript\ud835\udc48\ud835\udc561\ud835\udc41\ud835\udc41subscript\ud835\udc48\ud835\udc561\ud835\udc41\ud835\udc41\u22ef\ud835\udc41subscript\ud835\udc48\ud835\udc58\ud835\udc41(D/N,Z(D/N);U_{1}N/N,\\ldots,U_{i-1}N/N,U_{i+1}N/N,\\cdots,NU_{k}/N)( italic_D / italic_N , italic_Z ( italic_D / italic_N ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N / italic_N , \u2026 , italic_U start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT italic_N / italic_N , italic_U start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT italic_N / italic_N , \u22ef , italic_N italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_N ) is\na Robinson complex of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N and Ui/N=Z\u2062(D)\u2062N/N=Z\u2062(D/N)subscript\ud835\udc48\ud835\udc56\ud835\udc41\ud835\udc4d\ud835\udc37\ud835\udc41\ud835\udc41\ud835\udc4d\ud835\udc37\ud835\udc41U_{i}/N=Z(D)N/N=Z(D/N)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_N = italic_Z ( italic_D ) italic_N / italic_N = italic_Z ( italic_D / italic_N ). (3) If N\ud835\udc41Nitalic_N is nilpotent, then (D\u2062N/N,Z\u2062(D)\u2062N/N;U1\u2062N/N,\u2026,N\u2062Uk/N)\ud835\udc37\ud835\udc41\ud835\udc41\ud835\udc4d\ud835\udc37\ud835\udc41\ud835\udc41subscript\ud835\udc481\ud835\udc41\ud835\udc41\u2026\ud835\udc41subscript\ud835\udc48\ud835\udc58\ud835\udc41(DN/N,Z(D)N/N;U_{1}N/N,\\ldots,NU_{k}/N)( italic_D italic_N / italic_N , italic_Z ( italic_D ) italic_N / italic_N ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N / italic_N , \u2026 , italic_N italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_N ) is\na Robinson complex of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N and Z\u2062(D)\u2062N/N=Z\u2062(D/N)\ud835\udc4d\ud835\udc37\ud835\udc41\ud835\udc41\ud835\udc4d\ud835\udc37\ud835\udc41Z(D)N/N=Z(D/N)italic_Z ( italic_D ) italic_N / italic_N = italic_Z ( italic_D / italic_N ). (4) If p\u2208\u03c0\u2062(Z\u2062(D))\ud835\udc5d\ud835\udf0b\ud835\udc4d\ud835\udc37p\\in\\pi(Z(D))italic_p \u2208 italic_\u03c0 ( italic_Z ( italic_D ) ), then p\u2208\u03c0\u2062(Z\u2062(Ui\u2032))\ud835\udc5d\ud835\udf0b\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032p\\in\\pi(Z(U_{i}^{\\prime}))italic_p \u2208 italic_\u03c0 ( italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) ) for some i\ud835\udc56iitalic_i. In particular,\np\u2208{2,3}\ud835\udc5d23p\\in\\{2,3\\}italic_p \u2208 { 2 , 3 }. Proof. Let Z:=Z\u2062(D)=\u03a6\u2062(D)assign\ud835\udc4d\ud835\udc4d\ud835\udc37\u03a6\ud835\udc37Z:=Z(D)=\\Phi(D)italic_Z := italic_Z ( italic_D ) = roman_\u03a6 ( italic_D ). (1)\nFirst observe that Ui=Ui\u2032\u2062Z=Ui\ud835\udd16\u2062Zsubscript\ud835\udc48\ud835\udc56superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\ud835\udd16\ud835\udc4dU_{i}=U_{i}^{\\prime}Z=U_{i}^{\\mathfrak{S}}Zitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_Z = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT italic_Z,\nwhere \ud835\udd16\ud835\udd16\\mathfrak{S}fraktur_S is the class of all soluble groups,\nsince Ui/Zsubscript\ud835\udc48\ud835\udc56\ud835\udc4dU_{i}/Zitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z is a simple non-abelian group and so Ui\ud835\udd16\u2264Ui\u2032\u2264Ui\ud835\udd16superscriptsubscript\ud835\udc48\ud835\udc56\ud835\udd16superscriptsubscript\ud835\udc48\ud835\udc56\u2032superscriptsubscript\ud835\udc48\ud835\udc56\ud835\udd16U_{i}^{\\mathfrak{S}}\\leq U_{i}^{\\prime}\\leq U_{i}^{\\mathfrak{S}}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT \u2264 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2264 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT. Hence Ui\ud835\udd16=Ui\u2032superscriptsubscript\ud835\udc48\ud835\udc56\ud835\udd16superscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\mathfrak{S}}=U_{i}^{\\prime}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is perfect.\nOn the other hand,\nUi/Z=Ui\u2032\u2062Z/Z\u2243Ui\u2032/(Ui\u2032\u2229Z)subscript\ud835\udc48\ud835\udc56\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4d\ud835\udc4dsimilar-to-or-equalssuperscriptsubscript\ud835\udc48\ud835\udc56\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4dU_{i}/Z=U_{i}^{\\prime}Z/Z\\simeq U_{i}^{\\prime}/(U_{i}^{\\prime}\\cap Z)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_Z / italic_Z \u2243 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2229 italic_Z ) is a simple non-abelian group.\nTherefore Ui\u2032\u2229Z=\u03a6\u2062(Ui\u2032)=Z\u2062(Ui\u2032)superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4d\u03a6superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}\\cap Z=\\Phi(U_{i}^{\\prime})=Z(U_{i}^{\\prime})italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2229 italic_Z = roman_\u03a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) = italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) since \u03a6\u2062(Ui\u2032)\u2264\u03a6\u2062(D)\u03a6superscriptsubscript\ud835\udc48\ud835\udc56\u2032\u03a6\ud835\udc37\\Phi(U_{i}^{\\prime})\\leq\\Phi(D)roman_\u03a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) \u2264 roman_\u03a6 ( italic_D ). (2), (3) See Remark 1.6.8 in [14] or Lemma 3.1 in [11]. (4) Assume that p\u2209\u03c0\u2062(Z\u2062(Ui\u2032))\ud835\udc5d\ud835\udf0b\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032p\\not\\in\\pi(Z(U_{i}^{\\prime}))italic_p \u2209 italic_\u03c0 ( italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) ) for all i\ud835\udc56iitalic_i and let Z=Zp\u00d7V\ud835\udc4dsubscript\ud835\udc4d\ud835\udc5d\ud835\udc49Z=Z_{p}\\times Vitalic_Z = italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00d7 italic_V,\nwhere\nZpsubscript\ud835\udc4d\ud835\udc5dZ_{p}italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT is the Sylow p\ud835\udc5dpitalic_p-subgroup of Z\ud835\udc4dZitalic_Z. Then Zp\u2229Ui\u2032=1subscript\ud835\udc4d\ud835\udc5dsuperscriptsubscript\ud835\udc48\ud835\udc56\u20321Z_{p}\\cap U_{i}^{\\prime}=1italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = 1, so\nUi\u2032\u2229Z=Ui\u2032\u2229V=\u03a6\u2062(Ui\u2032)=Z\u2062(Ui\u2032)superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc49\u03a6superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}\\cap Z=U_{i}^{\\prime}\\cap V=\\Phi(U_{i}^{\\prime})=Z(U_{i}^{\\prime})italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2229 italic_Z = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2229 italic_V = roman_\u03a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) = italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) for all i\ud835\udc56iitalic_i.\nOn the other hand, D=U1\u22efUk=ZU1\u2032\u22efUk\u2032=Zp(V(U1\u2032\u22efUk\u2032)D=U_{1}\\cdots U_{k}=ZU_{1}^{\\prime}\\cdots U_{k}^{\\prime}=Z_{p}(V(U_{1}^{\\prime%\n}\\cdots U_{k}^{\\prime})italic_D = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_Z italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_V ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ), so D=V\u2062(U1\u2032\u2062\u22ef\u2062Uk\u2032)\ud835\udc37\ud835\udc49superscriptsubscript\ud835\udc481\u2032\u22efsuperscriptsubscript\ud835\udc48\ud835\udc58\u2032D=V(U_{1}^{\\prime}\\cdots U_{k}^{\\prime})italic_D = italic_V ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) since\nZp\u2264\u03a6\u2062(D)subscript\ud835\udc4d\ud835\udc5d\u03a6\ud835\udc37Z_{p}\\leq\\Phi(D)italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u2264 roman_\u03a6 ( italic_D ). Hence Z\u2264V\u2062(U1\u2032\u2062\u22ef\u2062Uk\u2032)\ud835\udc4d\ud835\udc49superscriptsubscript\ud835\udc481\u2032\u22efsuperscriptsubscript\ud835\udc48\ud835\udc58\u2032Z\\leq V(U_{1}^{\\prime}\\cdots U_{k}^{\\prime})italic_Z \u2264 italic_V ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ). But V\ud835\udc49Vitalic_V and\nevery subgroup Ui\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT has no a composition factor of order p\ud835\udc5dpitalic_p by Lemma 2.11,\na contradiction. Therefore p\u2208\u03c0\u2062(Z\u2062(Ui\u2032))\ud835\udc5d\ud835\udf0b\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032p\\in\\pi(Z(U_{i}^{\\prime}))italic_p \u2208 italic_\u03c0 ( italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) ) for some i\ud835\udc56iitalic_i, where\nUi\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is a quasi-simple group by Part (1). But then |Z\u2062(Ui\u2032)|\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032|Z(U_{i}^{\\prime})|| italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) |\ndivides the order of the Schur multiplier M\u2062(Ui\u2032/Z\u2062(Ui\u2032))\ud835\udc40superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032M(U_{i}^{\\prime}/Z(U_{i}^{\\prime}))italic_M ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) ) of Ui\u2032/Z\u2062(Ui\u2032)superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}/Z(U_{i}^{\\prime})italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ).\nHence \u03c0\u2062(Z\u2062(Ui\u2032))\u2286{2,3}\ud835\udf0b\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u203223\\pi(Z(U_{i}^{\\prime}))\\subseteq\\{2,3\\}italic_\u03c0 ( italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) ) \u2286 { 2 , 3 } (see Section 4.15(A)\nin [22, Ch. 4]. Therefore p\u2208{2,3}\ud835\udc5d23p\\in\\{2,3\\}italic_p \u2208 { 2 , 3 }.\nHence we have (4).\nThe lemma is proved. Lemma 2.14. Let U\ud835\udc48Uitalic_U and N\u2062\u22b4\u2062G\ud835\udc41\u22b4\ud835\udc3aN\\trianglelefteq Gitalic_N \u22b4 italic_G be subgroups of G\ud835\udc3aGitalic_G, where\nU\ud835\udc48Uitalic_U is of prime power order. Suppose that U\u2062N/N\ud835\udc48\ud835\udc41\ud835\udc41UN/Nitalic_U italic_N / italic_N is a modular\nnon-subnormal subgroup of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N.\nThen where UG\u2062N/(U\u2062N)Gsuperscript\ud835\udc48\ud835\udc3a\ud835\udc41subscript\ud835\udc48\ud835\udc41\ud835\udc3aU^{G}N/(UN)_{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_N / ( italic_U italic_N ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT\nis a non-abelian P\ud835\udc43Pitalic_P-group of order prime to |K/U\u2062NG|\ud835\udc3e\ud835\udc48subscript\ud835\udc41\ud835\udc3a|K/UN_{G}|| italic_K / italic_U italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT |. Proof. The subgroup U\u2062N/N\u2243U/(U\u2229N)similar-to-or-equals\ud835\udc48\ud835\udc41\ud835\udc41\ud835\udc48\ud835\udc48\ud835\udc41UN/N\\simeq U/(U\\cap N)italic_U italic_N / italic_N \u2243 italic_U / ( italic_U \u2229 italic_N ) of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N is of prime power order,\nso we can apply Lemma 2.8(1). First observe that (U\u2062N/N)G/N=(U\u2062N)G/Nsubscript\ud835\udc48\ud835\udc41\ud835\udc41\ud835\udc3a\ud835\udc41subscript\ud835\udc48\ud835\udc41\ud835\udc3a\ud835\udc41(UN/N)_{G/N}=(UN)_{G}/N( italic_U italic_N / italic_N ) start_POSTSUBSCRIPT italic_G / italic_N end_POSTSUBSCRIPT = ( italic_U italic_N ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT / italic_N and\n(U\u2062N/N)G/N=(U\u2062N)G/N=UG\u2062N/Nsuperscript\ud835\udc48\ud835\udc41\ud835\udc41\ud835\udc3a\ud835\udc41superscript\ud835\udc48\ud835\udc41\ud835\udc3a\ud835\udc41superscript\ud835\udc48\ud835\udc3a\ud835\udc41\ud835\udc41(UN/N)^{G/N}=(UN)^{G}/N=U^{G}N/N( italic_U italic_N / italic_N ) start_POSTSUPERSCRIPT italic_G / italic_N end_POSTSUPERSCRIPT = ( italic_U italic_N ) start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_N = italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_N / italic_N. Therefore, by Lemma 2.8(1), where is a non-abelian\nP\ud835\udc43Pitalic_P-group of order prime to |(K/N)/(U\u2062N/N)G/N|\ud835\udc3e\ud835\udc41subscript\ud835\udc48\ud835\udc41\ud835\udc41\ud835\udc3a\ud835\udc41|(K/N)/(UN/N)_{G/N}|| ( italic_K / italic_N ) / ( italic_U italic_N / italic_N ) start_POSTSUBSCRIPT italic_G / italic_N end_POSTSUBSCRIPT | and so to\n|K/(U\u2062N)G|\ud835\udc3esubscript\ud835\udc48\ud835\udc41\ud835\udc3a|K/(UN)_{G}|| italic_K / ( italic_U italic_N ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT |.\nThe lemma is proved. A group G\ud835\udc3aGitalic_G is called \u03c0\ud835\udf0b\\piitalic_\u03c0-closed if G\ud835\udc3aGitalic_G has a normal Hall\n\u03c0\ud835\udf0b\\piitalic_\u03c0-subgroup. The following lemma is well-known [20, Chapter A, 13.2]. Lemma 2.15.  If H\ud835\udc3bHitalic_H is a normal\nsubgroup of G\ud835\udc3aGitalic_G and H/(H\u2229\u03a6\u2062(G))\ud835\udc3b\ud835\udc3b\u03a6\ud835\udc3aH/(H\\cap\\Phi(G))italic_H / ( italic_H \u2229 roman_\u03a6 ( italic_G ) ) is \u03c0\ud835\udf0b\\piitalic_\u03c0-closed, then\nH\ud835\udc3bHitalic_H is \u03c0\ud835\udf0b\\piitalic_\u03c0-closed. Recall that a group G\ud835\udc3aGitalic_G is said to be a P\u2217superscript\ud835\udc43P^{*}italic_P start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT-group if G=A\u22ca\u27e8t\u27e9\ud835\udc3aright-normal-factor-semidirect-product\ud835\udc34delimited-\u27e8\u27e9\ud835\udc61G=A\\rtimes\\langle t\\rangleitalic_G = italic_A \u22ca \u27e8 italic_t \u27e9,\nwhere A\ud835\udc34Aitalic_A is an elementary\nabelian subgroup of G\ud835\udc3aGitalic_G, |t|=rn\ud835\udc61superscript\ud835\udc5f\ud835\udc5b|t|=r^{n}| italic_t | = italic_r start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT for some prime r\ud835\udc5fritalic_r and t\ud835\udc61titalic_t induces a power\nautomorphism of prime order on A\ud835\udc34Aitalic_A [1, p. 69]. Lemma 2.16.  Let G=A\u22ca\u27e8t\u27e9\ud835\udc3aright-normal-factor-semidirect-product\ud835\udc34delimited-\u27e8\u27e9\ud835\udc61G=A\\rtimes\\langle t\\rangleitalic_G = italic_A \u22ca \u27e8 italic_t \u27e9 be a P\u2217superscript\ud835\udc43P^{*}italic_P start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT-group and let\n|\u27e8t\u27e9|=pn.delimited-\u27e8\u27e9\ud835\udc61superscript\ud835\udc5d\ud835\udc5b|\\langle t\\rangle|=p^{n}.| \u27e8 italic_t \u27e9 | = italic_p start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT . Then Z\u2062(G)=\u27e8tp\u27e9=\u03a6\u2062(G)\ud835\udc4d\ud835\udc3adelimited-\u27e8\u27e9superscript\ud835\udc61\ud835\udc5d\u03a6\ud835\udc3aZ(G)=\\langle t^{p}\\rangle=\\Phi(G)italic_Z ( italic_G ) = \u27e8 italic_t start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT \u27e9 = roman_\u03a6 ( italic_G ), G/Z\u2062(G)\ud835\udc3a\ud835\udc4d\ud835\udc3aG/Z(G)italic_G / italic_Z ( italic_G ) is\na non-abelian P\ud835\udc43Pitalic_P-group and the lattice \u2112\u2062(G)\u2112\ud835\udc3a{\\cal L}(G)caligraphic_L ( italic_G ) is modular. The following lemma is a corollary of Theorem C. Lemma 2.17.  If G\ud835\udc3aGitalic_G is a soluible Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group, then\nevery subgroup of G\ud835\udc3aGitalic_G is a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group. Proof of Theorem E.\nFirst assume that G\ud835\udc3aGitalic_G is a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group.\nThen G\ud835\udc3aGitalic_G is a P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group and every quotient G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N is\na Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group by Lemma 2.4. Let\nD\ud835\udc37Ditalic_D be the soluble residual of G\ud835\udc3aGitalic_G. Then D\ud835\udc37Ditalic_D is perfect and\nG/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is a soluble group Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group, so\nCondition (i) holds for G\ud835\udc3aGitalic_G. Now assume that D\u22601\ud835\udc371D\\neq 1italic_D \u2260 1. Then, in view of Theorem D,\nG\ud835\udc3aGitalic_G has a Robinson complex\n(D,Z(D);(D,Z(D);( italic_D , italic_Z ( italic_D ) ; U1,\u2026,Uk)U_{1},\\ldots,U_{k})italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) such that\nfor any set {i1,\u2026,ir}\u2286{1,\u2026,k}subscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc5f1\u2026\ud835\udc58\\{i_{1},\\ldots,i_{r}\\}\\subseteq\\{1,\\ldots,k\\}{ italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u2286 { 1 , \u2026 , italic_k }, where\n1\u2264r<k1\ud835\udc5f\ud835\udc581\\leq r<k1 \u2264 italic_r < italic_k, G\ud835\udc3aGitalic_G and G/Ui1\u2032\u2062\u22ef\u2062Uir\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48subscript\ud835\udc561\u2032\u22efsuperscriptsubscript\ud835\udc48subscript\ud835\udc56\ud835\udc5f\u2032G/U_{i_{1}}^{\\prime}\\cdots U_{i_{r}}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT satisfy\n\ud835\udc0dpsubscript\ud835\udc0d\ud835\udc5d{\\bf N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u2208{2,3}\u2229\u03c0\u2062(Z\u2062(D))\ud835\udc5d23\ud835\udf0b\ud835\udc4d\ud835\udc37p\\in\\{2,3\\}\\cap\\pi(Z(D))italic_p \u2208 { 2 , 3 } \u2229 italic_\u03c0 ( italic_Z ( italic_D ) ) and\n\ud835\udc0fpsubscript\ud835\udc0f\ud835\udc5d{\\bf P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u2208\u03c0\u2062(D)\ud835\udc5d\ud835\udf0b\ud835\udc37p\\in\\pi(D)italic_p \u2208 italic_\u03c0 ( italic_D ). Moreover, in view of Lemma 2.5,\nG\ud835\udc3aGitalic_G\nand G/Ui1\u2032\u2062\u22ef\u2062Uir\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48subscript\ud835\udc561\u2032\u22efsuperscriptsubscript\ud835\udc48subscript\ud835\udc56\ud835\udc5f\u2032G/U_{i_{1}}^{\\prime}\\cdots U_{i_{r}}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT satisfy \ud835\udc10\u03c3\u2062Psubscript\ud835\udc10\ud835\udf0e\ud835\udc43{\\bf Q}_{\\sigma P}bold_Q start_POSTSUBSCRIPT italic_\u03c3 italic_P end_POSTSUBSCRIPT and, in particular,\nsatisfy \ud835\udc10\u03c3\u2062(p,q)subscript\ud835\udc10\ud835\udf0e\ud835\udc5d\ud835\udc5e{\\bf Q}_{\\sigma(p,q)}bold_Q start_POSTSUBSCRIPT italic_\u03c3 ( italic_p , italic_q ) end_POSTSUBSCRIPT\nfor all pairs\n{p,q}\u2229\u03c0\u2062(D)\u2260\u2205\ud835\udc5d\ud835\udc5e\ud835\udf0b\ud835\udc37\\{p,q\\}\\cap\\pi(D)\\neq\\emptyset{ italic_p , italic_q } \u2229 italic_\u03c0 ( italic_D ) \u2260 \u2205.\nHence Conditions (ii) and (iii) hold for G\ud835\udc3aGitalic_G.\nTherefore the necessity\nof the condition of the theorem holds. Now, assume, arguing\nby contradiction, that G\ud835\udc3aGitalic_G is a non-Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group of minimal order\nsatisfying Conditions (i), (ii), and (iii). Then, in view of Lemma 2.13(4) and Theorem D,\nG\ud835\udc3aGitalic_G is a P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group, so\nD\u22601\ud835\udc371D\\neq 1italic_D \u2260 1\nand G\ud835\udc3aGitalic_G has a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal U\ud835\udc48Uitalic_U such that U\ud835\udc48Uitalic_U is not \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal\nin G\ud835\udc3aGitalic_G\nbut every \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal subgroup U0subscript\ud835\udc480U_{0}italic_U start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT of G\ud835\udc3aGitalic_G with U0<Usubscript\ud835\udc480\ud835\udc48U_{0}<Uitalic_U start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT < italic_U\nis \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal\nin\nG\ud835\udc3aGitalic_G. Let Z=Z\u2062(D).\ud835\udc4d\ud835\udc4d\ud835\udc37Z=Z(D).italic_Z = italic_Z ( italic_D ) . (1) If N\ud835\udc41Nitalic_N\nis either a non-identity normal nilpotent subgroup of G\ud835\udc3aGitalic_G or N=Ui\u2032\ud835\udc41superscriptsubscript\ud835\udc48\ud835\udc56\u2032N=U_{i}^{\\prime}italic_N = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT for some i\ud835\udc56iitalic_i,\nthen G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N is a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group. First assume that k=1\ud835\udc581k=1italic_k = 1 and N=U1\u2032\ud835\udc41superscriptsubscript\ud835\udc481\u2032N=U_{1}^{\\prime}italic_N = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. Then D\u2032=D=U1=U1\u2032=Nsuperscript\ud835\udc37\u2032\ud835\udc37subscript\ud835\udc481superscriptsubscript\ud835\udc481\u2032\ud835\udc41D^{\\prime}=D=U_{1}=U_{1}^{\\prime}=Nitalic_D start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = italic_D = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = italic_N. Therefore\nG/N=G/D\ud835\udc3a\ud835\udc41\ud835\udc3a\ud835\udc37G/N=G/Ditalic_G / italic_N = italic_G / italic_D is a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group by Condition (i). Now assume that k>1\ud835\udc581k>1italic_k > 1 and N=Ni\u2032\ud835\udc41superscriptsubscript\ud835\udc41\ud835\udc56\u2032N=N_{i}^{\\prime}italic_N = italic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. We\ncan assume without loss of generality that i=1\ud835\udc561i=1italic_i = 1.\nThen\n(G/N)/(D/N)\u2243G/Dsimilar-to-or-equals\ud835\udc3a\ud835\udc41\ud835\udc37\ud835\udc41\ud835\udc3a\ud835\udc37(G/N)/(D/N)\\simeq G/D( italic_G / italic_N ) / ( italic_D / italic_N ) \u2243 italic_G / italic_D is a aoluble Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group and (D/N)\u2032=D\u2032/N=D/Nsuperscript\ud835\udc37\ud835\udc41\u2032superscript\ud835\udc37\u2032\ud835\udc41\ud835\udc37\ud835\udc41(D/N)^{\\prime}=D^{\\prime}/N=D/N( italic_D / italic_N ) start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = italic_D start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / italic_N = italic_D / italic_N. From Lemma 2.13(2) it follows that\n(D/N,Z\u2062(D/N);U2\u2062N/N,\u2026,Uk\u2062N/N)\ud835\udc37\ud835\udc41\ud835\udc4d\ud835\udc37\ud835\udc41subscript\ud835\udc482\ud835\udc41\ud835\udc41\u2026subscript\ud835\udc48\ud835\udc58\ud835\udc41\ud835\udc41(D/N,Z(D/N);U_{2}N/N,\\ldots,U_{k}N/N)( italic_D / italic_N , italic_Z ( italic_D / italic_N ) ; italic_U start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_N / italic_N , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_N / italic_N ) is\na Robinson complex of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N and\nU1/N=Z\u2062N/N=Z\u2062(D/N)subscript\ud835\udc481\ud835\udc41\ud835\udc4d\ud835\udc41\ud835\udc41\ud835\udc4d\ud835\udc37\ud835\udc41U_{1}/N=ZN/N=Z(D/N)italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT / italic_N = italic_Z italic_N / italic_N = italic_Z ( italic_D / italic_N ), where Z\u2062N/N\u2243Z/(Z\u2229N)similar-to-or-equals\ud835\udc4d\ud835\udc41\ud835\udc41\ud835\udc4d\ud835\udc4d\ud835\udc41ZN/N\\simeq Z/(Z\\cap N)italic_Z italic_N / italic_N \u2243 italic_Z / ( italic_Z \u2229 italic_N ).\nMoreover, by Condition (iii), if\n{i1,\u2026,ir}\u2286{2,\u2026,k}subscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc5f2\u2026\ud835\udc58\\{i_{1},\\ldots,i_{r}\\}\\subseteq\\{2,\\ldots,k\\}{ italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u2286 { 2 , \u2026 , italic_k }, where 2\u2264r<k2\ud835\udc5f\ud835\udc582\\leq r<k2 \u2264 italic_r < italic_k,\nthen the quotients\nG/N=G/U1\u2032\ud835\udc3a\ud835\udc41\ud835\udc3asuperscriptsubscript\ud835\udc481\u2032G/N=G/U_{1}^{\\prime}italic_G / italic_N = italic_G / italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT and, in view o lemma 2.12(2), satisfy\n\ud835\udc0dpsubscript\ud835\udc0d\ud835\udc5d{\\bf N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u2208{2,3}\u2229\u03c0\u2062(Z\u2062N/N)\ud835\udc5d23\ud835\udf0b\ud835\udc4d\ud835\udc41\ud835\udc41p\\in\\{2,3\\}\\cap\\pi(ZN/N)italic_p \u2208 { 2 , 3 } \u2229 italic_\u03c0 ( italic_Z italic_N / italic_N ),\n\ud835\udc0fpsubscript\ud835\udc0f\ud835\udc5d{\\bf P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all\np\u2208\u03c0(D/N))\u2286\u03c0(D)p\\in\\pi(D/N))\\subseteq\\pi(D)italic_p \u2208 italic_\u03c0 ( italic_D / italic_N ) ) \u2286 italic_\u03c0 ( italic_D ), and \ud835\udc10\u03c3\u2062(p,q)subscript\ud835\udc10\ud835\udf0e\ud835\udc5d\ud835\udc5e{\\bf Q}_{\\sigma(p,q)}bold_Q start_POSTSUBSCRIPT italic_\u03c3 ( italic_p , italic_q ) end_POSTSUBSCRIPT\nfor all pairs\n{p,q}\u2229\u03c0\u2062(D/N)\u2260\u2205\ud835\udc5d\ud835\udc5e\ud835\udf0b\ud835\udc37\ud835\udc41\\{p,q\\}\\cap\\pi(D/N)\\neq\\emptyset{ italic_p , italic_q } \u2229 italic_\u03c0 ( italic_D / italic_N ) \u2260 \u2205.\nTherefore the hypothesis holds for G/N=G/U1\u2032\ud835\udc3a\ud835\udc41\ud835\udc3asuperscriptsubscript\ud835\udc481\u2032G/N=G/U_{1}^{\\prime}italic_G / italic_N = italic_G / italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, so G/Ui\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48\ud835\udc56\u2032G/U_{i}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT\nis a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group for all i\ud835\udc56iitalic_i by the choice of G\ud835\udc3aGitalic_G. Similary, it can be proved that if N\ud835\udc41Nitalic_N\nis a non-identity nilpotent normal subgroup of G\ud835\udc3aGitalic_G, then\nthe hypothesis holds for G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N and so G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N is a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group. (2) U\ud835\udc48Uitalic_U is supersoluble. It is clear that D=G\ud835\udd16=G\ud835\udd18\ud835\udc37superscript\ud835\udc3a\ud835\udd16superscript\ud835\udc3a\ud835\udd18D=G^{\\mathfrak{S}}=G^{\\mathfrak{U}}italic_D = italic_G start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT = italic_G start_POSTSUPERSCRIPT fraktur_U end_POSTSUPERSCRIPT and\nU\u2062Ui\u2032/Ui\u2032\ud835\udc48superscriptsubscript\ud835\udc48\ud835\udc56\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032UU_{i}^{\\prime}/U_{i}^{\\prime}italic_U italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal in G/Ui\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48\ud835\udc56\u2032G/U_{i}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT by Lemma 2.3(2).\nTherefore U\u2062Ui\u2032/Ui\u2032\ud835\udc48superscriptsubscript\ud835\udc48\ud835\udc56\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032UU_{i}^{\\prime}/U_{i}^{\\prime}italic_U italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G/Ui\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48\ud835\udc56\u2032G/U_{i}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT by Claim (1)\nfor all i\ud835\udc56iitalic_i. Hence U\ud835\udc48Uitalic_U is supersoluble by Lemma 2.6(1). (3) Suppose that N\ud835\udc41Nitalic_N is either\na non-identity normal nilpotent subgroup of G\ud835\udc3aGitalic_G or N=Ui\u2032\ud835\udc41superscriptsubscript\ud835\udc48\ud835\udc56\u2032N=U_{i}^{\\prime}italic_N = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT for\nsome i\ud835\udc56iitalic_i.\nIf X\ud835\udc4bXitalic_X is a subgroup of G\ud835\udc3aGitalic_G such that X\u2062N/N\ud835\udc4b\ud835\udc41\ud835\udc41XN/Nitalic_X italic_N / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal\nin G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N, then\nX\u2062N/N\ud835\udc4b\ud835\udc41\ud835\udc41XN/Nitalic_X italic_N / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal\nin G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N and X\u2062N\ud835\udc4b\ud835\udc41XNitalic_X italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G.\nIn particular, UG=1subscript\ud835\udc48\ud835\udc3a1U_{G}=1italic_U start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = 1. In view of Claim (1), G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N is a Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group, so X\u2062N/N\ud835\udc4b\ud835\udc41\ud835\udc41XN/Nitalic_X italic_N / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal\nin G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N and hence X\u2062N\ud835\udc4b\ud835\udc41XNitalic_X italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G by Lemma 2.1(3). Therefore,\nsince U\ud835\udc48Uitalic_U is supersoluble by Claim (2), the choice of U\ud835\udc48Uitalic_U implies that UG=1subscript\ud835\udc48\ud835\udc3a1U_{G}=1italic_U start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = 1. (4) U\ud835\udc48Uitalic_U is a cyclic p\ud835\udc5dpitalic_p-group for some prime p\ud835\udc5dpitalic_p and\nV:=U\u2229Z\u221e\u2062(G)assign\ud835\udc49\ud835\udc48subscript\ud835\udc4d\ud835\udc3aV:=U\\cap Z_{\\infty}(G)italic_V := italic_U \u2229 italic_Z start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT ( italic_G ) is the maximal subgroup of U\ud835\udc48Uitalic_U. Let N\ud835\udc41Nitalic_N be a nilpotent\nnon-identity normal subgroup of G\ud835\udc3aGitalic_G. Then U\u2062N/N\ud835\udc48\ud835\udc41\ud835\udc41UN/Nitalic_U italic_N / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal\nin G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N by Lemma 2.3(2), so U\u2062N/N\ud835\udc48\ud835\udc41\ud835\udc41UN/Nitalic_U italic_N / italic_N is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal\nin G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N by Claim (1). Hence U\ud835\udc48Uitalic_U is a cyclic\np\ud835\udc5dpitalic_p-group for some prime p\ud835\udc5dpitalic_p by Claim (2) and Lemma 2.6(2). Now,\nlet V\ud835\udc49Vitalic_V be the maximal subgroup of U\ud835\udc48Uitalic_U. Then V=U\ud835\udd04\u2217\ud835\udc49superscript\ud835\udc48superscript\ud835\udd04V=U^{{\\mathfrak{A}^{*}}}italic_V = italic_U start_POSTSUPERSCRIPT fraktur_A start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT\nis subnormal in G\ud835\udc3aGitalic_G by Lemma 2.3(4) since U\ud835\udc48Uitalic_U is a cyclic\np\ud835\udc5dpitalic_p-group, hence V\ud835\udc49Vitalic_V is quasinormal in G\ud835\udc3aGitalic_G since G\ud835\udc3aGitalic_G is a P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group.\nTherefore\nV\u2264Z\u221e\u2062(G)\ud835\udc49subscript\ud835\udc4d\ud835\udc3aV\\leq Z_{\\infty}(G)italic_V \u2264 italic_Z start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT ( italic_G ) by [14, Corollary 1.5.6] since VG=1=UGsubscript\ud835\udc49\ud835\udc3a1subscript\ud835\udc48\ud835\udc3aV_{G}=1=U_{G}italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = 1 = italic_U start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT\nby Claim (3). (5) G\ud835\udc3aGitalic_G has a normal subgroup Cqsubscript\ud835\udc36\ud835\udc5eC_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT of order q\ud835\udc5eqitalic_q for some prime q\ud835\udc5eqitalic_q. If Z\u22601\ud835\udc4d1Z\\neq 1italic_Z \u2260 1, it is clear. Now assume\nthat Z=1\ud835\udc4d1Z=1italic_Z = 1. Then D=U1\u00d7\u22ef\u00d7Uk\ud835\udc37subscript\ud835\udc481\u22efsubscript\ud835\udc48\ud835\udc58D=U_{1}\\times\\cdots\\times U_{k}italic_D = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00d7 \u22ef \u00d7 italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, where Uisubscript\ud835\udc48\ud835\udc56U_{i}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a simple non-abelian minimal normal subgroup of G\ud835\udc3aGitalic_G\nfor all i\ud835\udc56iitalic_i. Let E=Ui\u2062U\ud835\udc38subscript\ud835\udc48\ud835\udc56\ud835\udc48E=U_{i}Uitalic_E = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_U, where Ui\u2270Unot-less-than-nor-greater-thansubscript\ud835\udc48\ud835\udc56\ud835\udc48U_{i}\\nleq Uitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2270 italic_U. We show that Ui\u2264NG\u2062(U)subscript\ud835\udc48\ud835\udc56subscript\ud835\udc41\ud835\udc3a\ud835\udc48U_{i}\\leq N_{G}(U)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2264 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ).\nSince U\ud835\udc48Uitalic_U is a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal\nsubgroup of E\ud835\udc38Eitalic_E by Lemma 2.3(1), there is a subgroup chain\nU=E0<E1<\u22ef<Et\u22121<Et=E\ud835\udc48subscript\ud835\udc380subscript\ud835\udc381\u22efsubscript\ud835\udc38\ud835\udc611subscript\ud835\udc38\ud835\udc61\ud835\udc38U=E_{0}<E_{1}<\\cdots<E_{t-1}<E_{t}=Eitalic_U = italic_E start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < \u22ef < italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_E such that Ei\u22121subscript\ud835\udc38\ud835\udc561E_{i-1}italic_E start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT is a maximal\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup of Eisubscript\ud835\udc38\ud835\udc56E_{i}italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for all i=1,\u2026,t\ud835\udc561\u2026\ud835\udc61i=1,\\ldots,titalic_i = 1 , \u2026 , italic_t\nand for M=Et\u22121\ud835\udc40subscript\ud835\udc38\ud835\udc611M=E_{t-1}italic_M = italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT we have M=U\u2062(M\u2229Ui)\ud835\udc40\ud835\udc48\ud835\udc40subscript\ud835\udc48\ud835\udc56M=U(M\\cap U_{i})italic_M = italic_U ( italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Moreover, M\u2229Ui\ud835\udc40subscript\ud835\udc48\ud835\udc56M\\cap U_{i}italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal in E\ud835\udc38Eitalic_E\nand M\u2229Ui<Ui\ud835\udc40subscript\ud835\udc48\ud835\udc56subscript\ud835\udc48\ud835\udc56M\\cap U_{i}<U_{i}italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT since\nM<E\ud835\udc40\ud835\udc38M<Eitalic_M < italic_E, so M\u2229Ui=1\ud835\udc40subscript\ud835\udc48\ud835\udc561M\\cap U_{i}=1italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1. Therefore U=M\ud835\udc48\ud835\udc40U=Mitalic_U = italic_M is a maximal\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup of E\ud835\udc38Eitalic_E. Assume that U\ud835\udc48Uitalic_U is not normal in E\ud835\udc38Eitalic_E. Then,\nby Lemma 2.2, E/UE\ud835\udc38subscript\ud835\udc48\ud835\udc38E/U_{E}italic_E / italic_U start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a group of order q\u2062r\ud835\udc5e\ud835\udc5fqritalic_q italic_r for primes q\ud835\udc5eqitalic_q and r\ud835\udc5fritalic_r. But this is\nimposible since\nUi\u2243Ui\u2062UE/UE\u2264E/UEsimilar-to-or-equalssubscript\ud835\udc48\ud835\udc56subscript\ud835\udc48\ud835\udc56subscript\ud835\udc48\ud835\udc38subscript\ud835\udc48\ud835\udc38\ud835\udc38subscript\ud835\udc48\ud835\udc38U_{i}\\simeq U_{i}U_{E}/U_{E}\\leq E/U_{E}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2243 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_U start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT / italic_U start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT \u2264 italic_E / italic_U start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT.\nTherefore Ui\u2264NE\u2062(U)subscript\ud835\udc48\ud835\udc56subscript\ud835\udc41\ud835\udc38\ud835\udc48U_{i}\\leq N_{E}(U)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2264 italic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_U ) for all i\ud835\udc56iitalic_i,\nso\nD\u2264NG\u2062(U)\ud835\udc37subscript\ud835\udc41\ud835\udc3a\ud835\udc48D\\leq N_{G}(U)italic_D \u2264 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ) and hence U\u2229D\u2264Op\u2062(D)=1\ud835\udc48\ud835\udc37subscript\ud835\udc42\ud835\udc5d\ud835\udc371U\\cap D\\leq O_{p}(D)=1italic_U \u2229 italic_D \u2264 italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_D ) = 1 by Claim (4). It follows than D\u2062U=D\u00d7U\ud835\udc37\ud835\udc48\ud835\udc37\ud835\udc48DU=D\\times Uitalic_D italic_U = italic_D \u00d7 italic_U, so\n1<U\u2264CG\u2062(D)1\ud835\udc48subscript\ud835\udc36\ud835\udc3a\ud835\udc371<U\\leq C_{G}(D)1 < italic_U \u2264 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ). But CG\u2062(D)\u2229D=1subscript\ud835\udc36\ud835\udc3a\ud835\udc37\ud835\udc371C_{G}(D)\\cap D=1italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) \u2229 italic_D = 1 since Z=Z\u2062(D)=1\ud835\udc4d\ud835\udc4d\ud835\udc371Z=Z(D)=1italic_Z = italic_Z ( italic_D ) = 1.\nTherefore CG\u2062(D)\u2243CG\u2062(D)\u2062D/Dsimilar-to-or-equalssubscript\ud835\udc36\ud835\udc3a\ud835\udc37subscript\ud835\udc36\ud835\udc3a\ud835\udc37\ud835\udc37\ud835\udc37C_{G}(D)\\simeq C_{G}(D)D/Ditalic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) \u2243 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) italic_D / italic_D is soluble. Hence for some prime q\ud835\udc5eqitalic_q\ndividing |CG\u2062(D)|subscript\ud835\udc36\ud835\udc3a\ud835\udc37|C_{G}(D)|| italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) | we have\nOq\u2062(CG\u2062(D))\u22601subscript\ud835\udc42\ud835\udc5esubscript\ud835\udc36\ud835\udc3a\ud835\udc371O_{q}(C_{G}(D))\\neq 1italic_O start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) ) \u2260 1. But Oq\u2062(CG\u2062(D))subscript\ud835\udc42\ud835\udc5esubscript\ud835\udc36\ud835\udc3a\ud835\udc37O_{q}(C_{G}(D))italic_O start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) ) is characteristic in CG\u2062(D)subscript\ud835\udc36\ud835\udc3a\ud835\udc37C_{G}(D)italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ),\nso\nOq\u2062(CG\u2062(D))subscript\ud835\udc42\ud835\udc5esubscript\ud835\udc36\ud835\udc3a\ud835\udc37O_{q}(C_{G}(D))italic_O start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) ) is normal in G\ud835\udc3aGitalic_G and hence we have (5). (6) UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is soluble. The subgroup Cq\u2062U/Cqsubscript\ud835\udc36\ud835\udc5e\ud835\udc48subscript\ud835\udc36\ud835\udc5eC_{q}U/C_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal\nin G/Cq\ud835\udc3asubscript\ud835\udc36\ud835\udc5eG/C_{q}italic_G / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT by Lemma 2.3(2), so this subgroup is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal and\nhence modular in G/Cq\ud835\udc3asubscript\ud835\udc36\ud835\udc5eG/C_{q}italic_G / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT by Claim (3). First assume that Cq\u2062U/Cqsubscript\ud835\udc36\ud835\udc5e\ud835\udc48subscript\ud835\udc36\ud835\udc5eC_{q}U/C_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is not subnormal in G/Cq\ud835\udc3asubscript\ud835\udc36\ud835\udc5eG/C_{q}italic_G / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT.\nThen, by Lemma 2.14,\nCq\u2062UG/(Cq\u2062U)Gsubscript\ud835\udc36\ud835\udc5esuperscript\ud835\udc48\ud835\udc3asubscriptsubscript\ud835\udc36\ud835\udc5e\ud835\udc48\ud835\udc3aC_{q}U^{G}/(C_{q}U)_{G}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT\nis a non-abelian P\ud835\udc43Pitalic_P-group, so Cq\u2062UG/(Cq\u2062U)Gsubscript\ud835\udc36\ud835\udc5esuperscript\ud835\udc48\ud835\udc3asubscriptsubscript\ud835\udc36\ud835\udc5e\ud835\udc48\ud835\udc3aC_{q}U^{G}/(C_{q}U)_{G}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT\nis soluble and hence is soluble since\nCq\u2062Usubscript\ud835\udc36\ud835\udc5e\ud835\udc48C_{q}Uitalic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U is soluble.\nHence UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is soluble. Now assume that Cq\u2062U/Cqsubscript\ud835\udc36\ud835\udc5e\ud835\udc48subscript\ud835\udc36\ud835\udc5eC_{q}U/C_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is subnormal in G/Cq\ud835\udc3asubscript\ud835\udc36\ud835\udc5eG/C_{q}italic_G / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT, so by Claim (4).\nHence UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is soluble. (7) U\ud835\udc48Uitalic_U is not subnormal in G\ud835\udc3aGitalic_G. Assume that U\ud835\udc48Uitalic_U is subnormal in G\ud835\udc3aGitalic_G.\nThen U\ud835\udc48Uitalic_U is quasinormal and\nso \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G since\nG\ud835\udc3aGitalic_G is a P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group, a contradiction. Hence we have (7). (8) |U|=p\ud835\udc48\ud835\udc5d|U|=p| italic_U | = italic_p. Assume that |U|>p\ud835\udc48\ud835\udc5d|U|>p| italic_U | > italic_p. Then 1<V\u2264R:=Op\u2062(Z\u221e\u2062(G))1\ud835\udc49\ud835\udc45assignsubscript\ud835\udc42\ud835\udc5dsubscript\ud835\udc4d\ud835\udc3a1<V\\leq R:=O_{p}(Z_{\\infty}(G))1 < italic_V \u2264 italic_R := italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_Z start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT ( italic_G ) ) by Claim (4) and\nU\u2270Rnot-less-than-nor-greater-than\ud835\udc48\ud835\udc45U\\nleq Ritalic_U \u2270 italic_R by Claim (7). Denote E=R\u2062U\ud835\udc38\ud835\udc45\ud835\udc48E=RUitalic_E = italic_R italic_U. Then EG=UG\u2062Rsuperscript\ud835\udc38\ud835\udc3asuperscript\ud835\udc48\ud835\udc3a\ud835\udc45E^{G}=U^{G}Ritalic_E start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_R and, in view\nof Claims (4) and (7), E\ud835\udc38Eitalic_E is not subnormal in G\ud835\udc3aGitalic_G. Moreover, E\ud835\udc38Eitalic_E\nis \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal and so\nmodular in G\ud835\udc3aGitalic_G by Claim (3). The group\nU\u2062R/R\u2243U/(U\u2229R)=U/Vsimilar-to-or-equals\ud835\udc48\ud835\udc45\ud835\udc45\ud835\udc48\ud835\udc48\ud835\udc45\ud835\udc48\ud835\udc49UR/R\\simeq U/(U\\cap R)=U/Vitalic_U italic_R / italic_R \u2243 italic_U / ( italic_U \u2229 italic_R ) = italic_U / italic_V has order p\ud835\udc5dpitalic_p, so (R\u2062U)G=Rsubscript\ud835\udc45\ud835\udc48\ud835\udc3a\ud835\udc45(RU)_{G}=R( italic_R italic_U ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_R. In view of Lemma 2.14, where\nR\u2062UG/R\u2243UG/(UG\u2229R)similar-to-or-equals\ud835\udc45superscript\ud835\udc48\ud835\udc3a\ud835\udc45superscript\ud835\udc48\ud835\udc3asuperscript\ud835\udc48\ud835\udc3a\ud835\udc45RU^{G}/R\\simeq U^{G}/(U^{G}\\cap R)italic_R italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_R \u2243 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R )\nis a non-abelian P\ud835\udc43Pitalic_P-group of order prime to K/R\ud835\udc3e\ud835\udc45K/Ritalic_K / italic_R. The group UG/(UG\u2229R)superscript\ud835\udc48\ud835\udc3asuperscript\ud835\udc48\ud835\udc3a\ud835\udc45U^{G}/(U^{G}\\cap R)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R ) is q\ud835\udc5eqitalic_q-closed for some prime q\ud835\udc5eqitalic_q\ndividing its order and\nso UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is q\ud835\udc5eqitalic_q-closed by Lemma 2.9 since UG\u2229R\u2264Z\u221e\u2062(UG)superscript\ud835\udc48\ud835\udc3a\ud835\udc45subscript\ud835\udc4dsuperscript\ud835\udc48\ud835\udc3aU^{G}\\cap R\\leq Z_{\\infty}(U^{G})italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R \u2264 italic_Z start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT ).\nIf Q\ud835\udc44Qitalic_Q is the normal Sylow q\ud835\udc5eqitalic_q-subgroup of UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT, then U\u2270Qnot-less-than-nor-greater-than\ud835\udc48\ud835\udc44U\\nleq Qitalic_U \u2270 italic_Q by Claim (7), so\nq\u2260p\ud835\udc5e\ud835\udc5dq\\neq pitalic_q \u2260 italic_p. Therefore UG/(UG\u2229R)superscript\ud835\udc48\ud835\udc3asuperscript\ud835\udc48\ud835\udc3a\ud835\udc45U^{G}/(U^{G}\\cap R)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R )\nis a non-abelian P\ud835\udc43Pitalic_P-group of type (q,p)\ud835\udc5e\ud835\udc5d(q,p)( italic_q , italic_p ), so UG=Q\u22caPsuperscript\ud835\udc48\ud835\udc3aright-normal-factor-semidirect-product\ud835\udc44\ud835\udc43U^{G}=Q\\rtimes Pitalic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_Q \u22ca italic_P, where\nP\ud835\udc43Pitalic_P is a non-normal Sylow p\ud835\udc5dpitalic_p-subgroup of UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT, containing U\ud835\udc48Uitalic_U, and Q\ud835\udc44Qitalic_Q is\nsubnormal in G\ud835\udc3aGitalic_G.\nIn particular, UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT and R\u2062UG/R\ud835\udc45superscript\ud835\udc48\ud835\udc3a\ud835\udc45RU^{G}/Ritalic_R italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_R are \u03c0\ud835\udf0b\\piitalic_\u03c0-groups,\nwhere \u03c0={p,q}\ud835\udf0b\ud835\udc5d\ud835\udc5e\\pi=\\{p,q\\}italic_\u03c0 = { italic_p , italic_q }, so G\ud835\udc3aGitalic_G is \u03c0\ud835\udf0b\\piitalic_\u03c0-soluble and hence\nD\ud835\udc37Ditalic_D and D/Z\ud835\udc37\ud835\udc4dD/Zitalic_D / italic_Z are \u03c0\ud835\udf0b\\piitalic_\u03c0-soluble groups. Assume that UG\u2229D\u22601superscript\ud835\udc48\ud835\udc3a\ud835\udc371U^{G}\\cap D\\neq 1italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_D \u2260 1. Since\nUG\u2229D\u2264Z\u2264\u03a6\u2062(D)superscript\ud835\udc48\ud835\udc3a\ud835\udc37\ud835\udc4d\u03a6\ud835\udc37U^{G}\\cap D\\leq Z\\leq\\Phi(D)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_D \u2264 italic_Z \u2264 roman_\u03a6 ( italic_D ) by Claim (6),\nfor some i\ud835\udc56iitalic_i and for some r\u2208{p,q}\ud835\udc5f\ud835\udc5d\ud835\udc5er\\in\\{p,q\\}italic_r \u2208 { italic_p , italic_q } the mumber r\ud835\udc5fritalic_r divides |Ui/Z|subscript\ud835\udc48\ud835\udc56\ud835\udc4d|U_{i}/Z|| italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z |.\nIt follows that Ui/Zsubscript\ud835\udc48\ud835\udc56\ud835\udc4dU_{i}/Zitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z is an abelian group, a contradiction. Therefore UG\u2229D=1superscript\ud835\udc48\ud835\udc3a\ud835\udc371U^{G}\\cap D=1italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_D = 1 and\nso where\nG/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is a soluble Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group by Condition (i).\nTherefore, in view of Theorem C,\nG/D=T\u22caL\ud835\udc3a\ud835\udc37right-normal-factor-semidirect-product\ud835\udc47\ud835\udc3fG/D=T\\rtimes Litalic_G / italic_D = italic_T \u22ca italic_L, where T=(G/D)\ud835\udd11\u03c3\ud835\udc47superscript\ud835\udc3a\ud835\udc37subscript\ud835\udd11\ud835\udf0eT=(G/D)^{\\mathfrak{N_{\\sigma}}}italic_T = ( italic_G / italic_D ) start_POSTSUPERSCRIPT fraktur_N start_POSTSUBSCRIPT italic_\u03c3 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT and the following hold:\nT\ud835\udc47Titalic_T is an abelian Hall\nsubgroup of G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D and all subgroups of T\ud835\udc47Titalic_T are normal G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D and the\nlattice \u2112\u2062(L)\u2112\ud835\udc3f{\\cal L}(L)caligraphic_L ( italic_L ),\nof all subgroups of L\ud835\udc3fLitalic_L, is modular. Then P\u2062D/D\u2270Tnot-less-than-nor-greater-than\ud835\udc43\ud835\udc37\ud835\udc37\ud835\udc47PD/D\\nleq Titalic_P italic_D / italic_D \u2270 italic_T,\nso U\u2062D/D\u2264P\u2062D/D\u2264Lx\ud835\udc48\ud835\udc37\ud835\udc37\ud835\udc43\ud835\udc37\ud835\udc37superscript\ud835\udc3f\ud835\udc65UD/D\\leq PD/D\\leq L^{x}italic_U italic_D / italic_D \u2264 italic_P italic_D / italic_D \u2264 italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT for some x\u2208G/D\ud835\udc65\ud835\udc3a\ud835\udc37x\\in G/Ditalic_x \u2208 italic_G / italic_D. First assume that Q\u2062D/D\u2264T\ud835\udc44\ud835\udc37\ud835\udc37\ud835\udc47QD/D\\leq Titalic_Q italic_D / italic_D \u2264 italic_T. Since U\u2062D/D\ud835\udc48\ud835\udc37\ud835\udc37UD/Ditalic_U italic_D / italic_D is a\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-subquasinormal p\ud835\udc5dpitalic_p-subgroup of G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D by Lemmma 2.3(2),\nT\u2264CG/D\u2062(U\u2062D/D)\ud835\udc47subscript\ud835\udc36\ud835\udc3a\ud835\udc37\ud835\udc48\ud835\udc37\ud835\udc37T\\leq C_{G/D}(UD/D)italic_T \u2264 italic_C start_POSTSUBSCRIPT italic_G / italic_D end_POSTSUBSCRIPT ( italic_U italic_D / italic_D ) by Lemma 2.7, so a contradiction. Hence Q\u2062D/D\u2270Tnot-less-than-nor-greater-than\ud835\udc44\ud835\udc37\ud835\udc37\ud835\udc47QD/D\\nleq Titalic_Q italic_D / italic_D \u2270 italic_T and so (Q\u2062D/D)\u22ca(P\u2062D/D)\u2264Lxright-normal-factor-semidirect-product\ud835\udc44\ud835\udc37\ud835\udc37\ud835\udc43\ud835\udc37\ud835\udc37superscript\ud835\udc3f\ud835\udc65(QD/D)\\rtimes(PD/D)\\leq L^{x}( italic_Q italic_D / italic_D ) \u22ca ( italic_P italic_D / italic_D ) \u2264 italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT since T\ud835\udc47Titalic_T and Lxsuperscript\ud835\udc3f\ud835\udc65L^{x}italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT\nare Hall subgroups of G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D and Q\u2062D/D\ud835\udc44\ud835\udc37\ud835\udc37QD/Ditalic_Q italic_D / italic_D is a subnormal q\ud835\udc5eqitalic_q-subgroup of G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D. In view of Theorem 2.4.4 in [1], Lxsuperscript\ud835\udc3f\ud835\udc65L^{x}italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT is a direct product of\nP\u2217superscript\ud835\udc43P^{*}italic_P start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT-groups Pisubscript\ud835\udc43\ud835\udc56P_{i}italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and primary groups Qjsubscript\ud835\udc44\ud835\udc57Q_{j}italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT\n(that is, Qjsubscript\ud835\udc44\ud835\udc57Q_{j}italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is of prime power order) with relatively prime\norders. Then for any factor\nQjsubscript\ud835\udc44\ud835\udc57Q_{j}italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT of Lxsuperscript\ud835\udc3f\ud835\udc65L^{x}italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT we have\nQj\u2264Z\u221e\u2062(Lx)subscript\ud835\udc44\ud835\udc57subscript\ud835\udc4dsuperscript\ud835\udc3f\ud835\udc65Q_{j}\\leq Z_{\\infty}(L^{x})italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u2264 italic_Z start_POSTSUBSCRIPT \u221e end_POSTSUBSCRIPT ( italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT ), so\nQ\u2062D/D\u2270Qjnot-less-than-nor-greater-than\ud835\udc44\ud835\udc37\ud835\udc37subscript\ud835\udc44\ud835\udc57QD/D\\nleq Q_{j}italic_Q italic_D / italic_D \u2270 italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT and P\u2062D/D\u2270Qjnot-less-than-nor-greater-than\ud835\udc43\ud835\udc37\ud835\udc37subscript\ud835\udc44\ud835\udc57PD/D\\nleq Q_{j}italic_P italic_D / italic_D \u2270 italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT for all j\ud835\udc57jitalic_j since\nUG\u2243UG\u2062D/D\u2243Q\u2062D/D\u22caP\u2062D/Dsimilar-to-or-equalssuperscript\ud835\udc48\ud835\udc3asuperscript\ud835\udc48\ud835\udc3a\ud835\udc37\ud835\udc37similar-to-or-equalsright-normal-factor-semidirect-product\ud835\udc44\ud835\udc37\ud835\udc37\ud835\udc43\ud835\udc37\ud835\udc37U^{G}\\simeq U^{G}D/D\\simeq QD/D\\rtimes PD/Ditalic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2243 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_D / italic_D \u2243 italic_Q italic_D / italic_D \u22ca italic_P italic_D / italic_D is not nilpotent. Therefore for some i\ud835\udc56iitalic_i and k\ud835\udc58kitalic_k we have\nQ\u2062D/D\u2264Pi\ud835\udc44\ud835\udc37\ud835\udc37subscript\ud835\udc43\ud835\udc56QD/D\\leq P_{i}italic_Q italic_D / italic_D \u2264 italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and P\u2062D/D\u2264Pk\ud835\udc43\ud835\udc37\ud835\udc37subscript\ud835\udc43\ud835\udc58PD/D\\leq P_{k}italic_P italic_D / italic_D \u2264 italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, where [Pi,Pk]=1subscript\ud835\udc43\ud835\udc56subscript\ud835\udc43\ud835\udc581[P_{i},P_{k}]=1[ italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ] = 1 for i\u2260k\ud835\udc56\ud835\udc58i\\neq kitalic_i \u2260 italic_k, so i=k\ud835\udc56\ud835\udc58i=kitalic_i = italic_k.\nHence Q\u2062D/D\u22caP\u2062D/D\u2264Pi=A\u22ca\u27e8t\u27e9right-normal-factor-semidirect-product\ud835\udc44\ud835\udc37\ud835\udc37\ud835\udc43\ud835\udc37\ud835\udc37subscript\ud835\udc43\ud835\udc56right-normal-factor-semidirect-product\ud835\udc34delimited-\u27e8\u27e9\ud835\udc61QD/D\\rtimes PD/D\\leq P_{i}=A\\rtimes\\langle t\\rangleitalic_Q italic_D / italic_D \u22ca italic_P italic_D / italic_D \u2264 italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_A \u22ca \u27e8 italic_t \u27e9, where A\ud835\udc34Aitalic_A is elementary\nabelian subgroup of Pisubscript\ud835\udc43\ud835\udc56P_{i}italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, |t|=rn\ud835\udc61superscript\ud835\udc5f\ud835\udc5b|t|=r^{n}| italic_t | = italic_r start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT for some prime r\ud835\udc5fritalic_r and t\ud835\udc61titalic_t induces a power\nautomorphism of prime order on A\ud835\udc34Aitalic_A. Therefore\nA\ud835\udc34Aitalic_A is a q\ud835\udc5eqitalic_q-group and t\ud835\udc61titalic_t is a p\ud835\udc5dpitalic_p-element of Pksubscript\ud835\udc43\ud835\udc58P_{k}italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT by Lemma 2.16. Hence P\u2243P\u2062D/Dsimilar-to-or-equals\ud835\udc43\ud835\udc43\ud835\udc37\ud835\udc37P\\simeq PD/Ditalic_P \u2243 italic_P italic_D / italic_D is a cyclic p\ud835\udc5dpitalic_p-group. Since UG/(UG\u2229R)superscript\ud835\udc48\ud835\udc3asuperscript\ud835\udc48\ud835\udc3a\ud835\udc45U^{G}/(U^{G}\\cap R)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R )\nis a non-abelian P\ud835\udc43Pitalic_P-group and U\u2270UG\u2229Rnot-less-than-nor-greater-than\ud835\udc48superscript\ud835\udc48\ud835\udc3a\ud835\udc45U\\nleq U^{G}\\cap Ritalic_U \u2270 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R,\nU\u2062(UG\u2229R)/(UG\u2229R)\ud835\udc48superscript\ud835\udc48\ud835\udc3a\ud835\udc45superscript\ud835\udc48\ud835\udc3a\ud835\udc45U(U^{G}\\cap R)/(U^{G}\\cap R)italic_U ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R ) / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R ) is a Sylow p\ud835\udc5dpitalic_p-subgroup of\nUG/(UG\u2229R)superscript\ud835\udc48\ud835\udc3asuperscript\ud835\udc48\ud835\udc3a\ud835\udc45U^{G}/(U^{G}\\cap R)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R ) and so\nU\u2062(UG\u2229R)\ud835\udc48superscript\ud835\udc48\ud835\udc3a\ud835\udc45U(U^{G}\\cap R)italic_U ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R ) is a cyclic Sylow p\ud835\udc5dpitalic_p-subgroup of UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT.\nIt follows that either U\u2062(UG\u2229R)=U\ud835\udc48superscript\ud835\udc48\ud835\udc3a\ud835\udc45\ud835\udc48U(U^{G}\\cap R)=Uitalic_U ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R ) = italic_U or U\u2062(UG\u2229R)=UG\u2229R\ud835\udc48superscript\ud835\udc48\ud835\udc3a\ud835\udc45superscript\ud835\udc48\ud835\udc3a\ud835\udc45U(U^{G}\\cap R)=U^{G}\\cap Ritalic_U ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R ) = italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R.\nIn the former case\nwe have UG\u2229R=V\u2264UGsuperscript\ud835\udc48\ud835\udc3a\ud835\udc45\ud835\udc49subscript\ud835\udc48\ud835\udc3aU^{G}\\cap R=V\\leq U_{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R = italic_V \u2264 italic_U start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT, which is impossible by Claim (3),\nso\nU\u2062(UG\u2229R)=UG\u2229R\ud835\udc48superscript\ud835\udc48\ud835\udc3a\ud835\udc45superscript\ud835\udc48\ud835\udc3a\ud835\udc45U(U^{G}\\cap R)=U^{G}\\cap Ritalic_U ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R ) = italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_R and hence U\ud835\udc48Uitalic_U is subormal in G\ud835\udc3aGitalic_G, contrary to Claim (7).\nTherefore we have (8). (9) U\u2270Dnot-less-than-nor-greater-than\ud835\udc48\ud835\udc37U\\nleq Ditalic_U \u2270 italic_D. Assume U\u2264D\ud835\udc48\ud835\udc37U\\leq Ditalic_U \u2264 italic_D.\nFrom Claim (7) it follows that U\u2270Znot-less-than-nor-greater-than\ud835\udc48\ud835\udc4dU\\nleq Zitalic_U \u2270 italic_Z and then, by Claim (8) and\nLemma 2.3(1)(2)(5), for some i\ud835\udc56iitalic_i we have\nU\u2243U\u2062Z/Z=Ui/Zsimilar-to-or-equals\ud835\udc48\ud835\udc48\ud835\udc4d\ud835\udc4dsubscript\ud835\udc48\ud835\udc56\ud835\udc4dU\\simeq UZ/Z=U_{i}/Zitalic_U \u2243 italic_U italic_Z / italic_Z = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z, a\ncontradiction. Hence we have\u00a0(9). (10) Op\u2062(D)=1subscript\ud835\udc42\ud835\udc5d\ud835\udc371O_{p}(D)=1italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_D ) = 1. Assume that G\ud835\udc3aGitalic_G has a normal subgroup Zp\u2264Z=\u03a6\u2062(D)subscript\ud835\udc4d\ud835\udc5d\ud835\udc4d\u03a6\ud835\udc37Z_{p}\\leq Z=\\Phi(D)italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u2264 italic_Z = roman_\u03a6 ( italic_D ) of order p\ud835\udc5dpitalic_p.\nThen Zp\u2062Usubscript\ud835\udc4d\ud835\udc5d\ud835\udc48Z_{p}Uitalic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U is not subnormal in G\ud835\udc3aGitalic_G by Claim (7) and, also, (Zp\u2062U)G=Zpsubscriptsubscript\ud835\udc4d\ud835\udc5d\ud835\udc48\ud835\udc3asubscript\ud835\udc4d\ud835\udc5d(Z_{p}U)_{G}=Z_{p}( italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT\nby Claim (8) and\n(Zp\u2062U)G=Zp\u2062UGsuperscriptsubscript\ud835\udc4d\ud835\udc5d\ud835\udc48\ud835\udc3asubscript\ud835\udc4d\ud835\udc5dsuperscript\ud835\udc48\ud835\udc3a(Z_{p}U)^{G}=Z_{p}U^{G}( italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U ) start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT, so\nG/Zp\u2243Zp\u2062UG/Zp\u00d7K/Zp,similar-to-or-equals\ud835\udc3asubscript\ud835\udc4d\ud835\udc5dsubscript\ud835\udc4d\ud835\udc5dsuperscript\ud835\udc48\ud835\udc3asubscript\ud835\udc4d\ud835\udc5d\ud835\udc3esubscript\ud835\udc4d\ud835\udc5dG/Z_{p}\\simeq Z_{p}U^{G}/Z_{p}\\times K/Z_{p},italic_G / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u2243 italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00d7 italic_K / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , where Zp\u2062UG/Zpsubscript\ud835\udc4d\ud835\udc5dsuperscript\ud835\udc48\ud835\udc3asubscript\ud835\udc4d\ud835\udc5dZ_{p}U^{G}/Z_{p}italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT is\na non-abelian P\ud835\udc43Pitalic_P-group of order pa\u2062qbsuperscript\ud835\udc5d\ud835\udc4esuperscript\ud835\udc5e\ud835\udc4fp^{a}q^{b}italic_p start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT prime to |K/Zp|\ud835\udc3esubscript\ud835\udc4d\ud835\udc5d|K/Z_{p}|| italic_K / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT | by Lemma 2.14. Hence\nG/Zp\ud835\udc3asubscript\ud835\udc4d\ud835\udc5dG/Z_{p}italic_G / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT, D/Zp\ud835\udc37subscript\ud835\udc4d\ud835\udc5dD/Z_{p}italic_D / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT, and D\ud835\udc37Ditalic_D are {p,q}\ud835\udc5d\ud835\udc5e\\{p,q\\}{ italic_p , italic_q }-soluble and p\ud835\udc5dpitalic_p divides |D/Zp|\ud835\udc37subscript\ud835\udc4d\ud835\udc5d|D/Z_{p}|| italic_D / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT |.\nHence Op\u2062(D/Z)\u22601subscript\ud835\udc42\ud835\udc5d\ud835\udc37\ud835\udc4d1O_{p}(D/Z)\\neq 1italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_D / italic_Z ) \u2260 1. This contradiction completes the proof of the claim. (11) Ui\u2032\u2062U=Ui\u2032\u00d7Usuperscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc48superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc48U_{i}^{\\prime}U=U_{i}^{\\prime}\\times Uitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_U = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u00d7 italic_U and so Ui\u2032\u2062Usuperscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc48U_{i}^{\\prime}Uitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_U is not subnormal in G\ud835\udc3aGitalic_G\nfor all i\ud835\udc56iitalic_i. In view of Claims (8) and (9), it is enough to show that Ui\u2032\u2264NG\u2062(U)superscriptsubscript\ud835\udc48\ud835\udc56\u2032subscript\ud835\udc41\ud835\udc3a\ud835\udc48U_{i}^{\\prime}\\leq N_{G}(U)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2264 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ). By Lemma 2.13(1), Ui\u2032\u2229Z=\u03a6\u2062(Ui\u2032)=Z\u2062(Ui\u2032)superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4d\u03a6superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4dsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}\\cap Z=\\Phi(U_{i}^{\\prime})=Z(U_{i}^{\\prime})italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2229 italic_Z = roman_\u03a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) = italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT )\nand Ui\u2032/\u03a6\u2062(Ui\u2032)superscriptsubscript\ud835\udc48\ud835\udc56\u2032\u03a6superscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}/\\Phi(U_{i}^{\\prime})italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / roman_\u03a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) is a simple non-abelian group. In particular,\nUi\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is quasi-simple. Let E=Ui\u2032\u2062U=Ui\u2032\u22caU\ud835\udc38superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc48right-normal-factor-semidirect-productsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc48E=U_{i}^{\\prime}U=U_{i}^{\\prime}\\rtimes Uitalic_E = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_U = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ca italic_U. Then E\u2032=Ui\u2032superscript\ud835\udc38\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032E^{\\prime}=U_{i}^{\\prime}italic_E start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. Let\nU=E0<E1<\u22ef<Et\u22121<Et=E\ud835\udc48subscript\ud835\udc380subscript\ud835\udc381\u22efsubscript\ud835\udc38\ud835\udc611subscript\ud835\udc38\ud835\udc61\ud835\udc38U=E_{0}<E_{1}<\\cdots<E_{t-1}<E_{t}=Eitalic_U = italic_E start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < \u22ef < italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_E be a subgroup chain such that\nEi\u22121subscript\ud835\udc38\ud835\udc561E_{i-1}italic_E start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT\nis a maximal \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal subgroup\nof Eisubscript\ud835\udc38\ud835\udc56E_{i}italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for all i=1,\u2026,t\ud835\udc561\u2026\ud835\udc61i=1,\\ldots,titalic_i = 1 , \u2026 , italic_t and for M=Et\u22121\ud835\udc40subscript\ud835\udc38\ud835\udc611M=E_{t-1}italic_M = italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT we have\nM=U\u2062(M\u2229Ui\u2032)\ud835\udc40\ud835\udc48\ud835\udc40superscriptsubscript\ud835\udc48\ud835\udc56\u2032M=U(M\\cap U_{i}^{\\prime})italic_M = italic_U ( italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ). Then, by Lemma 2.2, we have either\nM=Et\u22121\ud835\udc40subscript\ud835\udc38\ud835\udc611M=E_{t-1}italic_M = italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT is a maximal normal subgroup of E\ud835\udc38Eitalic_E or M\ud835\udc40Mitalic_M\nis a maximal subgroup of E\ud835\udc38Eitalic_E such that\nE/ME\ud835\udc38subscript\ud835\udc40\ud835\udc38E/M_{E}italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-primary non-abelian group of order q\u2062r\ud835\udc5e\ud835\udc5fqritalic_q italic_r\nfor some primes q\ud835\udc5eqitalic_q and r\ud835\udc5fritalic_r. First assume that M\ud835\udc40Mitalic_M is normal in E\ud835\udc38Eitalic_E.\nFrom E=Ui\u2032\u2062U=Ui\u2032\u2062M\ud835\udc38superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc48superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc40E=U_{i}^{\\prime}U=U_{i}^{\\prime}Mitalic_E = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_U = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_M it follows\nthat\nE/M\u2243Ui\u2032/(M\u2229Ui\u2032)similar-to-or-equals\ud835\udc38\ud835\udc40superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc40superscriptsubscript\ud835\udc48\ud835\udc56\u2032E/M\\simeq U_{i}^{\\prime}/(M\\cap U_{i}^{\\prime})italic_E / italic_M \u2243 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / ( italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) is a\nsimple group and so Ui\u2032/(M\u2229Ui\u2032)superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc40superscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}/(M\\cap U_{i}^{\\prime})italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / ( italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) is a\nsimple non-abelian group since Ui\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is perfect. Therefore\nM\u2229Ui\u2032=Ui\u2032\u2229Z=\u03a6\u2062(Ui\u2032)\ud835\udc40superscriptsubscript\ud835\udc48\ud835\udc56\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032\ud835\udc4d\u03a6superscriptsubscript\ud835\udc48\ud835\udc56\u2032M\\cap U_{i}^{\\prime}=U_{i}^{\\prime}\\cap Z=\\Phi(U_{i}^{\\prime})italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2229 italic_Z = roman_\u03a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) is a p\u2032superscript\ud835\udc5d\u2032p^{\\prime}italic_p start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT-group\nby Claim (10), so\nU\ud835\udc48Uitalic_U is a Sylow p\ud835\udc5dpitalic_p-subgroup\nof M=U\u2062(M\u2229Ui\u2032)\ud835\udc40\ud835\udc48\ud835\udc40superscriptsubscript\ud835\udc48\ud835\udc56\u2032M=U(M\\cap U_{i}^{\\prime})italic_M = italic_U ( italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ).\nThen, by the Frattini argument,\nE=M\u2062NE\u2062(U)=(M\u2229Ui\u2032)\u2062NE\u2062(U)=\u03a6\u2062(Ui\u2032)\u2062NE\u2062(U)\ud835\udc38\ud835\udc40subscript\ud835\udc41\ud835\udc38\ud835\udc48\ud835\udc40superscriptsubscript\ud835\udc48\ud835\udc56\u2032subscript\ud835\udc41\ud835\udc38\ud835\udc48\u03a6superscriptsubscript\ud835\udc48\ud835\udc56\u2032subscript\ud835\udc41\ud835\udc38\ud835\udc48E=MN_{E}(U)=(M\\cap U_{i}^{\\prime})N_{E}(U)=\\Phi(U_{i}^{\\prime})N_{E}(U)italic_E = italic_M italic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_U ) = ( italic_M \u2229 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_U ) = roman_\u03a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_U ).\nBut \u03a6\u2062(Ui\u2032)\u2264\u03a6\u2062(E)\u03a6superscriptsubscript\ud835\udc48\ud835\udc56\u2032\u03a6\ud835\udc38\\Phi(U_{i}^{\\prime})\\leq\\Phi(E)roman_\u03a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) \u2264 roman_\u03a6 ( italic_E ), therefore NE\u2062(U)=Esubscript\ud835\udc41\ud835\udc38\ud835\udc48\ud835\udc38N_{E}(U)=Eitalic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_U ) = italic_E and so Ui\u2032\u2264NG\u2062(U)superscriptsubscript\ud835\udc48\ud835\udc56\u2032subscript\ud835\udc41\ud835\udc3a\ud835\udc48U_{i}^{\\prime}\\leq N_{G}(U)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2264 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ). Finally, assume that E/ME\ud835\udc38subscript\ud835\udc40\ud835\udc38E/M_{E}italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a non-abelian group of order q\u2062r\ud835\udc5e\ud835\udc5fqritalic_q italic_r\nwith V/ME=(E/ME)\u2032\ud835\udc49subscript\ud835\udc40\ud835\udc38superscript\ud835\udc38subscript\ud835\udc40\ud835\udc38\u2032V/M_{E}=(E/M_{E})^{\\prime}italic_V / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT = ( italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT.\nThen |(E/ME)/(E/ME)\u2032|=(E/ME)/(V/ME)=|E/V|\ud835\udc38subscript\ud835\udc40\ud835\udc38superscript\ud835\udc38subscript\ud835\udc40\ud835\udc38\u2032\ud835\udc38subscript\ud835\udc40\ud835\udc38\ud835\udc49subscript\ud835\udc40\ud835\udc38\ud835\udc38\ud835\udc49|(E/M_{E})/(E/M_{E})^{\\prime}|=(E/M_{E})/(V/M_{E})=|E/V|| ( italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ) / ( italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT | = ( italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ) / ( italic_V / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ) = | italic_E / italic_V | is a prime,\nso V=Ui\u2032\ud835\udc49superscriptsubscript\ud835\udc48\ud835\udc56\u2032V=U_{i}^{\\prime}italic_V = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. Hence ME\u2264Ui\u2032subscript\ud835\udc40\ud835\udc38superscriptsubscript\ud835\udc48\ud835\udc56\u2032M_{E}\\leq U_{i}^{\\prime}italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT \u2264 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT and Ui\u2032/MEsuperscriptsubscript\ud835\udc48\ud835\udc56\u2032subscript\ud835\udc40\ud835\udc38U_{i}^{\\prime}/M_{E}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a non-identity soluble\ngroup, so Ui\u2032superscriptsubscript\ud835\udc48\ud835\udc56\u2032U_{i}^{\\prime}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is not perfect. This contradiction shows that\nwe have (11). (12) UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is not a non-abelian P\ud835\udc43Pitalic_P-group. Assume that UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is a non-abelian P\ud835\udc43Pitalic_P-group. Then, in view of Claim (7),\nUG=Q\u22caUsuperscript\ud835\udc48\ud835\udc3aright-normal-factor-semidirect-product\ud835\udc44\ud835\udc48U^{G}=Q\\rtimes Uitalic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_Q \u22ca italic_U is of type (q,p)\ud835\udc5e\ud835\udc5d(q,p)( italic_q , italic_p ) for some prime q\ud835\udc5eqitalic_q. Let \u03c0={q,p}\ud835\udf0b\ud835\udc5e\ud835\udc5d\\pi=\\{q,p\\}italic_\u03c0 = { italic_q , italic_p }. First suppose that \u03c0\u2229\u03c0\u2062(D)=\u2205\ud835\udf0b\ud835\udf0b\ud835\udc37\\pi\\cap\\pi(D)=\\emptysetitalic_\u03c0 \u2229 italic_\u03c0 ( italic_D ) = \u2205.\nThen UG\u2229D=1superscript\ud835\udc48\ud835\udc3a\ud835\udc371U^{G}\\cap D=1italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_D = 1, so [UG,D]=1superscript\ud835\udc48\ud835\udc3a\ud835\udc371[U^{G},D]=1[ italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT , italic_D ] = 1 and G\ud835\udc3aGitalic_G is \u03c0\ud835\udf0b\\piitalic_\u03c0-soluble. We show that G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is \u03c0\ud835\udf0b\\piitalic_\u03c0-decomposable. Let\nN=U1\u2032\ud835\udc41superscriptsubscript\ud835\udc481\u2032N=U_{1}^{\\prime}italic_N = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT and F=N\u2062U=N\u00d7U\ud835\udc39\ud835\udc41\ud835\udc48\ud835\udc41\ud835\udc48F=NU=N\\times Uitalic_F = italic_N italic_U = italic_N \u00d7 italic_U. Then FG=N\u2062UGsuperscript\ud835\udc39\ud835\udc3a\ud835\udc41superscript\ud835\udc48\ud835\udc3aF^{G}=NU^{G}italic_F start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_N italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT and\nFG=Nsubscript\ud835\udc39\ud835\udc3a\ud835\udc41F_{G}=Nitalic_F start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_N by Claim (8). In view of Claims (3) and (7),\nF/N\ud835\udc39\ud835\udc41F/Nitalic_F / italic_N is not subnormal but modular in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N and so where\nN\u2062UG/N=O\u03c0\u2062(G/N)\ud835\udc41superscript\ud835\udc48\ud835\udc3a\ud835\udc41subscript\ud835\udc42\ud835\udf0b\ud835\udc3a\ud835\udc41NU^{G}/N=O_{\\pi}(G/N)italic_N italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_N = italic_O start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ( italic_G / italic_N ) and K/N=O\u03c0\u2032\u2062(G/N)\ud835\udc3e\ud835\udc41subscript\ud835\udc42superscript\ud835\udf0b\u2032\ud835\udc3a\ud835\udc41K/N=O_{\\pi^{\\prime}}(G/N)italic_K / italic_N = italic_O start_POSTSUBSCRIPT italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_G / italic_N ), by Lemma 2.14. Therefore\nG/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N is \u03c0\ud835\udf0b\\piitalic_\u03c0-decomposable. Hence\nG/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is \u03c0\ud835\udf0b\\piitalic_\u03c0-decomposable. Let E\ud835\udc38Eitalic_E be a minimal supplement to D\ud835\udc37Ditalic_D in G\ud835\udc3aGitalic_G. Then E\u2229D\u2264\u03a6\u2062(E)\ud835\udc38\ud835\udc37\u03a6\ud835\udc38E\\cap D\\leq\\Phi(E)italic_E \u2229 italic_D \u2264 roman_\u03a6 ( italic_E ), so E\ud835\udc38Eitalic_E is\nsoluble and \u03c0\ud835\udf0b\\piitalic_\u03c0-decomposable, that is, E=O\u03c0\u2062(E)\u00d7O\u03c0\u2032\u2062(E)\ud835\udc38subscript\ud835\udc42\ud835\udf0b\ud835\udc38subscript\ud835\udc42superscript\ud835\udf0b\u2032\ud835\udc38E=O_{\\pi}(E)\\times O_{\\pi^{\\prime}}(E)italic_E = italic_O start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ( italic_E ) \u00d7 italic_O start_POSTSUBSCRIPT italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_E ) by Lemma 2.15\nsince\nG/D\u2243E/(E\u2229D)similar-to-or-equals\ud835\udc3a\ud835\udc37\ud835\udc38\ud835\udc38\ud835\udc37G/D\\simeq E/(E\\cap D)italic_G / italic_D \u2243 italic_E / ( italic_E \u2229 italic_D ). Let x\u2208Gr\ud835\udc65subscript\ud835\udc3a\ud835\udc5fx\\in G_{r}italic_x \u2208 italic_G start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, where Grsubscript\ud835\udc3a\ud835\udc5fG_{r}italic_G start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT be a Sylow r\ud835\udc5fritalic_r-subgroup of G\ud835\udc3aGitalic_G.\nAssume that r\u2209\u03c0\ud835\udc5f\ud835\udf0br\\not\\in\\piitalic_r \u2209 italic_\u03c0. Then for some Sylow\nr\ud835\udc5fritalic_r-subgroup Drsubscript\ud835\udc37\ud835\udc5fD_{r}italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT of D\ud835\udc37Ditalic_D\nand a Sylow r\ud835\udc5fritalic_r-subgroup Ersubscript\ud835\udc38\ud835\udc5fE_{r}italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT of E\ud835\udc38Eitalic_E and some y\u2208G\ud835\udc66\ud835\udc3ay\\in Gitalic_y \u2208 italic_G we have\nGr=Dr\u2062Erysubscript\ud835\udc3a\ud835\udc5fsubscript\ud835\udc37\ud835\udc5fsuperscriptsubscript\ud835\udc38\ud835\udc5f\ud835\udc66G_{r}=D_{r}E_{r}^{y}italic_G start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT. Hence x=d\u2062e\ud835\udc65\ud835\udc51\ud835\udc52x=deitalic_x = italic_d italic_e, where d\u2208Dr\ud835\udc51subscript\ud835\udc37\ud835\udc5fd\\in D_{r}italic_d \u2208 italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and e\u2208Ery\ud835\udc52superscriptsubscript\ud835\udc38\ud835\udc5f\ud835\udc66e\\in E_{r}^{y}italic_e \u2208 italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT. Then d\u2264CG\u2062(U)\ud835\udc51subscript\ud835\udc36\ud835\udc3a\ud835\udc48d\\leq C_{G}(U)italic_d \u2264 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U )\nsince [UG,D]=1superscript\ud835\udc48\ud835\udc3a\ud835\udc371[U^{G},D]=1[ italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT , italic_D ] = 1. Since |G:Ery|=|DEry:Ery|=|D:D\u2229Ery||G:E_{r}^{y}|=|DE_{r}^{y}:E_{r}^{y}|=|D:D\\cap E_{r}^{y}|| italic_G : italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT | = | italic_D italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT : italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT | = | italic_D : italic_D \u2229 italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT | is\na \u03c0\u2032superscript\ud835\udf0b\u2032\\pi^{\\prime}italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT-mumber, the Hall \u03c0\ud835\udf0b\\piitalic_\u03c0-subgroup O\u03c0\u2062(Ey)subscript\ud835\udc42\ud835\udf0bsuperscript\ud835\udc38\ud835\udc66O_{\\pi}(E^{y})italic_O start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ( italic_E start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT ) of Eysuperscript\ud835\udc38\ud835\udc66E^{y}italic_E start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT\nis a Hall \u03c0\ud835\udf0b\\piitalic_\u03c0-subgroup\nof G\ud835\udc3aGitalic_G. Hence UG\u2264O\u03c0\u2062(Ey)superscript\ud835\udc48\ud835\udc3asubscript\ud835\udc42\ud835\udf0bsuperscript\ud835\udc38\ud835\udc66U^{G}\\leq O_{\\pi}(E^{y})italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2264 italic_O start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ( italic_E start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT ) and so e\u2264CG\u2062(U)\ud835\udc52subscript\ud835\udc36\ud835\udc3a\ud835\udc48e\\leq C_{G}(U)italic_e \u2264 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ) since\ne\u2208O\u03c0\u2032\u2062(Ey)\ud835\udc52subscript\ud835\udc42superscript\ud835\udf0b\u2032superscript\ud835\udc38\ud835\udc66e\\in O_{\\pi^{\\prime}}(E^{y})italic_e \u2208 italic_O start_POSTSUBSCRIPT italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_E start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT ).\nTherefore x\u2264CG\u2062(U)\ud835\udc65subscript\ud835\udc36\ud835\udc3a\ud835\udc48x\\leq C_{G}(U)italic_x \u2264 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ) and hence U\ud835\udc48Uitalic_U is normal and so modular\nin\n\u27e8x,U\u27e9\ud835\udc65\ud835\udc48\\langle x,U\\rangle\u27e8 italic_x , italic_U \u27e9. Now let r\u2208\u03c0\ud835\udc5f\ud835\udf0br\\in\\piitalic_r \u2208 italic_\u03c0. Then V=UG\u2062Gr\ud835\udc49superscript\ud835\udc48\ud835\udc3asubscript\ud835\udc3a\ud835\udc5fV=U^{G}G_{r}italic_V = italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_G start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT is a \u03c0\ud835\udf0b\\piitalic_\u03c0-subgroup G\ud835\udc3aGitalic_G, so\nV\u2229D=1\ud835\udc49\ud835\udc371V\\cap D=1italic_V \u2229 italic_D = 1 and therefore V\u2243V\u2062D/Dsimilar-to-or-equals\ud835\udc49\ud835\udc49\ud835\udc37\ud835\udc37V\\simeq VD/Ditalic_V \u2243 italic_V italic_D / italic_D is a soluble Q\u2062\u03c3\u2062T\ud835\udc44\ud835\udf0e\ud835\udc47Q\\sigma Titalic_Q italic_\u03c3 italic_T-group by\nLemma 2.17,\nso U\ud835\udc48Uitalic_U is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal and so modular in V\ud835\udc49Vitalic_V. Hence\nU\ud835\udc48Uitalic_U is modular in \u27e8x,U\u27e9\ud835\udc65\ud835\udc48\\langle x,U\\rangle\u27e8 italic_x , italic_U \u27e9 by [1, Page 201, Property (2)].\nTherefore U\ud835\udc48Uitalic_U is modular in G\ud835\udc3aGitalic_G by Lemma 2.8(2)\nand so U\ud835\udc48Uitalic_U is \u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal in G\ud835\udc3aGitalic_G, a contradiction. Finally, if\n\u03c0\u2229\u03c0\u2062(D)\u2260\u2205\ud835\udf0b\ud835\udf0b\ud835\udc37\\pi\\cap\\pi(D)\\neq\\emptysetitalic_\u03c0 \u2229 italic_\u03c0 ( italic_D ) \u2260 \u2205, then G\ud835\udc3aGitalic_G satisfies\n\ud835\udc10\u03c3\u2062(p,q)subscript\ud835\udc10\ud835\udf0e\ud835\udc5d\ud835\udc5e{\\bf Q}_{\\sigma(p,q)}bold_Q start_POSTSUBSCRIPT italic_\u03c3 ( italic_p , italic_q ) end_POSTSUBSCRIPT by Condition (iii), so U\ud835\udc48Uitalic_U is modular and so\n\u03c3\ud835\udf0e\\sigmaitalic_\u03c3-quasinormal\nin G\ud835\udc3aGitalic_G.\nThis contradiction completes the proof of the claim. (13) G\ud835\udc3aGitalic_G has a normal subgroup Cqsubscript\ud835\udc36\ud835\udc5eC_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT of prime\norder q\ud835\udc5eqitalic_q such that Cq\u2264Z\u2062(U1\u2032)=\u03a6\u2062(U1\u2032)subscript\ud835\udc36\ud835\udc5e\ud835\udc4dsuperscriptsubscript\ud835\udc481\u2032\u03a6superscriptsubscript\ud835\udc481\u2032C_{q}\\leq Z(U_{1}^{\\prime})=\\Phi(U_{1}^{\\prime})italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u2264 italic_Z ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) = roman_\u03a6 ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ). Let E=U1\u2032\u2062U=U1\u2032\u00d7U\ud835\udc38superscriptsubscript\ud835\udc481\u2032\ud835\udc48superscriptsubscript\ud835\udc481\u2032\ud835\udc48E=U_{1}^{\\prime}U=U_{1}^{\\prime}\\times Uitalic_E = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_U = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u00d7 italic_U. Then E\ud835\udc38Eitalic_E is modular and\nnot subnormal in G\ud835\udc3aGitalic_G by Claims (3) and (7). Moreover, EG=U1\u2032subscript\ud835\udc38\ud835\udc3asuperscriptsubscript\ud835\udc481\u2032E_{G}=U_{1}^{\\prime}italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT by Claim (8)\nand\nE/U1\u2032\u2243Usimilar-to-or-equals\ud835\udc38superscriptsubscript\ud835\udc481\u2032\ud835\udc48E/U_{1}^{\\prime}\\simeq Uitalic_E / italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2243 italic_U is a modular non-subnormal subgroup of G/U1\u2032\ud835\udc3asuperscriptsubscript\ud835\udc481\u2032G/U_{1}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. Hence is a\nnon-abelian P\ud835\udc43Pitalic_P-group by Lemma 2.8(1).\nHence 1<UG\u2229U1\u2032\u2264Z\u2062(U1\u2032)1superscript\ud835\udc48\ud835\udc3asuperscriptsubscript\ud835\udc481\u2032\ud835\udc4dsuperscriptsubscript\ud835\udc481\u20321<U^{G}\\cap U_{1}^{\\prime}\\leq Z(U_{1}^{\\prime})1 < italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2229 italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u2264 italic_Z ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) by Claims (6) and (12). Hence G\ud835\udc3aGitalic_G\nhas a normal subgroup Cqsubscript\ud835\udc36\ud835\udc5eC_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT of prime\norder q\ud835\udc5eqitalic_q such that Cq\u2264U1\u2032subscript\ud835\udc36\ud835\udc5esuperscriptsubscript\ud835\udc481\u2032C_{q}\\leq U_{1}^{\\prime}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u2264 italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. But U1\u2032superscriptsubscript\ud835\udc481\u2032U_{1}^{\\prime}italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is a quasi-simple group by Lemma 2.13(1)\nand so\nCq\u2264Z\u2062(U1\u2032)=\u03a6\u2062(U1\u2032)subscript\ud835\udc36\ud835\udc5e\ud835\udc4dsuperscriptsubscript\ud835\udc481\u2032\u03a6superscriptsubscript\ud835\udc481\u2032C_{q}\\leq Z(U_{1}^{\\prime})=\\Phi(U_{1}^{\\prime})italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u2264 italic_Z ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) = roman_\u03a6 ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ). Final contradiction. From Claims (7), (9) and (11) it follows that\nE=Cq\u2062U=Cq\u00d7U\ud835\udc38subscript\ud835\udc36\ud835\udc5e\ud835\udc48subscript\ud835\udc36\ud835\udc5e\ud835\udc48E=C_{q}U=C_{q}\\times Uitalic_E = italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U = italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00d7 italic_U is not subnormal in G\ud835\udc3aGitalic_G and, in view of Claim (8),\nEG=Cqsubscript\ud835\udc38\ud835\udc3asubscript\ud835\udc36\ud835\udc5eE_{G}=C_{q}italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT.\nHence G/EG\u2243EG/EG\u00d7K/EG,similar-to-or-equals\ud835\udc3asubscript\ud835\udc38\ud835\udc3asuperscript\ud835\udc38\ud835\udc3asubscript\ud835\udc38\ud835\udc3a\ud835\udc3esubscript\ud835\udc38\ud835\udc3aG/E_{G}\\simeq E^{G}/E_{G}\\times K/E_{G},italic_G / italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT \u2243 italic_E start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT \u00d7 italic_K / italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , where is a non-abelian\nP\ud835\udc43Pitalic_P-group of order prime to |K/Cq|\ud835\udc3esubscript\ud835\udc36\ud835\udc5e|K/C_{q}|| italic_K / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT | by Lemma 2.8(1). Hence G\ud835\udc3aGitalic_G is a \u03c0\ud835\udf0b\\piitalic_\u03c0-soluble\ngroup, where \u03c0=\u03c0\u2062(UG/(Cq\u2229UG))\ud835\udf0b\ud835\udf0bsuperscript\ud835\udc48\ud835\udc3asubscript\ud835\udc36\ud835\udc5esuperscript\ud835\udc48\ud835\udc3a\\pi=\\pi(U^{G}/(C_{q}\\cap U^{G}))italic_\u03c0 = italic_\u03c0 ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u2229 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT ) ). Then D/Z\ud835\udc37\ud835\udc4dD/Zitalic_D / italic_Z is\n\u03c0\ud835\udf0b\\piitalic_\u03c0-soluble. But Cq\u2264\u03a6\u2062(U1\u2032)\u2264\u03a6\u2062(D)=Zsubscript\ud835\udc36\ud835\udc5e\u03a6superscriptsubscript\ud835\udc481\u2032\u03a6\ud835\udc37\ud835\udc4dC_{q}\\leq\\Phi(U_{1}^{\\prime})\\leq\\Phi(D)=Zitalic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u2264 roman_\u03a6 ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ) \u2264 roman_\u03a6 ( italic_D ) = italic_Z by Claim (1),\nso q\ud835\udc5eqitalic_q divides |D/Z|\ud835\udc37\ud835\udc4d|D/Z|| italic_D / italic_Z |. Hence\nq\ud835\udc5eqitalic_q does not divides |Cq\u2062UG/Cq|subscript\ud835\udc36\ud835\udc5esuperscript\ud835\udc48\ud835\udc3asubscript\ud835\udc36\ud835\udc5e|C_{q}U^{G}/C_{q}|| italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT |. If Cq\u2229UG=1subscript\ud835\udc36\ud835\udc5esuperscript\ud835\udc48\ud835\udc3a1C_{q}\\cap U^{G}=1italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u2229 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = 1, then UG\u2243Cq\u2062UG/Cqsimilar-to-or-equalssuperscript\ud835\udc48\ud835\udc3asubscript\ud835\udc36\ud835\udc5esuperscript\ud835\udc48\ud835\udc3asubscript\ud835\udc36\ud835\udc5eU^{G}\\simeq C_{q}U^{G}/C_{q}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u2243 italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is a non-abelian\nP\ud835\udc43Pitalic_P-group, contrary to Claim (12), so Cq\u2264UGsubscript\ud835\udc36\ud835\udc5esuperscript\ud835\udc48\ud835\udc3aC_{q}\\leq U^{G}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u2264 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT. Then\nCqsubscript\ud835\udc36\ud835\udc5eC_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is a Sylow q\ud835\udc5eqitalic_q-subgroup of UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT.\nHence UG=Cq\u22ca(R\u22caU)superscript\ud835\udc48\ud835\udc3aright-normal-factor-semidirect-productsubscript\ud835\udc36\ud835\udc5eright-normal-factor-semidirect-product\ud835\udc45\ud835\udc48U^{G}=C_{q}\\rtimes(R\\rtimes U)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u22ca ( italic_R \u22ca italic_U ),\nwhere R\u22caU\u2243UG/Cqsimilar-to-or-equalsright-normal-factor-semidirect-product\ud835\udc45\ud835\udc48superscript\ud835\udc48\ud835\udc3asubscript\ud835\udc36\ud835\udc5eR\\rtimes U\\simeq U^{G}/C_{q}italic_R \u22ca italic_U \u2243 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is a non-abelian P\ud835\udc43Pitalic_P-group.\nLet C=CUG\u2062(Cq)\ud835\udc36subscript\ud835\udc36superscript\ud835\udc48\ud835\udc3asubscript\ud835\udc36\ud835\udc5eC=C_{U^{G}}(C_{q})italic_C = italic_C start_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ). Then U\u2264C\ud835\udc48\ud835\udc36U\\leq Citalic_U \u2264 italic_C by Claim (11) and so, by Lemma\n2.10(1), R\u22caU=UR\u22caU\u2264Cright-normal-factor-semidirect-product\ud835\udc45\ud835\udc48superscript\ud835\udc48right-normal-factor-semidirect-product\ud835\udc45\ud835\udc48\ud835\udc36R\\rtimes U=U^{R\\rtimes U}\\leq Citalic_R \u22ca italic_U = italic_U start_POSTSUPERSCRIPT italic_R \u22ca italic_U end_POSTSUPERSCRIPT \u2264 italic_C. Hence Cq\u2264Z\u2062(UG)subscript\ud835\udc36\ud835\udc5e\ud835\udc4dsuperscript\ud835\udc48\ud835\udc3aC_{q}\\leq Z(U^{G})italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u2264 italic_Z ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT ).\nTherefore\nUG=Cq\u00d7(R\u22caU)superscript\ud835\udc48\ud835\udc3asubscript\ud835\udc36\ud835\udc5eright-normal-factor-semidirect-product\ud835\udc45\ud835\udc48U^{G}=C_{q}\\times(R\\rtimes U)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00d7 ( italic_R \u22ca italic_U ), where R\u22caUright-normal-factor-semidirect-product\ud835\udc45\ud835\udc48R\\rtimes Uitalic_R \u22ca italic_U is characterisric in UGsuperscript\ud835\udc48\ud835\udc3aU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT\nand so it is normal in G\ud835\udc3aGitalic_G. But then UG=R\u22caU\u2260Cq\u22ca(R\u22caU)superscript\ud835\udc48\ud835\udc3aright-normal-factor-semidirect-product\ud835\udc45\ud835\udc48right-normal-factor-semidirect-productsubscript\ud835\udc36\ud835\udc5eright-normal-factor-semidirect-product\ud835\udc45\ud835\udc48U^{G}=R\\rtimes U\\neq C_{q}\\rtimes(R\\rtimes U)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_R \u22ca italic_U \u2260 italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u22ca ( italic_R \u22ca italic_U ),\na contradiction.\nThe theorem is proved. Proof of Theorem F. In view of Example 1.2(i),\nTeorem F is a special case of Theorem E, where \u03c3={\u2119}\ud835\udf0e\u2119\\sigma=\\{\\mathbb{P}\\}italic_\u03c3 = { blackboard_P }. 1. First Consider the special case of Theorem E where\n\u03c3=\u03c31\u2062\u03c0={{p1},\u2026,{pn},\u03c0\u2032}\ud835\udf0esuperscript\ud835\udf0e1\ud835\udf0bsubscript\ud835\udc5d1\u2026subscript\ud835\udc5d\ud835\udc5bsuperscript\ud835\udf0b\u2032\\sigma=\\sigma^{1\\pi}=\\{\\{p_{1}\\},\\ldots,\\{p_{n}\\},\\pi^{\\prime}\\}italic_\u03c3 = italic_\u03c3 start_POSTSUPERSCRIPT 1 italic_\u03c0 end_POSTSUPERSCRIPT = { { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } , \u2026 , { italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT } and\n\u03c0={p1,\u2026,pn}\ud835\udf0bsubscript\ud835\udc5d1\u2026subscript\ud835\udc5d\ud835\udc5b\\pi=\\{p_{1},\\ldots,p_{n}\\}italic_\u03c0 = { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } (see Example 1.2(iii)). In this case we say that\nG\ud835\udc3aGitalic_G is a Q\u20621\u2062\u03c0\u2062T\ud835\udc441\ud835\udf0b\ud835\udc47Q1\\pi Titalic_Q 1 italic_\u03c0 italic_T-group\nif 1\u2062\u03c01\ud835\udf0b1\\pi1 italic_\u03c0-quasinormality\nis a transitive relation on G\ud835\udc3aGitalic_G,\nand we also say in this case that \u201dG\ud835\udc3aGitalic_G satisfies \ud835\udc101\u2062\u03c0\u2062(p,q)subscript\ud835\udc101\ud835\udf0b\ud835\udc5d\ud835\udc5e{\\bf Q}_{1\\pi(p,q)}bold_Q start_POSTSUBSCRIPT 1 italic_\u03c0 ( italic_p , italic_q ) end_POSTSUBSCRIPT\u201d\ninstead of \u201dG\ud835\udc3aGitalic_G satisfies \ud835\udc10\u03c3\u2062(p,q)subscript\ud835\udc10\ud835\udf0e\ud835\udc5d\ud835\udc5e{\\bf Q}_{\\sigma(p,q)}bold_Q start_POSTSUBSCRIPT italic_\u03c3 ( italic_p , italic_q ) end_POSTSUBSCRIPT\u201d. Observe that G\ud835\udc3aGitalic_G satisfies \ud835\udc101\u2062\u03c0\u2062(p,q)subscript\ud835\udc101\ud835\udf0b\ud835\udc5d\ud835\udc5e{\\bf Q}_{1\\pi(p,q)}bold_Q start_POSTSUBSCRIPT 1 italic_\u03c0 ( italic_p , italic_q ) end_POSTSUBSCRIPT\nif whenever N\ud835\udc41Nitalic_N is a soluble normal\nsubgroup of G\ud835\udc3aGitalic_G and P/N\ud835\udc43\ud835\udc41P/Nitalic_P / italic_N is a normal non-abelian\nP\ud835\udc43Pitalic_P-subgroup of type (p,q)\ud835\udc5d\ud835\udc5e(p,q)( italic_p , italic_q ) of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N, where p,q\u2208\u03c0\u2032\ud835\udc5d\ud835\udc5esuperscript\ud835\udf0b\u2032p,q\\in\\pi^{\\prime}italic_p , italic_q \u2208 italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT,\nevery subgroup of P/N\ud835\udc43\ud835\udc41P/Nitalic_P / italic_N is\nmodular in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N.\nTherefore we get from Theorem E the following result. Corollary 4.1. A group G\ud835\udc3aGitalic_G is a Q\u20621\u2062\u03c0\u2062T\ud835\udc441\ud835\udf0b\ud835\udc47Q1\\pi Titalic_Q 1 italic_\u03c0 italic_T-group if\nand only if G\ud835\udc3aGitalic_G has a perfect normal subgroup D\ud835\udc37Ditalic_D such that: (i) G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is a soluble Q\u20621\u2062\u03c0\u2062T\ud835\udc441\ud835\udf0b\ud835\udc47Q1\\pi Titalic_Q 1 italic_\u03c0 italic_T-group, (ii) if D\u22601\ud835\udc371D\\neq 1italic_D \u2260 1, G\ud835\udc3aGitalic_G has a Robinson complex\n(D,Z\u2062(D);U1,\u2026,Uk)\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\u2026subscript\ud835\udc48\ud835\udc58(D,Z(D);U_{1},\\ldots,U_{k})( italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u2026,ir}\u2286{1,\u2026,k}subscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc5f1\u2026\ud835\udc58\\{i_{1},\\ldots,i_{r}\\}\\subseteq\\{1,\\ldots,k\\}{ italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u2286 { 1 , \u2026 , italic_k }, where\n1\u2264r<k1\ud835\udc5f\ud835\udc581\\leq r<k1 \u2264 italic_r < italic_k, the groups G\ud835\udc3aGitalic_G and G/Ui1\u2032\u2062\u22ef\u2062Uir\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48subscript\ud835\udc561\u2032\u22efsuperscriptsubscript\ud835\udc48subscript\ud835\udc56\ud835\udc5f\u2032G/U_{i_{1}}^{\\prime}\\cdots U_{i_{r}}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT satisfy\n\ud835\udc0dpsubscript\ud835\udc0d\ud835\udc5d{\\bf N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u2208{2,3}\u2229\u03c0\u2062(Z\u2062(D))\ud835\udc5d23\ud835\udf0b\ud835\udc4d\ud835\udc37p\\in\\{2,3\\}\\cap\\pi(Z(D))italic_p \u2208 { 2 , 3 } \u2229 italic_\u03c0 ( italic_Z ( italic_D ) ),\n\ud835\udc0fpsubscript\ud835\udc0f\ud835\udc5d{\\bf P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT\nfor all p\u2208\u03c0\u2062(D)\ud835\udc5d\ud835\udf0b\ud835\udc37p\\in\\pi(D)italic_p \u2208 italic_\u03c0 ( italic_D ), and \ud835\udc101\u03c0(p,q){\\bf Q}_{1\\pi(p,q})bold_Q start_POSTSUBSCRIPT 1 italic_\u03c0 ( italic_p , italic_q end_POSTSUBSCRIPT )\nfor all pairs {p,q}\u2286\u03c0\u2032\ud835\udc5d\ud835\udc5esuperscript\ud835\udf0b\u2032\\{p,q\\}\\subseteq\\pi^{\\prime}{ italic_p , italic_q } \u2286 italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT with\n{p,q}\u2229\u03c0\u2062(D)\u2260\u2205\ud835\udc5d\ud835\udc5e\ud835\udf0b\ud835\udc37\\{p,q\\}\\cap\\pi(D)\\neq\\emptyset{ italic_p , italic_q } \u2229 italic_\u03c0 ( italic_D ) \u2260 \u2205. 2. Now Consider the special case of Theorem E where\n\u03c3=\u03c3\u03c0={\u03c0,\u03c0\u2032}\ud835\udf0esuperscript\ud835\udf0e\ud835\udf0b\ud835\udf0bsuperscript\ud835\udf0b\u2032\\sigma=\\sigma^{\\pi}=\\{\\pi,\\pi^{\\prime}\\}italic_\u03c3 = italic_\u03c3 start_POSTSUPERSCRIPT italic_\u03c0 end_POSTSUPERSCRIPT = { italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT } (see Example 1.2(iv)). In this case we say that\nG\ud835\udc3aGitalic_G is a Q\u2062\u03c0,\u03c0\u2032\u2062T\ud835\udc44\ud835\udf0bsuperscript\ud835\udf0b\u2032\ud835\udc47Q\\pi,\\pi^{\\prime}Titalic_Q italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_T-group\nif \u03c0,\u03c0\u2032\ud835\udf0bsuperscript\ud835\udf0b\u2032\\pi,\\pi^{\\prime}italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT-quasinormality\nis a transitive relation on G\ud835\udc3aGitalic_G,\nand we also say in this case that G\ud835\udc3aGitalic_G \u201dsatisfies \ud835\udc10\u03c0,\u03c0\u2032\u2062(p,q)subscript\ud835\udc10\ud835\udf0bsuperscript\ud835\udf0b\u2032\ud835\udc5d\ud835\udc5e{\\bf Q}_{\\pi,\\pi^{\\prime}(p,q)}bold_Q start_POSTSUBSCRIPT italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_p , italic_q ) end_POSTSUBSCRIPT\u201d\ninstead of \u201dG\ud835\udc3aGitalic_G satisfies \ud835\udc10\u03c3\u2062(p,q)subscript\ud835\udc10\ud835\udf0e\ud835\udc5d\ud835\udc5e{\\bf Q}_{\\sigma(p,q)}bold_Q start_POSTSUBSCRIPT italic_\u03c3 ( italic_p , italic_q ) end_POSTSUBSCRIPT\u201d. Observe that G\ud835\udc3aGitalic_G satisfies \ud835\udc10\u03c0,\u03c0\u2032\u2062(p,q)subscript\ud835\udc10\ud835\udf0bsuperscript\ud835\udf0b\u2032\ud835\udc5d\ud835\udc5e{\\bf Q}_{\\pi,\\pi^{\\prime}(p,q)}bold_Q start_POSTSUBSCRIPT italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_p , italic_q ) end_POSTSUBSCRIPT\nif whenever N\ud835\udc41Nitalic_N is a soluble normal\nsubgroup of G\ud835\udc3aGitalic_G and P/N\ud835\udc43\ud835\udc41P/Nitalic_P / italic_N is a normal non-abelian\nP\ud835\udc43Pitalic_P-subgroup of type (p,q)\ud835\udc5d\ud835\udc5e(p,q)( italic_p , italic_q ) of G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N, where p,q\u2208\u03c00\u2208{\u03c0,\u03c0\u2032}\ud835\udc5d\ud835\udc5esubscript\ud835\udf0b0\ud835\udf0bsuperscript\ud835\udf0b\u2032p,q\\in\\pi_{0}\\in\\{\\pi,\\pi^{\\prime}\\}italic_p , italic_q \u2208 italic_\u03c0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2208 { italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT },\nevery subgroup of P/N\ud835\udc43\ud835\udc41P/Nitalic_P / italic_N is modular in G/N\ud835\udc3a\ud835\udc41G/Nitalic_G / italic_N. Therefore we get from Theorem E the following result. Corollary 4.2. A group G\ud835\udc3aGitalic_G is a Q\u2062\u03c0,\u03c0\u2032\u2062T\ud835\udc44\ud835\udf0bsuperscript\ud835\udf0b\u2032\ud835\udc47Q\\pi,\\pi^{\\prime}Titalic_Q italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_T-group if\nand only if G\ud835\udc3aGitalic_G has a perfect normal subgroup D\ud835\udc37Ditalic_D such that: (i) G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is a soluble Q\u2062\u03c0,\u03c0\u2032\u2062T\ud835\udc44\ud835\udf0bsuperscript\ud835\udf0b\u2032\ud835\udc47Q\\pi,\\pi^{\\prime}Titalic_Q italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT italic_T-group, (ii) if D\u22601\ud835\udc371D\\neq 1italic_D \u2260 1, G\ud835\udc3aGitalic_G has a Robinson complex\n(D,Z\u2062(D);U1,\u2026,Uk)\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\u2026subscript\ud835\udc48\ud835\udc58(D,Z(D);U_{1},\\ldots,U_{k})( italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u2026,ir}\u2286{1,\u2026,k}subscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc5f1\u2026\ud835\udc58\\{i_{1},\\ldots,i_{r}\\}\\subseteq\\{1,\\ldots,k\\}{ italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u2286 { 1 , \u2026 , italic_k }, where\n1\u2264r<k1\ud835\udc5f\ud835\udc581\\leq r<k1 \u2264 italic_r < italic_k, the groups G\ud835\udc3aGitalic_G and G/Ui1\u2032\u2062\u22ef\u2062Uir\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48subscript\ud835\udc561\u2032\u22efsuperscriptsubscript\ud835\udc48subscript\ud835\udc56\ud835\udc5f\u2032G/U_{i_{1}}^{\\prime}\\cdots U_{i_{r}}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT satisfy\n\ud835\udc0dpsubscript\ud835\udc0d\ud835\udc5d{\\bf N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u2208{2,3}\u2229\u03c0\u2062(Z\u2062(D))\ud835\udc5d23\ud835\udf0b\ud835\udc4d\ud835\udc37p\\in\\{2,3\\}\\cap\\pi(Z(D))italic_p \u2208 { 2 , 3 } \u2229 italic_\u03c0 ( italic_Z ( italic_D ) ),\n\ud835\udc0fpsubscript\ud835\udc0f\ud835\udc5d{\\bf P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT\nfor all p\u2208\u03c0\u2062(D)\ud835\udc5d\ud835\udf0b\ud835\udc37p\\in\\pi(D)italic_p \u2208 italic_\u03c0 ( italic_D ), and \ud835\udc10\u03c0,\u03c0\u2032(p,q){\\bf Q}_{\\pi,\\pi^{\\prime}(p,q})bold_Q start_POSTSUBSCRIPT italic_\u03c0 , italic_\u03c0 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_p , italic_q end_POSTSUBSCRIPT ) for all pairs\n{p,q}\u2229\u03c0\u2062(D)\u2260\u2205\ud835\udc5d\ud835\udc5e\ud835\udf0b\ud835\udc37\\{p,q\\}\\cap\\pi(D)\\neq\\emptyset{ italic_p , italic_q } \u2229 italic_\u03c0 ( italic_D ) \u2260 \u2205. 3. In the case when \u03c3=\u03c31={{2},{3},{5}\u2062\u2026}\ud835\udf0esuperscript\ud835\udf0e1235\u2026\\sigma=\\sigma^{1}=\\{\\{2\\},\\{3\\},\\{5\\}\\ldots\\}italic_\u03c3 = italic_\u03c3 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT = { { 2 } , { 3 } , { 5 } \u2026 } (see Example 1.2(ii))\nwe get from Theorem E the following clarification of Theorem D. Corollary 4.3.\nG\ud835\udc3aGitalic_G is a P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group if\nand only if G\ud835\udc3aGitalic_G has a normal perfect subgroup D\ud835\udc37Ditalic_D such that: (i) G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is a soluble P\u2062T\ud835\udc43\ud835\udc47PTitalic_P italic_T-group, and (i) if D\u22601\ud835\udc371D\\neq 1italic_D \u2260 1, G\ud835\udc3aGitalic_G has a Robinson complex\n(D,Z\u2062(D);U1,\u2026,Uk)\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\u2026subscript\ud835\udc48\ud835\udc58(D,Z(D);U_{1},\\ldots,U_{k})( italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u2026,ir}\u2286{1,\u2026,k}subscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc5f1\u2026\ud835\udc58\\{i_{1},\\ldots,i_{r}\\}\\subseteq\\{1,\\ldots,k\\}{ italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u2286 { 1 , \u2026 , italic_k }, where\n1\u2264r<k1\ud835\udc5f\ud835\udc581\\leq r<k1 \u2264 italic_r < italic_k, G\ud835\udc3aGitalic_G and G/Ui1\u2032\u2062\u22ef\u2062Uir\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48subscript\ud835\udc561\u2032\u22efsuperscriptsubscript\ud835\udc48subscript\ud835\udc56\ud835\udc5f\u2032G/U_{i_{1}}^{\\prime}\\cdots U_{i_{r}}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT satisfy\n\ud835\udc0dpsubscript\ud835\udc0d\ud835\udc5d{\\bf N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u2208{2,3}\u2229\u03c0\u2062(Z\u2062(D))\ud835\udc5d23\ud835\udf0b\ud835\udc4d\ud835\udc37p\\in\\{2,3\\}\\cap\\pi(Z(D))italic_p \u2208 { 2 , 3 } \u2229 italic_\u03c0 ( italic_Z ( italic_D ) ) and\n\ud835\udc0fpsubscript\ud835\udc0f\ud835\udc5d{\\bf P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT\nfor all p\u2208\u03c0\u2062(D)\ud835\udc5d\ud835\udf0b\ud835\udc37p\\in\\pi(D)italic_p \u2208 italic_\u03c0 ( italic_D ). 4. In the paper [21], the following special case of Theorem F was proved. Corollary 4.4. A group G\ud835\udc3aGitalic_G is an M\u2062T\ud835\udc40\ud835\udc47MTitalic_M italic_T-group if\nand only if G\ud835\udc3aGitalic_G has a perfect normal subgroup D\ud835\udc37Ditalic_D such that: (i) G/D\ud835\udc3a\ud835\udc37G/Ditalic_G / italic_D is an M\ud835\udc40Mitalic_M-group, (ii) if D\u22601\ud835\udc371D\\neq 1italic_D \u2260 1, G\ud835\udc3aGitalic_G has a Robinson complex\n(D,Z\u2062(D);U1,\u2026,Uk)\ud835\udc37\ud835\udc4d\ud835\udc37subscript\ud835\udc481\u2026subscript\ud835\udc48\ud835\udc58(D,Z(D);U_{1},\\ldots,U_{k})( italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u2026,ir}\u2286{1,\u2026,k}subscript\ud835\udc561\u2026subscript\ud835\udc56\ud835\udc5f1\u2026\ud835\udc58\\{i_{1},\\ldots,i_{r}\\}\\subseteq\\{1,\\ldots,k\\}{ italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u2286 { 1 , \u2026 , italic_k }, where\n1\u2264r<k1\ud835\udc5f\ud835\udc581\\leq r<k1 \u2264 italic_r < italic_k, G\ud835\udc3aGitalic_G and G/Ui1\u2032\u2062\u22ef\u2062Uir\u2032\ud835\udc3asuperscriptsubscript\ud835\udc48subscript\ud835\udc561\u2032\u22efsuperscriptsubscript\ud835\udc48subscript\ud835\udc56\ud835\udc5f\u2032G/U_{i_{1}}^{\\prime}\\cdots U_{i_{r}}^{\\prime}italic_G / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT \u22ef italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT satisfy\n\ud835\udc0dpsubscript\ud835\udc0d\ud835\udc5d{\\bf N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u2208\u03c0\u2062(Z\u2062(D))\ud835\udc5d\ud835\udf0b\ud835\udc4d\ud835\udc37p\\in\\pi(Z(D))italic_p \u2208 italic_\u03c0 ( italic_Z ( italic_D ) ),\n\ud835\udc0fpsubscript\ud835\udc0f\ud835\udc5d{\\bf P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT\nfor all p\u2208\u03c0\u2062(D)\ud835\udc5d\ud835\udf0b\ud835\udc37p\\in\\pi(D)italic_p \u2208 italic_\u03c0 ( italic_D ), and \ud835\udc0cp,qsubscript\ud835\udc0c\ud835\udc5d\ud835\udc5e{\\bf M}_{p,q}bold_M start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT for all pairs\n{p,q}\u2229\u03c0\u2062(D)\u2260\u2205.\ud835\udc5d\ud835\udc5e\ud835\udf0b\ud835\udc37\\{p,q\\}\\cap\\pi(D)\\neq\\emptyset.{ italic_p , italic_q } \u2229 italic_\u03c0 ( italic_D ) \u2260 \u2205 . Remark 4.5. Theorem F not only strengthens Corollary 4.4\nbut also gives a new proof of it."
    },
    {
        "id": 22,
        "title": "Bachelor thesis \n Introduction: Swarm-based gradient descent for non convex optimization",
        "corpus": "Thesis.bib Department of Mathematics and Computer Science \n\nDivision of Mathematics \n\nUniversity of Cologne Supervisor: Prof. Dr. Angela Kunoth At this point, I would like to thank Prof. Angela Kunoth for the opportunity to write a bachelor thesis under her supervision. The topic she gave me is based on the work of Prof. Eitan Tadmor and was fascinating. Moreover she encouraged me to contact Prof. Eitan Tadmor directly to help answer my questions. Therefore I would like to thank him for our correspondence. For tips and comments I am also thankful to Sarah Knoll, who I could also turn to at any time.\nI would also like to thank my family, my partner and a friend for proofreading. The field of optimization has the goal to find an optimal solution to a target function. This means to minimize (or maximize) the target function.\nSuch optimization problems are found in several scientific disciplines, for example in physics or computer science.\nOften it is not possible to find the analytical solution, thus one has to consider numerical approaches.\n\n\nWe consider a general optimization problem for a function F:\u03a9\u2282\u211dd\u2192\u211d:\ud835\udc39\u03a9superscript\u211d\ud835\udc51\u2192\u211dF:\\Omega\\subset\\mathbb{R}^{d}\\to\\mathbb{R}italic_F : roman_\u03a9 \u2282 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u2192 blackboard_R.\nTo find a minimum, we can use the classical gradient descent method. First, we compute the local gradient \u2207F\u2062(\ud835\udc31)\u2207\ud835\udc39\ud835\udc31\\nabla F(\\bm{\\mathrm{x}})\u2207 italic_F ( bold_x ) to find a search direction and after choosing a step size, we can run along the function to search for a minimum. Once the gradient approaches zero, we know that a minimum has been found. However, initially we can only assume a local minimum. If we want to find a global minimum, this method is often not suitable. For example the function\nS\u2062(x)=(1.5\u2062t\u22122)2\u22c5cos\u2061(30\u2062\u03c0+(3\u2062\u03c0\u2062t)2)\ud835\udc46\ud835\udc65\u22c5superscript1.5\ud835\udc612230\ud835\udf0bsuperscript3\ud835\udf0b\ud835\udc612S(x)=(1.5t-2)^{2}\\cdot\\cos(30\\pi+(3\\pi t)^{2})italic_S ( italic_x ) = ( 1.5 italic_t - 2 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \u22c5 roman_cos ( 30 italic_\u03c0 + ( 3 italic_\u03c0 italic_t ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) in figure 1.1 has many local minima and one global minimum. If the starting point is not well chosen, the classical gradient descent method would stop at a local minimum because the gradient equals zero and therefore the method would never reach the global minimum. In the case of the function S\ud835\udc46Sitalic_S, a starting position outside of the first quarter of the interval would lead to an incorrect result. Therefore, the subject of this paper is the introduction of the swarm-based gradient descent for solving the global optimization problem (1.1) based on [tad].\n\n\nAs implied by the name, a swarm of multiple agents is used for finding a global minimum. The agents are characterized by a time-dependent position \ud835\udc31i\u2062(tn)\u2208\u03a9\u2282\u211ddsubscript\ud835\udc31\ud835\udc56superscript\ud835\udc61\ud835\udc5b\u03a9superscript\u211d\ud835\udc51\\bm{\\mathrm{x}}_{i}(t^{n})\\in\\Omega\\subset\\mathbb{R}^{d}bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) \u2208 roman_\u03a9 \u2282 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and a relative mass m~i\u2062(tn)\u2208[0,1]subscript~\ud835\udc5a\ud835\udc56superscript\ud835\udc61\ud835\udc5b01\\tilde{m}_{i}(t^{n})\\in[0,1]over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) \u2208 [ 0 , 1 ]. Each agent is also given its own step size, defined by its relative mass. Heavier agents receive smaller step sizes and converge to local minima, while lighter agents have a larger step size, improving the global position of the swarm.\nAs animals in nature, the agents in a swarm communicate with each other. This communication leads to a mass transition between the agents, so that lighter\nagents have a possibility to grow heavier and therefore converge to a potential global minima. Another characteristic of this method is the\n\u201eSurvival of the fittest\u201c approach. After each iteration the \u201eworst\u201cagent will be eliminated from the swarm.\n\n\nA further explanation of the algorithm with more detail is given in chapter 2.\nIn chapter 3, I will also demonstrate the method with an example. Thereby the advantages compared to the gradient descent become clearer.\nAfter that, in chapter 4, I show my implemented version in the programming language Julia, before finally in chapter 5 the convergence and error analysis follows. As mentioned before, the classical gradient descent is often the first approach to find a solution for a problem like (1.1).\nAnd because of the disadvantages, one might start to try and improve this method.\nNaturally the first thing to do would be to consider more than one explorer. Like in daily life, a group is often faster in solving a problem than one individual.\nMoreover, a group could be spread around the target function to help avoiding being trapped in local minima. In section 3.2 we will see that this is\nan improvement, but the method still has some disadvantages.\n\n\nSince we have a group of explorers now, the question is how to improve the group\u2019s behavior. For this purpose, we can consider nature\u2019s principles.\nIn nature there are several swarms of animals that act in groups in order to survive. The question is now, what is the characteristic of a swarm?\n\nA swarm is based on both a number of individuals, also called agents, and an interaction process between them. To describe this process, we consider the Cucker-Smale [cuc] model. It describes a pairwise interaction between agents, that steer the swarm towards average heading. The interactions are dictated by a communication kernel. That means, to improve our group of agents, a design of a communication kernel is needed. This leads us to the swarm-based gradient descent method. The swarm-based gradient method (SBGD) involves three main aspects:\nthe agents, the step size protocol, and the communication. For determining the step size, we will use the backtracking method 2.3 as explained in [tad]. The algorithm uses J\u2208\u2115\ud835\udc3d\u2115J\\in\\mathbb{N}italic_J \u2208 blackboard_N agents from \u211dd\u00d7(0,1]superscript\u211d\ud835\udc5101\\mathbb{R}^{d}\\times(0,1]blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00d7 ( 0 , 1 ]. For i=1,\u2026,J\ud835\udc561\u2026\ud835\udc3di=1,...,Jitalic_i = 1 , \u2026 , italic_J each agent is characterized by a position \ud835\udc31i\u2062(t)\u2208\u211ddsubscript\ud835\udc31\ud835\udc56\ud835\udc61superscript\u211d\ud835\udc51\\bm{\\mathrm{x}}_{i}(t)\\in\\mathbb{R}^{d}bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) \u2208 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT\nand a mass mi\u2062(t)\u2208(0,1]subscript\ud835\udc5a\ud835\udc56\ud835\udc6101m_{i}(t)\\in(0,1]italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) \u2208 ( 0 , 1 ].\nThe total mass of all agents is constant at all times In each iteration the agents positions are dynamically adjusted by a time step hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT in direction of the gradient \u2207F\u2062(\ud835\udc31i\u2062(t))\u2207\ud835\udc39subscript\ud835\udc31\ud835\udc56\ud835\udc61\\nabla F(\\bm{\\mathrm{x}}_{i}(t))\u2207 italic_F ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) ) The time step hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT depends on the current position \ud835\udc31i\u2062(t)subscript\ud835\udc31\ud835\udc56\ud835\udc61\\bm{\\mathrm{x}}_{i}(t)bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) and the relative mass of the agent, where the relative mass of the agent is defined as with m+:=maxi\u2208J\u2061mi\u2062(t)assignsubscript\ud835\udc5asubscript\ud835\udc56\ud835\udc3dsubscript\ud835\udc5a\ud835\udc56\ud835\udc61m_{+}:=\\max\\limits_{i\\in J}m_{i}(t)italic_m start_POSTSUBSCRIPT + end_POSTSUBSCRIPT := roman_max start_POSTSUBSCRIPT italic_i \u2208 italic_J end_POSTSUBSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ). The function hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT should therefore be chosen as a decreasing function of the relative masses, i.e. heavier agents get smaller time steps while lighter agents receive larger step sizes. The relative mass m~isubscript~\ud835\udc5a\ud835\udc56\\tilde{m}_{i}over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can alternatively be understood as the probability of the agent to find a global minimum. Agents with mi\u2062(t)\u226am+\u2062(t)much-less-thansubscript\ud835\udc5a\ud835\udc56\ud835\udc61subscript\ud835\udc5a\ud835\udc61m_{i}(t)\\ll m_{+}(t)italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) \u226a italic_m start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_t ) have to get larger step sizes, because at the current position the probability to find a minimum is rather low. To compute the time step hisubscript\u210e\ud835\udc56h_{i}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT we use the backtracking line search method based on the Wolfe conditions [wol].\nIn each iteration we want to take a time step in direction of the gradient \u2207F\u2062(\ud835\udc31\u2062(t))\u2207\ud835\udc39\ud835\udc31\ud835\udc61\\nabla F(\\bm{\\mathrm{x}}(t))\u2207 italic_F ( bold_x ( italic_t ) ), thus The idea of the backtracking line search method is to choose a time step h\u210ehitalic_h in such a way, that Of course for h\u226a1much-less-than\u210e1h\\ll 1italic_h \u226a 1 is and therefore (2.1) holds for any fixed \u03bb\u2208(0,1)\ud835\udf0601\\lambda\\in(0,1)italic_\u03bb \u2208 ( 0 , 1 ). However, this is not what we want and numerically not useful.\nWe want the step size h\u210ehitalic_h as large as possible, so that we can maximize the descent towards \u03bb\u2062h\u2062|\u2207F\u2062(\ud835\udc31n)|2\ud835\udf06\u210esuperscript\u2207\ud835\udc39superscript\ud835\udc31\ud835\udc5b2\\lambda h|\\nabla F(\\bm{\\mathrm{x}}^{n})|^{2}italic_\u03bb italic_h | \u2207 italic_F ( bold_x start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT.\nTherefore, we start with a large h\u210ehitalic_h such that holds.\nThen we successively decrease the step size with a shrinking factor \u03b3>0\ud835\udefe0\\gamma>0italic_\u03b3 > 0 until (2.1) is reached for h=h\u2062(\ud835\udc31n,\u03bb)\u210e\u210esuperscript\ud835\udc31\ud835\udc5b\ud835\udf06h=h(\\bm{\\mathrm{x}}^{n},\\lambda)italic_h = italic_h ( bold_x start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_\u03bb ).\n\n\nNow the choice of \u03bb\ud835\udf06\\lambdaitalic_\u03bb can be problematic. For larger \u03bb\ud835\udf06\\lambdaitalic_\u03bb the step size is limited and no larger jumps are possible.\nIf \u03bb\u226a1much-less-than\ud835\udf061\\lambda\\ll 1italic_\u03bb \u226a 1 there is a danger of taking too small steps and stopping at a local minimum. To get around this, we use the relative mass of the\nindividual agents to adjust \u03bb\ud835\udf06\\lambdaitalic_\u03bb. To do this, define \u03c8q\u2062(m~n+1):=(m~n+1)qassignsubscript\ud835\udf13\ud835\udc5esuperscript~\ud835\udc5a\ud835\udc5b1superscriptsuperscript~\ud835\udc5a\ud835\udc5b1\ud835\udc5e\\psi_{q}(\\tilde{m}^{n+1}):=(\\tilde{m}^{n+1})^{q}italic_\u03c8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( over~ start_ARG italic_m end_ARG start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) := ( over~ start_ARG italic_m end_ARG start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT, with q>0\ud835\udc5e0q>0italic_q > 0.\nFor i=1,\u2026,J\ud835\udc561\u2026\ud835\udc3di=1,...,Jitalic_i = 1 , \u2026 , italic_J we thus obtain the step size The parameter q\ud835\udc5eqitalic_q determines the influence of the relative mass. That means if q\ud835\udc5eqitalic_q is larger, \u03c8q\u2062(m~in+1)subscript\ud835\udf13\ud835\udc5esuperscriptsubscript~\ud835\udc5a\ud835\udc56\ud835\udc5b1\\psi_{q}(\\tilde{m}_{i}^{n+1})italic_\u03c8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) will be smaller and agents with\na relative mass in the middle range can get larger time steps from the backtracking method. By default, we assume q=1\ud835\udc5e1q=1italic_q = 1. Communication is the aspect in which the SBGD method differs from others. Considering the relative heights of each agent, we redistribute the masses in each iteration step. The lowest positioned agent attracts the mass from the other agents to approach a potential minimum through smaller step sizes. Meanwhile the other\nagents become lighter and lighter and thus explore further in the region of interest.\nBut a lighter agent may be better positioned after a large time step and thus become the new heaviest agent and therefore approaches a new potential minimum.\nThis mass transition is described as follows:\n\n\nSet Fmax\u2062(t):=maxi\u2208J\u2061F\u2062(\ud835\udc31j\u2062(t))assignsubscript\ud835\udc39\ud835\udc61subscript\ud835\udc56\ud835\udc3d\ud835\udc39subscript\ud835\udc31\ud835\udc57\ud835\udc61F_{\\max}(t):=\\max\\limits_{i\\in J}F(\\bm{\\mathrm{x}}_{j}(t))italic_F start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ( italic_t ) := roman_max start_POSTSUBSCRIPT italic_i \u2208 italic_J end_POSTSUBSCRIPT italic_F ( bold_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_t ) ) and Fmin\u2062(t):=mini\u2208J\u2061F\u2062(\ud835\udc31j\u2062(t))assignsubscript\ud835\udc39\ud835\udc61subscript\ud835\udc56\ud835\udc3d\ud835\udc39subscript\ud835\udc31\ud835\udc57\ud835\udc61F_{\\min}(t):=\\min\\limits_{i\\in J}F(\\bm{\\mathrm{x}}_{j}(t))italic_F start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT ( italic_t ) := roman_min start_POSTSUBSCRIPT italic_i \u2208 italic_J end_POSTSUBSCRIPT italic_F ( bold_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_t ) ). At time t\ud835\udc61titalic_t, Fmax\u2062(t)subscript\ud835\udc39\ud835\udc61F_{\\max}(t)italic_F start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ( italic_t ) is the maximum height and Fmin\u2062(t)subscript\ud835\udc39\ud835\udc61F_{\\min}(t)italic_F start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT ( italic_t ) is the minimum height of the swarm. Thus, we define the relative height of an agent as With i\u2217:=argmini\u2208JF\u2062(\ud835\udc31i\u2062(t))assignsuperscript\ud835\udc56subscriptargmin\ud835\udc56\ud835\udc3d\ud835\udc39subscript\ud835\udc31\ud835\udc56\ud835\udc61i^{*}:=\\operatorname*{argmin}\\limits_{i\\in J}F(\\bm{\\mathrm{x}}_{i}(t))italic_i start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT := roman_argmin start_POSTSUBSCRIPT italic_i \u2208 italic_J end_POSTSUBSCRIPT italic_F ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) ) we then describe the mass transition by where \u03d5p\u2062(\u03b7)=\u03b7p\u2208(0,1]subscriptitalic-\u03d5\ud835\udc5d\ud835\udf02superscript\ud835\udf02\ud835\udc5d01\\phi_{p}(\\eta)=\\eta^{p}\\in(0,1]italic_\u03d5 start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_\u03b7 ) = italic_\u03b7 start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT \u2208 ( 0 , 1 ] and p>0\ud835\udc5d0p>0italic_p > 0. By default p=1\ud835\udc5d1p=1italic_p = 1, but it can be adjusted for optimization purposes. For the time discretization, we set tn+1=tn+\u0394\u2062tsuperscript\ud835\udc61\ud835\udc5b1superscript\ud835\udc61\ud835\udc5b\u0394\ud835\udc61t^{n+1}=t^{n}+\\Delta titalic_t start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT = italic_t start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT + roman_\u0394 italic_t, with \u0394\u2062t=1\u0394\ud835\udc611\\Delta t=1roman_\u0394 italic_t = 1. Thus, for the i-th agent \ud835\udc31in+1=\ud835\udc31i\u2062(tn+1)superscriptsubscript\ud835\udc31\ud835\udc56\ud835\udc5b1subscript\ud835\udc31\ud835\udc56superscript\ud835\udc61\ud835\udc5b1\\bm{\\mathrm{x}}_{i}^{n+1}=\\bm{\\mathrm{x}}_{i}(t^{n+1})bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT = bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) is the position, and\nmin+1=mi\u2062(tn+1)superscriptsubscript\ud835\udc5a\ud835\udc56\ud835\udc5b1subscript\ud835\udc5a\ud835\udc56superscript\ud835\udc61\ud835\udc5b1m_{i}^{n+1}=m_{i}(t^{n+1})italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT = italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) the mass at time tn+1superscript\ud835\udc61\ud835\udc5b1t^{n+1}italic_t start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT. For the initialization of the algorithm, we set all agents to random positions {\ud835\udc31i0}superscriptsubscript\ud835\udc31\ud835\udc560\\{\\bm{\\mathrm{x}}_{i}^{0}\\}{ bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT }\nand all agents are given the uniformly distributed mass {mi0=1J}superscriptsubscript\ud835\udc5a\ud835\udc5601\ud835\udc3d\\{m_{i}^{0}=\\frac{1}{J}\\}{ italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_J end_ARG }. Then we proceed with all agents with min>0superscriptsubscript\ud835\udc5a\ud835\udc56\ud835\udc5b0m_{i}^{n}>0italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT > 0 in each iteration as follows: with in:=argminiF\u2062(\ud835\udc31in)assignsubscript\ud835\udc56\ud835\udc5bsubscriptargmin\ud835\udc56\ud835\udc39superscriptsubscript\ud835\udc31\ud835\udc56\ud835\udc5bi_{n}:=\\operatorname*{argmin}\\limits_{i}F(\\bm{\\mathrm{x}}_{i}^{n})italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT := roman_argmin start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_F ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) and m~in+1=min+1m+n+1superscriptsubscript~\ud835\udc5a\ud835\udc56\ud835\udc5b1superscriptsubscript\ud835\udc5a\ud835\udc56\ud835\udc5b1superscriptsubscript\ud835\udc5a\ud835\udc5b1\\tilde{m}_{i}^{n+1}=\\frac{m_{i}^{n+1}}{m_{+}^{n+1}}over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT = divide start_ARG italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT end_ARG start_ARG italic_m start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT end_ARG. First, we apply communication and redistribute the masses so that the best-positioned agent becomes the heaviest. After that, each agent is given a time step by the\nbacktracking method and we update the positions.\nBy computing \ud835\udc31+:=argmaxi\u2208JF\u2062(\ud835\udc31in)assignsubscript\ud835\udc31subscriptargmax\ud835\udc56\ud835\udc3d\ud835\udc39superscriptsubscript\ud835\udc31\ud835\udc56\ud835\udc5b\\bm{\\mathrm{x}}_{+}:=\\operatorname*{argmax}_{i\\in J}F(\\bm{\\mathrm{x}}_{i}^{n})bold_x start_POSTSUBSCRIPT + end_POSTSUBSCRIPT := roman_argmax start_POSTSUBSCRIPT italic_i \u2208 italic_J end_POSTSUBSCRIPT italic_F ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) we find the \u201eworst \u201cagent, which will be eliminated. Repeating this will leave us with the heaviest agent. To better understand how the SBGD method works, I would like to demonstrate an example. We are looking for the global minimum of the\nfunction F\u2062(x)=esin\u2061(2\u2062x2)+110\u2062(x\u2212\u03c02)\ud835\udc39\ud835\udc65superscript\ud835\udc522superscript\ud835\udc652110\ud835\udc65\ud835\udf0b2F(x)=e^{\\sin(2x^{2})}+\\frac{1}{10}(x-\\frac{\\pi}{2})italic_F ( italic_x ) = italic_e start_POSTSUPERSCRIPT roman_sin ( 2 italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT + divide start_ARG 1 end_ARG start_ARG 10 end_ARG ( italic_x - divide start_ARG italic_\u03c0 end_ARG start_ARG 2 end_ARG ) on the interval [\u22123,3]33[-3,3][ - 3 , 3 ]. We apply the SBGD method with ten agents and the backtracking parameters \u03bb=0.2\ud835\udf060.2\\lambda=0.2italic_\u03bb = 0.2 and \u03b3=0.9\ud835\udefe0.9\\gamma=0.9italic_\u03b3 = 0.9.\nFor simplicity, we initialize the agents with equal distance to each other as shown in Figure 3.1. Let the size of the points represent the\nmasses of the individual agents. Initially, all\nagents have the same mass, therefore they are all the same size. The global minimum is located in the area [1,2]12[1,2][ 1 , 2 ] and two agents are placed nearby. One of them is expected to approach the minimum. To the right in the subinterval [2,3]23[2,3][ 2 , 3 ] is a local minimum, where another agent is closely placed. We expect this agent to become initially the heaviest agent of the swarm. In Figure 3.2 we can observe the movement of the swarm. After one iteration the agents are already different in size and weight. As assumed, the agent near the local minimum pulls the mass of the others towards it. We also see that another agent is already approaching the global minimum. However, this one also loses its mass to the heaviest agent. After five iterations, two of the lighter agents have approached the global minimum. From now on, the mass distribution changes, as seen in iteration 7. Due to the better position near the global minimum, one of the lighter agents pulls mass from the heaviest agent and the remaining others to itself. Thus, it becomes the new heaviest agent and converges towards the global minimum in the further iterations. The communication aspect is the key element in the efficiency of SBGD. In [tad] the authors compared the SBGD method with backtracking gradient descent method\nand the Adams method. Compared to both methods, SBGD had an overall better performance. In addition, I want to show the advantages of SBGD with a visual comparison to the backtracking gradient descent.\n\n\nTherefore consider the SBGD method but without communication between the agents. That means there is no mass transition, min\u22611Jsuperscriptsubscript\ud835\udc5a\ud835\udc56\ud835\udc5b1\ud835\udc3dm_{i}^{n}\\equiv\\frac{1}{J}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \u2261 divide start_ARG 1 end_ARG start_ARG italic_J end_ARG, and\n\u03c8q\u2062(m~in)\u22611subscript\ud835\udf13\ud835\udc5esuperscriptsubscript~\ud835\udc5a\ud835\udc56\ud835\udc5b1\\psi_{q}(\\tilde{m}_{i}^{n})\\equiv 1italic_\u03c8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) \u2261 1 yields If we apply this method with the same backtracking parameters on the example before, we notice a different movement behavior of the agents towards the global minimum (see figure 3.3).\nThe agents flock together in groups and are trapped in the basins of local minima. Because of the equidistant initialization over the whole interval, one group of agents is able to reach the global minimum.\nBut the initial starting positions of the agents determine if they can reach the global minimum or not. As shown in figure 3.4, if we move all agents\nto the left side of the interval, the backtracking gradient descent stops before the global minimum. On the other hand, the SBGD method leads the swarm\nfurther to reach the wanted global minimum. By default we assume p=q=1\ud835\udc5d\ud835\udc5e1p=q=1italic_p = italic_q = 1. The question is, how does changing these two parameters affect the S\u2062B\u2062G\u2062Dp,q\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc37\ud835\udc5d\ud835\udc5eSBGD_{p,q}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT method and its results?\nIn [tad] is mentioned, that the parameter p\ud835\udc5dpitalic_p has a low influence level, while q\ud835\udc5eqitalic_q has more significant influence and therefore can be used for\nfine-tuning purposes. As mentioned in 2.3, q\ud835\udc5eqitalic_q determines the influence of the relative mass. If q\ud835\udc5eqitalic_q is larger, \u03c8q\u2062(m~in+1)subscript\ud835\udf13\ud835\udc5esuperscriptsubscript~\ud835\udc5a\ud835\udc56\ud835\udc5b1\\psi_{q}(\\tilde{m}_{i}^{n+1})italic_\u03c8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) will be\nsmaller and agents with a relative mass in the middle range receive larger time steps from the backtracking method. To demonstrate the influence of q\ud835\udc5eqitalic_q, which affects the swarms movement, I want to consider the two cases with different starting positions (equidistant vs left sided) from before.\nFor the case with equidistant starting positions as shown in figure 3.5, we notice that more agents approach the global minimum with S\u2062B\u2062G\u2062D1,2\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc3712SBGD_{1,2}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT, than with S\u2062B\u2062G\u2062D1,1\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc3711SBGD_{1,1}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT 1 , 1 end_POSTSUBSCRIPT.\nMoreover, mass gaining of the minimizer happens faster with S\u2062B\u2062G\u2062D1,2\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc3712SBGD_{1,2}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT due to its better position, gained from a better stepsize.\nThe worst case left sided scenario however (see figure 3.6), seems to be more challenging for S\u2062B\u2062G\u2062D1,2\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc3712SBGD_{1,2}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT, than for S\u2062B\u2062G\u2062D1,1\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc3711SBGD_{1,1}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT 1 , 1 end_POSTSUBSCRIPT. While the agents with S\u2062B\u2062G\u2062D1,1\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc3711SBGD_{1,1}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT 1 , 1 end_POSTSUBSCRIPT approach the global minimum\ndirectly, the agents with S\u2062B\u2062G\u2062D1,2\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc3712SBGD_{1,2}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT are more widely spread over the interval. Hence the minimizer gains weight later with S\u2062B\u2062G\u2062D1,2\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc3712SBGD_{1,2}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT, than with S\u2062B\u2062G\u2062D1,1\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc3711SBGD_{1,1}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT 1 , 1 end_POSTSUBSCRIPT. \n\nTherefore, we find that the speed and the movement of the swarm are influenced by q\ud835\udc5eqitalic_q. Although the swarms behave different for both cases, in the end the global minimum is reached visually. But we need to evaluate, if both results are equally good.\nIn table 3.1 we see the deviation from the result for the second case (left sided starting positions) with different\np\ud835\udc5dpitalic_p and q\ud835\udc5eqitalic_q pairings. First of all, we can agree with [tad] that p\ud835\udc5dpitalic_p has no significant influence on the results. However, increasing q\ud835\udc5eqitalic_q has an effect.\nBut increasing q\ud835\udc5eqitalic_q alone does not lead to better results. We can see, that for SBGD with ten agents, an increasing of q\ud835\udc5eqitalic_q leads to worse results.\nOn the other hand, increasing both q\ud835\udc5eqitalic_q and the number of acting agents provide us with better results. For this case, S\u2062B\u2062G\u2062D1,3\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc3713SBGD_{1,3}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT 1 , 3 end_POSTSUBSCRIPT with 20 agents\nhas the best results. Although increasing agents seems to have more influence, than increasing q\ud835\udc5eqitalic_q. For q=1\ud835\udc5e1q=1italic_q = 1 the results for 20 and 50 agents are equal to\nq=2\ud835\udc5e2q=2italic_q = 2. Therefore we can conclude, for SBGD to provide us with good results, we need to consider different numbers of agents and different values of q\ud835\udc5eqitalic_q. In the following we consider the SBGD method for a one-dimensional function in Julia. The parameters will be set as default, thus p=q=1\ud835\udc5d\ud835\udc5e1p=q=1italic_p = italic_q = 1. First, we review the basic version of pseudocode as shown in algorithm 1 and 2, before I introduce my implemented version.\nAfterwards I discuss the usage of tolerance factors. We start with the backtracking line search, since we use it for the time step protocol.\nTherefore we set all parameters first and initialize a time step h=h0\u210esubscript\u210e0h=h_{0}italic_h = italic_h start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT afterwards. In Lemma 5.1 is shown that we can use Then we proceed with a while-loop to decrease the step length h\u210ehitalic_h as shown in section 2.3. For the main algorithm the SBGD method, we again first set all parameters. Then the agents will be randomly placed and each is given the initial mass.\nIn each iteration the best placed agent receives masses from the other agents. To update the masses according to (2.4), we need to compute the relative heights first. After that we then find the maximum mass from all agents. This is used to compute the relative masses. These are needed to compute the step length\nusing the backtracking line search. After all agents have updated positions, we eliminate the highest placed agent and reduce the number of active agents. For my implementation I used the Julia Version 1.7.1. and I required only the package Random to place the agents randomly.\nTo have a better overview, I divided the program in several functions, which I will explain below. The main function SBGD() (see listing 4.4) uses help functions to compute the global minimum with the SBGD algorithm.\nThe first step is to generate the agents. Therefore I created the function generateAgents() (listing 4.1). This function\nneeds the parameters a,b\ud835\udc4e\ud835\udc4fa,bitalic_a , italic_b as interval borders and J\ud835\udc3dJitalic_J for the number of agents. The agents are generated as J\u00d72\ud835\udc3d2J\\times 2italic_J \u00d7 2 array. The first column contains\nthe positions of the agents and the second column contains the masses. Next, I set the counter for active agents N\ud835\udc41Nitalic_N and i\u2062n\u2062d\u2062e\u2062x\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc65indexitalic_i italic_n italic_d italic_e italic_x, which will hold the index of the heaviest agent. After that, I start the iterations with a while-loop. In each iteration I begin with computing the best and worst placed agent. Therefore I am using two help functions searchMax() (listing 4.2) and analogous to this searchMin(). Julia already has functions for searching the maximum and minimum value from an array, but we can not use them because\nwe need to find the maximum and minimum from the still active agents. Hence, in searchMax() and searchMin() I check the condition if the mass is\nnot equal to zero. After that I use the obtained maximum and minimum position of the swarm to calculate the relative heights, which are used to compute the mass transitions.\nThe variable s\u2062u\u2062m\ud835\udc60\ud835\udc62\ud835\udc5asumitalic_s italic_u italic_m holds the shedded mass from the agents, which the best placed agent receives after completing the for-loop. \n\nBefore continuing with the updating of the positions, I eliminate the worst placed agent. After that I use the f\u2062i\u2062n\u2062d\u2062m\u2062a\u2062x\u2062()\ud835\udc53\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc5a\ud835\udc4e\ud835\udc65findmax()italic_f italic_i italic_n italic_d italic_m italic_a italic_x ( ) function, which Julia provides,\nto find the heaviest agent. This agents mass is used to calculate the relative masses, which are passed to the backtracking() function (listing 4.3).\nThis function works as in algorithm 4.1 already explained. This process is repeated until one agent remains, of which the position will be returned. In section 3 of [tad] three tolerance factors are introduced: tolm, tolmerge and tolres.\nThese are used for a more optimized version of implementation. Because in the basic version shown before, one agent at a time will be eliminated, this\ncould take a while if we use a large number of agents. To avoid this, the usage of the tolerance factors is recommended.\n\n\nFirst, instead of eliminating one agent in each iteration, we eliminate all agents, whose masses are below our tolm value. Because these agents are such lightly\nweighted, we do not expect them to improve the global swarm position. \nThe second tolerance factor tolmerge is used to determine if two agents are too close to each other. If they are too close to each other, instead of continuing with both, we merge them. This is because, even if we continue with both, only one might go further and gain mass in the next iterations and the other one will be eliminated at some point. Therefore to reduce computation time, we merge them. \nLastly, we use tolres to determine, if we can stop the computation already. Instead of waiting until only one agent remains, we can\ncompute the residual between the best agent of the current and the last iteration. If the difference is small enough, we can stop the computation. For the example from section 3 I used the thresholds mentioned in [tad]. These are In table 4.1 is shown, how the SBGD method performed with different numbers of agents.\nThe first case is, when all agents are equidistant distributed over the whole interval. We notice that the number of iterations is significantly smaller, than\nthe number of agents. Moreover, the more agents we use, the more precise the solution becomes. However the difference between 20, 50 and 100 agents is relatively\nsmall. For 1000 agents the SBGD method astonishingly only needs one iteration and returns the best solution. Compared to that, it might not be useful to use\nthe tolerance factors for less than 20 agents. As seen in section 3 the agent, which converges to the global minimum in the end, first loses a lot of its mass to the heaviest agent, before it gains it back. Therefore the factor tolm might lead to an early elimination of the minimizer. \nIf we compare all this to the worst case scenario, where all agents are initialized on the left end of the interval, we notice a slightly worse behavior of the SBGD method. Although there are still many fewer iterations used, the results are different. The tolerance factors seem to not worsen the case with 10 agents, like before. On the contrary, it seems to be slightly better using 10 agents than 50 or 100. We can conclude, that if we use the thresholds, the computation is considerably faster. However the results depend on where the agents might be placed and the number of agents used. Moreover we saw that depending on the case, more or less agents should be used to require a fast and precise solution. In this chapter we consider the S\u2062B\u2062G\u2062Dp,q\ud835\udc46\ud835\udc35\ud835\udc3asubscript\ud835\udc37\ud835\udc5d\ud835\udc5eSBGD_{p,q}italic_S italic_B italic_G italic_D start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT iterations (2.4) using the backtracking line search for determining the step size hin=h\u2062(\ud835\udc31in,\u03bb\u2062\u03c8q\u2062(m~in+1))superscriptsubscript\u210e\ud835\udc56\ud835\udc5b\u210esuperscriptsubscript\ud835\udc31\ud835\udc56\ud835\udc5b\ud835\udf06subscript\ud835\udf13\ud835\udc5esuperscriptsubscript~\ud835\udc5a\ud835\udc56\ud835\udc5b1h_{i}^{n}=h(\\bm{\\mathrm{x}}_{i}^{n},\\lambda\\psi_{q}(\\tilde{m}_{i}^{n+1}))italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT = italic_h ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_\u03bb italic_\u03c8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) ) with shrinkage factor \u03b3\u2208(0,1)\ud835\udefe01\\gamma\\in(0,1)italic_\u03b3 \u2208 ( 0 , 1 ).\nTo simplify matters, we again assume p=q=1\ud835\udc5d\ud835\udc5e1p=q=1italic_p = italic_q = 1.\nMoreover we assume that for all agents there exists a bounded region \u03a9\u03a9\\Omegaroman_\u03a9. We do not have apriori a bound on \u03a9\u03a9\\Omegaroman_\u03a9, because lighter agents\nare allowed to explore the ambient space with larger step sizes. Hence the footprint of the agents c\u2062o\u2062n\u2062vi\u2062{\ud835\udc31in}\ud835\udc50\ud835\udc5c\ud835\udc5bsubscript\ud835\udc63\ud835\udc56superscriptsubscript\ud835\udc31\ud835\udc56\ud835\udc5bconv_{i}\\{\\bm{\\mathrm{x}}_{i}^{n}\\}italic_c italic_o italic_n italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT { bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT } may expand beyond its initial\nconvex hull c\u2062o\u2062n\u2062vi\u2062{\ud835\udc31i0}\ud835\udc50\ud835\udc5c\ud835\udc5bsubscript\ud835\udc63\ud835\udc56superscriptsubscript\ud835\udc31\ud835\udc560conv_{i}\\{\\bm{\\mathrm{x}}_{i}^{0}\\}italic_c italic_o italic_n italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT { bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT }. Consider the class of loss functions F\u2208\ud835\udc9e2\u2062(\u03a9)\ud835\udc39superscript\ud835\udc9e2\u03a9F\\in\\mathcal{C}^{2}(\\Omega)italic_F \u2208 caligraphic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( roman_\u03a9 ) with Lipschitz-bound The lower bound on the step length is By Taylor\u2019s theorem and the Lipschitz continuity of \u2207F\u2207\ud835\udc39\\nabla F\u2207 italic_F Hence, if hin\u22642L\u2062(1\u2212\u03bb\u2062\u03c8q\u2062(m~im+1))superscriptsubscript\u210e\ud835\udc56\ud835\udc5b2\ud835\udc3f1\ud835\udf06subscript\ud835\udf13\ud835\udc5esuperscriptsubscript~\ud835\udc5a\ud835\udc56\ud835\udc5a1h_{i}^{n}\\leq\\frac{2}{L}(1-\\lambda\\psi_{q}(\\tilde{m}_{i}^{m+1}))italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \u2264 divide start_ARG 2 end_ARG start_ARG italic_L end_ARG ( 1 - italic_\u03bb italic_\u03c8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m + 1 end_POSTSUPERSCRIPT ) ), By the backtracking line search iterations, the inequality holds for hinsuperscriptsubscript\u210e\ud835\udc56\ud835\udc5bh_{i}^{n}italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT but not for hin\u03b3superscriptsubscript\u210e\ud835\udc56\ud835\udc5b\ud835\udefe\\frac{h_{i}^{n}}{\\gamma}divide start_ARG italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG start_ARG italic_\u03b3 end_ARG. \nTherefore \u220e Next we discuss the convergence of the SBGD method, which is determined by the time series of SBGD minimizers, and the time series of its heaviest agents, The communication of masses leads to a shift of mass from higher ground to the minimizers. When the minimizer attracts enough mass to gain the role of the\nheaviest agent, the two sequences coincide.\nFurthermore, since F\u2062(\ud835\udc31in)\ud835\udc39superscriptsubscript\ud835\udc31\ud835\udc56\ud835\udc5bF(\\bm{\\mathrm{x}}_{i}^{n})italic_F ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) are decreasing, we conclude that \u2200n,ifor-all\ud835\udc5b\ud835\udc56\\forall n,i\u2200 italic_n , italic_i the SBGD iterations remain in a range Let {\ud835\udc17\u2212n}n\u22650subscriptsubscriptsuperscript\ud835\udc17\ud835\udc5b\ud835\udc5b0\\{\\bm{\\mathrm{X}}^{n}_{-}\\}_{n\\geq 0}{ bold_X start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n \u2265 0 end_POSTSUBSCRIPT and {\ud835\udc17+n}n\u22650subscriptsubscriptsuperscript\ud835\udc17\ud835\udc5b\ud835\udc5b0\\{\\bm{\\mathrm{X}}^{n}_{+}\\}_{n\\geq 0}{ bold_X start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n \u2265 0 end_POSTSUBSCRIPT denote the time sequence of SBGD minimizers and heaviest agents at tnsuperscript\ud835\udc61\ud835\udc5bt^{n}italic_t start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Then\nthere exists a constant C=C\u2062(\u03b3,L,M,\u03bb)\ud835\udc36\ud835\udc36\ud835\udefe\ud835\udc3f\ud835\udc40\ud835\udf06C=C(\\gamma,L,M,\\lambda)italic_C = italic_C ( italic_\u03b3 , italic_L , italic_M , italic_\u03bb ), such that By Lemma (5.1) the step length hin\u22652\u2062\u03b3L\u2062(1\u2212\u03bb\u2062\u03c8q\u2062(m~im+1))superscriptsubscript\u210e\ud835\udc56\ud835\udc5b2\ud835\udefe\ud835\udc3f1\ud835\udf06subscript\ud835\udf13\ud835\udc5esuperscriptsubscript~\ud835\udc5a\ud835\udc56\ud835\udc5a1h_{i}^{n}\\geq\\frac{2\\gamma}{L}(1-\\lambda\\psi_{q}(\\tilde{m}_{i}^{m+1}))italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \u2265 divide start_ARG 2 italic_\u03b3 end_ARG start_ARG italic_L end_ARG ( 1 - italic_\u03bb italic_\u03c8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m + 1 end_POSTSUPERSCRIPT ) ) and the descent property (5.3) implies Since the descent bound applies for all agents, we consider that bound for the minimizer in=argmini\u2208JF\u2062(\ud835\udc31in)subscript\ud835\udc56\ud835\udc5bsubscriptargmin\ud835\udc56\ud835\udc3d\ud835\udc39superscriptsubscript\ud835\udc31\ud835\udc56\ud835\udc5bi_{n}=\\operatorname*{argmin}\\limits_{i\\in J}F(\\bm{\\mathrm{x}}_{i}^{n})italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = roman_argmin start_POSTSUBSCRIPT italic_i \u2208 italic_J end_POSTSUBSCRIPT italic_F ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ).\nFor this purpose we need to distinguish two scenarios: \n\nThe first scenario is the canonical scenario, in which the minimizer coincides with the heaviest agent, minn+1=m+n+1superscriptsubscript\ud835\udc5asubscript\ud835\udc56\ud835\udc5b\ud835\udc5b1superscriptsubscript\ud835\udc5a\ud835\udc5b1m_{i_{n}}^{n+1}=m_{+}^{n+1}italic_m start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT = italic_m start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT and thus m~inn+1=1superscriptsubscript~\ud835\udc5asubscript\ud835\udc56\ud835\udc5b\ud835\udc5b11\\tilde{m}_{i_{n}}^{n+1}=1over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT = 1. Hence, we conclude hinn\u22652\u2062\u03b3L\u2062(1\u2212\u03bb)superscriptsubscript\u210esubscript\ud835\udc56\ud835\udc5b\ud835\udc5b2\ud835\udefe\ud835\udc3f1\ud835\udf06h_{i_{n}}^{n}\\geq\\frac{2\\gamma}{L}(1-\\lambda)italic_h start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \u2265 divide start_ARG 2 italic_\u03b3 end_ARG start_ARG italic_L end_ARG ( 1 - italic_\u03bb ) and because \ud835\udc17\u2212n+1=\ud835\udc31in+1n+1superscriptsubscript\ud835\udc17\ud835\udc5b1superscriptsubscript\ud835\udc31subscript\ud835\udc56\ud835\udc5b1\ud835\udc5b1\\bm{\\mathrm{X}}_{-}^{n+1}=\\bm{\\mathrm{x}}_{i_{n+1}}^{n+1}bold_X start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT = bold_x start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT is\nthe global minimizer at time tn+1superscript\ud835\udc61\ud835\udc5b1t^{n+1}italic_t start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT, holds. The second scenario takes place, when the mass of the minimizer is minn+1<mjnn+1superscriptsubscript\ud835\udc5asubscript\ud835\udc56\ud835\udc5b\ud835\udc5b1superscriptsubscript\ud835\udc5asubscript\ud835\udc57\ud835\udc5b\ud835\udc5b1m_{i_{n}}^{n+1}<m_{j_{n}}^{n+1}italic_m start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT < italic_m start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT. That means the mass of the minimizer is not greater yet, than the mass of the heaviest agent from the iteration before positioned at \ud835\udc31jnnsuperscriptsubscript\ud835\udc31subscript\ud835\udc57\ud835\udc5b\ud835\udc5b\\bm{\\mathrm{x}}_{j_{n}}^{n}bold_x start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. So even after losing a portion of its mass, the heaviest agent from before is still heavier than the minimizer at \ud835\udc31inn+1superscriptsubscript\ud835\udc31subscript\ud835\udc56\ud835\udc5b\ud835\udc5b1\\bm{\\mathrm{x}}_{i_{n}}^{n+1}bold_x start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT. Because the minimizer gained the mass lost by the heaviest agent,\nfor the relative mass of the minimizer applies and thus with (2.3) we conclude Depending on F\u2062(\ud835\udc17+n)\u2212F\u2062(\ud835\udc17\u2212n)\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udc5b\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udc5bF(\\bm{\\mathrm{X}}_{+}^{n})-F(\\bm{\\mathrm{X}}_{-}^{n})italic_F ( bold_X start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) - italic_F ( bold_X start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ), there are two subcases of this scenario: \nFirst we assume F\u2062(\ud835\udc17+n)\u2212F\u2062(\ud835\udc17\u2212n)\u2264\u03b3L\u2062(1\u2212\u03bb)\u2062\u03bb\u2062|\u2207F\u2062(\ud835\udc17+n)|2\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udc5b\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udc5b\ud835\udefe\ud835\udc3f1\ud835\udf06\ud835\udf06superscript\u2207\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udc5b2F(\\bm{\\mathrm{X}}_{+}^{n})-F(\\bm{\\mathrm{X}}_{-}^{n})\\leq\\frac{\\gamma}{L}(1-%\n\\lambda)\\lambda|\\nabla F(\\bm{\\mathrm{X}}_{+}^{n})|^{2}italic_F ( bold_X start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) - italic_F ( bold_X start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) \u2264 divide start_ARG italic_\u03b3 end_ARG start_ARG italic_L end_ARG ( 1 - italic_\u03bb ) italic_\u03bb | \u2207 italic_F ( bold_X start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT.\nWith that and the descent property (5.6) for the heaviest agent at \ud835\udc31+nsuperscriptsubscript\ud835\udc31\ud835\udc5b\\bm{\\mathrm{x}}_{+}^{n}bold_x start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, where m~inn+1\u2192m~+n+1=1\u2192superscriptsubscript~\ud835\udc5asubscript\ud835\udc56\ud835\udc5b\ud835\udc5b1superscriptsubscript~\ud835\udc5a\ud835\udc5b11\\tilde{m}_{i_{n}}^{n+1}\\to\\tilde{m}_{+}^{n+1}=1over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT \u2192 over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT = 1, we find We remain with the worst case scenario F\u2062(\ud835\udc17+n)\u2212F\u2062(\ud835\udc17\u2212n)\u2265\u03b3L\u2062(1\u2212\u03bb)\u2062\u03bb\u2062|\u2207F\u2062(\ud835\udc17+n)|2\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udc5b\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udc5b\ud835\udefe\ud835\udc3f1\ud835\udf06\ud835\udf06superscript\u2207\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udc5b2F(\\bm{\\mathrm{X}}_{+}^{n})-F(\\bm{\\mathrm{X}}_{-}^{n})\\geq\\frac{\\gamma}{L}(1-%\n\\lambda)\\lambda|\\nabla F(\\bm{\\mathrm{X}}_{+}^{n})|^{2}italic_F ( bold_X start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) - italic_F ( bold_X start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) \u2265 divide start_ARG italic_\u03b3 end_ARG start_ARG italic_L end_ARG ( 1 - italic_\u03bb ) italic_\u03bb | \u2207 italic_F ( bold_X start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. In this case,\nwe have a large difference of heights between the minimizer and the heaviest agent. This implies Without loss of generality [tad, S. 15], we can assume (1\u2212\u03bb\u2062m~inn+1)>121\ud835\udf06superscriptsubscript~\ud835\udc5asubscript\ud835\udc56\ud835\udc5b\ud835\udc5b112(1-\\lambda\\tilde{m}_{i_{n}}^{n+1})>\\frac{1}{2}( 1 - italic_\u03bb over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) > divide start_ARG 1 end_ARG start_ARG 2 end_ARG. Together with the secured lower bound for m~inn+1superscriptsubscript~\ud835\udc5asubscript\ud835\udc56\ud835\udc5b\ud835\udc5b1\\tilde{m}_{i_{n}}^{n+1}over~ start_ARG italic_m end_ARG start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT\nand the descent property (5.6) we conclude By combining all cases (5.7), (5.8) and (5.9), we find and The bound in (5.5) follows by a telescoping sum.\n\u220e We have seen that the summability bound (5.5) depends only on the time sequence of minimizers and heaviest agents, but not on the lighter agents.\nFor n\ud835\udc5bnitalic_n large enough, both sequences coincide into one sequence {\ud835\udc17n}superscript\ud835\udc17\ud835\udc5b\\{\\bm{\\mathrm{X}}^{n}\\}{ bold_X start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }. To prove convergence of SBGD, time sub-sequences {\ud835\udc17n\u03b1}superscript\ud835\udc17subscript\ud835\udc5b\ud835\udefc\\{\\bm{\\mathrm{X}}^{n_{\\alpha}}\\}{ bold_X start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT } need to\nsatisfy a Palais-Smale condition [str]:\nby monotonicity F\u2062(\ud835\udc17n\u03b1)\u2264maxi\u2208J\u2061F\u2062(\ud835\udc31i0)\ud835\udc39superscript\ud835\udc17subscript\ud835\udc5b\ud835\udefcsubscript\ud835\udc56\ud835\udc3d\ud835\udc39superscriptsubscript\ud835\udc31\ud835\udc560F(\\bm{\\mathrm{X}}^{n_{\\alpha}})\\leq\\max\\limits_{i\\in J}F(\\bm{\\mathrm{x}}_{i}^{%\n0})italic_F ( bold_X start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) \u2264 roman_max start_POSTSUBSCRIPT italic_i \u2208 italic_J end_POSTSUBSCRIPT italic_F ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ) and \u2207F\u2062(\ud835\udc17n\u03b1)\u2062\u27f6\u03b1\u2192\u221e\u20620\u2207\ud835\udc39superscript\ud835\udc17subscript\ud835\udc5b\ud835\udefc\u2192\ud835\udefc\u27f60\\nabla F(\\bm{\\mathrm{X}}^{n_{\\alpha}})\\overset{\\alpha\\to\\infty}{%\n\\longrightarrow}0\u2207 italic_F ( bold_X start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_OVERACCENT italic_\u03b1 \u2192 \u221e end_OVERACCENT start_ARG \u27f6 end_ARG 0. Consider the loss function F\u2208\ud835\udc9e2\u2062(\u03a9)\ud835\udc39superscript\ud835\udc9e2\u03a9F\\in\\mathcal{C}^{2}(\\Omega)italic_F \u2208 caligraphic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( roman_\u03a9 ) such that the Lipschitz-bound (5.1) holds and let {\ud835\udc17\u2212n}n\u22650subscriptsubscriptsuperscript\ud835\udc17\ud835\udc5b\ud835\udc5b0\\{\\bm{\\mathrm{X}}^{n}_{-}\\}_{n\\geq 0}{ bold_X start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n \u2265 0 end_POSTSUBSCRIPT denote the\ntime sequence of SBGD minimizers. Then {\ud835\udc17\u2212n}n\u22650subscriptsubscriptsuperscript\ud835\udc17\ud835\udc5b\ud835\udc5b0\\{\\bm{\\mathrm{X}}^{n}_{-}\\}_{n\\geq 0}{ bold_X start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n \u2265 0 end_POSTSUBSCRIPT consists of one or more sub-sequences, {\ud835\udc17\u2212n\u03b1,\u03b1=1,2,\u2026}formulae-sequencesubscriptsuperscript\ud835\udc17subscript\ud835\udc5b\ud835\udefc\ud835\udefc12\u2026\\{\\bm{\\mathrm{X}}^{n_{\\alpha}}_{-},\\alpha=1,2,\\ldots\\}{ bold_X start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - end_POSTSUBSCRIPT , italic_\u03b1 = 1 , 2 , \u2026 }, that converge to a band of local minima with equal heights, such that \u2207F\u2062(\ud835\udc17\u03b1\u2217)=0\u2207\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udefc0\\nabla F(\\bm{\\mathrm{X}}_{\\alpha}^{*})=0\u2207 italic_F ( bold_X start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) = 0 and F\u2062(\ud835\udc17\u03b1\u2217)=F\u2062(\ud835\udc17\u03b2\u2217)\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udefc\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udefdF(\\bm{\\mathrm{X}}_{\\alpha}^{*})=F(\\bm{\\mathrm{X}}_{\\beta}^{*})italic_F ( bold_X start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) = italic_F ( bold_X start_POSTSUBSCRIPT italic_\u03b2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ). In particular, if F\ud835\udc39Fitalic_F admits only distinct local minima in \u03a9\u03a9\\Omegaroman_\u03a9,\nthen the whole sequence \ud835\udc17nsuperscript\ud835\udc17\ud835\udc5b\\bm{\\mathrm{X}}^{n}bold_X start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT converges to a minimum. Because we assume the sequence {\ud835\udc17\u2212n}superscriptsubscript\ud835\udc17\ud835\udc5b\\{\\bm{\\mathrm{X}}_{-}^{n}\\}{ bold_X start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT } is bounded in \u03a9\u03a9\\Omegaroman_\u03a9, we know it has converging sub-sequences. We take any converging sub-sequences\n\ud835\udc17\u2212n\u03b1\u2192\ud835\udc17\u03b1\u2217\u2208\u03a9\u2192superscriptsubscript\ud835\udc17subscript\ud835\udc5b\ud835\udefcsuperscriptsubscript\ud835\udc17\ud835\udefc\u03a9\\bm{\\mathrm{X}}_{-}^{n_{\\alpha}}\\to\\bm{\\mathrm{X}}_{\\alpha}^{*}\\in\\Omegabold_X start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT \u2192 bold_X start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT \u2208 roman_\u03a9. Then by the proposition (5.2) before, and thus \ud835\udc17\u03b1\u2217superscriptsubscript\ud835\udc17\ud835\udefc\\bm{\\mathrm{X}}_{\\alpha}^{*}bold_X start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT are local minimizers with \u2207F\u2062(\ud835\udc17\u03b1\u2217)=0\u2207\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udefc0\\nabla F(\\bm{\\mathrm{X}}_{\\alpha}^{*})=0\u2207 italic_F ( bold_X start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) = 0. Since F\u2062(\ud835\udc17\u2212n)\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udc5bF(\\bm{\\mathrm{X}}_{-}^{n})italic_F ( bold_X start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) is decreasing, all F\u2062(\ud835\udc17\u03b1\u2217)\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udefcF(\\bm{\\mathrm{X}}_{\\alpha}^{*})italic_F ( bold_X start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) must have the\nsame height. The collection of equi-height minimizers {\ud835\udc17\u03b1\u2217|F\u2062(\ud835\udc17\u03b1\u2217)=F\u2062(\ud835\udc17\u03b2\u2217)}conditional-setsuperscriptsubscript\ud835\udc17\ud835\udefc\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udefc\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udefd\\{\\bm{\\mathrm{X}}_{\\alpha}^{*}|F(\\bm{\\mathrm{X}}_{\\alpha}^{*})=F(\\bm{\\mathrm{X%\n}}_{\\beta}^{*})\\}{ bold_X start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT | italic_F ( bold_X start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) = italic_F ( bold_X start_POSTSUBSCRIPT italic_\u03b2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) } is the limit-set of {\ud835\udc17\u2212n}superscriptsubscript\ud835\udc17\ud835\udc5b\\{\\bm{\\mathrm{X}}_{-}^{n}\\}{ bold_X start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }.\n\u220e To quantify convergence rate, we need a classification for the level of flatness our target function has. For this we use the Lojasiewicz condition [toj]: \nIf F\ud835\udc39Fitalic_F is analytic in \u03a9\u03a9\\Omegaroman_\u03a9, then for every critical point of F\ud835\udc39Fitalic_F, \ud835\udc31\u2217\u2208\u03a9superscript\ud835\udc31\u03a9\\bm{\\mathrm{x}}^{*}\\in\\Omegabold_x start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT \u2208 roman_\u03a9, exists a neighborhood \ud835\udca9\u2217subscript\ud835\udca9\\mathcal{N}_{*}caligraphic_N start_POSTSUBSCRIPT \u2217 end_POSTSUBSCRIPT surrounding \ud835\udc31\u2217\u2208\ud835\udca9\u2217superscript\ud835\udc31subscript\ud835\udca9\\bm{\\mathrm{x}}^{*}\\in\\mathcal{N}_{*}bold_x start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT \u2208 caligraphic_N start_POSTSUBSCRIPT \u2217 end_POSTSUBSCRIPT,\nan exponent \u03b2\u2208(1,2]\ud835\udefd12\\beta\\in(1,2]italic_\u03b2 \u2208 ( 1 , 2 ] and a constant \u03bc>0\ud835\udf070\\mu>0italic_\u03bc > 0 such that In case of local convexity, (5.12) is reduced to the Polyack-Lojasiewicz condition [pol] For the next theorem we assume that n\ud835\udc5bnitalic_n is large enough, so that we are allowed to discuss only the canonical scenario, where minimizers and heaviest agents coincide. Consider the loss function F\u2208\ud835\udc9e2\ud835\udc39superscript\ud835\udc9e2F\\in\\mathcal{C}^{2}italic_F \u2208 caligraphic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT such that the Lipschitz-bound (5.1) holds, with minimal flatness \u03b2\ud835\udefd\\betaitalic_\u03b2.\nLet {\ud835\udc17\u2212n}n\u22650subscriptsubscriptsuperscript\ud835\udc17\ud835\udc5b\ud835\udc5b0\\{\\bm{\\mathrm{X}}^{n}_{-}\\}_{n\\geq 0}{ bold_X start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n \u2265 0 end_POSTSUBSCRIPT denote the time sequence of SBGD minimizers. Then, there exists a constant C=C\u2062(\u03b3,\u03bb,\u03bc)\ud835\udc36\ud835\udc36\ud835\udefe\ud835\udf06\ud835\udf07C=C(\\gamma,\\lambda,\\mu)italic_C = italic_C ( italic_\u03b3 , italic_\u03bb , italic_\u03bc ), such that We again start with the descent property (5.7) Focussing on the converging sub-sequence {\ud835\udc17\u2212n\u03b1}superscriptsubscript\ud835\udc17subscript\ud835\udc5b\ud835\udefc\\{\\bm{\\mathrm{X}}_{-}^{n_{\\alpha}}\\}{ bold_X start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT }, we get For the quadratic case of the Polyack-Lojasiewicz condition (5.13), we follow Now consider the error En\u03b1:=F\u2062(\ud835\udc17\u2212n\u03b1)\u2212F\u2062(\ud835\udc17\u03b1\u2217)assignsubscript\ud835\udc38subscript\ud835\udc5b\ud835\udefc\ud835\udc39superscriptsubscript\ud835\udc17subscript\ud835\udc5b\ud835\udefc\ud835\udc39superscriptsubscript\ud835\udc17\ud835\udefcE_{n_{\\alpha}}:=F(\\bm{\\mathrm{X}}_{-}^{n_{\\alpha}})-F(\\bm{\\mathrm{X}}_{\\alpha}%\n^{*})italic_E start_POSTSUBSCRIPT italic_n start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT := italic_F ( bold_X start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) - italic_F ( bold_X start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT ) in the case of general Lojasiewicz bound (5.12), then This is a Riccati inequality [ric] and the solution yields \u220e The swarm-based method is a new approach for non-convex optimization. By applying the model of a swarm, we use different agents to find a global minimum.\nThe swarm-based gradient descent is one method from a class of swarm-based methods. Also based on swarm behavior is the swarm-based random descent (SBRD) method [zen].\nThis method uses random descent directions to improve the global swarm position and to find the global minimum.\nTherefore, following this work, further insights into swarm-based methods is possible and needed. In this thesis we learned about the swarm-based gradient descent, how it works, how we can implement it, and we discussed the convergence rate.\nWe learned, that the key element of this method is the communication. By communicating the swarm avoids being trapped\nin basins of local minima and therefore is able to reach the global minimum, as we saw by an example. Compared to the backtracking gradient descent method,\nthe SBGD method is less dependent on the initial starting positions. However, the performance of SBGD depends on the number of agents, the parameter q\ud835\udc5eqitalic_q and the used thresholds.\nTo get the best results, it is necessary to find a balance between all of them. Although we can say in general, the more agents are used,\nthe more precise the result will be. However, the fine-tuning aspect should be further looked at with more examples. Depending on the case, different options for q\ud835\udc5eqitalic_q and the thresholds might be considered best.\nMoreover, it is possible to use other methods, than the backtracking line search to compute a step length. The question is, how other methods affect the\nSBGD-method and the results.\nFurthermore, we need to discuss the SBGD method for higher dimensional functions. In the one-dimensional case we saw advantages of using SBGD compared to other\ngradient methods. But does this still apply for the higher dimensional case, or is the SBGD method even more superior for this case? [keyword=quellen] Hiermit versichere ich an Eides statt, dass ich die vorliegende Arbeit selbstst\u00e4ndig und ohne die Benutzung anderer als der angegebenen Hilfsmittel angefertigt habe. Alle Stellen, die w\u00f6rtlich oder sinngem\u00e4\u00df aus ver\u00f6ffentlichten und nicht ver\u00f6ffentlichten Schriften entnommen wurden, sind als solche kenntlich gemacht.\nDie Arbeit ist in gleicher oder \u00e4hnlicher Form oder auszugsweise im Rahmen einer anderen Pr\u00fcfung noch nicht vorgelegt worden. Ich versichere, dass die eingereichte elektronische Fassung der eingereichten Druckfassung vollst\u00e4ndig entspricht.\n\n\n\n\nJanina Tikko"
    },
    {
        "id": 23,
        "title": "A Critique of Chen\u2019s \u201cThe 2-MAXSAT Problem Can Be Solved in Polynomial Time\u201d\u2020\u2020thanks: Supported in part by NSF grant\nCCF-2006496.",
        "corpus": "In this paper, we examine Yangjun Chen\u2019s technical report titled \u201cThe 2-MAXSAT Problem Can Be Solved in Polynomial Time\u201d\u00a0[Che23], which revises and expands upon their conference paper of the same name\u00a0[Che22].\nChen\u2019s paper purports to build a polynomial-time algorithm for the NP-complete problem 2-MAXSAT by converting a 2-CNF formula into a graph that is then searched.\nWe show through multiple counterexamples that Chen\u2019s proposed algorithms contain flaws, and we find that the structures they create lack properly formalized definitions. Furthermore, we elaborate on how the author fails to prove the correctness of their algorithms and how they make overgeneralizations in their time analysis of their proposed solution. Due to these issues, we conclude that Chen\u2019s technical report\u00a0[Che23] and conference paper\u00a0[Che22] both fail to provide a proof that P=NPPNP{\\rm P}={\\rm NP}roman_P = roman_NP. This critique looks at Yangjun Chen\u2019s paper titled \u201cThe 2-MAXSAT Problem Can Be Solved in Polynomial Time\u201d [Che23], which claims to give a polynomial-time algorithm for solving the well-known NPNP{\\rm NP}roman_NP-complete problem 2-MAXSAT\u00a0[GJS74](also known as maximum\u00a02-satisfiability or MAX\u00a02-SAT). In their paper, Chen claims to provide a proof that such an algorithm exists, which would also be a proof that P=NPPNP{\\rm P}={\\rm NP}roman_P = roman_NP. In this paper, we argue that the algorithm for solving the 2-MAXSAT problem given by Chen does not solve the 2-MAXSAT problem by providing cases where Chen\u2019s algorithm produces incorrect results. Additionally, we remark that due to poor algorithm formalizations, arguments that lack support, and overgeneralizations, it is possible that Chen\u2019s algorithm may not run in polynomial-time. Our Section\u00a02 covers preliminary topics related to our paper. Section\u00a03 gives a high-level overview of Chen\u2019s proposed solution, including an example. Section\u00a04 examines Chen\u2019s Algorithm\u00a01 (also called their SEARCH algorithm) and Algorithm\u00a02 (also called their findSubset algorithm). For the former we give examples that cause the algorithm to fail, and for the latter we cast doubt on the validity of Chen\u2019s proof of a polynomial runtime.\nSection\u00a05 examines Chen\u2019s graph improvements and shows an example where their Algorithm\u00a03 (which is claimed to be an improved version of their Algorithm\u00a01) fails. Section\u00a06 examines Chen\u2019s analysis of the overall complexity of their solution and finds several flaws. Finally, Section\u00a07 notes Chen\u2019s problematic use of examples over proofs in attempting to show correctness. We critique here the technical report version\u00a0[Che23] of Chen\u2019s paper. However, their paper also appears as a conference version\u00a0[Che22]. We chose to critique Chen\u2019s technical report since it is the most detailed and up-to-date version of their paper, and it claims a looser polynomial-time bound for the runtime of their algorithm than the bound that is claimed in the conference version, which suggests that the bound claimed in their conference version may be incorrect. Furthermore, the analysis section from the conference version\u00a0[Che22] is completely removed from their technical report\u00a0[Che23], and replaced with a new analysis of an algorithm that Chen claims is an improvement upon that of the conference version\u2019s. However, the fact that the conference version\u2019s analysis was entirely removed leads us to doubt it\u2019s correctness. The conference version covers a subset of the sections contained in the technical report, including Sections 1\u20133 and Algorithms\u00a01 and 2, and the technical report builds upon the conference version with an updated improvements section. Any of our findings that apply to these sections and algorithms, found in Sections 4 and 7 of this paper, apply to the conference version of Chen\u2019s paper as well; Sections\u00a05 and 6 of this paper critique content appearing only in Chen\u2019s technical report and are not applicable to their conference version. However, the content we provide that is applicable to Chen\u2019s conference version\u00a0[Che22] is more than enough to disprove that the algorithm detailed in that paper is not able to solve 2-MAXSAT. In this paper, we assume the reader has a foundational understanding of algorithmic complexity analysis, the P, NP, and NP-complete complexity classes, graph structures, trie structures, and set operations. We also assume basic knowledge of boolean algebra, boolean formulas, and the SAT problem. Occasionally, we deviate from the original notation of Chen\u2019s paper to ensure clearer comprehension. When these changes occur, they will be pointed out alongside the original notation. In this paper we refer to boolean formulas of two specific forms: 2-conjunctive normal form (2-CNF) and 2-disjunctive normal form (2-DNF). A boolean formula in 2-CNF is a conjunction of clauses, where each clause is the disjunction of two literals (a literal being either a variable or a negated variable), e.g.,\u00a0(v1\u2228\u00acv2)\u2227(v2\u2228v3)\u2227(\u00acv1\u2228v3)subscript\ud835\udc631subscript\ud835\udc632subscript\ud835\udc632subscript\ud835\udc633subscript\ud835\udc631subscript\ud835\udc633(v_{1}\\vee\\neg v_{2})\\wedge(v_{2}\\vee v_{3})\\wedge(\\neg v_{1}\\vee v_{3})( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2228 \u00ac italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) \u2227 ( italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2228 italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) \u2227 ( \u00ac italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2228 italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ). A boolean formula in 2-DNF is a disjunction of conjunctions, where each conjunction is between two literals, e.g., (v1\u2227\u00acv1)\u2228(v2\u2227v3)\u2228(\u00acv1\u2227v2)subscript\ud835\udc631subscript\ud835\udc631subscript\ud835\udc632subscript\ud835\udc633subscript\ud835\udc631subscript\ud835\udc632(v_{1}\\wedge\\neg v_{1})\\vee(v_{2}\\wedge v_{3})\\vee(\\neg v_{1}\\wedge v_{2})( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 \u00ac italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) \u2228 ( italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2227 italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) \u2228 ( \u00ac italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ). Informally, given a boolean formula f\ud835\udc53fitalic_f in 2-CNF, the 2-MAXSAT problem asks if at least k\ud835\udc58kitalic_k clauses in f\ud835\udc53fitalic_f can be satisfied under a single assignment to the variables in f\ud835\udc53fitalic_f. Previous work has shown that 2-MAXSAT is an NPNP{\\rm NP}roman_NP-complete problem through a polynomial-time many-one reduction from 3-SAT\u00a0[GJS74]. We define the 2-MAXSAT problem as follows\u00a0[Che23]. Name: 2 maximum satisfiability (2-MAXSAT). Given: A set of boolean variables V, a boolean formula f\ud835\udc53fitalic_f in 2-CNF form that is the conjunction of the clauses C1,C2,\u2026,Cnsubscript\ud835\udc361subscript\ud835\udc362\u2026subscript\ud835\udc36\ud835\udc5bC_{1},C_{2},\\ldots,C_{n}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_C start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT with each clause containing at most 2222 disjunctive literals from V\ud835\udc49Vitalic_V, and a positive integer k<n\ud835\udc58\ud835\udc5bk<nitalic_k < italic_n. Question: Is there a truth assignment to V\ud835\udc49Vitalic_V that will satisfy at least k\ud835\udc58kitalic_k clauses in f\ud835\udc53fitalic_f? When we speak of the \u201cmaximum number of satisfied clauses in a formula F\ud835\udc39Fitalic_F,\u201d what we always mean is the number of clauses in F\ud835\udc39Fitalic_F that simultaneously evaluate to true under the variable assignment to F\ud835\udc39Fitalic_F (from all possible variables assignments) that maximizes this number. We detail here, informally, a high-level step-by-step overview of Chen\u2019s solution to the 2-MAXSAT problem. Below the description of each step, we build upon a running example.\nIn later sections, when simulating Chen\u2019s algorithms applied to example 2-CNF formulas, we omit the details of more trivial steps for the sake of brevity. Begin with a 2-CNF formula over the set of boolean variables V\ud835\udc49Vitalic_V, call it F\ud835\udc39Fitalic_F, of the form c1\u2227c2\u2227\u22ef\u2227cnsubscript\ud835\udc501subscript\ud835\udc502\u22efsubscript\ud835\udc50\ud835\udc5bc_{1}\\wedge c_{2}\\wedge\\cdots\\wedge c_{n}italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2227 \u22ef \u2227 italic_c start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, where each cisubscript\ud835\udc50\ud835\udc56c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a clause and there are n\ud835\udc5bnitalic_n clauses. F=(v1\u2228\u00acv2)\u2227(\u00acv1\u2228v3).\ud835\udc39subscript\ud835\udc631subscript\ud835\udc632subscript\ud835\udc631subscript\ud835\udc633F=(v_{1}\\vee\\neg v_{2})\\wedge(\\neg v_{1}\\vee v_{3}).italic_F = ( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2228 \u00ac italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) \u2227 ( \u00ac italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2228 italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) . Step 1. Convert F\ud835\udc39Fitalic_F to a 2-DNF formula, call it D\ud835\udc37Ditalic_D, of the form d1\u2228d2\u2228\u22ef\u2228dnsubscript\ud835\udc511subscript\ud835\udc512\u22efsubscript\ud835\udc51\ud835\udc5bd_{1}\\vee d_{2}\\vee\\cdots\\vee d_{n}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2228 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2228 \u22ef \u2228 italic_d start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, where each clause ci=(l1\u2228l2)subscript\ud835\udc50\ud835\udc56subscript\ud835\udc591subscript\ud835\udc592c_{i}=(l_{1}\\vee l_{2})italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = ( italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2228 italic_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) is turned into two conjunctions of the form di=(l1\u2227yi)\u2228(l2\u2227\u00acyi)subscript\ud835\udc51\ud835\udc56subscript\ud835\udc591subscript\ud835\udc66\ud835\udc56subscript\ud835\udc592subscript\ud835\udc66\ud835\udc56d_{i}=(l_{1}\\wedge y_{i})\\vee(l_{2}\\wedge\\neg y_{i})italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = ( italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \u2228 ( italic_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2227 \u00ac italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) (yisubscript\ud835\udc66\ud835\udc56y_{i}italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a new variable that does not appear in V\ud835\udc49Vitalic_V). (continued)\nD=(v1\u2227y1)\u23dfConjunction a\u2228(\u00acv2\u2227\u00acy1)\u23dfConjunction b\u2228(\u00acv1\u2227y2)\u23dfConjunction c\u2228(v3\u2227\u00acy2)\u23dfConjunction d.Dsubscript\u23dfsubscriptv1subscripty1Conjunction asubscript\u23dfsubscriptv2subscripty1Conjunction bsubscript\u23dfsubscriptv1subscripty2Conjunction csubscript\u23dfsubscriptv3subscripty2Conjunction dD=\\underbrace{(v_{1}\\wedge y_{1})}_{\\text{Conjunction a}}\\vee\\underbrace{(\\neg\nv%\n_{2}\\wedge\\neg y_{1})}_{\\text{Conjunction b}}\\vee\\underbrace{(\\neg v_{1}\\wedge\ny%\n_{2})}_{\\text{Conjunction c}}\\vee\\underbrace{(v_{3}\\wedge\\neg y_{2})}_{\\text{%\nConjunction d}}.italic_D = under\u23df start_ARG ( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_ARG start_POSTSUBSCRIPT Conjunction a end_POSTSUBSCRIPT \u2228 under\u23df start_ARG ( \u00ac italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2227 \u00ac italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_ARG start_POSTSUBSCRIPT Conjunction b end_POSTSUBSCRIPT \u2228 under\u23df start_ARG ( \u00ac italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_ARG start_POSTSUBSCRIPT Conjunction c end_POSTSUBSCRIPT \u2228 under\u23df start_ARG ( italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2227 \u00ac italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_ARG start_POSTSUBSCRIPT Conjunction d end_POSTSUBSCRIPT . Step 2. Create a boolean formula D\u2032superscript\ud835\udc37\u2032D^{\\prime}italic_D start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT that is a modification of D\ud835\udc37Ditalic_D. D\u2032superscript\ud835\udc37\u2032D^{\\prime}italic_D start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is initially identical to D\ud835\udc37Ditalic_D, except that if a variable visubscript\ud835\udc63\ud835\udc56v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT that appears in D\ud835\udc37Ditalic_D is absent from a conjunction d\ud835\udc51ditalic_d in D\ud835\udc37Ditalic_D, the clause (vi\u2228\u00acvi)subscript\ud835\udc63\ud835\udc56subscript\ud835\udc63\ud835\udc56(v_{i}\\vee\\neg v_{i})( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2228 \u00ac italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) is added to d\ud835\udc51ditalic_d (appended with \u2227\\wedge\u2227). Chen uses a special syntax (vi,\u2217)subscript\ud835\udc63\ud835\udc56(v_{i},*)( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , \u2217 ) to represent these clauses, and we will also refer to variables such as visubscript\ud835\udc63\ud835\udc56v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT as \u201cmissing\u201d variables. (continued)\nD\u2032=(v1\u2227y1\u2227(v2,\u2217)\u2227(v3,\u2217)\u2227(y2,\u2217))\u23dfa\u2228(\u00acv2\u2227\u00acy1\u2227(v1,\u2217)\u2227(v3,\u2217)\u2227(y2,\u2217))\u23dfb\u2228(\u00acv1\u2227y2\u2227(v2,\u2217)\u2227(v3,\u2217)\u2227(y1,\u2217))\u23dfc\u2228(v3\u2227\u00acy2\u2227(v1,\u2217)\u2227(v2,\u2217)\u2227(y1,\u2217))\u23dfd.superscriptD\u2032absentlimit-fromsubscript\u23dfsubscriptv1subscripty1subscriptv2subscriptv3subscripty2amissing-subexpressionlimit-fromsubscript\u23dfsubscriptv2subscripty1subscriptv1subscriptv3subscripty2bmissing-subexpressionlimit-fromsubscript\u23dfsubscriptv1subscripty2subscriptv2subscriptv3subscripty1cmissing-subexpressionsubscript\u23dfsubscriptv3subscripty2subscriptv1subscriptv2subscripty1d\\begin{aligned} D^{\\prime}=~{}&\\underbrace{\\bigl{(}v_{1}\\wedge y_{1}\\wedge(v_{%\n2},*)\\wedge(v_{3},*)\\wedge(y_{2},*)\\bigr{)}}_{\\text{a}}\\vee~{}\\\\\n&\\underbrace{\\bigl{(}\\neg v_{2}\\wedge\\neg y_{1}\\wedge(v_{1},*)\\wedge(v_{3},*)%\n\\wedge(y_{2},*)\\bigr{)}}_{\\text{b}}\\vee~{}\\\\\n&\\underbrace{\\bigl{(}\\neg v_{1}\\wedge y_{2}\\wedge(v_{2},*)\\wedge(v_{3},*)%\n\\wedge(y_{1},*)\\bigr{)}}_{\\text{c}}\\vee~{}\\\\\n&\\underbrace{\\bigl{(}v_{3}\\wedge\\neg y_{2}\\wedge(v_{1},*)\\wedge(v_{2},*)\\wedge%\n(y_{1},*)\\bigr{)}}_{\\text{d}}.\\end{aligned}start_ROW start_CELL italic_D start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = end_CELL start_CELL under\u23df start_ARG ( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 ( italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2217 ) \u2227 ( italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , \u2217 ) \u2227 ( italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2217 ) ) end_ARG start_POSTSUBSCRIPT a end_POSTSUBSCRIPT \u2228 end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL under\u23df start_ARG ( \u00ac italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2227 \u00ac italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 ( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2217 ) \u2227 ( italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , \u2217 ) \u2227 ( italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2217 ) ) end_ARG start_POSTSUBSCRIPT b end_POSTSUBSCRIPT \u2228 end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL under\u23df start_ARG ( \u00ac italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2227 ( italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2217 ) \u2227 ( italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , \u2217 ) \u2227 ( italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2217 ) ) end_ARG start_POSTSUBSCRIPT c end_POSTSUBSCRIPT \u2228 end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL under\u23df start_ARG ( italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u2227 \u00ac italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2227 ( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2217 ) \u2227 ( italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2217 ) \u2227 ( italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2217 ) ) end_ARG start_POSTSUBSCRIPT d end_POSTSUBSCRIPT . end_CELL end_ROW Step 3. Convert each conjunction in D\u2032superscript\ud835\udc37\u2032D^{\\prime}italic_D start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT into a sequence of variables with all negated variables removed, of the form v1.v2.\u22ef.vkformulae-sequencesubscript\ud835\udc631subscript\ud835\udc632\u22efsubscript\ud835\udc63\ud835\udc58v_{1}.v_{2}.\\cdots.v_{k}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT . italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT . \u22ef . italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, where each visubscript\ud835\udc63\ud835\udc56v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is either a variable or a missing variable from the conjunction. Matching Chen\u2019s syntax, the \u2018.\u2019 delineate the elements of the sequence. (continued)\nUnsorted variable sequences. Step 4. Sort the sequences of variables using any global ordering over the variables (Chen uses the frequency of the variables across all of the sequences to build the ordering\u00a0[Che23]). The global ordering is fixed for the algorithm, i.e.\u00a0the ordering is not passed as input to the algorithm. After the sorting, add the start character \u2018#\u2019 to the front of each sequence and the terminal character \u2018$\u2019 to the end of each sequence. (continued)\nVariable sequences sorted using a lexical global ordering. Step 5. Turn each sorted sequence into a p\ud835\udc5dpitalic_p-graph, which is a graph with nodes corresponding to the variables of the sequence (in order) and edges connecting nodes that represent adjacent variables in the sequence. A p\ud835\udc5dpitalic_p-graph also has dashed edges that Chen calls \u201cspans\u201d\u00a0[Che23]. A span is an edge that \u201cjumps over\u201d a missing variable (of the form (vk,\u2217)subscript\ud835\udc63\ud835\udc58(v_{k},*)( italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , \u2217 )) to connect the variables before and after the missing variable, represented as \u27e8vi,vk,vj\u27e9subscript\ud835\udc63\ud835\udc56subscript\ud835\udc63\ud835\udc58subscript\ud835\udc63\ud835\udc57\\langle v_{i},v_{k},v_{j}\\rangle\u27e8 italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 where vksubscript\ud835\udc63\ud835\udc58v_{k}italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT is the missing variable. Chen occasionally calls p\ud835\udc5dpitalic_p-graphs \u201cp\ud835\udc5dpitalic_p-paths\u201d\u00a0[Che23], however we refer to them only as p\ud835\udc5dpitalic_p-graphs. (continued)\nSee Figure\u00a01 for the pppitalic_p-graphs corresponding to the four sorted sequences. #v1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT$a#v1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT$b#v2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT$c#v1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT$d Step 6. Convert each p\ud835\udc5dpitalic_p-graph into a p\ud835\udc5dpitalic_p*-graph (which we create now but use later in Step\u00a08) by merging the spans of the p\ud835\udc5dpitalic_p-graph that overlap to create larger spans: For two overlapping spans \u27e8vi,\u22ef,vk,vj\u27e9subscript\ud835\udc63\ud835\udc56\u22efsubscript\ud835\udc63\ud835\udc58subscript\ud835\udc63\ud835\udc57\\langle v_{i},\\cdots,v_{k},v_{j}\\rangle\u27e8 italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , \u22ef , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u27e9 and \u27e8vk,vj,\u22ef,vl\u27e9subscript\ud835\udc63\ud835\udc58subscript\ud835\udc63\ud835\udc57\u22efsubscript\ud835\udc63\ud835\udc59\\langle v_{k},v_{j},\\cdots,v_{l}\\rangle\u27e8 italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , \u22ef , italic_v start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT \u27e9, i.e.\u00a0the two-node suffix of the first span is identical to the two-node prefix of the second span, a new span \u27e8vi,\u22ef,vk,vj,\u22ef,vl\u27e9subscript\ud835\udc63\ud835\udc56\u22efsubscript\ud835\udc63\ud835\udc58subscript\ud835\udc63\ud835\udc57\u22efsubscript\ud835\udc63\ud835\udc59\\langle v_{i},\\cdots,v_{k},v_{j},\\cdots,v_{l}\\rangle\u27e8 italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , \u22ef , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , \u22ef , italic_v start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT \u27e9 is added to the p\ud835\udc5dpitalic_p*-graph (without removing the original two spans). These successively larger spans are added to the p\ud835\udc5dpitalic_p*-graph until all overlapping spans have been merged. Chen calls this merging process the \u201ctransitive closure\u201d\u00a0[Che23] of the base spans (the spans of the p\ud835\udc5dpitalic_p-graph, consisting of three variables). (continued)\nSee Figure\u00a02 for the pppitalic_p*-graphs. #v1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT$a#v1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT$b#v2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT$c#v1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT$d Step 7. Independent of Step\u00a06, merge what Chen calls the \u201cmain paths\u201d\u00a0[Che23] of the p\ud835\udc5dpitalic_p-graphs into a single trie, call it T\ud835\udc47Titalic_T, with the merging process working as follows: For the set of p\ud835\udc5dpitalic_p-graphs R\ud835\udc45Ritalic_R, divide R\ud835\udc45Ritalic_R into subsets where, within each subset, the p\ud835\udc5dpitalic_p-graphs have the same label on their first node (first with regards to the sequence the p\ud835\udc5dpitalic_p-graph is derived from, or uppermost with regards to the p\ud835\udc5dpitalic_p-graph itself). Within a subset, call it Risubscript\ud835\udc45\ud835\udc56R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, remove the first node, labeled with v\ud835\udc63vitalic_v, from each p\ud835\udc5dpitalic_p-graph. Connect all one-node-smaller p\ud835\udc5dpitalic_p-graphs with only one node (which must be labelled with $) to a new root node labeled with v\ud835\udc63vitalic_v, and label the only node to indicate which p\ud835\udc5dpitalic_p-graph that trie branch corresponds to. Recursively merge the remaining one-node-smaller p\ud835\udc5dpitalic_p-graphs with two or more nodes, resulting in a set of tries, and connect the root of those tries to the new root. The new root should have some metadata such that all of the removed first nodes of the p\ud835\udc5dpitalic_p-graphs (with the same label) now correspond to the new root (Chen does not mention or detail this metadata). During this step, the spans of the p\ud835\udc5dpitalic_p-graphs are ignored. (continued)\nSee Figure\u00a03 for the trie TTTitalic_T produced by the recursive merging process. #n1subscriptn1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn2subscriptn2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn6subscriptn6n_{6}italic_n start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn7subscriptn7n_{7}italic_n start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn8subscriptn8n_{8}italic_n start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn9subscriptn9n_{9}italic_n start_POSTSUBSCRIPT 9 end_POSTSUBSCRIPT${a}a\\{a\\}{ italic_a }n10subscriptn10n_{10}italic_n start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn3subscriptn3n_{3}italic_n start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn4subscriptn4n_{4}italic_n start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT${b}b\\{b\\}{ italic_b }n5subscriptn5n_{5}italic_n start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn12subscriptn12n_{12}italic_n start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn13subscriptn13n_{13}italic_n start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn14subscriptn14n_{14}italic_n start_POSTSUBSCRIPT 14 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn15subscriptn15n_{15}italic_n start_POSTSUBSCRIPT 15 end_POSTSUBSCRIPT${c}c\\{c\\}{ italic_c }n16subscriptn16n_{16}italic_n start_POSTSUBSCRIPT 16 end_POSTSUBSCRIPT${d}d\\{d\\}{ italic_d }n11subscriptn11n_{11}italic_n start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT Step 8. Convert the trie T\ud835\udc47Titalic_T into a trie-like graph G\ud835\udc3aGitalic_G by adding to T\ud835\udc47Titalic_T the spans of each p\ud835\udc5dpitalic_p*-graph (which can result in cycles and thus makes T\ud835\udc47Titalic_T no longer a true trie). Chen does not specify how to add the spans to T\ud835\udc47Titalic_T\u00a0[Che23], however we presume that, as touched on in Step 7, there is some metadata that establishes a correspondence between nodes of the p\ud835\udc5dpitalic_p-graphs/p\ud835\udc5dpitalic_p*-graphs and the nodes of T\ud835\udc47Titalic_T. (continued)\nSee Figure\u00a04 for the trie-like graph GGGitalic_G. While Chen does not algorithmically describe how to create the trie-like graph, GGGitalic_G was constructed based on Chen\u2019s informal descriptions of the trie-like graphs and the process of creating them\u00a0[Che23]. #n1subscriptn1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn2subscriptn2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn6subscriptn6n_{6}italic_n start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn7subscriptn7n_{7}italic_n start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn8subscriptn8n_{8}italic_n start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn9subscriptn9n_{9}italic_n start_POSTSUBSCRIPT 9 end_POSTSUBSCRIPT${a}a\\{a\\}{ italic_a }n10subscriptn10n_{10}italic_n start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn3subscriptn3n_{3}italic_n start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn4subscriptn4n_{4}italic_n start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT${b}b\\{b\\}{ italic_b }n5subscriptn5n_{5}italic_n start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn12subscriptn12n_{12}italic_n start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn13subscriptn13n_{13}italic_n start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn14subscriptn14n_{14}italic_n start_POSTSUBSCRIPT 14 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn15subscriptn15n_{15}italic_n start_POSTSUBSCRIPT 15 end_POSTSUBSCRIPT${c}c\\{c\\}{ italic_c }n16subscriptn16n_{16}italic_n start_POSTSUBSCRIPT 16 end_POSTSUBSCRIPT${d}d\\{d\\}{ italic_d }n11subscriptn11n_{11}italic_n start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT Step 9. Convert the trie-like graph G\ud835\udc3aGitalic_G into a layered graph, call it G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, using either Chen\u2019s Algorithm\u00a01 or Algorithm\u00a03 (their improved version of Algorithm\u00a01). A layered graph consists of nodes from the trie-like graph G\ud835\udc3aGitalic_G, possibly duplicates, arranged in \u201cstacked layers,\u201d with edges from G\ud835\udc3aGitalic_G (again, possibly duplicates) going between the layers. (continued)\nSee Figure\u00a05 for the layered graph G\u2032superscriptG\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT produced by Chen\u2019s Algorithm\u00a01 applied to GGGitalic_G. ${a}a\\{a\\}{ italic_a }n10subscriptn10n_{10}italic_n start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT${b}b\\{b\\}{ italic_b }n5subscriptn5n_{5}italic_n start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT${c}c\\{c\\}{ italic_c }n16subscriptn16n_{16}italic_n start_POSTSUBSCRIPT 16 end_POSTSUBSCRIPT${d}d\\{d\\}{ italic_d }n11subscriptn11n_{11}italic_n start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPTLayer 1:y1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn8subscriptn8n_{8}italic_n start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn9subscriptn9n_{9}italic_n start_POSTSUBSCRIPT 9 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn4subscriptn4n_{4}italic_n start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPTy2subscripty2y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn15subscriptn15n_{15}italic_n start_POSTSUBSCRIPT 15 end_POSTSUBSCRIPTv1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn2subscriptn2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn3subscriptn3n_{3}italic_n start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn7subscriptn7n_{7}italic_n start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT#n1subscriptn1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTLayer 2:y1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn14subscriptn14n_{14}italic_n start_POSTSUBSCRIPT 14 end_POSTSUBSCRIPTy1subscripty1y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn8subscriptn8n_{8}italic_n start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn3subscriptn3n_{3}italic_n start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn13subscriptn13n_{13}italic_n start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPTv1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn2subscriptn2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn12subscriptn12n_{12}italic_n start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT#n1subscriptn1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn2subscriptn2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn6subscriptn6n_{6}italic_n start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT#n1subscriptn1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn2subscriptn2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn6subscriptn6n_{6}italic_n start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn12subscriptn12n_{12}italic_n start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn7subscriptn7n_{7}italic_n start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPTv3subscriptv3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPTn13subscriptn13n_{13}italic_n start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT#n1subscriptn1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn2subscriptn2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn12subscriptn12n_{12}italic_n start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT#n1subscriptn1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn2subscriptn2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT#n1subscriptn1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn6subscriptn6n_{6}italic_n start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPTv2subscriptv2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPTn12subscriptn12n_{12}italic_n start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPTv1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn2subscriptn2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT#n1subscriptn1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTv1subscriptv1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTn2subscriptn2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT#n1subscriptn1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTLayer 3:Layer 4:Layer 5:Layer 6: Step 10. Apply Chen\u2019s Algorithm\u00a02 to G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, which Chen claims gives in its output the maximum number of satisfied clauses in the original 2-CNF formula\u00a0F\ud835\udc39Fitalic_F\u00a0[Che23]. (continued)\nChen\u2019s Algorithm\u00a02 examines G\u2032superscriptG\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT and returns 2222 as the maximum number of satisfied clauses in FFFitalic_F. Chen\u2019s Algorithm\u00a01 takes a trie-like graph G\ud835\udc3aGitalic_G as input, uses G\ud835\udc3aGitalic_G to form a layered graph called G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, and then returns Algorithm\u00a02 applied to G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, which itself returns a tuple of values that includes the maximum number of satisfied clauses\u00a0[Che23]. We detail here, informally, how Chen\u2019s Algorithm\u00a01 and Algorithm\u00a02 work, with changes to notation for clarity. Algorithm\u00a01 first initializes the layered graph G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT to be the set of all leaf nodes in the trie-like graph G\ud835\udc3aGitalic_G, and subsequently pushes this set onto an empty stack S\ud835\udc46Sitalic_S. In the main loop of the algorithm, a set g\ud835\udc54gitalic_g is popped off of S\ud835\udc46Sitalic_S. For each node n\ud835\udc5bnitalic_n in g\ud835\udc54gitalic_g, every parent node p\ud835\udc5dpitalic_p of n\ud835\udc5bnitalic_n and the corresponding edge from n\ud835\udc5bnitalic_n to p\ud835\udc5dpitalic_p are added to G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. All of the parents of nodes in g\ud835\udc54gitalic_g are then grouped into sets by their variable label,111We note here that nodes in a layer form a group only if the nodes they are parents of exist in the same group in the next lowest layer. For example, looking at the running example layered graph of Figure\u00a05, in Layer 4 the shaded nodes n6subscript\ud835\udc5b6n_{6}italic_n start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT and n12subscript\ud835\udc5b12n_{12}italic_n start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT (both labeled v2subscript\ud835\udc632v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT) form a group as they are parents of nodes that form a group in Layer 3 (which are also shaded). However, another instance of the node n12subscript\ud835\udc5b12n_{12}italic_n start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT that is in Layer 4 (on the right side of the layer) cannot group with the shaded n6subscript\ud835\udc5b6n_{6}italic_n start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT and n12subscript\ud835\udc5b12n_{12}italic_n start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT as it is not a parent of the shaded group in Layer 3. As a consequence of this behavior, layers in G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT can contain multiple instances of the same node (as seen in the case of n12subscript\ud835\udc5b12n_{12}italic_n start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT in Layer 4). and sets with at least two nodes are pushed onto S\ud835\udc46Sitalic_S. This loop repeats until S\ud835\udc46Sitalic_S is empty. Finally, Algorithm\u00a01 returns Algorithm\u00a02 applied to the completed G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. Chen purports that Algorithm\u00a01 correctly creates a G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT of \u201crooted subgraphs\u201d\u00a0[Che23]. Algorithm\u00a02 works by examining G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT to find rooted subgraphs. A rooted subgraph consists of a root node (a node without parents), internal nodes, and one or more leaf nodes that each correspond to one or more 2-DNF conjunctions, with the variable labels of the nodes along a path from the root to a leaf forming a satisfying assignment to the conjunction(s) at the leaf. An example of a rooted subgraph can be seen in the layered graph depicted in Figure\u00a05. In Algorithm\u00a02, the rooted subgraphs are derived from G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, and for each rooted subgraph the subset of satisfied 2-DNF conjunction is found. Once finished, the algorithm outputs a tuple that includes the maximum number of 2-DNF conjunctions satisfied by a truth assignment within a rooted subgraph, which Chen claims is equal to the maximum number of satisfied clauses in the original 2-CNF formula\u00a0[Che23]. In this subsection, we give three counterexample 2-CNF formulas that result in Chen\u2019s Algorithm\u00a01 reporting incorrect results, which demonstrate that Algorithm\u00a01 is flawed. The first and second of these counterexamples can be extended to infinitely many counterexamples. In these counterexamples, we assume that Chen\u2019s Algorithm\u00a02 is correctly implemented, i.e.\u00a0that it behaves as described by Chen. For the first counterexample (Counterexample\u00a01), consider the 2-CNF formula This formula clearly can have at most 2 satisfied clauses. The first step is to convert the 2-CNF formula into a new 2-DNF formula as described by Chen, with the added variables being of the form yisubscript\ud835\udc66\ud835\udc56y_{i}italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT: Next, we convert the 2-DNF formula into sequences of variables, while removing the negated variables (including all occurrences of v1subscript\ud835\udc631v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT), and sorting each sequence by a global variable ordering. This global ordering is determined by the frequencies with which the variables appear across all sequences, with the most frequent variable (the variable appearing in the most sequences) coming first in the ordering (Chen claims that any global ordering can be used\u00a0[Che23], but that one based on the frequencies of the variables improves the efficiency of Algorithm\u00a01; thus we also order variables based on their frequencies to match the process used in Chen\u2019s paper). Crucially, Chen specifies that ties in the global ordering are broken arbitrarily\u00a0[Che23]. All of the variables that appear in our sequences occur with the same frequency, so we can arrange a variable ordering that exploits flaws in Chen\u2019s Algorithm\u00a01. Specifically, we use the global ordering y1>y2>v1subscript\ud835\udc661subscript\ud835\udc662subscript\ud835\udc631y_{1}>y_{2}>v_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT (v1subscript\ud835\udc631v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT has a frequency of 0), where k>j\ud835\udc58\ud835\udc57k>jitalic_k > italic_j indicates that variable k\ud835\udc58kitalic_k comes before (to the left of) variable j\ud835\udc57jitalic_j in the sequence, to create the following sorted sequences (listed in the same order as the corresponding conjunctions in the 2-DNF formula) Note that sequences a\ud835\udc4eaitalic_a and c\ud835\udc50citalic_c contain exactly the same variables, and that the variables of sequences b\ud835\udc4fbitalic_b and d\ud835\udc51ditalic_d can all be spanned. From each sorted sequence we form a p\ud835\udc5dpitalic_p-graph and p\ud835\udc5dpitalic_p*-graph, which are then merged together to form the trie-like graph of Figure\u00a06. We can then run Algorithm\u00a01 on this trie-like graph to create the layered graph shown in Figure\u00a07 (the dashed boxes indicate a grouping of two or more nodes labeled with the same variable). The layered graph clearly contains a rooted subgraph (shaded) that has three satisfied conjunctions among its roots (in fact, the layered graph contains two such rooted subgraphs). Therefore, Algorithm\u00a02 will report the maximum number of satisfied clauses to be three, which is incorrect. This counterexample can be extended to infinite counterexamples of the form where n>1\ud835\udc5b1n>1italic_n > 1. For a boolean formula of the above form with n\ud835\udc5bnitalic_n clauses assume without loss of generality that the 2-DNF conjunctions were created in the same order as their corresponding 2-CNF clauses, and that the variables in the 2-DNF conjunctions that were added during the 2-CNF to 2-DNF conversion are numbered in order they were added. Additionally, assume that the order of the sequences matches that of the 2-DNF conjunctions. Then if the sequences are sorted using a global ordering that has the additional variables in numerical order and v1subscript\ud835\udc631v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is last (y1>y2>\u22ef>yn>v1subscript\ud835\udc661subscript\ud835\udc662\u22efsubscript\ud835\udc66\ud835\udc5bsubscript\ud835\udc631y_{1}>y_{2}>\\cdots>y_{n}>v_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > \u22ef > italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT > italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT), half of the sequences (every odd one, for a total of n\ud835\udc5bnitalic_n), call them the \u201cfull\u201d sequences, will contain every variable except v1subscript\ud835\udc631v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. One sequence (the final sequence), call it the \u201cprefix\u201d sequence, will contain every variable except v1subscript\ud835\udc631v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and ynsubscript\ud835\udc66\ud835\udc5by_{n}italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, the numerically last variable added during the 2-CNF to 2-DNF conversion. When creating the trie-like graph, the full sequences and the prefix sequences will share a trie branch as depicted in Figure\u00a08, with the number below a leaf indicating the number of conjunctions associated with that leaf. Chen\u2019s search algorithm will create a layered graph that contains a rooted subgraph with three nodes: two leaf nodes with the conjunctions of the full and prefix sequences among them, and a root node labeled with the variable yn\u22121subscript\ud835\udc66\ud835\udc5b1y_{n-1}italic_y start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT. Clearly, Algorithm\u00a02 will report the maximum number of satisfied clauses to be n+1\ud835\udc5b1n+1italic_n + 1, despite the 2-CNF formula containing only n\ud835\udc5bnitalic_n clauses. There may exist multiple such \u201cillegal\u201d rooted subgraphs in a layered graph. We briefly mention here our second counterexample (Counterexample\u00a02), the 2-CNF formula (v1\u2228v1)\u2227(v1\u2228v1)subscript\ud835\udc631subscript\ud835\udc631subscript\ud835\udc631subscript\ud835\udc631(v_{1}\\vee v_{1})\\wedge(v_{1}\\vee v_{1})( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2228 italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) \u2227 ( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2228 italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ), which is a slight variation of that of Counterexample\u00a01. The steps of this counterexample are essentially the same as for Counterexample\u00a01, except that the global ordering must have v1subscript\ud835\udc631v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT at the front rather than the end, and so v1subscript\ud835\udc631v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT will appear at the front of all of the sequences. The trie-like graph will contain the same section as depicted in Figure\u00a08, and so Algorithm\u00a01 will exhibit an identical issue as to Counterexample\u00a01, incorrectly reporting the maximum number of satisfied clauses to be three. We leave it to the reader to see that, as with Counterexample\u00a01, this can also be extended to infinitely many counterexamples. For the third counterexample (Counterexample\u00a03), consider the following 2-CNF formula Unlike the previous two counterexamples, this formula is clearly not satisfiable. As with Counterexample\u00a01, the first step is to convert the 2-CNF formula into the following 2-DNF formula: Next, we convert the 2-DNF formula into sequences of variables. We again \u201crig\u201d the global ordering, exploiting the fact that ties are broken arbitrarily to create the ordering y2>y1>v1subscript\ud835\udc662subscript\ud835\udc661subscript\ud835\udc631y_{2}>y_{1}>v_{1}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT (v1subscript\ud835\udc631v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT must come last in the ordering), which results in the following sorted sequences (in the same order as the corresponding conjunctions of the 2-DNF formula): From the sorted sequences, we form the trie-like graph of Figure\u00a09. We run Algorithm\u00a01 on the trie-like graph, creating the layered graph of Figure\u00a010. The layered graph clearly contains a rooted subgraph (shaded) with two satisfied conjunctions among its roots. Therefore, Algorithm\u00a02 will report the maximum number of satisfied clauses to be two, which is incorrect. One issue made apparent by these counterexamples is that the spans (and the fact that variable sequences can share branches in the trie-like graph) allow Algorithm\u00a01 to \u201cskip over\u201d variables that are \u201cimportant\u201d to the satisfiability of a conjunction. For instance, in the layered graph of Counterexample\u00a01, conjunctions a\ud835\udc4eaitalic_a and c\ud835\udc50citalic_c are shown to be satisfied by setting y1subscript\ud835\udc661y_{1}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT to true and v1subscript\ud835\udc631v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and y2subscript\ud835\udc662y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT to false, even though y2subscript\ud835\udc662y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT must be set to true for conjunction c\ud835\udc50citalic_c to be satisfied. When Algorithm\u00a01 is searching up the trie-like graph having started at the leaf for conjunction c\ud835\udc50citalic_c, the algorithm \u201cthinks\u201d it can skip over and ignore y2subscript\ud835\udc662y_{2}italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT because there is a span over it, even though that span only applies to conjunction a\ud835\udc4eaitalic_a, not conjunction c\ud835\udc50citalic_c. An identical issue is present in Counterexample\u00a03, again for conjunctions a\ud835\udc4eaitalic_a and c\ud835\udc50citalic_c. The three counterexamples presented here demonstrate critical flaws in Chen\u2019s Algorithm\u00a01 and show that it does not function as intended. Given that Chen\u2019s algorithm fails on relatively simple 2-CNF formulas, we think it is at least potentially possible that more complex counterexamples might reveal additional flaws. Interestingly, Chen does not provide any time analysis for Algorithm\u00a01, and neither do we as we have already shown the algorithm is flawed. Later in Chen\u2019s paper, Algorithm\u00a01 is replaced with with Algorithm\u00a03, which they claim is an improved search algorithm\u00a0[Che23]. It is unclear whether Algorithm\u00a03 is an improvement over Algorithm\u00a01 in that it brings the runtime from exponential time to polynomial time, or whether Algorithm\u00a01 already runs in polynomial time and Algorithm\u00a03 simply reduces the degree of the polynomial.\nAs we later show in Section\u00a05, the issue found with Algorithm\u00a01, originating in the trie-like graph, still holds in Algorithm\u00a03, which also takes a trie-like graph as input. Chen\u2019s Algorithm\u00a02 takes a layered graph G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT and outputs a tuple that includes the largest subset of conjunctions satisfied by a certain truth assignment. The algorithm works by determining the subset D\u2032superscript\ud835\udc37\u2032D^{\\prime}italic_D start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT of satisfied conjunctions in each rooted subgraph Gvsubscript\ud835\udc3a\ud835\udc63G_{v}italic_G start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT and updating the maximum size for each iteration. First, it should be noted that in their paper\u00a0[Che23], Chen uses n\ud835\udc5bnitalic_n to refer to the number of clauses and m\ud835\udc5amitalic_m to refer to the number of variables in a boolean formula; however, this is only mentioned briefly in their introduction. In Section\u00a03 of Chen\u2019s paper\u00a0[Che23], the author themselves seems to confuse these two values by incorrectly claiming that the maximum number of edges in the trie-like graph is in O\u2062(n2)\ud835\udc42superscript\ud835\udc5b2O(n^{2})italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) (but this is fixed later in Chen\u2019s Section\u00a05). Additionally, in Chen\u2019s introduction, it is stated that n\ud835\udc5bnitalic_n and m\ud835\udc5amitalic_m refer to the 2-CNF formula C\ud835\udc36Citalic_C, however during our analysis of their paper, we found that these values seem to refer to the 2-DNF formula D\ud835\udc37Ditalic_D. Since the number of clauses in D\ud835\udc37Ditalic_D is equal to twice the number of clauses in C\ud835\udc36Citalic_C, this does not directly impact the complexity analysis in terms of Big-Oh (but should be pointed out regardless). However, it can easily be verified that D\ud835\udc37Ditalic_D will have at exactly the number of variables in C\ud835\udc36Citalic_C plus the number of clauses in C\ud835\udc36Citalic_C, which may impact the complexity. To avoid confusion in terms of the complexity analysis, we assume n\ud835\udc5bnitalic_n and m\ud835\udc5amitalic_m refer to the number of clauses and variables in a 2-DNF boolean formula, and we use n0subscript\ud835\udc5b0n_{0}italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and m0subscript\ud835\udc5a0m_{0}italic_m start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT to refer to the number of clauses and variables in a 2-CNF boolean formula. Initially, we want to find the upper bounds of Chen\u2019s algorithm on the size of the layered representation for any trie-graph G\ud835\udc3aGitalic_G. For any 2-DNF boolean formula of n\ud835\udc5bnitalic_n clauses and m\ud835\udc5amitalic_m variables that is in the format specified by Chen, its trie-like graph G\ud835\udc3aGitalic_G will have at most n\u2062(m+2)\u22121\ud835\udc5b\ud835\udc5a21n(m+2)-1italic_n ( italic_m + 2 ) - 1 vertices and (m+2)\u2062(m+1)\u2062n2\ud835\udc5a2\ud835\udc5a1\ud835\udc5b2\\frac{(m+2)(m+1)n}{2}divide start_ARG ( italic_m + 2 ) ( italic_m + 1 ) italic_n end_ARG start_ARG 2 end_ARG edges, and its layered-graph G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT will have at most (n\u2062(m+2)\u22121)\u2062(m+2)\ud835\udc5b\ud835\udc5a21\ud835\udc5a2(n(m+2)-1)(m+2)( italic_n ( italic_m + 2 ) - 1 ) ( italic_m + 2 ) vertices and (m+2)\u2062(m+1)2\u2062n2\ud835\udc5a2superscript\ud835\udc5a12\ud835\udc5b2\\frac{(m+2)(m+1)^{2}n}{2}divide start_ARG ( italic_m + 2 ) ( italic_m + 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_n end_ARG start_ARG 2 end_ARG edges. We will use similar notation to that of Chen\u2019s paper, and will reference steps from Section\u00a03. Let C=C1\u2227C2\u2227\u22ef\u2227Cn0\ud835\udc36subscript\ud835\udc361subscript\ud835\udc362\u22efsubscript\ud835\udc36subscript\ud835\udc5b0C=C_{1}\\wedge C_{2}\\wedge\\cdots\\wedge C_{n_{0}}italic_C = italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u2227 italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u2227 \u22ef \u2227 italic_C start_POSTSUBSCRIPT italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT be a 2-CNF formula with n0subscript\ud835\udc5b0n_{0}italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT clauses and m0subscript\ud835\udc5a0m_{0}italic_m start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT variables, where m0\u22642\u2062n0subscript\ud835\udc5a02subscript\ud835\udc5b0m_{0}\\leq 2n_{0}italic_m start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2264 2 italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and each Cisubscript\ud835\udc36\ud835\udc56C_{i}italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a clause of the form yi\u2228yjsubscript\ud835\udc66\ud835\udc56subscript\ud835\udc66\ud835\udc57y_{i}\\vee y_{j}italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2228 italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. By converting it to a 2-DNF formula in Step\u00a01, the number of clauses will be n=2\u2062n0\ud835\udc5b2subscript\ud835\udc5b0n=2n_{0}italic_n = 2 italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and the number of variables will be m=m0+n0\ud835\udc5asubscript\ud835\udc5a0subscript\ud835\udc5b0m=m_{0}+n_{0}italic_m = italic_m start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. We then convert each conjunction into a variable sequence and pad with (cj,\u2217)subscript\ud835\udc50\ud835\udc57(c_{j},*)( italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , \u2217 ), where (cj,\u2217)=cj\u2228\u00accjsubscript\ud835\udc50\ud835\udc57subscript\ud835\udc50\ud835\udc57subscript\ud835\udc50\ud835\udc57(c_{j},*)=c_{j}\\vee\\neg c_{j}( italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , \u2217 ) = italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u2228 \u00ac italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT and get at most 2\u2062n0\u2062(n0+m0)=m\u2062n2subscript\ud835\udc5b0subscript\ud835\udc5b0subscript\ud835\udc5a0\ud835\udc5a\ud835\udc5b2n_{0}(n_{0}+m_{0})=mn2 italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = italic_m italic_n variables before converting to p\ud835\udc5dpitalic_p-graph, finishing Step\u00a02. After that, by Steps 3 and 4, for each clause, we will have 2222 new symbols, ##\\## and $currency-dollar\\$$, making at most m\u2062n+2\u2062n=(m+2)\u2062n\ud835\udc5a\ud835\udc5b2\ud835\udc5b\ud835\udc5a2\ud835\udc5bmn+2n=(m+2)nitalic_m italic_n + 2 italic_n = ( italic_m + 2 ) italic_n variables and n\ud835\udc5bnitalic_n clauses. For Step\u00a05, we convert each of the sorted sequence into a p\ud835\udc5dpitalic_p-graph. Given any clause Disubscript\ud835\udc37\ud835\udc56D_{i}italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT with at most m+2\ud835\udc5a2m+2italic_m + 2 variables, its p\ud835\udc5dpitalic_p-graph Pisubscript\ud835\udc43\ud835\udc56P_{i}italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT will have at most (m+1)+m=2\u2062m+1\ud835\udc5a1\ud835\udc5a2\ud835\udc5a1(m+1)+m=2m+1( italic_m + 1 ) + italic_m = 2 italic_m + 1 edges. Hence, considering all of the p\ud835\udc5dpitalic_p-graphs, we will get n\ud835\udc5bnitalic_n different graphs, with each of them having at most 2\u2062m+12\ud835\udc5a12m+12 italic_m + 1 edges and m+2\ud835\udc5a2m+2italic_m + 2 vertices. In total, there will be at most n\u2062(2\u2062m+1)\ud835\udc5b2\ud835\udc5a1n(2m+1)italic_n ( 2 italic_m + 1 ) edges and n\u2062(m+2)\ud835\udc5b\ud835\udc5a2n(m+2)italic_n ( italic_m + 2 ) vertices. For Step\u00a06, we convert each p\ud835\udc5dpitalic_p-graph into a p\u2217superscript\ud835\udc5dp^{*}italic_p start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT-graph. We see that the total number of vertices will also be n\u2062(m+2)\ud835\udc5b\ud835\udc5a2n(m+2)italic_n ( italic_m + 2 ), while for each p\ud835\udc5dpitalic_p-graph, the worst case is to have any two vertices connected to each other. Thus for each p\ud835\udc5dpitalic_p-graph, its corresponding p\u2217superscript\ud835\udc5dp^{*}italic_p start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT-graph will have at most (m+2)\u2062(m+1)2\ud835\udc5a2\ud835\udc5a12\\frac{(m+2)(m+1)}{2}divide start_ARG ( italic_m + 2 ) ( italic_m + 1 ) end_ARG start_ARG 2 end_ARG edges, where we consider that there exists an edge between any two vertices. Hence in total we have at most (m+2)\u2062(m+1)\u2062n2\ud835\udc5a2\ud835\udc5a1\ud835\udc5b2\\frac{(m+2)(m+1)n}{2}divide start_ARG ( italic_m + 2 ) ( italic_m + 1 ) italic_n end_ARG start_ARG 2 end_ARG edges and n\u2062(m+2)\ud835\udc5b\ud835\udc5a2n(m+2)italic_n ( italic_m + 2 ) vertices. For Step\u00a07, we merge the p\ud835\udc5dpitalic_p-graphs into a single trie T\ud835\udc47Titalic_T. We see that, without counting the spans of the p\ud835\udc5dpitalic_p-graphs, the worst case for creating T\ud835\udc47Titalic_T would involve the p\ud835\udc5dpitalic_p-graphs only sharing their initial ##\\##-vertex. Then, every other edge from the p\ud835\udc5dpitalic_p-graphs would need to be added to T\ud835\udc47Titalic_T, as none of these edges would be duplicates of each other. Hence, T\ud835\udc47Titalic_T will have at most n\u2062(m+2)\u22121\ud835\udc5b\ud835\udc5a21n(m+2)-1italic_n ( italic_m + 2 ) - 1 vertices and (m+1)\u2062n\ud835\udc5a1\ud835\udc5b(m+1)n( italic_m + 1 ) italic_n edges, since the trie will only have edges between consecutive vertices. For Step\u00a08, we convert T\ud835\udc47Titalic_T into a trie-like graph G\ud835\udc3aGitalic_G by adding the spans from all of the p\u2217superscript\ud835\udc5dp^{*}italic_p start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT-graphs generated in Step\u00a06 to T\ud835\udc47Titalic_T. We see that after this process, the number of edges cannot exceed the total number of edges in the p\u2217superscript\ud835\udc5dp^{*}italic_p start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT-graphs so we will have at most n\u2062(m+2)\u22121\ud835\udc5b\ud835\udc5a21n(m+2)-1italic_n ( italic_m + 2 ) - 1 vertices and (m+2)\u2062(m+1)\u2062n2\ud835\udc5a2\ud835\udc5a1\ud835\udc5b2\\frac{(m+2)(m+1)n}{2}divide start_ARG ( italic_m + 2 ) ( italic_m + 1 ) italic_n end_ARG start_ARG 2 end_ARG edges. Finally, we want to convert G\ud835\udc3aGitalic_G into the layered graph G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. Chen achieves this by searching G\ud835\udc3aGitalic_G from the bottom up, and connecting the nodes in each layer of G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT to all of its parents\u00a0[Che23]. We can see that the depth of the layered graph is at most m+2\ud835\udc5a2m+2italic_m + 2 minus the largest number of vertices on each of the p\ud835\udc5dpitalic_p-graphs, which can only be achieved if we move through the main path of G\ud835\udc3aGitalic_G from the bottom of the graph to the top. Note that the condition for vertex x\ud835\udc65xitalic_x in layer i\ud835\udc56iitalic_i and vertex y\ud835\udc66yitalic_y in layer i+1\ud835\udc561i+1italic_i + 1 to have an edge in G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is that the group of x\ud835\udc65xitalic_x at layer i\ud835\udc56iitalic_i has at least two elements and there is an edge between x\ud835\udc65xitalic_x and y\ud835\udc66yitalic_y in G\ud835\udc3aGitalic_G. Hence, between each layer, the number of edges is at most the total number of edges in G\ud835\udc3aGitalic_G (which is (m+2)\u2062(m+1)\u2062n2\ud835\udc5a2\ud835\udc5a1\ud835\udc5b2\\frac{(m+2)(m+1)n}{2}divide start_ARG ( italic_m + 2 ) ( italic_m + 1 ) italic_n end_ARG start_ARG 2 end_ARG), so in total there will be at most (m+2)\u2062(m+1)2\u2062n2\ud835\udc5a2superscript\ud835\udc5a12\ud835\udc5b2\\frac{(m+2)(m+1)^{2}n}{2}divide start_ARG ( italic_m + 2 ) ( italic_m + 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_n end_ARG start_ARG 2 end_ARG edges in G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. Moreover, we see that the number of vertices in each layers is also at most n\u2062(m+2)\u22121\ud835\udc5b\ud835\udc5a21n(m+2)-1italic_n ( italic_m + 2 ) - 1 so we have at most (n\u2062(m+2)\u22121)\u2062(m+2)\ud835\udc5b\ud835\udc5a21\ud835\udc5a2(n(m+2)-1)(m+2)( italic_n ( italic_m + 2 ) - 1 ) ( italic_m + 2 ) vertices in G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. In conclusion, the layered graph generated by Algorithm\u00a01 has at most (n\u2062(m+2)\u22121)\u2062(m+2)\ud835\udc5b\ud835\udc5a21\ud835\udc5a2(n(m+2)-1)(m+2)( italic_n ( italic_m + 2 ) - 1 ) ( italic_m + 2 ) vertices and (m+2)\u2062(m+1)2\u2062n2\ud835\udc5a2superscript\ud835\udc5a12\ud835\udc5b2\\frac{(m+2)(m+1)^{2}n}{2}divide start_ARG ( italic_m + 2 ) ( italic_m + 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_n end_ARG start_ARG 2 end_ARG edges.\n\n\u220e From Proposition\u00a01, we see that the layered graph will have at most a polynomial number of vertices and edges with respect to the number of clauses and variables in its corresponding 2-DNF formula. Additionally, we see that in Algorithm\u00a02 we are iterating over each rooted subgraph Gvsubscript\ud835\udc3a\ud835\udc63G_{v}italic_G start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT to find a maximized number of satisfied conjunctions. Since there are only a polynomial number of iterations, if we can show that the main loop of Algorithm\u00a02 runs in polynomial time, we will have shown that all of Algorithm\u00a02 runs in polynomial time. Suppose \u03c4\u2062(G)\ud835\udf0f\ud835\udc3a\\tau(G)italic_\u03c4 ( italic_G ) is the amount of time Algorithm\u00a02 takes to run on the trie-like graph G\ud835\udc3aGitalic_G. Then we have where \u03c4\u2032\u2062(Gv)superscript\ud835\udf0f\u2032subscript\ud835\udc3a\ud835\udc63\\tau^{\\prime}(G_{v})italic_\u03c4 start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ( italic_G start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) is the time complexity to determine the set of satisfied conjunctions in Gvsubscript\ud835\udc3a\ud835\udc63G_{v}italic_G start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT. However, Chen does not detail the runtime of this process. If Algorithm\u00a02 tries to find an exact satisfiable set for Gvsubscript\ud835\udc3a\ud835\udc63G_{v}italic_G start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT, then this algorithm is trying to solve the SAT problem, which is known to be NP-complete\u00a0[GJS74]. Note that as we are converting to the layered-graph, the number of terms in each of the clauses does not have an upper bound. Hence, unless the boolean function has a \u201cnice\u201d form, we are unable to determine what the actual runtime is. On the other hand, if\nthe algorithm only tries to run a depth-first search on each of the rooted nodes and calculate the size of the $currency-dollar\\$$-leaves, then the algorithm runs in polynomial time.\nNonetheless, as we have mentioned in Section\u00a04.1, Chen\u2019s algorithm does not always return the correct answer. We now detail Chen\u2019s proposed improvements to generating layered graphs as described in their technical report\u00a0[Che23]. Although this section and the subsequent section (Section\u00a06) are not applicable to Chen\u2019s conference version\u00a0[Che22], we have already provided examples where the algorithm detailed in that paper reports incorrect results. We will also detail further issues regarding Chen\u2019s conference version in Section\u00a07 In Chen\u2019s Section\u00a04, significant changes are made to Algorithm\u00a01, the algorithm that generates the layered graph G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, to create Algorithm\u00a03. Chen claims that their changes improve the runtime of Algorithm\u00a01\u00a0[Che23]. These changes include eliminating duplicate occurrences of nodes in the layered graph G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, and creating new structures to search G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT (namely, Chen creates what they call \u201creachable subsets through spans\u201d and \u201cupper boundaries\u201d to aid Algorithm\u00a03)\u00a0[Che23]. As we will show, Chen fails to provide formal instructions on how to generate these new structures, and only gives definitions and examples of what values they should take on. In Chen\u2019s Subsection 4.A titled \u201cRedundancy analysis\u201d\u00a0[Che23], Chen gives three cases that they claim can identify whether a duplicate node will be created in a layer of G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT when traversing the trie-like graph G\ud835\udc3aGitalic_G. These cases depend on knowing how the structure of the trie-like graph G\ud835\udc3aGitalic_G will effect the layered graph G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT; specifically, they depend on whether the node(s) in G\ud835\udc3aGitalic_G that cause a duplicate node to appear in G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT are contained on one or more branches of G\ud835\udc3aGitalic_G. While Chen claims these cases can be used to eliminate redundant nodes in the same layer of G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, this approach does not prevent multiple occurrences of the same nodes from appearing in other layers of G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT (which may lead to a higher runtime), and lumps special cases that don\u2019t reflect Case\u00a01 or Case\u00a02 into a general third case without explanation. Additionally, while merging these nodes reduces the number of nodes in each level (effectively bounding each level to have at most O\u2062(n\u2062m)\ud835\udc42\ud835\udc5b\ud835\udc5aO(nm)italic_O ( italic_n italic_m ) nodes), this approach does not reduce the number of edges in G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, which is potentially problematic as the recursive algorithm is based on searching subsets of G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT. From these cases that claim to determine when duplicate nodes appear in a layer of G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, Chen changes the way the layered graph G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is generated in an attempt to make searching G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT more computationally efficient. To achieve this, a subset of nodes called a reachable subset through spans is defined for a node u\ud835\udc62uitalic_u that lies on the main trie path between the root node and a repeated node v\ud835\udc63vitalic_v of Chen\u2019s Case\u00a01 (where u\u2260v\ud835\udc62\ud835\udc63u\\neq vitalic_u \u2260 italic_v), and a clause\u00a0c\ud835\udc50citalic_c\u00a0[Che23]. A reachable subset of u\ud835\udc62uitalic_u through spans with label c\ud835\udc50citalic_c (which Chen denotes as R\u2062Su\u2062[c]\ud835\udc45subscript\ud835\udc46\ud835\udc62delimited-[]\ud835\udc50RS_{u}[c]italic_R italic_S start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT [ italic_c ]) is then defined to be \u201c[the set of] nodes with a same label c\ud835\udc50citalic_c in different subgraphs in G\u2062[v]\ud835\udc3adelimited-[]\ud835\udc63G[v]italic_G [ italic_v ] (subgraph rooted at v\ud835\udc63vitalic_v) and reachable from u\ud835\udc62uitalic_u through a span\u201d\u00a0[Che23]. It is required that u\ud835\udc62uitalic_u is a node on a path in the trie-like graph between the root and a repeated node of Case\u00a01 labeled v\ud835\udc63vitalic_v. It should be noted that Chen occasionally abuses this notation in their paper by omitting the label c\ud835\udc50citalic_c (as can be seen in their statement \u201cR\u2062Sv\u20621=\u2205\ud835\udc45subscript\ud835\udc46\ud835\udc631RS_{v1}=\\emptysetitalic_R italic_S start_POSTSUBSCRIPT italic_v 1 end_POSTSUBSCRIPT = \u2205\u201d\u00a0[Che23]), which is unclear as c\ud835\udc50citalic_c is required to define this structure. Chen\u2019s definition of a reachable subset through spans is also confusing for a set that is supposed to improve their algorithm\u2019s runtime, as it seems to require the G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT from Algorithm\u00a01 to be (at least partially) generated as the rooted subgraphs that are defined in G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT need to be searched. However, while an individual rooted subgraph could be generated by traversing the spans in G\ud835\udc3aGitalic_G, this would require an extra search algorithm that Chen fails to define\u00a0[Che23]. Another concern about the reachable subset through spans definition is that it requires a node of Case\u00a01 to be found between two arbitrary points, as the specific node v\ud835\udc63vitalic_v does not appear in the final structure. This concept of a reachable subset through spans is then extended into a different set of nodes that Chen calls upper boundaries\u00a0[Che23]. The definition for these upper boundaries again depends on rooted subgraphs of G\ud835\udc3aGitalic_G which are not defined in the paper. Additionally, generating even one upper bound requires both generating and searching an arbitrarily large number of reachable spans, which leads us to doubt that this method is more efficient than Chen\u2019s Algorithm\u00a01. While it is claimed that these upper boundaries and reachable subsets through spans lead to a more efficient algorithm\u00a0[Che23], no proof of this is ever provided by Chen, and the overall complexity for generating these structures to remove duplicate nodes in a single layer is never analyzed. Additionally, Chen\u2019s Algorithm\u00a03 can be shown to fail on certain inputs. For example, consider the trie-like graph we used in our Counterexample\u00a01, depicted in Figure\u00a06. If Algorithm\u00a03 takes this graph as input, on the first iteration of its main loop it will generate the parent node n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT from n3subscript\ud835\udc5b3n_{3}italic_n start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, and the parent node n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT from n7subscript\ud835\udc5b7n_{7}italic_n start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT. Clearly this is an example of a Case\u00a01 repeated node as described by Chen\u00a0[Che23], because n3subscript\ud835\udc5b3n_{3}italic_n start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and n7subscript\ud835\udc5b7n_{7}italic_n start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT appear on different main branches of G\ud835\udc3aGitalic_G. Next, according to Algorithm\u00a03 we need to generate the reachable subsets of spans relative to n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. But by their definition, a reachable subset can only be defined for nodes between the root and the node before n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT on the main path of G\ud835\udc3aGitalic_G. Since n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is the root of G\ud835\udc3aGitalic_G, such a node does not exist and we cannot calculate a reachable subset of spans (by extension, we also cannot define an upper boundary). Therefore, the recursive call will only be over the single node n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, which may itself be undefined as it is unclear if all of the nodes in G\ud835\udc3aGitalic_G contain labels indicating which clauses they are a part of, or if this only applies to the leaf nodes of G\ud835\udc3aGitalic_G. Similarly, the parent n2subscript\ud835\udc5b2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT will also be generated from both n3subscript\ud835\udc5b3n_{3}italic_n start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and n5subscript\ud835\udc5b5n_{5}italic_n start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT. While it is not clear which duplicate node case this falls under, the reachable subset through spans will similarly be undefined as n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is the only node that fits the description of u\ud835\udc62uitalic_u, but it has no subset with more than two nodes that is relevant for generating an upper bound. Following this pattern, in all subsequently generated levels when a duplicate node appears the reachable subset through spans and upper bounds cannot be properly defined, so while duplicate nodes are still merged, the recursive calls will only be called on a single node (n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT). Finally, after the layered graph G\u2032superscript\ud835\udc3a\u2032G^{\\prime}italic_G start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is generated by Algorithm\u00a03, it is passed to Algorithm\u00a02 like before. As can be seen in Figure\u00a011, there is still clearly a rooted subgraph that reports that three clauses can be satisfied. Therefore, despite the claimed improvements of Algorithm\u00a03, there still exist cases where it gives an incorrect solution to the 2-MAXSAT problem. We now remark on Chen\u2019s complexity analysis of the improved algorithm described in their technical report\u00a0[Che23], which omits any complexity analysis of the unimproved algorithm. The conference version of Chen\u2019s paper\u00a0[Che22] does include complexity analysis of the unimproved algorithm. However, its absence from the technical report and the fact that the polynomial bound of O\u2062(n2\u2062m3)\ud835\udc42superscript\ud835\udc5b2superscript\ud835\udc5a3O(n^{2}m^{3})italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_m start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) proposed in the conference version\u00a0[Che22] is different than the bound of O\u2062(n3\u2062m3)\ud835\udc42superscript\ud835\udc5b3superscript\ud835\udc5a3O(n^{3}m^{3})italic_O ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_m start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) claimed in their updated technical report\u00a0[Che23] gives us reason to doubt the validity of the complexity analysis detailed in Chen\u2019s conference paper. Despite being a paper focused entirely on constructing an algorithm that is claimed to run in polynomial time, Chen says little on algorithmic complexity in the sections where they introduce and define their algorithms. Instead, in Chen\u2019s Section\u00a05\u00a0[Che23], the complexity of both the proposed construction of the trie-like graph G\ud835\udc3aGitalic_G and Algorithm\u00a03 are briefly analyzed. Due to the vagueness of Chen\u2019s different structures (such as the reachable subsets from spans and upper bounds), we do not attempt to give further analysis of the complexity of Algorithm\u00a03 beyond the work in Chen\u2019s paper\u00a0[Che23] for concern that we will not implement their algorithms as intended. Despite this, there still seem to be flaws and overgeneralizations in Chen\u2019s analysis. When analyzing the runtime of the initial structure constructions and search algorithms, Chen separates the problem into three main subcategories, \u03c41subscript\ud835\udf0f1\\tau_{1}italic_\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u03c42subscript\ud835\udf0f2\\tau_{2}italic_\u03c4 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT (which is further divided into \u03c421subscript\ud835\udf0f21\\tau_{21}italic_\u03c4 start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT, \u03c422subscript\ud835\udf0f22\\tau_{22}italic_\u03c4 start_POSTSUBSCRIPT 22 end_POSTSUBSCRIPT, and \u03c423subscript\ud835\udf0f23\\tau_{23}italic_\u03c4 start_POSTSUBSCRIPT 23 end_POSTSUBSCRIPT), and \u03c43subscript\ud835\udf0f3\\tau_{3}italic_\u03c4 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. While each subsection represents the runtime for a specific step or algorithm in Chen\u2019s solution, these runtimes are merely listed with minimal explanation\u00a0[Che23]. We believe further analysis should be used here to improve comprehension. For example, Chen states that the complexity for sorting the variable sequences in the Disubscript\ud835\udc37\ud835\udc56D_{i}italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT\u2019s is clearly O\u2062(n\u2062m\u2062log\u2061m)\ud835\udc42\ud835\udc5b\ud835\udc5a\ud835\udc5aO(nm\\log m)italic_O ( italic_n italic_m roman_log italic_m ) without any further reasoning\u00a0[Che23]. Instead, it would be helpful to reiterate that this is because there are n\ud835\udc5bnitalic_n different Disubscript\ud835\udc37\ud835\udc56D_{i}italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT sequences to sort that each contain m\ud835\udc5amitalic_m variables. Similarly, for the complexity of constructing the n\ud835\udc5bnitalic_n p\ud835\udc5dpitalic_p*-graphs, it is claimed that \u03c422subscript\ud835\udf0f22\\tau_{22}italic_\u03c4 start_POSTSUBSCRIPT 22 end_POSTSUBSCRIPT is O\u2062(n\u2062m2)\ud835\udc42\ud835\udc5bsuperscript\ud835\udc5a2O(nm^{2})italic_O ( italic_n italic_m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) since at most O\u2062(m2)\ud835\udc42superscript\ud835\udc5a2O(m^{2})italic_O ( italic_m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) time is needed to find the transitive closure over each graph\u2019s spans without explanation\u00a0[Che23]. This is because in the worst case each p\ud835\udc5dpitalic_p-graph can have m\u22122\ud835\udc5a2m-2italic_m - 2 spans (besides the edges that Chen calls the \u201cmain path\u201d of a p\ud835\udc5dpitalic_p-graph), and therefore at most (m\u22122)+(m\u22123)+\u22ef+1=(m\u22122)\u2062(m\u22121)2\ud835\udc5a2\ud835\udc5a3\u22ef1\ud835\udc5a2\ud835\udc5a12(m-2)+(m-3)+\\dots+1=\\frac{(m-2)(m-1)}{2}( italic_m - 2 ) + ( italic_m - 3 ) + \u22ef + 1 = divide start_ARG ( italic_m - 2 ) ( italic_m - 1 ) end_ARG start_ARG 2 end_ARG edges will be created. Finally, Chen establishes a recursive relationship to analyze \u03c43subscript\ud835\udf0f3\\tau_{3}italic_\u03c4 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, the average complexity of searching G\ud835\udc3aGitalic_G with the improved Algorithm\u00a03. Since Chen claims that their analysis gives the average time complexity of \u03c43subscript\ud835\udf0f3\\tau_{3}italic_\u03c4 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT\u00a0[Che23], they are in fact not providing the worst-case analysis of the algorithm and are incorrectly using Big-Oh notation. However, it is unclear if this mistake in notation was an error in wording (and Chen meant to say worst-case) or practice (and Chen is really giving an average time analysis). Regardless of Chen\u2019s incorrect usage of Big-Oh notation, their proof for the average complexity of \u03c43subscript\ud835\udf0f3\\tau_{3}italic_\u03c4 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT still contains major concerns. For instance, they introduce constants that can take on undefined values (such as using d\ud835\udc51ditalic_d, which can take on the value of one and cause many logarithms in Chen\u2019s analysis to be undefined), and constants that lack definitions whatsoever (such as the undefined constant used to establish the base case of their recursive relation)\u00a0[Che23]. Furthermore, it is unclear how d\u2308logd\u2061l\u2309\u2264lsuperscript\ud835\udc51subscript\ud835\udc51\ud835\udc59\ud835\udc59d^{\\lceil\\log_{d}l\\rceil}\\leq litalic_d start_POSTSUPERSCRIPT \u2308 roman_log start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT italic_l \u2309 end_POSTSUPERSCRIPT \u2264 italic_l is derived in the computations to simplify Chen\u2019s Equation\u00a06\u00a0[Che23], and why the ceiling function is not applied to the exponent of (l\u2062o\u2062gd\u2062l)\ud835\udc59\ud835\udc5csubscript\ud835\udc54\ud835\udc51\ud835\udc59(log_{d}l)( italic_l italic_o italic_g start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT italic_l ). Despite their initial analysis, Chen notes that their recursive relation does not show that their proposed algorithm has a polynomially-bounded runtime, so the author attempts to give a lower bound. In the final paragraph of Chen\u2019s Section\u00a05\u00a0[Che23], it is claimed that each branching node can be involved in at most O\u2062(n)\ud835\udc42\ud835\udc5bO(n)italic_O ( italic_n ) recursive calls. It is unclear how this claim is being proved, however it seems that Chen claims the number of recursive calls a node is involved in is at most n\u22122\ud835\udc5b2n-2italic_n - 2, but if there is an upper bound to that node it may be involved in an additional recursive call. Since the number of branching nodes is at most the number of nodes in a trie-like subgraph (O\u2062(n\u2062m)\ud835\udc42\ud835\udc5b\ud835\udc5aO(nm)italic_O ( italic_n italic_m )) and each recursive call is claimed to run in O\u2062(n\u2062m2)\ud835\udc42\ud835\udc5bsuperscript\ud835\udc5a2O(nm^{2})italic_O ( italic_n italic_m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), this would cause the worst case runtime of the algorithm to be O\u2062(n\u00d7n\u2062m\u00d7n\u2062m2)=O\u2062(n3\u2062m3)\ud835\udc42\ud835\udc5b\ud835\udc5b\ud835\udc5a\ud835\udc5bsuperscript\ud835\udc5a2\ud835\udc42superscript\ud835\udc5b3superscript\ud835\udc5a3O(n\\times nm\\times nm^{2})=O(n^{3}m^{3})italic_O ( italic_n \u00d7 italic_n italic_m \u00d7 italic_n italic_m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) = italic_O ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_m start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ). Furthermore, recall that since n\ud835\udc5bnitalic_n and m\ud835\udc5amitalic_m were found to refer to the number of clauses and variables in the 2-DNF formula D, this paper (in Section\u00a04.2) defined n0subscript\ud835\udc5b0n_{0}italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and m0subscript\ud835\udc5a0m_{0}italic_m start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT to be the respective number of clauses and variables in the corresponding 2-CNF formula. It is clear that in the worst-case n=2\u2062n0\ud835\udc5b2subscript\ud835\udc5b0n=2n_{0}italic_n = 2 italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT as Chen converts every clause in the 2-CNF boolean formula into two new clauses in their DNF formula and similarly m=n0+m0\ud835\udc5asubscript\ud835\udc5b0subscript\ud835\udc5a0m=n_{0}+m_{0}italic_m = italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT as a new variable is created in the 2-DNF formula for every clause in the 2-CNF formula. Additionally, it is clear that in the worst-case there can be at most 2\u2062n02subscript\ud835\udc5b02n_{0}2 italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT unique variables in a 2-CNF formula if each clause contains two unique variables. Therefore, in the worst-case, it follows that Thus the worst-case runtime of Chen\u2019s solution in terms of the number of clauses in a 2-CNF formula is O\u2062(n06)\ud835\udc42superscriptsubscript\ud835\udc5b06O(n_{0}^{6})italic_O ( italic_n start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT ). While analyzing Chen\u2019s work we could not find any specific algorithm that stood out as concretely running in exponential time. Nonetheless, we have provided reasons to doubt the validity of Chen\u2019s claims that their algorithm has a polynomial runtime. Furthermore, as we have shown through our counterexamples, regardless of whether Chen\u2019s Algorithm\u00a03 does have a polynomial runtime, the algorithm does not always provide valid solutions for the 2-MAXSAT problem. Throughout the technical-report version\u00a0[Che23] and conference version\u00a0[Che22] of Chen\u2019s papers, the 2-CNF boolean formula is used as an example to detail the steps of Chen\u2019s proposed solution to 2-MAXSAT and to show that their solution is correct, in place of formal definitions. In general, showing that an algorithm finds a solution to a single example is not a sufficient proof of correctness. Furthermore, some steps of Chen\u2019s solution such as the global ordering of the variable sequences and specific implementations of the p\ud835\udc5dpitalic_p-graphs, p\ud835\udc5dpitalic_p*-graphs, trie-like graph, and layered graph are only partially formalized. This is problematic as different design choices to implement these steps could lead to major variations in both the runtime and validity of Chen\u2019s proposed solution. Chen\u2019s use of formula C\ud835\udc36Citalic_C as a reoccurring example is also problematic as this formula is satisfiable\u00a0[Che23]. It is well known that the problem of deciding whether a 2-CNF boolean formula has at least one satisfying assignment (also called 2-SAT) is in PP{\\rm P}roman_P. Therefore, there clearly exists a polynomial-time algorithm that can determine if C\ud835\udc36Citalic_C has an assignment that satisfies at least k\ud835\udc58kitalic_k clauses (with 1\u2264k\u2264n1\ud835\udc58\ud835\udc5b1\\leq k\\leq n1 \u2264 italic_k \u2264 italic_n). Thus the 2-MAXSAT problem for C\ud835\udc36Citalic_C (or any formula in 2-SAT) can be solved trivially, with the maximum number of satisfied clauses equal to the number of clauses in C\ud835\udc36Citalic_C. This leads us to further doubt Chen\u2019s algorithm, as the formula C\ud835\udc36Citalic_C that they use to show the correctness and polynomial runtime of their algorithm can already be computed, in polynomial time, to have a maximum of three satisfied clauses. Finally, Chen fails to provide valid proofs that any of their proposed algorithms always return a correct result.\nIndeed, for Algorithms\u00a01 and 2, which we have shown to produce incorrect results on certain inputs, a proof of correctness cannot exist.\nChen\u2019s Proposition\u00a02 claims to provide such a proof for Algorithms\u00a01\u00a0and\u00a02\u00a0[Che23], but it assumes both that there are no issues in constructing the trie-like graph G\ud835\udc3aGitalic_G, and that Algorithm\u00a01 and Algorithm\u00a02 will each work as informally described. A similarly-styled proof is also used for Chen\u2019s Proposition\u00a03\u00a0[Che23], which claims to show the correctness of Algorithm\u00a03. In this paper, we have provided examples where Chen\u2019s proposed algorithms fail to solve instances of the 2-MAXSAT problem. This disproves the central claims of both Chen\u2019s conference version\u00a0[Che22] and technical-report version\u00a0[Che23]. Additionally, we have shown that due to poor definitions and vague analyses, Chen fails to establish whether the proposed algorithms run in polynomial time. We conclude that Chen has failed to prove the claim made in the title of their papers\u00a0[Che22, Che23], and so has also failed to prove that P=NPPNP{\\rm P}={\\rm NP}roman_P = roman_NP. We would like to thank\nMichael\u00a0C.\u00a0Chavrimootoo,\nLane\u00a0A.\u00a0Hemaspaandra,\nHarry\u00a0Liuson,\nand\nZeyu\u00a0Nie\nfor their helpful comments on prior drafts. The authors are responsible for any remaining errors."
    },
    {
        "id": 24,
        "title": "A Comprehensive Tutorial on over 100 Years of Diagrammatic Representations of \nLogical Statements and Relational Queries",
        "corpus": "tcb@breakable Query formulation is increasingly performed by systems that need to guess a user\u2019s intent\n(e.g.\u00a0via spoken word interfaces).\nBut how can a user know that the computational agent is returning answers to the \u201cright\u201d query?\nMore generally,\ngiven that relational queries can become pretty complicated,\nhow can we help users understand relational queries, whether human-generated or automatically generated?\nNow seems the right moment to revisit a topic that predates the birth of the relational model:\ndeveloping visual metaphors that help users understand relational queries. This lecture-style tutorial\nsurveys the key visual metaphors developed\nfor diagrammatic representations of logical statements and relational expressions,\nacross both the relational database and the much older diagrammatic reasoning communities.\nWe survey the history and state-of-the-art of relationally-complete\ndiagrammatic representations of relational queries,\ndiscuss the key visual metaphors developed in over a century of\ninvestigations into diagrammatic languages,\nand organize the landscape by mapping the visual alphabets of diagrammatic representation systems to the syntax and semantics of Relational Algebra (RA) and Relational Calculus (RC).\nTutorial website:\nhttps://northeastern-datalab.github.io/diagrammatic-representation-tutorial/ The design of relational query languages and the difficulty for users to compose relational queries have\nreceived much attention over the\nlast 40 years\u00a0[10, 12, 30, 35, 40, 52, 53, 64, 65].\nA complementary and much-less-studied problem is that of helping users\nread and understand existing queries.\nWith the proliferation of public data sources and associated queries, users increasingly have to read other people\u2019s queries and scripts.\nAt the same time, Large Language Models (LLMs) have become an effective way to generate \u201cstarter code\u201d (including SQL queries [22, 49]) which still has to be checked for correctness and undergo refinement.\nSome even predict that\n\u201call programs in the future will ultimately be written by AIs, with humans relegated to, at best, a supervisory role\u201d\u00a0[63].\nBut while it is easier to modify a \u201cstarter query\u201d than to write something from scratch,\nreading code is hard, and SQL is no exception.\nAny \u201chuman-AI-database interaction\u201d relying on starter queries still requires users to understand written queries.\nFor that reason alone, it is an opportune moment to study ways that help users understand queries,\nand visualization is one obvious route.\nWhile visual methods for composing queries have been studied\nextensively in the database literature under the topic of Visual Query Languages (VQLs)\u00a0[10],\nthe challenges for supporting the reverse functionality of automatically creating a visual representation of an existing query\n(\u201cQuery Visualization\u201d) are different than the problem of composing a new query. The tutorial uses a few relational queries\nto survey and summarize the history of diagrammatic (thus visual) representations\nof first-order logic queries and statements.\nThe goal is to highlight similarities and differences\nbetween approaches proposed across communities by contrasting mapping of\nvarious visual representations to equivalent expressions in\nRelational Algebra (RA) and Relational Calculus (RC). Outline.\nThe lecture-style 3-hour tutorial consists of six parts: (1) Why visualizing queries and why now:\nWe contrast Query Visualization (QV) with Visual Query Languages (VQL)\nand give several usage scenarios\nfor the use of query visualization\n(see\u00a0Figs.\u00a01 and\u00a02). (2) Principles of query visualization:\nWe discuss several proposed principles of query visualization\u00a0[27, 23], re-phrased in the terminology of \u201cAlgebraic Visualization Design\u201d\u00a0[37].\nWe use these principles as guides when later discussing different diagrammatic representations. (3) Logical foundations of relational query languages:\nWe discuss the logical foundations of relational query languages.\nWe show a few example queries over the sailors-reserve-boats database\nin different relational query languages, which we later use when discussing and comparing\nvisual representations. (4) Early diagrammatic representations:\nDiagrammatic representations for logical statements\nwere developed well before relational databases.\nWe discuss several visual formalisms developed over more than 100 years of work on diagrammatic reasoning systems,\nin particular the influential beta existential graphs by Peirce\u00a0[47]\nand their connection to the much later developed Domain Relational Calculus (DRC). (5) Modern visual query representations:\nWe use the earlier introduced queries over the sailors-reserve-boats database\nto discuss the main families of visual representations for relational queries\nproposed by the database community. (6) Lessons learned and open challenges:\nWe extract insights from our survey and discuss open challenges. Audience and prerequisite.\nThis 180\u00a0min tutorial targets\nresearchers and practitioners\nwho desire an intuitive, yet comprehensive survey\nof diagrammatic representations of logical statements and relational queries.\nOur focus is on the commonalities and differences between\nmajor design ideas.\nThe tutorial is best followed by being familiar with Relational Algebra (RA), Relational Calculus (RC) and the safety conditions to make them equivalent in expressiveness.\nHowever, the tutorial is self-contained and includes\na short-paced summary of the characteristics of 5 relational query languages. Scope of this tutorial.\nThis tutorial surveys visual formalisms for representing relational queries.\nThe focus is on relationally complete formalisms whose expressiveness is equivalent to Relational Algebra (RA), Relational Calculus (RC), and non-recursive Datalog with stratified negation.\nIn order to guide the discussion, the tutorial discusses mapping the visual alphabets of visual formalisms\nto expressions of RA and RC. It thus starts with a quick fast-paced overview of RA and RC and their connections to first-order logic. Out-of-scope.\nThe tutorial does not cover domain-specific visualizations, such as those for geographic information systems, time-series, and\nspatio-temporal\ndata\u00a0[14, 42, 39].\nNeither does it cover\ndynamic\ninteraction with queries or data\u00a0[46]. Related other tutorials.\nA tutorial at SIGMOD\u201919\u00a0[59] (\u201cTowards Democratizing Relational Data Visualizations\u201d) focused on ways to visualize data and languages that allow users to specify what visualizations they want to apply to data.\nThe focus of this tutorial is instead of visual representations of queries.\nTwo tutorials at SIGMOD\u201917\u00a0[8] (\u201cGraph Querying Meets HCI\u201d) and SIGMOD\u201922\u00a0[7] (\u201cData-driven Visual Query Interfaces for Graphs\u201d) focused on visual composition of graph queries.\nThe types of queries discussed in those tutorials basically correspond to conjunctive queries with inequalities over binary predicates, whereas our focus is on full first-order logic.\nAlso, the focus was on the human-interaction aspect of how to compose queries, while our focus is on the visual formalisms developed for relational queries over the last century (thus even predating the relational model). Contrast to prior offerings of this tutorial.\nA 90-min tutorial on the topic\nwas presented at the \u201cInternational Conference on the Theory and Application of Diagrams 2022\u201d (DIAGRAMS-22)\u00a0[24],\nthe main international venue covering all aspects of research on the theory and application of diagrams.\nThis conference attracts an audience with close to no intersection with the audience at database conferences.\nThe emphasis of that tutorial was on the logical foundations of relational databases,\nthe resulting different focus from the diagrammatic reasoning community,\nand the problems arising from visualizing logical disjunctions as diagrams.\nA 90-min version of the proposed tutorial\nwas presented at VLDB 2023\u00a0[25].\nThe emphasis of that tutorial was on the principles guiding effective Query Visualization,\nand an overview of representations suggested by the database community.\nThe tutorial is available as a 300-page slide deck on the tutorial web page\u00a0[25]. The key novel parts of this 3-h tutorial will be as follows:\n 1\u00a0Part 4 includes a comprehensive survey of early diagrammatic approaches for representing logical statements\nthat largely predate attempts in the database community and are seemingly disconnected to them.\nWe will cover\nEuler circles\u00a0[18],\nVenn diagrams\u00a0[62],\nVenn-Peirce diagrams\u00a0[47],\nconstraint diagrams\u00a0[36, 28],\nPeirce\u2019s beta existential graphs, and\nSowa\u2019s conceptual graphs\u00a0[57].\nWe also discuss\nformalisms embodied by Higraphs\u00a0[29]\nand UML notation\u00a0[20].\n 2\u00a0Part\u00a05 compares past approaches in the database community. It was previously (at VLDB 2023) only covered partially due to the limited time.\nThis tutorial includes an additional query\nfocusing on diagrammatic representations for disjunctions and unions,\nwhich are known to be the greatest challenge for diagrammatic representations (see e.g., discussion by Shin\u00a0[55]).\nWe will also cover two additional very recent diagrammatic formalisms.\nFurthermore, the historical comparisons (parts 4 and 5 together) will culminate in a new \u201clessons learned\u201d synthesis (part 6).\n 3 The new material grows the expected number of slides to over 400 pages.\nSlides (and possibly videos) of the tutorial will be made available afterward on the tutorial web page,\nsimilar to other recent tutorials by the presenter and collaborators on unrelated topics\u00a0[60, 61]. We give several scenarios\nin which \u201cappropriate\u201d query visualizations could help users\nachieve new functionalities\nor increased efficiency in composing queries.\nAn important detail is here that visualizations can be used as complement\nto query composition\ninstead of substitution.\nThis contrasts with\nVisual Query Languages (VQLs) which allow users to express queries in a visual format.\nVisual methods for specifying relational queries have been studied\nextensively\u00a0[10],\nand\nmany commercial database products offer some visual interface for users to write simple conjunctive queries.\nIn parallel, there is a centuries-old history of the study of formal diagrammatic reasoning systems [33]\nwith the goal of helping humans to reason in terms of logical statements. Yet despite their intuitive appeal and extensive study, successful visual tools today mostly only\ncomplement instead of replace\ntext for composing queries.\nWe will discuss several reasons why visual query composition\nfor general relational queries\nhave not yet widely replaced textual query composition\nand discuss a user-query interaction\nthat separates the query composition from the visualization:\nComposition is either unchanged and still done in text,\nor alternatively replaced with natural language (NL) interfaces to personal assistants and learned models (Figs.\u00a01 and\u00a02).\nThis composition is then augmented and complemented with a visual interaction that helps interpretation and verification of correctness\u00a0[23]. With this motivation, the goal of this tutorial is to survey and highlight the key ideas behind\nmajor proposals for diagrammatic representations of relational statements and queries. The term query visualization refers to both (i\ud835\udc56iitalic_i) a graphical representation of a query\n(alternatively, \u201cquery diagram\u201d)\nand (i\u2062i\ud835\udc56\ud835\udc56iiitalic_i italic_i) the process of transforming a query into a graphical representation\n(alternatively, \u201cquery diagramming\u201d).\nThe goal of query visualization is to help users more quickly understand the intent of a query,\nas well as its relational query pattern. The challenge of query visualization is to find appropriate visual metaphors\nthat (i\ud835\udc56iitalic_i) allow users to quickly understand a query\u2019s intent, even for complex queries,\n(i\u2062i\ud835\udc56\ud835\udc56iiitalic_i italic_i) can be easily learned by users,\nand (i\u2062i\u2062i\ud835\udc56\ud835\udc56\ud835\udc56iiiitalic_i italic_i italic_i) can be obtained from textual queries by automatic translation,\nincluding a visually appealing automatic arrangement of elements of the visualization.\nWe discuss several earlier proposed principles of query visualization\u00a0[27, 23],\nwhich are newly organized, extended, and rephrased in the terminology of \u201cAlgebraic Visualization Design\u201d\u00a0[37].\nOne important \u201ccorrespondence principle\u201d relies on a recently proposed notion of \u201crelational query pattern\u201d\u00a0[26].\nWhile we call them \u201cprinciples\u201d, they are not meant to be irrevocable axioms, but rather intuitive objectives, whose formulation helps us develop a shared vocabulary for later discussing the trade-offs among various visualizations.\nWe also include them in order to spark a healthy debate during and after the tutorial. We give a\nbrief\noverview of the logical foundations of relational query languages\nby discussing 5 queries over a variant of the sailors-reserve-boats database\nfrom the \u201ccow book\u201d [51].\nWe use a consistent notation and give the queries in 5 textual query languages:\nSQL, Domain Relational Calculus (DRC), Tuple Relational Calculus (TRC), non-recursive Datalog with negation, and Relational Algebra (RA).\nWe use these queries and textual languages later in parts 4 and 5\nwhere we establish the mappings between various visual formalisms and these 5 queries.\nBy using a consistent set of queries throughout our survey we can give a unified comparison of visual alphabets and their \u201cpattern expressiveness\u201d.\nOur focus is on expressiveness equivalent to First-Order Logic (FOL),\nwhich allows us to make the connection to a century of research on formalisms for diagrammatic reasoning. A query in Relational Calculus (RC) is a logical formula with free variables and as such\na specialization of First-Order Logic (FOL).\nA logical statement has no free variables and is basically the same as a Boolean query that returns a truth value of TRUE or FALSE.\nDiagrammatic representations for logical statements\u00a0[33]\nhave been developed even before FOL, which was only clearly articulated in the 1928 first edition of David Hilbert and Wilhelm Ackermann\u2019s \u201cGrundz\u00fcge der theoretischen Logik\u201d\u00a0[32]. An influential diagrammatic notation is the Existential Graph (EG) notation by Charles Sanders Peirce\u00a0[47, 54, 56],\nwho wrote on graphical logic as early as 1882\u00a0[38].\nThese graphs exploit topological properties, such as enclosure, to represent logical expressions and set-theoretic relationships.\nPeirce\u2019s graphs come in two variants:\nalpha and beta.\nAlpha graphs represent propositional logic, whereas beta graphs represent First-Order Logic (FOL).\nBoth variants use so-called cuts (simple closed curves) to express negation,\nand beta graphs use a syntactical element called the Line of Identity (LI) to denote\nboth the existence of objects and the identity between objects.\nAn important component of our discussions of beta-existential graphs is showing their\nimperfect mapping to the Boolean fragment of Domain Relational Calculus (DRC).\nAs we show, this imperfection has led to a lot of follow-up and confusion in various works on Peirce\u2019s existential graphs. We also cover\nEuler circles\u00a0[18],\nVenn diagrams\u00a0[62], and\nVenn-Peirce diagrams\u00a0[47],\nfollowing mainly the exposition by Shin\u00a0[55].\nWe discuss\nconstraint diagrams\u00a0[36, 28],\nSowa\u2019s conceptual graphs\u00a0[57],\nand formalisms embodied by Higraphs\u00a0[29]\nand UML notation\u00a0[20].\nWe may or may not cover Frege\u2019s two-dimensional conceptual notation\u00a0[21]. We discuss the main proposed visual representations for relational queries.\nWe will also include influential Visual Query Languages (VQLs) as long as those support (either directly or via simple additions) the inverse functionality of visualizing an existing relational query.\nA key difference of our tutorial in contrast to all prior surveys and overviews that we are aware of (like [10]) is\nthat this tutorial shows original figures by using\na consistent schema (the sailor-boat-database from the \u201ccow book\u201d [51])\nand a few intuitive queries (such as \u201cfind sailors who have rented all red boats\u201d)\nto provide a consistent comparison across different past proposals. Query-By-Example (QBE)\u00a0[66] is an influential early VQL that was influenced by DRC.\nQBE can express relational division by\nbreaking the query into two logical steps and using a temporary relation\u00a0[51, Ch. 6.9].\nIn doing so, QBE\nuses a query pattern from\nDatalog of implementing relational division (or universal quantification)\nin a dataflow-type, sequential manner,\nrequiring multiple occurrences of the same table.\nWe compare queries in QBE against equivalent Datalog queries and ask whether QBE is really more \u201cvisual\u201d than Datalog. Interactive query builders employ\nvisual diagrams that\nusers can manipulate (most often in order to select tables and attributes)\nwhile using a separate query configurator\n(similar to QBE\u2019s condition boxes\u00a0[66])\nto specify selection predicates, attributes, and sometimes nesting between queries.\nThey work mainly for constructing conjunctive queries\nbut limited forms of negation and union can be incorporated into the condition part of such queries.\nFor more general forms of negation and union, however, views as intermediate relations need to be used, resulting in multiple screens.\ndbForge\u00a0[16] is the most advanced and commercially supported tool we found for interactive query building.\nYet it does not have a visual formalism for non-equi joins between tables\nand the actual filtering values and aggregation functions can only be added in a separate query configurator.\nMoreover, it has limited support for nested queries:\nthe inner and outer queries are built separately,\nand the diagram for the inner query is presented separately and disjointly\nfrom the diagram for the outer query.\nThus no visual depiction of correlated subqueries is possible.\nOther graphical SQL editors such as SQL Server Management Studio (SSMS)\u00a0[58], Active Query Builder\u00a0[2], QueryScope from SQLdep\u00a0[50], MS Access [43], and\nPostgreSQL\u2019s pgAdmin3\u00a0[48] lacks in even more aspects of visual query representations:\nmost do not allow nested queries,\nnone has a single visual element for the logical quantifiers\nNOT EXISTS or FOR ALL,\nand all require specifying details of the query in SQL or across several tabbed views\nseparate from a visual diagram. Dataflow Query Language (DFQL)\nis an example visual representation that is relationally complete [13, 10]\nby mapping its visual symbols to the operators of relational algebra.\nFollowing the same procedurality as RA, DFQL expresses the data flow in a top-down tree-like structure.\nLike most visual formalisms\nthat we are aware of and that were proven to be relationally complete\n(including those listed in\n[10])\nthey are at their core visualizations of relational algebra operators. Query By Diagram (QBD)\u00a0[3, 4, 11]\nis based on an ER (Entity-Relationship) model of the data.\nTableTalk\u00a0[17]\nvisualizes the flow of a query top-down and\ndisplays logical conditions in tiles.\nObject-Oriented VQL\u00a0[45]\nadds existential and universal quantifiers to attributes. Visual SQL\u00a0[34] is\na visual query language that also supports query visualization.\nWith its focus on query specification, it maintains the one-to-one correspondence to SQL,\nand syntactic variants of the same query lead to different representations.\nSimilarly, SQLVis\u00a0[44]\nplaces a strong focus on the actual syntax of SQL queries,\nand syntactic variants like nested EXISTS change the visualization. QueryVis (earlier QueryViz)\u00a0[15, 6, 23, 41]\nborrows the idea of a \u201cdefault reading order\u201d\nfrom diagrammatic reasoning systems\u00a0[19]\nand uses arrows to indicate an implicit reading order between different nesting levels.\nWithout the arrows, there would be no natural order placed on the existential quantifiers\nand the visualization would be ambiguous. DataPlay\u00a0[1]\nuses a nested universal relation data model and\nallows a user to compose their query by interactively modifying a query tree with quantifiers\nand observing changes in the matching/non-matching data. SIEUFERD\u00a0[5]\u00a0is a direct manipulation spreadsheet-like interface that lets users manipulate the actual data.\nIn SIEUFERD, a result header encodes \u201cthe structure\u201d of the query.\nThe query result is listed below that header. String diagrams\u00a0[31, 9]\nare essentially a variant of Peirce\u2019s beta graphs\nthat allow free variables in addition to bound variables.\nBoth types of variables are represented by lines, yet bound \u201cvariable lines\u201d end in a dot. Relational Diagrams\u00a0[26]\nare a recent variant inspired by QueryVis that indicates the nesting structure of table variables by using nested negated bounding boxes (instead of arrows)\ninspired by Peirce\u2019s beta existential graphs.\nInterestingly, because Relational Diagrams are based on Tuple Relational Calculus (instead of Domain Relational Calculus which is closer to First-Order Logic)\nthey solve interpretation problems of Peirce\u2019s beta graphs that have been the focus of intense research in the diagrammatic reasoning community. By extracting and synthesizing insights from our survey,\nwe give design choices that avoid ambiguities resulting from overloading the meaning of lines as geometric marks (dubbed \u201cthe 3 abuses of the line\u201d),\nand discuss open challenges. Wolfgang Gatterbauer is\nan Associate Professor at the Khoury College of Computer Sciences at Northeastern University. His research interests lie in the intersection of theory and practice of data management. He received an NSF Career award and \u2013 with his students and collaborators \u2013 a best paper award at EDBT 2021, best-of-conference mentions for PODS 2021, SIGMOD 2017, WALCOM 2017, and VLDB 2015, and two reproducibility awards for papers from SIGMOD 2020. This work was supported in part by the\nNSF\nunder award numbers CAREER IIS-1762268 and IIS-1956096."
    },
    {
        "id": 25,
        "title": "Best free knot linear spline approximation and its application to neural networks",
        "corpus": "The problem of fixed knot approximation is convex and there are several efficient approaches to solve this problem, yet, when the knots joining the affine parts are also variable, finding conditions for a best Chebyshev approximation remains an open problem. It was noticed before that piecewise linear approximation with free knots is equivalent to neural network approximation with piecewise linear activation functions (for example ReLU). In this paper, we demonstrate that in the case of one internal free knot, the problem of linear spline approximation can be reformulated as a mixed-integer linear programming problem and solved efficiently using, for example, a branch and bound type method. We also present a new sufficient optimality condition for a one free knot piecewise linear approximation. The results of numerical experiments are provided. Keywords:\nFree knot linear spline approximation; neural network approximation; optimality conditions. The problem of approximating a continuous function by a continuous piecewise polynomial functions (splines) has been studied for several decades\u00a0[1, 2]. When the points of joining the polynomial pieces (knots) are also variables, finding conditions for a best Chebyshev approximation remains an open\nproblem\u00a0[1]. This problem was identified as one the of the most important problems of modern approximation\u00a0[3]. There are a number of theoretical results on free knot polynomial spline approximation: necessary optimality conditions\u00a0[1, 6, 4, 5], sufficient optimality conditions\u00a0[1, 6] (just to name a few). As in most non-convex problems, necessary and sufficient optimality conditions do not coincide and it is not known if the conditions can be improved. In this paper, we consider a special class of free knot polynomial spline approximation, where the degree of the polynomial pieces does not exceed one (that is, approximation by free knot linear splines). This problem is simpler than the general free knot polynomial spline approximation, but it is also equivalent to approximation by a neural network with one hidden layer and ReLU (Leaky ReLU) activation function\u00a0[8], where the number of the nodes in the hidden layer does not exceed the number of distinct knots. All the results are for Chebyshev (uniform) norm. In this paper we are focusing on linear splines with only one knot. At first glance, this problem is simple, but this is the first step to create efficient Remez-type algorithms for free knot spline approximation. Moreover, this problem has many practical applications, including data science and deep learning. Artificial neural networks are very powerful and popular approximation techniques with many practical applications, including image and sound recognition, financial fraud detection, partial differential equation, fluid dynamics and many others, see\u00a0[9] and references therein. The list of applications where deep learning demonstrated its efficiency is growing. Neural networks can handle models with a large number of variables: complex models are decomposed into several simple optimisation problems that can be solved efficiently. Deep learning is based on artificial neural networks where the network has a specific structure: the input layer, one or more hidden layers and the output layer. In this paper, we consider artificial neural networks with a single hidden layer and therefore, in the context of this paper, deep learning algorithms and artificial neural networks algorithms refer to the same techniques. The goal of this paper is to start with linear spline approximation with only one free internal knot. The contribution of this paper is as follows. We reformulate one free knot linear spline problems as mixed-integer linear programming problems (MILP), whose solutions can be obtained using a branch and bound type of method. We develop strong sufficient optimality conditions for one free knot linear spline approximation problems that are stronger than the existing general case conditions\u00a0[1]. We also present the results of numerical experiments and compare them with the results obtained by neural network approximations.\nThere have been a number of attempts to explain the efficiency of neural networks, based on their optimisation properties\u00a0[9, 10, 11], but there are still many open problems remain. The paper is organised as follows. In Section\u00a02, we provide some preliminaries on free knot linear approximation, neural network approximation and their connections. Section\u00a03 discusses the reformulation of the one free knot linear spline problem as a mixed-integer linear programming problem. Sufficient optimality conditions are presented in Section\u00a04 and in Section\u00a05, we discuss the results of our numerical experiments. Finally, we summarise our work and comment on future research directions in Section\u00a06. Assume that a continuous univariate function f\u2062(t)\ud835\udc53\ud835\udc61f(t)italic_f ( italic_t ) is to be approximated by a continuous piecewise linear function (linear spline) in a bounded interval [c,d]\ud835\udc50\ud835\udc51[c,d][ italic_c , italic_d ]. The points c\ud835\udc50citalic_c and d\ud835\udc51ditalic_d are called the external knots. The external knots are fixed. The points where the piecewise linear function switches from one linear piece to the next one are called the internal knots. If n\ud835\udc5bnitalic_n is the number of subintervals within [c,d]\ud835\udc50\ud835\udc51[c,d][ italic_c , italic_d ], then the number of internal knots is n\u22121\ud835\udc5b1n-1italic_n - 1: A free knot linear spline approximation problem (that is, the internal knots are free and part of the decision variables) can be formulated as follows: where n\ud835\udc5bnitalic_n is the number of subintervals, \u03b80=csubscript\ud835\udf030\ud835\udc50\\theta_{0}=citalic_\u03b8 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_c, \u03b8n=dsubscript\ud835\udf03\ud835\udc5b\ud835\udc51\\theta_{n}=ditalic_\u03b8 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_d, A=(a0,a1,\u2026,an)\ud835\udc34subscript\ud835\udc4e0subscript\ud835\udc4e1\u2026subscript\ud835\udc4e\ud835\udc5bA=(a_{0},a_{1},\\dots,a_{n})italic_A = ( italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) are called the spline coefficients (spline parameters), X=(a0,a1,\u2026,an,\u03b81,\u2026,\u03b8n\u22121)\ud835\udc4bsubscript\ud835\udc4e0subscript\ud835\udc4e1\u2026subscript\ud835\udc4e\ud835\udc5bsubscript\ud835\udf031\u2026subscript\ud835\udf03\ud835\udc5b1X=(a_{0},a_{1},\\dots,a_{n},\\theta_{1},\\dots,\\theta_{n-1})italic_X = ( italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_\u03b8 start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT ) are the decision variables. In most practical problems, one needs to discretise the the domain and the problem is as follows: where N\ud835\udc41Nitalic_N is the number of discretisation points, tj\u2208[c,d]subscript\ud835\udc61\ud835\udc57\ud835\udc50\ud835\udc51t_{j}\\in[c,d]italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u2208 [ italic_c , italic_d ] for j=1,\u2026,N\ud835\udc571\u2026\ud835\udc41j=1,\\dots,Nitalic_j = 1 , \u2026 , italic_N, n\ud835\udc5bnitalic_n is the number of subintervals, \u03b80=csubscript\ud835\udf030\ud835\udc50\\theta_{0}=citalic_\u03b8 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_c, \u03b8n=dsubscript\ud835\udf03\ud835\udc5b\ud835\udc51\\theta_{n}=ditalic_\u03b8 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_d, X=(a0,a1,\u2026,an,\u03b81,\u2026,\u03b8n\u22121)\ud835\udc4bsubscript\ud835\udc4e0subscript\ud835\udc4e1\u2026subscript\ud835\udc4e\ud835\udc5bsubscript\ud835\udf031\u2026subscript\ud835\udf03\ud835\udc5b1X=(a_{0},a_{1},\\dots,a_{n},\\theta_{1},\\dots,\\theta_{n-1})italic_X = ( italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_\u03b8 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_\u03b8 start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT ) are the decision variables. Most numerical algorithms are based on discretisation and therefore this is the main target of our paper. If the internal knots are fixed (fixed knot spline approximation) the corresponding optimisation problem is convex and there are a number of efficient methods to solve this problem. If, however, the knots are part of the decision variables, the problem is still open. In this paper, we consider free knot linear splines with only one internal knot, that is, n=2\ud835\udc5b2n=2italic_n = 2. These problems are essential for further extension to a larger number of subintervals. Our approach is based on a reformulation of the original problem as a pair of mixed-integer linear programming problems, whose solution can be obtained by a branch and bound type of optimisation methods, available in most modern optimisaton packages (section\u00a03). In this paper, we also develop sufficient optimality conditions for linear spline approximation with one free internal knot (section\u00a04). These conditions are used to verify optimality. Apart from being a very important open problem, there are a number of practical applications for free knot linear spline approximation, including data approximation, deep learning and many others. In the next subsection, we provide a short introduction to neural networks and demonstrate the connections between free knot linear spline approximation and neural network approximation. In particular, these approaches are equivalent in the case of univariate function approximation. Uniform (Chebyshev) approximation problems and their optimality conditions (necessary, sufficient) are based on the number of alternating points, that is points whose absolute deviation is maximal and the signs of deviation are alternating\u00a0[1, 2, 6, 4, 5], just to name a few. The notion of alternating points and alternating sequences is central for uniform approximation and it is not specific for polynomial splines (free or fixed knots). The origins of uniform approximation start with P.\u00a0Chebyshev\u00a0[7]. (Chebyshev) A necessary and sufficient optimality condition for a polynomial of degree\u00a0n\ud835\udc5bnitalic_n is the existence of n+2\ud835\udc5b2n+2italic_n + 2 alternating points. In particular, if the degree of the polynomial is one (linear approximation), the necessary and sufficient optimality condition is the existence of three alternating points. Neural networks is a popular tool in the modern area of Machine learning and Artificial Intelligence. Deep learning is just a subclass of artificial neural networks that has many practical applications, including data analysis, signal and image processing and many others\u00a0[9, 10]. This popularity is due to the efficiency of approximation models (and methods) behind deep learning. Moreover, deep learning can be used as a purely approximation tool for univariate and multivariate functions. The goal of deep learning is to optimise weights in the network and therefore, this problem can be seen as an approximation problem treated using modern optimisation tools. In the corresponding optimisation models, the objective function represents the deviation (error) of the approximation from the original function (which may be a continuous function or a function whose values are known only at some discretisation points). The deviation function (called \u201closs function\u201d) can be the sum of the squares of the deviations (least squares based models), the maximum of the absolute values (uniform or Chebyshev based models), the sum of the absolute values (Manhattan-distance based models), etc. Deep learning is based on solid mathematical modelling established in\u00a0[12, 13, 14, 15], but the origins come to the work of A.\u00a0Kolmogorov and his student V.\u00a0Arnold. The celebrated Kolmogorov-Arnold Theorem\u00a0[16, 17] is an attempt to solve the 13th problem of Hilbert. It is customary to choose the mean least squares loss functions in neural networks. There are several reasons for this. First of all, this model involves minimising a smooth quadratic objective function, and therefore basic optimisation techniques such as the gradient descent can be used. Second, the least squares loss function also fares well with the assumption that the errors outside the discretisation points (where the value of the function is known) have a normal distribution. At the same time, the approximation results established in\u00a0[12, 13, 14, 15] rely on the Chebyshev (uniform) convergence, which is a stronger result. Therefore, there are a number of interesting results where the loss function is Chebyshev norm based\u00a0[18]. The ReLU (Rectified linear unit) function is defined as follows: where a\ud835\udc4eaitalic_a is the input from a given interval [am\u2062i\u2062n,am\u2062a\u2062x]subscript\ud835\udc4e\ud835\udc5a\ud835\udc56\ud835\udc5bsubscript\ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc65[a_{min},a_{max}][ italic_a start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT ]. Figure\u00a01 shows ReLU function defined in [\u22121,1].11[-1,1].[ - 1 , 1 ] . The function g\u2062(a)\ud835\udc54\ud835\udc4eg(a)italic_g ( italic_a ) has a discontinuity at 00 and therefore, it can be considered as a linear spline with one internal knot at 00. Let z\ud835\udc67zitalic_z be a single scalar input for the same function g\ud835\udc54gitalic_g above and z=w\u2062x+b\ud835\udc67\ud835\udc64\ud835\udc65\ud835\udc4fz=wx+bitalic_z = italic_w italic_x + italic_b\nwhere x\ud835\udc65xitalic_x is the input from the interval [xm\u2062i\u2062n,xm\u2062a\u2062x]subscript\ud835\udc65\ud835\udc5a\ud835\udc56\ud835\udc5bsubscript\ud835\udc65\ud835\udc5a\ud835\udc4e\ud835\udc65[x_{min},x_{max}][ italic_x start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT ], w\ud835\udc64witalic_w and b\ud835\udc4fbitalic_b are decision variables. First assume that w\u22600\ud835\udc640w\\neq 0italic_w \u2260 0, then, if w>0\ud835\udc640w>0italic_w > 0, we have: In a similar manner, for w<0\ud835\udc640w<0italic_w < 0, we have This means that there is a discontinuity at \u2212bw\ud835\udc4f\ud835\udc64\\frac{-b}{w}divide start_ARG - italic_b end_ARG start_ARG italic_w end_ARG and hence, there is an internal knot located at x=\u2212bw\ud835\udc65\ud835\udc4f\ud835\udc64x=\\frac{-b}{w}italic_x = divide start_ARG - italic_b end_ARG start_ARG italic_w end_ARG.\nA single linear piece will result in both cases if the knot is located outside of the considered domain.\nFinally, assume that w=0,\ud835\udc640w=0,italic_w = 0 , then where the output depends on the value of b\ud835\udc4fbitalic_b regardless of the input x\ud835\udc65xitalic_x. In this case, g\u2062(z)\ud835\udc54\ud835\udc67g(z)italic_g ( italic_z ) consists of only one linear piece. To summarise, each node in the hidden layer neural network approximation with ReLU activation function leads to a knot in the equivalent linear spline approximation. In the case when w\u22600\ud835\udc640w\\neq 0italic_w \u2260 0, the location of the knot is \u03b8=\u2212bw\ud835\udf03\ud835\udc4f\ud835\udc64\\theta=-\\frac{b}{w}italic_\u03b8 = - divide start_ARG italic_b end_ARG start_ARG italic_w end_ARG. In the case when w=0\ud835\udc640w=0italic_w = 0 the corresponding component is a single linear piece, which is equivalent to allocating a knot outside the approximation interval\u00a0[c,d]\ud835\udc50\ud835\udc51[c,d][ italic_c , italic_d ]. A natural step now is to extend the result to the neural networks with more than one node in their hidden layers. Intuitively, we expect that each node leads to a knot, but some knots may coincide and some may \u201cmove\u201d outside the approximation interval\u00a0[c,d]\ud835\udc50\ud835\udc51[c,d][ italic_c , italic_d ] and therefore the total number of internal knots in the linear spline approximation does not exceed the total number of nodes in the hidden layer. In the rest of this section, we present a formal explanation of this observation. Consider a neural network with one hidden layer where the activation function defined on the hidden nodes is ReLU and the output layer consists of just one node. This is a multilayered network (Figure\u00a02) whose final output is a composition of linear functions with the activation function ReLU. Let wj(i),subscriptsuperscript\ud835\udc64\ud835\udc56\ud835\udc57w^{(i)}_{j},italic_w start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , i=1,2,j=1,\u2026,nformulae-sequence\ud835\udc5612\ud835\udc571\u2026\ud835\udc5bi=1,2,j=1,\\ldots,nitalic_i = 1 , 2 , italic_j = 1 , \u2026 , italic_n be the weights of the network, bj(i),subscriptsuperscript\ud835\udc4f\ud835\udc56\ud835\udc57b^{(i)}_{j},italic_b start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , i=1,j=1,\u2026,nformulae-sequence\ud835\udc561\ud835\udc571\u2026\ud835\udc5bi=1,j=1,\\ldots,nitalic_i = 1 , italic_j = 1 , \u2026 , italic_n are the bias terms assigned to the nodes in the hidden layer, b(2)superscript\ud835\udc4f2b^{(2)}italic_b start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT is the bias term assigned to the output of the network. If the input for the inner nodes in the hidden layer are denoted as z1,z2,\u2026,znsubscript\ud835\udc671subscript\ud835\udc672\u2026subscript\ud835\udc67\ud835\udc5bz_{1},z_{2},\\ldots,z_{n}italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT where n\ud835\udc5bnitalic_n is the number of inner nodes in the hidden layer, then the output of hidden nodes (input for the output layer) can be defined as follows: If the neural network output is denoted by y\ud835\udc66yitalic_y, then y\ud835\udc66yitalic_y is an affine transformation of inner nodes: The union of all the knots created by the inner nodes represents the set of knots of the function y\ud835\udc66yitalic_y. As y\ud835\udc66yitalic_y consists of a linear combination of zisubscript\ud835\udc67\ud835\udc56z_{i}italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT\u2019s, one can see that y\ud835\udc66yitalic_y is a linear spline. A neural network (one hidden layer) with ReLU activation is a linear spline and the number of the nodes in the hidden layer does not exceed the number of distinct knots of the linear spline\u00a0[8, 19]. In this case, finding the internal knots is easier due to the natural architecture of the network itself. The weights and biases of the network are adjustable parameters decided by the training (optimisation) of the network. Hence, the location of the knots of the approximation computed by ReLU network with one hidden layer is decided in the optimisation of the weight space of the network. In the case of two subintervals (one free knot), the solution can be found by solving two mixed-integer linear programming problems. In the first problem, the optimal linear spline is the maximum of two affine pieces, while in the second problem the optimal linear spline is the minimum of two affine pieces. These pieces may be represented by the same affine function (single line). The main advantage of this approach is that the knot does not need to be calculated explicitly. Indeed, since there are at most two subintervals, the corresponding piecewise linear approximation is either a maximum or a minimum of two affine functions. For each case the problem can be formulated a mixed-integer linear programming problem. After solving both problems, the one with minimal optimal value is the solution to the original free knot linear spline problem. In the rest of this section, we work with the discretised problem\u00a0(2). Assume that a1subscript\ud835\udc4e1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and b1subscript\ud835\udc4f1b_{1}italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT are the slope and the intercept of the affine piece in the first subinterval, respectively and a2subscript\ud835\udc4e2a_{2}italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and b2subscript\ud835\udc4f2b_{2}italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are the slope and the intercept of the affine piece in the second subinterval, respectively. First, for each discretisation point ti,subscript\ud835\udc61\ud835\udc56t_{i},italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , i=1,\u2026,N\ud835\udc561\u2026\ud835\udc41i=1,\\dots,Nitalic_i = 1 , \u2026 , italic_N we introduce a new variable where N\ud835\udc41Nitalic_N is the number of discretisation points and may be large. The objective is to minimise the absolute deviation z\ud835\udc67zitalic_z, subject to the following constraints: Due to\u00a0(3), we have the following equations: and for every i\ud835\udc56iitalic_i, at least one of the inequalities has to be satisfied as equality. This is where we have to introduce a binary variable. This can be achieved by requiring that for each group\u00a0i\ud835\udc56iitalic_i, at least one of the following reverse inequalities is satisfied: For each group, introduce a binary variable zisubscript\ud835\udc67\ud835\udc56z_{i}italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Also consider a larger positive parameter M\ud835\udc40Mitalic_M (big-M\ud835\udc40Mitalic_M, fixed value). Then the requirement for at least one of the inequalities in each group holds can be expressed as follows: Finally, the goal is to minimise\u00a0z\ud835\udc67zitalic_z subject to\u00a0(4)-(10). Similar to the maximum problem, introduce a new variable where N\ud835\udc41Nitalic_N is the number of discretisation points. The objective is to minimise the absolute deviation y\ud835\udc66yitalic_y, subject to Due to\u00a0(11), we have the following equations: and for every i\ud835\udc56iitalic_i, at least one of the inequalities has to be satisfied as equality. For each group\u00a0i\ud835\udc56iitalic_i, at least one of the following reverse inequalities is satisfied: For each group, introduce a binary variable yisubscript\ud835\udc66\ud835\udc56y_{i}italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and a large positive number\u00a0M\ud835\udc40Mitalic_M. Then the final block of inequalities is as follows: Finally, the problem is to minimise\u00a0y\ud835\udc66yitalic_y subject to\u00a0(12)-(18). In this section, we develop sufficient optimality conditions for one free knot linear spline approximation. We have to treat two cases separately: the optimal spline contains two distinct linear segments; the optimal spline contains a single linear segment. The following two conditions are sufficient optimality conditions for free knot linear spline approximation in Chebyshev norm with one internal knot. The linear spline consists of two distinct linear pieces has at least three alternating points in each subinterval. The linear spline consists of a single linear piece and has at least four alternating points in the whole interval. Proof:\nLet f\u2062(t)\ud835\udc53\ud835\udc61f(t)italic_f ( italic_t ) be a continuous function which needs to be approximated in the interval\u00a0[c,d]\ud835\udc50\ud835\udc51[c,d][ italic_c , italic_d ]. Assume that there are two distinct linear pieces and at least three alternating points in each subinterval. Due to theorem\u00a02.1, at each subinterval the approximation is optimal and the maximal deviation can not be improved by changing the coefficients of the spline. The change of the location of the knot also can not improve the maximal deviation, since by increasing the length of one of the subintervals the maximal absolute deviation is non-decreasing and therefore the linear spline is optimal. Now assume that the spline consists of only one linear piece l\u2062(t)\ud835\udc59\ud835\udc61l(t)italic_l ( italic_t ) and there are four alternating points: t1,t2,t3subscript\ud835\udc611subscript\ud835\udc612subscript\ud835\udc613t_{1},t_{2},t_{3}italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and t4subscript\ud835\udc614t_{4}italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT. Due to theorem\u00a02.1, the current spline is optimal, unless the optimal spline consists of two linear pieces. Assume that the maximal deviation can be improved by splitting the original interval\u00a0[c,d]\ud835\udc50\ud835\udc51[c,d][ italic_c , italic_d ] into two subintervals: [c,\u03b8]\ud835\udc50\ud835\udf03[c,\\theta][ italic_c , italic_\u03b8 ] and [\u03b8,d]\ud835\udf03\ud835\udc51[\\theta,d][ italic_\u03b8 , italic_d ]. The corresponding linear pieces are l1\u2062(t)subscript\ud835\udc591\ud835\udc61l_{1}(t)italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ) and l2\u2062(t)subscript\ud835\udc592\ud835\udc61l_{2}(t)italic_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t ): It is clear that the knot \u03b8\u2208(t2,t3)\ud835\udf03subscript\ud835\udc612subscript\ud835\udc613\\theta\\in(t_{2},t_{3})italic_\u03b8 \u2208 ( italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ), since otherwise one of the intervals contains three alternating points and therefore the maximal deviation can not be improved. Without loss of generality, assume that Since s\u2062(t)\ud835\udc60\ud835\udc61s(t)italic_s ( italic_t ) provides a smaller absolute deviation, and Therefore, s\u2062(t1)=l1\u2062(t1)>l\u2062(t1)\ud835\udc60subscript\ud835\udc611subscript\ud835\udc591subscript\ud835\udc611\ud835\udc59subscript\ud835\udc611s(t_{1})=l_{1}(t_{1})>l(t_{1})italic_s ( italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) > italic_l ( italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) and s\u2062(t2)=l1\u2062(t2)<l\u2062(t2)\ud835\udc60subscript\ud835\udc612subscript\ud835\udc591subscript\ud835\udc612\ud835\udc59subscript\ud835\udc612s(t_{2})=l_{1}(t_{2})<l(t_{2})italic_s ( italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) < italic_l ( italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ). Hence, In a similar manner, the analysis of the behaviour of the linear pieces l2\u2062(t)subscript\ud835\udc592\ud835\udc61l_{2}(t)italic_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t ) and l\u2062(t)\ud835\udc59\ud835\udc61l(t)italic_l ( italic_t ) yields Combining\u00a0(19) and (20), conclude that s\u2062(t)\ud835\udc60\ud835\udc61s(t)italic_s ( italic_t ) is discontinuous at \u03b8\ud835\udf03\\thetaitalic_\u03b8, which contradicts to the requirement for the optimal linear spline to be continuous at its knot. \u25a1\u25a1\\square\u25a1 All the numerical experiments are performed on the interval [\u22121,1]11[-1,1][ - 1 , 1 ] and the discretisation step is\u00a0h=10\u22123\u210esuperscript103h=10^{-3}italic_h = 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT.\nWe test our method on five different functions: f1\u2062(t)=|t|subscript\ud835\udc531\ud835\udc61\ud835\udc61f_{1}(t)=\\sqrt{|t|}italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ) = square-root start_ARG | italic_t | end_ARG; this function is nonsmooth and non-Lipschitz. f2\u2062(t)=|t\u22120.75|subscript\ud835\udc532\ud835\udc61\ud835\udc610.75f_{2}(t)=\\sqrt{|t-0.75|}italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t ) = square-root start_ARG | italic_t - 0.75 | end_ARG; this function is similar to\u00a0f1\u2062(t)subscript\ud835\udc531\ud835\udc61f_{1}(t)italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ), but it is non-symmetric. f3\u2062(t)=sin\u2061(2\u2062\u03c0\u2062t)subscript\ud835\udc533\ud835\udc612\ud835\udf0b\ud835\udc61f_{3}(t)=\\sin(2\\pi t)italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_t ) = roman_sin ( 2 italic_\u03c0 italic_t ); this function is periodic and oscillating. f4\u2062(t)=t3\u22123\u2062t2+2subscript\ud835\udc534\ud835\udc61superscript\ud835\udc6133superscript\ud835\udc6122f_{4}(t)=t^{3}-3t^{2}+2italic_f start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( italic_t ) = italic_t start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT - 3 italic_t start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 2; this is a cubic function. The experiments with this function are interesting, since this is an example, where neural network was especially inaccurate, despite the fact that this is a smooth function without any abrupt changes. f5=1/(t25+0.5)subscript\ud835\udc5351superscript\ud835\udc61250.5f_{5}=1/(t^{25}+0.5)italic_f start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1 / ( italic_t start_POSTSUPERSCRIPT 25 end_POSTSUPERSCRIPT + 0.5 ); this is a very complex function for approximating by a continuous piecewise linear function with only two linear pieces. The structure of the approximation drastically changes when the the discretisation step is changing. We approximate above functions by one free knot piecewise linear functions and by one hidden layer neural network with ReLU activation function. The hidden layer consists of just one node which represents the internal knot of the piecewise linear approximation. The loss function is based on the uniform (Chebyshev) approximation and the optimiser, ADAM and ADAMAX (a certain adaptation of ADAM to uniform approximation) used to find the parameters of the network. Table\u00a01 contains the results of the numerical experiments. The first column corresponds to the function to be approximated. The second column corresponds to the parameter big-M\ud835\udc40Mitalic_M used in the corresponding mixed-linear integer programming problem. The third column is the location of the knot (N/A corresponds to the single linear piece, where the location of the knot is arbitrary and not restricted to [c,d]\ud835\udc50\ud835\udc51[c,d][ italic_c , italic_d ]). The results for ADAM and ADAMAX (network optimisation) are in the brackets of columns\u00a03,\u00a04 and\u00a06. ADAM results come first and then ADAMAX results. The fourth column is the error (maximal absolute deviation). The fifth column clarifies whether the optimal approximation corresponds to the maximum or the minimum of the linear pieces. Finally, the last column corresponds to the computational time (seconds). The results in brackets were obtained by applying neural network directly: the number of epochs for functions f1subscript\ud835\udc531f_{1}italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, f2subscript\ud835\udc532f_{2}italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and f3subscript\ud835\udc533f_{3}italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is\u00a050, for function f4subscript\ud835\udc534f_{4}italic_f start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT is 100 and for function f5subscript\ud835\udc535f_{5}italic_f start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT is 300. For functions f1subscript\ud835\udc531f_{1}italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, f2subscript\ud835\udc532f_{2}italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, f3subscript\ud835\udc533f_{3}italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and f4subscript\ud835\udc534f_{4}italic_f start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT the mixed-integer based models terminated at points that satisfy the sufficient optimality conditions (theorem\u00a04.1). In the case of the function\u00a0f3subscript\ud835\udc533f_{3}italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, where the optimal approximation is represented by a single interval, there are four alternating points, while for the functions\u00a0f1subscript\ud835\udc531f_{1}italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, f2subscript\ud835\udc532f_{2}italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and f4subscript\ud835\udc534f_{4}italic_f start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT there are three alternating points in each subinterval (the knot \u03b8\ud835\udf03\\thetaitalic_\u03b8 is one of the alternating points). In the case of the function f5subscript\ud835\udc535f_{5}italic_f start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT, the sufficient conditions are not met, but the necessary conditions from\u00a0[4] are met. The graphs of the functions, their linear spline approximations and the corresponding deviation are presented in figures\u00a03-7. Comparing MILPP based models and neural networks (both, ADAM and ADAMAX), one can see that the neural network models are much faster than the optimisation models, but the maximal deviation error is lower for optimisation (more accurate results). This observation is particularly interesting in the case of function f4subscript\ud835\udc534f_{4}italic_f start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT, where the approximation of a simple smooth function appeared as a challenge for neural network-based approach, while the optimisation-based approach is accurate. If we compare ADAM and ADAMAX, the results are very similar: ADAMAX is slightly more accurate and a bit slower. The only function, where ADAM is clearly preferable is f2subscript\ud835\udc532f_{2}italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. In our future research directions, we would like to investigate if there is something specific to neural network that makes them so fast for these particular problems. Overall, the mixed-integer based approach for free knot linear splines with two subintervals is efficient. The choice of the parameter M\ud835\udc40Mitalic_M is crucial, but this problem is out of scope of this paper. Another interesting observation is that the neural network-based models are reasonably accurate in terms of finding the location of the knot. This can be used in the future, since one can fix the knots obtained by a neural network based model and refine the parameters, which is a convex problem and there are several efficient approaches to solve this problem. In this paper, we work with free knot linear spline approximations with at most two subintervals. This model is essential for extending to more than just one internal knot. For this model, we developed a sufficient optimality condition and an algorithm (MILPP-based approach). In our numerical experiments, we use five functions. All these functions are challenging for linear spline approximation with one internal knot: abrupt changes, nonsmoothess, periodic nature, non-Lipschitzness. In all the experiments, except the last one (function\u00a0f5subscript\ud835\udc535f_{5}italic_f start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT) the approximations satisfy the sufficient optimality condition developed in this paper. Function\u00a0f5=1/(t25+0.5)subscript\ud835\udc5351superscript\ud835\udc61250.5f_{5}=1/(t^{25}+0.5)italic_f start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1 / ( italic_t start_POSTSUPERSCRIPT 25 end_POSTSUPERSCRIPT + 0.5 ) is a very complex function to approximate, but the final approximation satisfies the strongest known necessary optimality condition from\u00a0[4]. It is also important to note that the proposed MILPP-based approach is also suitable for approximating multivariate functions. In this case, the size of the discretisation lattice (total number of discretisation points) is increasing and therefore the dimension of the corresponding optimisation problems (due to cisubscript\ud835\udc50\ud835\udc56c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT) is increasing. Our future research directions include the following. The development of a Remez-type algorithm for linear spline approximation, where the point update procedure relies on the MILPP model proposed in this paper. The investigation how the results obtained by a fast neural network model can be used as an initial guess for free knot linear spline approximation. Moreover, it is important to understand what is so specific in modern neural network models that make them reasonably efficient at finding the location of the knots and if it will still be the case for more than one internal knot. This research was supported by the Australian Research Council (ARC), Solving hard Chebyshev approximation problems through nonsmooth analysis (Discovery Project DP180100602)."
    },
    {
        "id": 26,
        "title": "Applying Cognitive Diagnostic Models to Mechanics Concept Inventories",
        "corpus": "In physics education research, instructors and researchers often use research-based assessments (RBAs) to assess students\u2019 skills and knowledge. In this paper, we support the development of a mechanics cognitive diagnostic to test and implement effective and equitable pedagogies for physics instruction. Adaptive assessments using cognitive diagnostic models provide significant advantages over fixed-length RBAs commonly used in physics education research. As part of a broader project to develop a cognitive diagnostic assessment for introductory mechanics within an evidence-centered design framework, we identified and tested student models of four skills that cross content areas in introductory physics: apply vectors, conceptual relationships, algebra, and visualizations. We developed the student models in three steps. First, we based the model on learning objectives from instructors. Second, we coded the items on RBAs using the student models. Lastly, we then tested and refined this coding using a common cognitive diagnostic model, the deterministic inputs, noisy \u201cand\u201d gate (DINA) model. The data included 19,889 students who completed either the Force Concept Inventory, Force and Motion Conceptual Evaluation, or Energy and Momentum Conceptual Survey on the LASSO platform. The results indicated a good to adequate fit for the student models with high accuracies for classifying students with many of the skills. The items from these three RBAs do not cover all of the skills in enough detail, however, they will form a useful initial item bank for the development of the mechanics cognitive diagnostic. Since the development of the Force Concept Inventory (FCI), research-based assessments (RBAs) have played an important role in shaping the landscape of physics education research (PER) [Madsen\u00a0et\u00a0al., 2017; Docktor\u00a0and\u00a0Mestre, 2014]. RBAs have provided instructors and researchers with empirical evidence about how students learn and change throughout courses [Madsen\u00a0et\u00a0al., 2017, 2016]. Researchers used data from RBAs to assess the impact of curricular and pedagogical innovations [Madsen\u00a0et\u00a0al., 2017]. RBAs also play a central role in documenting inequities in physics courses before and after instruction [Van\u00a0Dusen\u00a0and\u00a0Nissen, 2020; Wilcox\u00a0and\u00a0Lewandowski, 2016].\nIn previous studies, researchers have primarily used the data from the RBAs as summative assessments to evaluate the effectiveness of a course [Wilcox\u00a0and\u00a0Lewandowski, 2016; Thornton\u00a0et\u00a0al., 2009; Stoen\u00a0et\u00a0al., 2020]. Although some instructors use RBAs as formative assessments to inform their instruction, such as creating groups with diverse content knowledge [Laverty\u00a0et\u00a0al., 2022; Wilson, 2008], two common shortcomings of existing RBAs hamper their use as formative assessments: 1) a lack of easily actionable information and 2) a lack of timely information [Madsen\u00a0et\u00a0al., 2016]. Examining overall RBA scores on student pre-tests can inform an instructor how well-prepared a group of students is. Still, the overall RBA scores do not help instructors identify the specific skills students need to gain to be successful. Instructors and researchers also examine student gains in scores from the first (pre-test) to the last (post-test) week of class. While this is a useful measure of the impact on instruction, it is an inherently retrospective activity that cannot inform instruction throughout a course. To address the shortcomings of existing RBAs, we are developing the mechanics cognitive diagnostic (MCD). The MCD is a cognitive diagnostic (CD) computerized adaptive testing (CAT) assessment [Leighton\u00a0and\u00a0Gierl, 2007]. CD-CATs are adaptive assessments that can cover the specific contents and skills an instructor needs and wishes to assess them. CDs assess which skills a student has or has not mastered [Cui\u00a0et\u00a0al., 2012]. CATs can adapt to students\u2019 proficiency level and skill mastery profile, making assessment individualized and more efficient. These features allow an instructor to administer a CD-CAT as a formative assessment throughout a semester. The MCD will provide instructors with student-level and course-level assessments of student content knowledge and skill acquisition to help tailor instruction to students\u2019 needs. To support the development of the MCD, we investigated the skills assessed by three RBAs commonly used in introductory college mechanics courses [Madsen\u00a0et\u00a0al., 2017]. This research develops the models for the student skills and the evidence for assessing those skills as a component of the larger development of the MCD. The MCD will leverage this information to provide instructors with timely and actionable formative assessments. To support the development of the MCD to measure skills across introductory mechanics content areas, we developed and applied a model of four skills to three commonly used RBAs for introductory mechanics courses. To this end, we ask the following research question: What skills and content areas do three RBAs for introductory mechanics cover? To support readers\u2019 interpretation of our research, Table 1 includes a selection of terms and their definitions. Many physics education researchers and instructors use existing fixed-length RBAs. PhysPort [Phy, n.d.a] and the LASSO platform [Alliance, 2020] provide lists and resources of these RBAs. Initially, instructors administered these RBAs with paper and pencil, but the administration is moving to online formats [Van\u00a0Dusen\u00a0et\u00a0al., 2021]. This move to online data collection has led to the development of CATs for introductory physics that have advantages over fixed-length tests. In this section, we discuss RBAs in introductory mechanics, options for administering RBAs online, CAT broadly, and the application of CAT to RBAs in physics. PhysPort [Phy, n.d.b] provides an extensive list of RBAs for physics and other extensive pedagogical resources. PhysPort, however, does not administer assessments online. RBA developers and researchers have instead often relied on Qualtrics to administer the RBAs they develop or use online or the LASSO platform [Alliance, 2020; Van\u00a0Dusen\u00a0et\u00a0al., 2021]. Administering RBAs online allows assessing students in class or outside of class to save class time, can automatically analyze the collected data, and can aggregate the data for research [Van\u00a0Dusen, 2018]. PhysPort describes 117 RBAs [Phy, n.d.b] with 16 RBAs for introductory mechanics. Each RBA targets content areas and skills important for physics learning. The titles of each RBA often state the focus of the RBAs. For example, our study analyzed data from three RBAs. The Force Concept Inventory (FCI) [Hestenes\u00a0et\u00a0al., 1992] focuses on conceptual knowledge of forces and kinematics. The Force and Motion Conceptual Evaluation (FMCE) [Thornton\u00a0and\u00a0Sokoloff, 1998] provides similar coverage but also has four questions on energy. The Energy and Motion Conceptual Survey (EMCS) [Singh\u00a0and\u00a0Rosengrant, 2003] covers exactly what the name states. Other assessment names also portray skills or content areas of interest to physics education: the Test of Understanding Graphs in Kinematics, the Test of Understanding Vectors in Kinematics, and the Rotational Kinematics Inventory. These names imply that graphs and vectors play an important role in many physics courses and that many physics courses cover rotation. Computerized adaptive testing (CAT) uses item response theory (IRT) to establish a relationship between the students\u2019 proficiency levels and the probability of their success in answering test items [Collares, 2022]. CAT selects items based on student responses to the preceding items to estimate the students proficiency and then align each item\u2019s difficulty with the individual\u2019s proficiency [Chang, 2015]. This continuous adaptation of item difficulty to student proficiency ensures that the test remains challenging and engaging for the students throughout its duration and provides a more precise estimation of the proficiency of students than paper-and-pencil assessment [Morphew\u00a0et\u00a0al., 2018; Chang, 2015; Weiss, 1982]. Compared to paper-and-pencil assessment methods, CAT requires fewer items to accurately measure students\u2019 proficiency meanwhile controlling the selected items concerning their content variety [\u015eahin\u00a0and\u00a0\u00d6zbasi, 2017]. Chen\u00a0et\u00a0al. [2008] shows that CAT supports test security by drawing from a large item bank to control for item overexposure and how CAT can use pretest proficiency estimates for item selection and proficiency estimation to maximize test efficiency. The combination of cognitive diagnostic (CD) models and CAT improves the assessment process and categorizes students based on their mastery of distinct skills associated with each item. CD models aim to estimate how the students\u2019 cognitive proficiency relates to the specific skills or contents necessary to solve individual test items [Chang, 2015; Collares, 2022], with skill as a fundamental cognitive unit or proficiency that students need to acquire and master to answer certain items [Helm\u00a0et\u00a0al., 2022; Li\u00a0and\u00a0Traynor, 2022]. Deterministic inputs, noisy \u201cand\u201d gate (DINA) model emerges as a CD model that facilitates the assessment of skill mastery profiles and the estimation of item parameters [Anamezie\u00a0and\u00a0Nnadi, 2018]. DINA model leverages a Q-matrix to delineate the relationships between items and the requisite skills [Chen\u00a0et\u00a0al., 2015], thereby providing a structured framework for monitoring the mastery levels of distinct proficiency Chen\u00a0et\u00a0al. [2015]. The DINA model is applied for the evaluation of the mastery situation of students across various skills, including problem-solving [Zhang\u00a0et\u00a0al., 2021], computational thinking [Li\u00a0and\u00a0Traynor, 2022], and domain-specific knowledge [Chen\u00a0et\u00a0al., 2015]. We are unaware of any CD assessments in physics education research (PER). Researchers have, however, conducted studies on the effectiveness of CAT using IRT to evaluate students\u2019 proficiencies [Morphew\u00a0et\u00a0al., 2018; Yasuda\u00a0et\u00a0al., 2021a]. One such study by Istiyono\u00a0et\u00a0al. [2018] utilized CAT to assess the physics problem-solving skills of senior high school students, revealing that most students\u2019 competencies fell within the medium to low categories. Morphew\u00a0et\u00a0al. [2018] explored the use of CAT to evaluate physics proficiency and identify the areas where students needed to improve when preparing for course exams in an introductory physics course. Their studies showed that students who engaged in using CAT improved their performance on subsequent exams. In another study, Yasuda\u00a0et\u00a0al. [2021b] also indicated CAT can reduce testing time by shorter test lengths while maintaining the accuracy of test measurement and administration. Yasuda\u00a0et\u00a0al. [2021a] examined item overexposure in FCI-CAT, employing pre-test proficiency for item selection, which shortened test duration while maintaining accuracy and enhanced security by reducing item content memorization and sharing among students. We drew on evidence-centered design (ECD) [Mislevy\u00a0et\u00a0al., 2003] to inform our development of the MCD. ECD was initially applied in the high-stakes contexts of the Graduate Record Examinations (GRE) [Mislevy\u00a0et\u00a0al., 2003; Sheehan\u00a0et\u00a0al., 2007], and has also been effectively utilized in PER for the development of RBAs [Pollard\u00a0et\u00a0al., 2021; Vignal\u00a0et\u00a0al., 2023]. There are three core premises in the ECD framework used in this study [Mislevy\u00a0et\u00a0al., 2003]: Assessment developers need content and context expertise to create high-quality items. In this analysis, we focused our analysis on three RBAs developed by physics education researchers - FCI, FMCE, and EMCS. Assessment developers use evidence-based reasoning to evaluate students\u2019 comprehension and identify misunderstandings accurately. In this analysis, we developed a Q-matrix that identified which underlying skills were required to correctly answer each item (more details in section VI.2). When creating assessments, developers must consider various factors such as resource availability, limitations, and usage conditions. For instance, the LASSO platform supports multiple-choice items and needs web-enabled devices, but it conserves class and instructor time. Our work used the conceptual assessment framework provided by the ECD framework with its six models [Mislevy\u00a0et\u00a0al., 2003] (shown in Fig. 1) to guide assessment development. The models and their connections to our work are as follows: Student models focus on identifying one or more variables directly relevant to the knowledge, skills, or proficiencies an instructor wishes to examine. In this project, a qualitative analysis (see section VI.2) indicated that four skills (i.e., apply vectors, conceptual relationships, algebra, and visualizations) and four content areas (i.e., kinematics, forces, energy, momentum) would be optimum for our MCD. Evidence models include evidence rules and measurement model to provide a comprehensive guide to update information regarding a student\u2019s performance. The evidence rules govern how observable variables summarize a student\u2019s performance on specific tasks. In this project, our evidence models are created by scoring student responses and iterative testing a Q-matrix that relates performance on each item to the underlying skills. The measurement model is the DINA model, which supports suggested Q-matrices. Task model describes the structure of situations such that the situation collects the essential data for the evidence models. It defines a class of test items based on specific topics or areas of knowledge. In this project, the task model focuses exclusively on multiple-choice items pertaining to the topics of kinematics, forces, energy, and momentum, where each item has a definitive right or wrong answer. Assembly model describes how the three models above, including the student models, evidence models, and task model, work together to form the psychometric frame of the assessment. In the broader project, we developed an IRT model and a CD model that coordinates the item difficulty, skills, and content areas of each next item based on a student\u2019s prior responses. The IRT model selects items that are appropriately difficult for each student and the CD model determines mastery of skills and content areas. Presentation model provides a realistic view of how tasks are presented across different evaluation settings. In this project, the items are presented in an online multiple-choice format. Delivery system model describes integrating all the models required for evaluation. In this project, we use the LASSO platform [Van\u00a0Dusen, 2018; Nissen\u00a0et\u00a0al., 2022]. In this paper, we focus on the student models and evidence models (models 1-2). These models are instrumental in aligning our analysis with the research question. By evaluating the student models, we gain insights into the range of competencies RBAs are designed to assess. Similarly, through evidence models, we understand how these assessments capture and represent student understanding in various skills and content areas. To answer the research question, we employed a mixed methods approach using qualitative coding to identify the skills and content areas to measure for the student models. Subsequent quantitative analyses drove the testing of the evidence models and iterative improvements of the student models. We first used artefacts from courses to build the student models of skills that cut across the content of introductory mechanics courses. We then identified RBAs with sufficient data available through the LASSO platform and coded each item for the skills it assessed. Last, we used an iterative process that applied DINA models to build the evidence models and to improve our definitions of the skills and the coding of the skills on each item. In this iterative process, the DINA model provided suggested changes to the item skill codes initially made by content experts. The suggested changes were accepted or rejected by content experts. We then ran a final DINA model on our revised codes. Our analysis examined student responses on three RBAs: the FCI (30 items, 12932 students), FMCE (47 items, 5510 students), and EMCS (25 items, 1447 students). Our dataset came from the LASSO platform [Van\u00a0Dusen, 2018; Nissen\u00a0et\u00a0al., 2022; Alliance, 2020]. LASSO provided post-test data from 19889 students across the three assessments. We removed assessments completed in less than five minutes and assessments with missing answers. We developed an initial list of skills and content areas covered in physics courses by coding learning objectives from courses using standards-based grading. We focused on standards-based grading because instructors explicitly list the learning objectives students should master during the course [Beatty, 2013]. Initially, we coded a wide range of skills based on our analysis from these RBAs [Madsen\u00a0et\u00a0al., 2017]. From this coding, we aggregated the broader set of skills into five initial skills: apply vectors, conceptual understanding, algebra, visualizations, and definitions. We discarded definitions as a skill because it represents a memorized response that the other skills covered in greater depth by asking students to apply or understand the concept. And, we are not aware of RBAs for introductory physics that ask definition questions. Table 2 lists the four skills and our definitions of the skills. We initially coded content areas at a finer grain size to match the standards-based grading learning objectives, e.g., kinematics was split into four areas across two variables: 1D or 2D and constant velocity or constant acceleration. These content areas, however, were too fine grained to develop an assessment with a reasonable length for students to complete it or a realistic size item bank. Therefore, we simplified the content codes: i.e. kinematics, forces, energy, and momentum for these three RBAs. Table 9 lists the four content areas covered by these three RBAs and their definitions. Based on this initial set of codes we developed, we coded each item for its relevant skills and content areas. Our coding team included three researchers with backgrounds in physics and teaching physics. Each item was independently coded by at least two team members. The three coders then compared the coding for the items and reached a consensus on all items. This consensus coding of the three assessments provided one of the inputs into the DINA analysis. Researchers commonly use the DINA model for cognitive diagnostic (CD) models [Haertel, 1984; Junker\u00a0and\u00a0Sijtsma, 2001], which aims to identify students\u2019 strengths and weaknesses across skills measured by an assessment. On a CD assessment, correctly answering each test item requires the mastery of different skills. The relationship between each item and its required skills is denoted by a Q-matrix [Tatsuoka, 2012], which is shown in Fig. 1. The Q-matrix is a J\u00d7K\ud835\udc3d\ud835\udc3eJ\\times Kitalic_J \u00d7 italic_K matrix, and qj\u2062k=1subscript\ud835\udc5e\ud835\udc57\ud835\udc581q_{jk}=1italic_q start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT = 1 indicates the correct answer on the j\ud835\udc57jitalic_jth items requires the mastery of the k\ud835\udc58kitalic_kth skill, and 00 otherwise. The DINA model assumes that an examinee has to master all the required skills for the item to answer an item correctly; lacking one or more of the required skills would lead to an incorrect response [de\u00a0la Torre, 2009]. The model, however, allows noise in the examinee\u2019s item-answering process. Some examinees may not answer certain items correctly even if they have mastered all the required skills (\u201cslipping\u201d), while some examinees may answer some items correctly even though they have not mastered at least one of the required skills (\u201cguessing\u201d). The probability of examinee i\ud835\udc56iitalic_i answering item j\ud835\udc57jitalic_j correctly is given by where the skill mastery vector \u03b1i=(\u03b1i\u20621,\u03b1i\u20622,\u2026,\u03b1i\u2062k)subscript\ud835\udefc\ud835\udc56subscript\ud835\udefc\ud835\udc561subscript\ud835\udefc\ud835\udc562\u2026subscript\ud835\udefc\ud835\udc56\ud835\udc58\\alpha_{i}=(\\alpha_{i1},\\alpha_{i2},...,\\alpha_{ik})italic_\u03b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = ( italic_\u03b1 start_POSTSUBSCRIPT italic_i 1 end_POSTSUBSCRIPT , italic_\u03b1 start_POSTSUBSCRIPT italic_i 2 end_POSTSUBSCRIPT , \u2026 , italic_\u03b1 start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT ), and \u03b1i\u2062k=1subscript\ud835\udefc\ud835\udc56\ud835\udc581\\alpha_{ik}=1italic_\u03b1 start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT = 1 indicates the i\ud835\udc56iitalic_ith examinee masters the k\ud835\udc58kitalic_kth skill, \u03b1i\u2062k=0subscript\ud835\udefc\ud835\udc56\ud835\udc580\\alpha_{ik}=0italic_\u03b1 start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT = 0 otherwise; sjsubscript\ud835\udc60\ud835\udc57s_{j}italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is the slipping parameter representing the probability of answering the j\ud835\udc57jitalic_jth item incorrectly when an examinee has mastered all the required skills; gjsubscript\ud835\udc54\ud835\udc57g_{j}italic_g start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is the guessing parameter representing the probability of answering the j\ud835\udc57jitalic_jth item correctly when an examinee has not mastered all the required skills; \u03b7i\u2062jsubscript\ud835\udf02\ud835\udc56\ud835\udc57\\eta_{ij}italic_\u03b7 start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT indicates whether the examinee has mastered all required skills or not, and it can be calculated as follows: \u03b7i\u2062j=1subscript\ud835\udf02\ud835\udc56\ud835\udc571\\eta_{ij}=1italic_\u03b7 start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 1 indicates all required skills have been mastered, and 00 otherwise. In this study, we used DINA to analyze students\u2019 response data for each of the three RBAs to further refine our item codes and calibrate all items\u2019 slipping and guessing parameters. DINA analyses also generated skill mastery profiles for each student, which were not the focus of the research question in this paper. These psychometric analyses were implemented using the G-DINA package [Ma\u00a0and\u00a0de\u00a0la Torre, 2020] in the R programming environment. RMSEA2 and SRMSR were used to assess the degree of the model-data fit. RMSEA2 is the root mean square error approximation (RMSEA) based on the M2 statistic using the univariate and bivariate margins. RMSEA2 ranges from 0 to 1, and RMSEA2 <0.06absent0.06<0.06< 0.06 indicates good fit [Hooper\u00a0et\u00a0al., 2008; Hu\u00a0and\u00a0Bentler, 1999]. SRMSR, the standardized root mean squared residual, has acceptable values ranging between 0 and 0.8. Models with SRMSR <0.05absent0.05<0.05< 0.05 can be viewed as a well-fitted model, and models with SRMSR <0.08absent0.08<0.08< 0.08 are typically considered acceptable models [Maydeu-Olivares\u00a0and\u00a0Joe, 2014; Hu\u00a0and\u00a0Bentler, 1999; Jang, 2018]. Additionally, the skill-level classification accuracy informed the reliability and validity of the CD assessment. Classification accuracy is the percentage of agreement between the observed and expected proportions of examinees in each of the skills. The appropriateness of the Q-matrix plays an important role in CD assessments and affects the degree of model-data fit. Inappropriate specifications in the Q-matrix may lead to poor model fit and thus may produce incorrect skill diagnosis results for students. Therefore, we need a Q-matrix validation step in the study. The input Q-matrices for the DINA analysis for each RBA were constructed by content experts, as detailed in the prior section. In the Q-matrix validation step, the DINA analysis further examined each Q-matrix to identify potential misspecifications in the Q-matrices. The analysis fitted the DINA model to students\u2019 post-assessment responses using the Q-matrix constructed by the three coders. The Proportion of Variance Accounted For method [de\u00a0la Torre\u00a0and\u00a0Chiu, 2016] measured the relationships between the items and the skills specified in the provided Q-matrix. The analysis of the empirical response data suggested changes to the provided Q-matrix, which the three coders reviewed. The coders assessed the suggested modifications for how well they aligned with the definitions and revised the Q-matrix when they agreed with the suggested changes. The refined Q-matrix was then used in subsequent CD Modeling analyses. Table 5 presents a summary detailing the frequency of data-driven modifications suggested, adopted by the coders, and the rate of adoption for each of the three assessments under study. The FCI, for example, had 11 proposed changes of the 90 possible changes (30 items each with three possible skills), and the coders adopted seven of these suggestions. For instance, conceptual relationships skill was initially not considered essential for item 7. However, empirical response data suggested that this skill was required to answer item 7 correctly. Post-review, the expert panel endorsed this modification; thereby, the value in the Q-matrix corresponding to the intersection of item 7 and conceptual relationships was changed from \u201c0\u201d to \u201c1\u201d. Overall, only 8.5% of the codings (26 of 306) were identified for re-examination by this analysis. Of the 26 proposed changes, 13 were adopted across the three assessments, yielding an overall adoption rate of 50%. This iterative approach to informing the validity of the Q-matrix avoids overreliance on either expert opinion or empirical data, harmonizing both information sources to enhance the accuracy of the Q-matrix. Table 11 shows the final coding for each RBA item across the four content areas and four skills. This section addresses the research question by detailing the skills and content areas measured by the three assessments, as detailed in Table 4. First, we present which of the four skills the items on the three assessments measured and the number of skills the items measured. The specific models relating the items to the four skills are presented in the Appendix, see Tables 12, 13, and 14. Second, we show the content areas covered in the three assessments. Finally, we examine the skills across content areas. This structure highlights the various aspects of the items in these three assessments. FCI - The FCI assessed three skills (Fig. 2). Eighteen items assessed apply vectors skill, 17 items assessed conceptual relationships skill, 1 item assessed visualizations skill, and 0 items assessed algebra skill. The majority of items assessed a single skill. Twenty-four items (80%) assessed a single skill, 6 items (20%) assessed two skills, and 0 items assessed three skills (Table 6). FMCE - The FMCE assessed the same three skills as the FCI (Fig. 2). All 47 items assessed conceptual relationships skill, 19 items assessed the visualizations skill, 18 items assessed apply vectors skill, and 0 items assessed algebra skill. The majority of items assessed multiple skills. Thirteen items (28%) assessed a single skill, while 31 items (66%) assessed two skills, and 3 items (6%) assessed three skills (Table 6). EMCS - Similar to the FCI and FMCE, the EMCS assessed the apply vectors and conceptual relationships skills (see Fig. 2 and Table 4). The EMCS differed in that it included 2 items that assessed the algebra skill. Of the 25 EMCS items, 23 assessed the conceptual relationships skill (with items 3 and 13 both coded for energy and momentum), 5 items assessed the apply vectors skill, 2 items assessed the algebra skill, and 0 items assessed the visualizations skill. The EMCS was the only assessment with items assessing the algebra skill. The majority of items assessed a single skill. Twenty items (80%) assessed a single skill, 5 items (20%) assessed two skills, and 0 items assessed three skills (Table 6). The analysis fitted the DINA model with the refined Q-matrix to the response data. Table 7 outlines the model fit statistics for each assessment. According to the established criteria [Hu\u00a0and\u00a0Bentler, 1999; Bentler, 1990], the model demonstrated satisfactory fit (RMSEA2 <0.05absent0.05<0.05< 0.05, SRMSR <0.07absent0.07<0.07< 0.07) for FCI and EMCS, whereas the fit for FMCE was unsatisfactory (RMSEA2 = 0.090, SRMSR = 0.110). These results suggest that the model adequately represents the underlying structure of data for FCI and EMCS but might not capture the latent structure of FMCE well. Table 8 presents the classification accuracy [Wang\u00a0et\u00a0al., 2015] for each skill across the three assessments. As discussed in the skills section, not all of the skills were measured by each of the assessments; 9 of 12 were possible. For those skills that were measured, 7 of the 9 classification accuracies were high (over 0.9). The classification accuracy of visualizations for the FCI (0.79) and algebra for the EMCS (0.63) was notably lower. The lower classification accuracy reflects the lack of items measuring these skills (Fig. 2). FCI - The FCI assessed two content areas (Fig. 2 & Table 9). Eighteen items assessed forces, 12 items assessed kinematics, and 0 items assessed energy and momentum. All 30 items (100%) assessed a single content area (Table 10). FMCE - The FMCE assessed three content areas (Fig. 2 & Table 9). Thirty-one items assessed forces, 12 items assessed kinematics, 4 items assessed energy, and 0 items assessed momentum. Similar to FCI, all 47 (100%) items assessed a single content area (Table 10). EMCS - The EMCS assessed two content areas (Fig. 2 & Table 9). Fifteen items assessed energy, 12 items assessed momentum, and 0 items assessed kinematics and forces. Unlike the FCI and the FMCE, 23 items assessed a single content area, and 2 items assessed two content areas (8%) (Table 10). The distribution of skills assessed was not consistent across content areas (Fig. 3 and Table 11). This inconsistency follows from several aspects of the three RBAs. The FCI and FMCE did not measure the algebra skill. The EMCS did not measure the visualizations skill. The majority of items came from the FMCE and FCI, which focused more on forces than on kinematics. Across the three RBAs, very few items measured the apply vectors skill for energy (1) and momentum (4), even though applying vectors is central to momentum. And, very few items measured the visualizations skills for energy (2) and momentum (0). This study supports the development of the MCD within the ECD framework by focusing on the student and evidence models (Fig. 1). For the student models, the three RBAs measured all four skills, though to different extents, across the four content areas. For the evidence models, the three RBAs assessed most of the skills with high classification accuracies. These results indicate that the combined items from the three RBAs will provide an adequate initial item bank for the further development of the MCD. The three RBAs - FCI, FMCE, and EMCS - each included items that assessed three of the four skills across two to three content areas. The three RBAs all included a majority of items that assessed the conceptual relationships skill, which follows from their conceptual focus. In addition to measuring the conceptual relationships skill, all three RBAs also included sufficient items to assess the apply vectors skill with high classification accuracies. The FMCE included sufficient items to assess the visualizations skill. These results, in addition to other RBAs on visualizations and vectors specifically Zavala\u00a0et\u00a0al. [2017]; Barniol\u00a0and\u00a0Zavala [2014], indicate that these three skills are common learning objectives of physics instruction. The three RBAs did not include enough items assessing the algebra skill to inform the extent to which that skill fits within our student models. This likely follows from these RBAs being conceptual assessments developed to refocus physics instruction from memorization and application of equations to a deeper understanding of the conceptual relationships linking the physical world. Applying and manipulating equations was, however, a common learning objective in the standards-based grading rubrics we used to develop our student models. Many instructors and students may want formative assessments on algebra skill to support their teaching and learning. Most items in both the FCI and EMCS required mastery of a single skill, while the majority of items in the FMCE needed multiple skills. Requiring multiple skills to answer an item correctly can have two effects. First, requiring mastery of more than one skill typically makes the items more difficult to answer. This is consistent with prior findings that the FMCE is more difficult than the FCI [Thornton\u00a0et\u00a0al., 2009]. Second, multi-skill items can provide different information than a single-skill item, and item banks should include a mix of single- and multi-skill items to pick from to maximize the information generated by each item a student answers. Combining the three assessments into a single test bank provides a more even mix of single- and multi-skill items than any of these three RBAs. The DINA model fit the FCI and EMCS well, but the fit for the FMCE was marginal. The length and difficulty of the FMCE may have driven this marginal fit. The large number of items assessing multiple skills may have also been a factor. Post-hoc analyses to test these possibilities indicated that they were not major contributors to the marginal model fit of the FMCE. The additional analyses included generalized DINA models, DINA models of the first and second half of the FMCE, and separate DINA models of the students from calculus- and algebra-based physics courses. The marginal fit likely follows from our post-hoc application of our skill model to the FMCE. This model fits two assessments well, and one assessment marginally indicates that the student models of the skills are broadly applicable to physics learning and items from these three assessments can form the initial item bank of a cognitive diagnostic. The three RBAs had classification accuracy (above 0.9) for the apply vectors and conceptual relationships skills, as shown in Table 10. This makes sense for the FMCE and FCI, given that they each had at least 17 items for each of the apply vectors and conceptual relationships skills (Fig. 2). Although the EMCS only had 5 items measuring apply vectors, the classification accuracy was still 0.94. This finding indicates that a relatively small number of items can still accurately assess a skill. The number of items measuring algebra skills on the EMCS (2) and visualization skills in FCI (1) were not sufficient to generate useful classification accuracies (<0.8). Combining the three assessments into a single-item bank should provide sufficient coverage of apply vectors, conceptual relationships, and visualization skills, but it will not offer enough items to assess the algebra skill. Additionally, the combined item bank will require additional items to assess the visualization and apply vectors skills in the content areas of energy and momentum. The DINA analysis assumes students have mastered each of the skills assessed by an item to answer that item correctly. A less restrictive analysis, such as generalized DINA, that assumes some questions can be answered by only mastering a subset of skills or by students who have only partially mastered skills may provide a better fit. The three RBAs constrained the skills that the analyses could test. This was an obvious issue for the algebra skill, which was only assessed by two items on one assessment. Physics instructors also likely value and teach other skills that they would want to assess, such as the ability to decompose complex problems into smaller pieces to solve as assessed by the Mechanics Reasoning Inventory [Pawl\u00a0et\u00a0al., 2012]). The analysis does not test the extent to which the items and assessments act differently across populations, e.g., gender, race, or type of physics course. Mixed evidence exists about the measurement invariance [Morley\u00a0et\u00a0al., 2023] and differential item functioning [Traxler\u00a0et\u00a0al., 2018; Henderson\u00a0et\u00a0al., 2018] of the FCI and FMCE. The combination of items from these three assessments administered through a cognitive diagnostic at a large scale will provide a dataset to identify and understand item differences and potential item biases between groups of students. Combining 102 items from three RBAs into a single item bank to create a CD-CAT provides a solid foundation for building the MCD. The limited number of items assessing the algebra skill and the apply vectors and visualizations skills for energy and momentum point to these as specific areas for improvement of the item bank. Delivering the MCD online, fortunately, has the advantage of allowing for the inclusion of new items under development to fill in gaps in the item bank. The combined item bank will also produce better classification accuracy by having more items to draw on. The high classification accuracy (0.941) for the apply vectors skill on the EMCS, however, indicates that even just 5 items can provide a high classification accuracy. This result indicates that shorter assessments may allow for high levels of classification accuracy for skills while also using fewer questions. Using LASSO as the delivery system for the MCD provides instructors with an adaptive tool to assess students\u2019 skills and knowledge across content areas or in specific content areas. In particular, using a cognitive diagnostic for the assembly model allows instructors to design formative assessments by choosing the skills, and content areas to measure. Integrating guidelines and constraints on test lengths will help instructors design accurate assessments of those skills and content areas. The cognitive diagnostic also allows flexible timing; instructors can design pre or post-tests that cover many skills and content areas or weekly tests focused on a few skills for one content area. For researchers, the MCD will collect longitudinal data across skills and content areas. This data can inform the development of learning progressions or the transfer of skills across content areas, such as applying vectors in mathematical, kinematics, and momentum content areas. Developing more items that cover multiple content areas can inform how physics content interacts, which current RBAs do not assess. Because LASSO is free for instructors to use, the data will likely also represent a broader cross-section of physics learners [Nissen\u00a0et\u00a0al., 2021] than physics education research has historically included [Kanim\u00a0and\u00a0Cid, 2020]. This research was made possible through the financial support provided by National Science Foundation Grants No. 2141847. We extend our appreciation to LASSO for their support in both collecting and sharing data for this research. The appendix includes the Q-matrices for the three assessments we used to conduct the DINA model analysis."
    }
]